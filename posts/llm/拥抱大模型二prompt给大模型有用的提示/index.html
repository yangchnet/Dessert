<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>拥抱大模型（二）：Prompt，给大模型有用的提示 | Linote</title><meta name=keywords content="prompt engine"><meta name=description content="极客时间《LangChain实战课》学习笔记
 构建prompt的原则 原则（吴恩达版）
 写出清晰而具体的提示 给模型思考的时间  原则（OpenAI版）
 写清晰的指示 给模型提供参考（也就是示例） 将复杂任务拆分成子任务 给 GPT 时间思考 使用外部工具 反复迭代问题   prompt的基本结构  instruction（指令）：告诉大模型要做什么，一个常见且有效的例子是，告诉大模型“你是一个XX专家” context（上下文）：充当模型的额外知识来源，这些知识可以从矢量数据库中得来或通过其他方式拉入 prompt input （提示输入）：具体的问题或大模型做的具体事情 output indicator（标记要生成的文本的开始）：用一个明显的提示词让大模型开始回答，这一部分不是必须的  使用langchain构建prompt
from langchain import PromptTemplate template = &#34;&#34;&#34;\ 你是业务咨询顾问。 你给一个销售{product}的电商公司，起一个好的名字？ &#34;&#34;&#34; prompt = PromptTemplate.from_template(template) print(prompt.format(product=&#34;鲜花&#34;)) prompt = PromptTemplate( input_variables=[&#34;product&#34;, &#34;market&#34;], template=&#34;你是业务咨询顾问。对于一个面向{market}市场的，专注于销售{product}的公司，你会推荐哪个名字？&#34; ) print(prompt.format(product=&#34;鲜花&#34;, market=&#34;高端&#34;)) 二者效果相同构建chat prompt对于像ChatGPT这种聊天模型，langchain提供了ChatPromptTemplate，其中有多种角色类型:
import openai openai.ChatCompletion.create( model=&#34;gpt-3.5-turbo&#34;, messages=[ {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful assistant.&#34;}, {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Who won the world series in 2020?"><meta name=author content="李昌"><link rel=canonical href=http://yangchnet.github.io/Dessert/posts/llm/%E6%8B%A5%E6%8A%B1%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%8Cprompt%E7%BB%99%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9C%89%E7%94%A8%E7%9A%84%E6%8F%90%E7%A4%BA/><link crossorigin=anonymous href=/Dessert/assets/css/stylesheet.min.7e145c6c051b0f6645e8d84c6faed7fed1214bbe82c223c2c19815bee6ee8403.css integrity="sha256-fhRcbAUbD2ZF6NhMb67X/tEhS76CwiPCwZgVvubuhAM=" rel="preload stylesheet" as=style><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Fira+Mono&display=swap" rel=stylesheet><script defer crossorigin=anonymous src=/Dessert/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon32.ico><link rel=apple-touch-icon href=http://yangchnet.github.io/Dessert/apple-touch-icon.png><link rel=mask-icon href=http://yangchnet.github.io/Dessert/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.81.0"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="拥抱大模型（二）：Prompt，给大模型有用的提示"><meta property="og:description" content="极客时间《LangChain实战课》学习笔记
 构建prompt的原则 原则（吴恩达版）
 写出清晰而具体的提示 给模型思考的时间  原则（OpenAI版）
 写清晰的指示 给模型提供参考（也就是示例） 将复杂任务拆分成子任务 给 GPT 时间思考 使用外部工具 反复迭代问题   prompt的基本结构  instruction（指令）：告诉大模型要做什么，一个常见且有效的例子是，告诉大模型“你是一个XX专家” context（上下文）：充当模型的额外知识来源，这些知识可以从矢量数据库中得来或通过其他方式拉入 prompt input （提示输入）：具体的问题或大模型做的具体事情 output indicator（标记要生成的文本的开始）：用一个明显的提示词让大模型开始回答，这一部分不是必须的  使用langchain构建prompt
from langchain import PromptTemplate template = &#34;&#34;&#34;\ 你是业务咨询顾问。 你给一个销售{product}的电商公司，起一个好的名字？ &#34;&#34;&#34; prompt = PromptTemplate.from_template(template) print(prompt.format(product=&#34;鲜花&#34;)) prompt = PromptTemplate( input_variables=[&#34;product&#34;, &#34;market&#34;], template=&#34;你是业务咨询顾问。对于一个面向{market}市场的，专注于销售{product}的公司，你会推荐哪个名字？&#34; ) print(prompt.format(product=&#34;鲜花&#34;, market=&#34;高端&#34;)) 二者效果相同构建chat prompt对于像ChatGPT这种聊天模型，langchain提供了ChatPromptTemplate，其中有多种角色类型:
import openai openai.ChatCompletion.create( model=&#34;gpt-3.5-turbo&#34;, messages=[ {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful assistant.&#34;}, {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Who won the world series in 2020?"><meta property="og:type" content="article"><meta property="og:url" content="http://yangchnet.github.io/Dessert/posts/llm/%E6%8B%A5%E6%8A%B1%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%8Cprompt%E7%BB%99%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9C%89%E7%94%A8%E7%9A%84%E6%8F%90%E7%A4%BA/"><meta property="og:image" content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-02-04T00:00:00+00:00"><meta property="article:modified_time" content="2024-02-04T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta name=twitter:title content="拥抱大模型（二）：Prompt，给大模型有用的提示"><meta name=twitter:description content="极客时间《LangChain实战课》学习笔记
 构建prompt的原则 原则（吴恩达版）
 写出清晰而具体的提示 给模型思考的时间  原则（OpenAI版）
 写清晰的指示 给模型提供参考（也就是示例） 将复杂任务拆分成子任务 给 GPT 时间思考 使用外部工具 反复迭代问题   prompt的基本结构  instruction（指令）：告诉大模型要做什么，一个常见且有效的例子是，告诉大模型“你是一个XX专家” context（上下文）：充当模型的额外知识来源，这些知识可以从矢量数据库中得来或通过其他方式拉入 prompt input （提示输入）：具体的问题或大模型做的具体事情 output indicator（标记要生成的文本的开始）：用一个明显的提示词让大模型开始回答，这一部分不是必须的  使用langchain构建prompt
from langchain import PromptTemplate template = &#34;&#34;&#34;\ 你是业务咨询顾问。 你给一个销售{product}的电商公司，起一个好的名字？ &#34;&#34;&#34; prompt = PromptTemplate.from_template(template) print(prompt.format(product=&#34;鲜花&#34;)) prompt = PromptTemplate( input_variables=[&#34;product&#34;, &#34;market&#34;], template=&#34;你是业务咨询顾问。对于一个面向{market}市场的，专注于销售{product}的公司，你会推荐哪个名字？&#34; ) print(prompt.format(product=&#34;鲜花&#34;, market=&#34;高端&#34;)) 二者效果相同构建chat prompt对于像ChatGPT这种聊天模型，langchain提供了ChatPromptTemplate，其中有多种角色类型:
import openai openai.ChatCompletion.create( model=&#34;gpt-3.5-turbo&#34;, messages=[ {&#34;role&#34;: &#34;system&#34;, &#34;content&#34;: &#34;You are a helpful assistant.&#34;}, {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;Who won the world series in 2020?"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"http://yangchnet.github.io/Dessert/posts/"},{"@type":"ListItem","position":3,"name":"拥抱大模型（二）：Prompt，给大模型有用的提示","item":"http://yangchnet.github.io/Dessert/posts/llm/%E6%8B%A5%E6%8A%B1%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%8Cprompt%E7%BB%99%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9C%89%E7%94%A8%E7%9A%84%E6%8F%90%E7%A4%BA/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"拥抱大模型（二）：Prompt，给大模型有用的提示","name":"拥抱大模型（二）：Prompt，给大模型有用的提示","description":"极客时间《LangChain实战课》学习笔记\n 构建prompt的原则 原则（吴恩达版）\n 写出清晰而具体的提示 给模型思考的时间  原则（OpenAI版）\n 写清晰的指示 给模型提供参考（也就是示例） 将复杂任务拆分成子任务 给 GPT 时间思考 使用外部工具 反复迭代问题   prompt的基本结构  instruction（指令）：告诉大模型要做什么，一个常见且有效的例子是，告诉大模型“你是一个XX专家” context（上下文）：充当模型的额外知识来源，这些知识可以从矢量数据库中得来或通过其他方式拉入 prompt input （提示输入）：具体的问题或大模型做的具体事情 output indicator（标记要生成的文本的开始）：用一个明显的提示词让大模型开始回答，这一部分不是必须的  使用langchain构建prompt\nfrom langchain import PromptTemplate template = \u0026#34;\u0026#34;\u0026#34;\\ 你是业务咨询顾问。 你给一个销售{product}的电商公司，起一个好的名字？ \u0026#34;\u0026#34;\u0026#34; prompt = PromptTemplate.from_template(template) print(prompt.format(product=\u0026#34;鲜花\u0026#34;)) prompt = PromptTemplate( input_variables=[\u0026#34;product\u0026#34;, \u0026#34;market\u0026#34;], template=\u0026#34;你是业务咨询顾问。对于一个面向{market}市场的，专注于销售{product}的公司，你会推荐哪个名字？\u0026#34; ) print(prompt.format(product=\u0026#34;鲜花\u0026#34;, market=\u0026#34;高端\u0026#34;)) 二者效果相同构建chat prompt对于像ChatGPT这种聊天模型，langchain提供了ChatPromptTemplate，其中有多种角色类型:\nimport openai openai.ChatCompletion.create( model=\u0026#34;gpt-3.5-turbo\u0026#34;, messages=[ {\u0026#34;role\u0026#34;: \u0026#34;system\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;You are a helpful assistant.\u0026#34;}, {\u0026#34;role\u0026#34;: \u0026#34;user\u0026#34;, \u0026#34;content\u0026#34;: \u0026#34;Who won the world series in 2020?","keywords":["prompt engine"],"articleBody":" 极客时间《LangChain实战课》学习笔记\n 构建prompt的原则 原则（吴恩达版）\n 写出清晰而具体的提示 给模型思考的时间  原则（OpenAI版）\n 写清晰的指示 给模型提供参考（也就是示例） 将复杂任务拆分成子任务 给 GPT 时间思考 使用外部工具 反复迭代问题   prompt的基本结构  instruction（指令）：告诉大模型要做什么，一个常见且有效的例子是，告诉大模型“你是一个XX专家” context（上下文）：充当模型的额外知识来源，这些知识可以从矢量数据库中得来或通过其他方式拉入 prompt input （提示输入）：具体的问题或大模型做的具体事情 output indicator（标记要生成的文本的开始）：用一个明显的提示词让大模型开始回答，这一部分不是必须的  使用langchain构建prompt\nfrom langchain import PromptTemplate template = \"\"\"\\ 你是业务咨询顾问。 你给一个销售{product}的电商公司，起一个好的名字？ \"\"\" prompt = PromptTemplate.from_template(template) print(prompt.format(product=\"鲜花\")) prompt = PromptTemplate( input_variables=[\"product\", \"market\"], template=\"你是业务咨询顾问。对于一个面向{market}市场的，专注于销售{product}的公司，你会推荐哪个名字？\" ) print(prompt.format(product=\"鲜花\", market=\"高端\")) 二者效果相同构建chat prompt对于像ChatGPT这种聊天模型，langchain提供了ChatPromptTemplate，其中有多种角色类型:\nimport openai openai.ChatCompletion.create( model=\"gpt-3.5-turbo\", messages=[ {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"}, {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers won the World Series in 2020.\"}, {\"role\": \"user\", \"content\": \"Where was it played?\"} ] )  system（系统消息，可选）：设置AI的行为，例如，你是一个客服 user（用户消息）：人类提出的问题 assistant（助理消息）：可以存储AI以前给出的响应，或在此处给出示例  # 导入聊天消息类模板 from langchain.prompts import ( ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, ) # 模板的构建 template=\"你是一位专业顾问，负责为专注于{product}的公司起名。\" system_message_prompt = SystemMessagePromptTemplate.from_template(template) human_template=\"公司主打产品是{product_detail}。\" human_message_prompt = HumanMessagePromptTemplate.from_template(human_template) prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt]) # 格式化提示消息生成提示 prompt = prompt_template.format_prompt(product=\"鲜花装饰\", product_detail=\"创新的鲜花设计。\").to_messages() # 下面调用模型，把提示传入模型，生成结果 import os os.environ[\"OPENAI_API_KEY\"] = '你的OpenAI Key' from langchain.chat_models import ChatOpenAI chat = ChatOpenAI() result = chat(prompt) print(result) 给LLM提供样本 根据给予模型样本的多少，可粗略分为Few-Shot ，One-Shot，Zero-Shot在 Few-Shot 学习设置中，模型会被给予几个示例，以帮助模型理解任务，并生成正确的响应。在One-Shot学习设置中，模型会被给予一个示例，以帮助模型理解任务，并生成正确的响应。在 Zero-Shot 学习设置中，模型只根据任务的描述生成响应，不需要任何示例。\n# 1. 创建一些示例 samples = [ { \"flower_type\": \"玫瑰\", \"occasion\": \"爱情\", \"ad_copy\": \"玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。\" }, { \"flower_type\": \"康乃馨\", \"occasion\": \"母亲节\", \"ad_copy\": \"康乃馨代表着母爱的纯洁与伟大，是母亲节赠送给母亲的完美礼物。\" }, { \"flower_type\": \"百合\", \"occasion\": \"庆祝\", \"ad_copy\": \"百合象征着纯洁与高雅，是你庆祝特殊时刻的理想选择。\" }, { \"flower_type\": \"向日葵\", \"occasion\": \"鼓励\", \"ad_copy\": \"向日葵象征着坚韧和乐观，是你鼓励亲朋好友的最好方式。\" } ] # 2. 创建一个提示模板 from langchain.prompts.prompt import PromptTemplate template=\"鲜花类型: {flower_type}\\n场合: {occasion}\\n文案: {ad_copy}\" prompt_sample = PromptTemplate(input_variables=[\"flower_type\", \"occasion\", \"ad_copy\"], template=template) print(prompt_sample.format(**samples[0])) # 3. 创建一个FewShotPromptTemplate对象 from langchain.prompts.few_shot import FewShotPromptTemplate prompt = FewShotPromptTemplate( examples=samples, example_prompt=prompt_sample, suffix=\"鲜花类型: {flower_type}\\n场合: {occasion}\", input_variables=[\"flower_type\", \"occasion\"] ) print(prompt.format(flower_type=\"野玫瑰\", occasion=\"爱情\")) # 4. 把提示传递给大模型 import os os.environ[\"OPENAI_API_KEY\"] = '你的Open AI Key' from langchain.llms import OpenAI model = OpenAI(model_name='text-davinci-003') result = model(prompt.format(flower_type=\"野玫瑰\", occasion=\"爱情\")) print(result) 如果你给出的示例过多，可使用示例选择器来进行筛选。 Chain Of Thought (COT) 思维链  如果生成一系列的中间推理步骤，就能够显著提高大型语言模型进行复杂推理的能力。\n 一个Few-Shot的COT示例，在示例中给出了思考过程# 设置环境变量和API密钥 import os os.environ[\"OPENAI_API_KEY\"] = '你的OpenAI API Key' # 创建聊天模型 from langchain.chat_models import ChatOpenAI llm = ChatOpenAI(temperature=0) # 设定 AI 的角色和目标 role_template = \"你是一个为花店电商公司工作的AI助手, 你的目标是帮助客户根据他们的喜好做出明智的决定\" # CoT 的关键部分，AI 解释推理过程，并加入一些先前的对话示例（Few-Shot Learning） cot_template = \"\"\" 作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。 我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。 同时，我也会向客户解释我这样推荐的原因。 示例 1: 人类：我想找一种象征爱情的花。 AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。 示例 2: 人类：我想要一些独特和奇特的花。 AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。 \"\"\" from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate system_prompt_role = SystemMessagePromptTemplate.from_template(role_template) system_prompt_cot = SystemMessagePromptTemplate.from_template(cot_template) # 用户的询问 human_template = \"{human_input}\" human_prompt = HumanMessagePromptTemplate.from_template(human_template) # 将以上所有信息结合为一个聊天提示 chat_prompt = ChatPromptTemplate.from_messages([system_prompt_role, system_prompt_cot, human_prompt]) prompt = chat_prompt.format_prompt(human_input=\"我想为我的女朋友购买一些花。她喜欢粉色和紫色。你有什么建议吗?\").to_messages() # 接收用户的询问，返回回答结果 response = llm(prompt) print(response) Tree Of Thought(TOT) 思维树 ToT 是一种解决复杂问题的框架，它在需要多步骤推理的任务中，引导语言模型搜索一棵由连贯的语言序列（解决问题的中间步骤）组成的思维树，而不是简单地生成一个答案。ToT 框架的核心思想是：让模型生成和评估其思维的能力，并将其与搜索算法（如广度优先搜索和深度优先搜索）结合起来，进行系统性地探索和验证。ToT 框架为每个任务定义具体的思维步骤和每个步骤的候选项数量。例如，要解决一个数学推理任务，先把它分解为 3 个思维步骤，并为每个步骤提出多个方案，并保留最优的 5 个候选方案。然后在多条思维路径中搜寻最优的解决方案。这种方法的优势在于，模型可以通过观察和评估其自身的思维过程，更好地解决问题，而不仅仅是基于输入生成输出。这对于需要深度推理的复杂任务非常有用。此外，通过引入强化学习、集束搜索等技术，可以进一步提高搜索策略的性能，并让模型在解决新问题或面临未知情况时有更好的表现。TOT的参考仓库：https://github.com/kyegomez/tree-of-thoughts\n","wordCount":"352","inLanguage":"en","datePublished":"2024-02-04T00:00:00Z","dateModified":"2024-02-04T00:00:00Z","author":{"@type":"Person","name":"李昌"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://yangchnet.github.io/Dessert/posts/llm/%E6%8B%A5%E6%8A%B1%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%8Cprompt%E7%BB%99%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%9C%89%E7%94%A8%E7%9A%84%E6%8F%90%E7%A4%BA/"},"publisher":{"@type":"Organization","name":"Linote","logo":{"@type":"ImageObject","url":"https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><header class=header><nav class=nav><div class=logo><a href=http://yangchnet.github.io/Dessert accesskey=h title="Linote (Alt + H)">Linote</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=http://yangchnet.github.io/Dessert/archives/ title=存档><span>存档</span></a></li><li><a href=http://yangchnet.github.io/Dessert/categories/ title=分类><span>分类</span></a></li><li><a href=http://yangchnet.github.io/Dessert/search/ title=搜索><span>搜索</span></a></li><li><a href=http://yangchnet.github.io/Dessert/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://yangchnet.github.io/Dessert>Home</a>&nbsp;»&nbsp;<a href=http://yangchnet.github.io/Dessert/posts/>Posts</a></div><h1 class=post-title>拥抱大模型（二）：Prompt，给大模型有用的提示</h1><div class=post-meta><span title="2024-02-04 00:00:00 +0000 UTC">February 4, 2024</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;李昌</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e6%9e%84%e5%bb%baprompt%e7%9a%84%e5%8e%9f%e5%88%99 aria-label=构建prompt的原则>构建prompt的原则</a></li><li><a href=#prompt%e7%9a%84%e5%9f%ba%e6%9c%ac%e7%bb%93%e6%9e%84 aria-label=prompt的基本结构>prompt的基本结构</a></li><li><a href=#%e7%bb%99llm%e6%8f%90%e4%be%9b%e6%a0%b7%e6%9c%ac aria-label=给LLM提供样本>给LLM提供样本</a></li><li><a href=#chain-of-thought-cot-%e6%80%9d%e7%bb%b4%e9%93%be aria-label="Chain Of Thought (COT) 思维链">Chain Of Thought (COT) 思维链</a></li><li><a href=#tree-of-thoughttot-%e6%80%9d%e7%bb%b4%e6%a0%91 aria-label="Tree Of Thought(TOT) 思维树">Tree Of Thought(TOT) 思维树</a></li></ul></div></details></div><div class=post-content><blockquote><p>极客时间《LangChain实战课》学习笔记</p></blockquote><h2 id=构建prompt的原则>构建prompt的原则<a hidden class=anchor aria-hidden=true href=#构建prompt的原则>#</a></h2><p>原则（吴恩达版）</p><ul><li>写出清晰而具体的提示</li><li>给模型思考的时间</li></ul><p>原则（OpenAI版）</p><ul><li>写清晰的指示</li><li>给模型提供参考（也就是示例）</li><li>将复杂任务拆分成子任务</li><li>给 GPT 时间思考</li><li>使用外部工具</li><li>反复迭代问题</li></ul><h2 id=prompt的基本结构>prompt的基本结构<a hidden class=anchor aria-hidden=true href=#prompt的基本结构>#</a></h2><p><img loading=lazy src=https://raw.githubusercontent.com/lich-Img/blogImg/master/img/20241220155210.png alt=20241220155210></p><ol><li>instruction（指令）：告诉大模型要做什么，一个常见且有效的例子是，告诉大模型“你是一个XX专家”</li><li>context（上下文）：充当模型的额外知识来源，这些知识可以从矢量数据库中得来或通过其他方式拉入</li><li>prompt input （提示输入）：具体的问题或大模型做的具体事情</li><li>output indicator（标记要生成的文本的开始）：用一个明显的提示词让大模型开始回答，这一部分不是必须的</li></ol><p><strong>使用langchain构建prompt</strong></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> langchain <span style=color:#f92672>import</span> PromptTemplate

template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;</span><span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span><span style=color:#e6db74>你是业务咨询顾问。
</span><span style=color:#e6db74>你给一个销售{product}的电商公司，起一个好的名字？
</span><span style=color:#e6db74>&#34;&#34;&#34;</span>
prompt <span style=color:#f92672>=</span> PromptTemplate<span style=color:#f92672>.</span>from_template(template)

<span style=color:#66d9ef>print</span>(prompt<span style=color:#f92672>.</span>format(product<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;鲜花&#34;</span>))
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>prompt <span style=color:#f92672>=</span> PromptTemplate(
    input_variables<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;product&#34;</span>, <span style=color:#e6db74>&#34;market&#34;</span>], 
    template<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你是业务咨询顾问。对于一个面向{market}市场的，专注于销售{product}的公司，你会推荐哪个名字？&#34;</span>
)
<span style=color:#66d9ef>print</span>(prompt<span style=color:#f92672>.</span>format(product<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;鲜花&#34;</span>, market<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;高端&#34;</span>))
</code></pre></div><p>二者效果相同<strong>构建chat prompt</strong>对于像ChatGPT这种聊天模型，langchain提供了ChatPromptTemplate，其中有多种角色类型:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> openai
openai<span style=color:#f92672>.</span>ChatCompletion<span style=color:#f92672>.</span>create(
  model<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;gpt-3.5-turbo&#34;</span>,
  messages<span style=color:#f92672>=</span>[
        {<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;system&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: <span style=color:#e6db74>&#34;You are a helpful assistant.&#34;</span>},
        {<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: <span style=color:#e6db74>&#34;Who won the world series in 2020?&#34;</span>},
        {<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;assistant&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: <span style=color:#e6db74>&#34;The Los Angeles Dodgers won the World Series in 2020.&#34;</span>},
        {<span style=color:#e6db74>&#34;role&#34;</span>: <span style=color:#e6db74>&#34;user&#34;</span>, <span style=color:#e6db74>&#34;content&#34;</span>: <span style=color:#e6db74>&#34;Where was it played?&#34;</span>}
    ]
)
</code></pre></div><ul><li>system（系统消息，可选）：设置AI的行为，例如，你是一个客服</li><li>user（用户消息）：人类提出的问题</li><li>assistant（助理消息）：可以存储AI以前给出的响应，或在此处给出示例</li></ul><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># 导入聊天消息类模板</span>
<span style=color:#f92672>from</span> langchain.prompts <span style=color:#f92672>import</span> (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
<span style=color:#75715e># 模板的构建</span>
template<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;你是一位专业顾问，负责为专注于{product}的公司起名。&#34;</span>
system_message_prompt <span style=color:#f92672>=</span> SystemMessagePromptTemplate<span style=color:#f92672>.</span>from_template(template)
human_template<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;公司主打产品是{product_detail}。&#34;</span>
human_message_prompt <span style=color:#f92672>=</span> HumanMessagePromptTemplate<span style=color:#f92672>.</span>from_template(human_template)
prompt_template <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_messages([system_message_prompt, human_message_prompt])

<span style=color:#75715e># 格式化提示消息生成提示</span>
prompt <span style=color:#f92672>=</span> prompt_template<span style=color:#f92672>.</span>format_prompt(product<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;鲜花装饰&#34;</span>, product_detail<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;创新的鲜花设计。&#34;</span>)<span style=color:#f92672>.</span>to_messages()

<span style=color:#75715e># 下面调用模型，把提示传入模型，生成结果</span>
<span style=color:#f92672>import</span> os
os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;OPENAI_API_KEY&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;你的OpenAI Key&#39;</span>
<span style=color:#f92672>from</span> langchain.chat_models <span style=color:#f92672>import</span> ChatOpenAI
chat <span style=color:#f92672>=</span> ChatOpenAI()
result <span style=color:#f92672>=</span> chat(prompt)
<span style=color:#66d9ef>print</span>(result)
</code></pre></div><p></p><h2 id=给llm提供样本>给LLM提供样本<a hidden class=anchor aria-hidden=true href=#给llm提供样本>#</a></h2><p>根据给予模型样本的多少，可粗略分为Few-Shot ，One-Shot，Zero-Shot在 Few-Shot 学习设置中，模型会被给予几个示例，以帮助模型理解任务，并生成正确的响应。在One-Shot学习设置中，模型会被给予一个示例，以帮助模型理解任务，并生成正确的响应。在 Zero-Shot 学习设置中，模型只根据任务的描述生成响应，不需要任何示例。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># 1. 创建一些示例</span>
samples <span style=color:#f92672>=</span> [
  {
    <span style=color:#e6db74>&#34;flower_type&#34;</span>: <span style=color:#e6db74>&#34;玫瑰&#34;</span>,
    <span style=color:#e6db74>&#34;occasion&#34;</span>: <span style=color:#e6db74>&#34;爱情&#34;</span>,
    <span style=color:#e6db74>&#34;ad_copy&#34;</span>: <span style=color:#e6db74>&#34;玫瑰，浪漫的象征，是你向心爱的人表达爱意的最佳选择。&#34;</span>
  },
  {
    <span style=color:#e6db74>&#34;flower_type&#34;</span>: <span style=color:#e6db74>&#34;康乃馨&#34;</span>,
    <span style=color:#e6db74>&#34;occasion&#34;</span>: <span style=color:#e6db74>&#34;母亲节&#34;</span>,
    <span style=color:#e6db74>&#34;ad_copy&#34;</span>: <span style=color:#e6db74>&#34;康乃馨代表着母爱的纯洁与伟大，是母亲节赠送给母亲的完美礼物。&#34;</span>
  },
  {
    <span style=color:#e6db74>&#34;flower_type&#34;</span>: <span style=color:#e6db74>&#34;百合&#34;</span>,
    <span style=color:#e6db74>&#34;occasion&#34;</span>: <span style=color:#e6db74>&#34;庆祝&#34;</span>,
    <span style=color:#e6db74>&#34;ad_copy&#34;</span>: <span style=color:#e6db74>&#34;百合象征着纯洁与高雅，是你庆祝特殊时刻的理想选择。&#34;</span>
  },
  {
    <span style=color:#e6db74>&#34;flower_type&#34;</span>: <span style=color:#e6db74>&#34;向日葵&#34;</span>,
    <span style=color:#e6db74>&#34;occasion&#34;</span>: <span style=color:#e6db74>&#34;鼓励&#34;</span>,
    <span style=color:#e6db74>&#34;ad_copy&#34;</span>: <span style=color:#e6db74>&#34;向日葵象征着坚韧和乐观，是你鼓励亲朋好友的最好方式。&#34;</span>
  }
]

<span style=color:#75715e># 2. 创建一个提示模板</span>
<span style=color:#f92672>from</span> langchain.prompts.prompt <span style=color:#f92672>import</span> PromptTemplate
template<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;鲜花类型: {flower_type}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>场合: {occasion}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>文案: {ad_copy}&#34;</span>
prompt_sample <span style=color:#f92672>=</span> PromptTemplate(input_variables<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;flower_type&#34;</span>, <span style=color:#e6db74>&#34;occasion&#34;</span>, <span style=color:#e6db74>&#34;ad_copy&#34;</span>], 
                               template<span style=color:#f92672>=</span>template)
<span style=color:#66d9ef>print</span>(prompt_sample<span style=color:#f92672>.</span>format(<span style=color:#f92672>**</span>samples[<span style=color:#ae81ff>0</span>]))

<span style=color:#75715e># 3. 创建一个FewShotPromptTemplate对象</span>
<span style=color:#f92672>from</span> langchain.prompts.few_shot <span style=color:#f92672>import</span> FewShotPromptTemplate
prompt <span style=color:#f92672>=</span> FewShotPromptTemplate(
    examples<span style=color:#f92672>=</span>samples,
    example_prompt<span style=color:#f92672>=</span>prompt_sample,
    suffix<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;鲜花类型: {flower_type}</span><span style=color:#ae81ff>\n</span><span style=color:#e6db74>场合: {occasion}&#34;</span>,
    input_variables<span style=color:#f92672>=</span>[<span style=color:#e6db74>&#34;flower_type&#34;</span>, <span style=color:#e6db74>&#34;occasion&#34;</span>]
)
<span style=color:#66d9ef>print</span>(prompt<span style=color:#f92672>.</span>format(flower_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;野玫瑰&#34;</span>, occasion<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;爱情&#34;</span>))

<span style=color:#75715e># 4. 把提示传递给大模型</span>
<span style=color:#f92672>import</span> os
os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;OPENAI_API_KEY&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;你的Open AI Key&#39;</span>
<span style=color:#f92672>from</span> langchain.llms <span style=color:#f92672>import</span> OpenAI
model <span style=color:#f92672>=</span> OpenAI(model_name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;text-davinci-003&#39;</span>)
result <span style=color:#f92672>=</span> model(prompt<span style=color:#f92672>.</span>format(flower_type<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;野玫瑰&#34;</span>, occasion<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;爱情&#34;</span>))
<span style=color:#66d9ef>print</span>(result)
</code></pre></div><p>如果你给出的示例过多，可使用<code>示例选择器</code>来进行筛选。</p><h2 id=chain-of-thought-cot-思维链>Chain Of Thought (COT) 思维链<a hidden class=anchor aria-hidden=true href=#chain-of-thought-cot-思维链>#</a></h2><blockquote><p>如果生成一系列的中间推理步骤，就能够显著提高大型语言模型进行复杂推理的能力。</p></blockquote><p>一个Few-Shot的COT示例，在示例中给出了思考过程
<img loading=lazy src=https://raw.githubusercontent.com/lich-Img/blogImg/master/img/20241220155243.png alt=20241220155243>
<img loading=lazy src=https://raw.githubusercontent.com/lich-Img/blogImg/master/img/20241220155314.png alt=20241220155314></p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#75715e># 设置环境变量和API密钥</span>
<span style=color:#f92672>import</span> os
os<span style=color:#f92672>.</span>environ[<span style=color:#e6db74>&#34;OPENAI_API_KEY&#34;</span>] <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;你的OpenAI API Key&#39;</span>

<span style=color:#75715e># 创建聊天模型</span>
<span style=color:#f92672>from</span> langchain.chat_models <span style=color:#f92672>import</span> ChatOpenAI
llm <span style=color:#f92672>=</span> ChatOpenAI(temperature<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)

<span style=color:#75715e># 设定 AI 的角色和目标</span>
role_template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;你是一个为花店电商公司工作的AI助手, 你的目标是帮助客户根据他们的喜好做出明智的决定&#34;</span>

<span style=color:#75715e># CoT 的关键部分，AI 解释推理过程，并加入一些先前的对话示例（Few-Shot Learning）</span>
cot_template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;&#34;&#34;
</span><span style=color:#e6db74>作为一个为花店电商公司工作的AI助手，我的目标是帮助客户根据他们的喜好做出明智的决定。 
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>我会按部就班的思考，先理解客户的需求，然后考虑各种鲜花的涵义，最后根据这个需求，给出我的推荐。
</span><span style=color:#e6db74>同时，我也会向客户解释我这样推荐的原因。
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>示例 1:
</span><span style=color:#e6db74>  人类：我想找一种象征爱情的花。
</span><span style=color:#e6db74>  AI：首先，我理解你正在寻找一种可以象征爱情的花。在许多文化中，红玫瑰被视为爱情的象征，这是因为它们的红色通常与热情和浓烈的感情联系在一起。因此，考虑到这一点，我会推荐红玫瑰。红玫瑰不仅能够象征爱情，同时也可以传达出强烈的感情，这是你在寻找的。
</span><span style=color:#e6db74>
</span><span style=color:#e6db74>示例 2:
</span><span style=color:#e6db74>  人类：我想要一些独特和奇特的花。
</span><span style=color:#e6db74>  AI：从你的需求中，我理解你想要的是独一无二和引人注目的花朵。兰花是一种非常独特并且颜色鲜艳的花，它们在世界上的许多地方都被视为奢侈品和美的象征。因此，我建议你考虑兰花。选择兰花可以满足你对独特和奇特的要求，而且，兰花的美丽和它们所代表的力量和奢侈也可能会吸引你。
</span><span style=color:#e6db74>&#34;&#34;&#34;</span>
<span style=color:#f92672>from</span> langchain.prompts <span style=color:#f92672>import</span> ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate
system_prompt_role <span style=color:#f92672>=</span> SystemMessagePromptTemplate<span style=color:#f92672>.</span>from_template(role_template)
system_prompt_cot <span style=color:#f92672>=</span> SystemMessagePromptTemplate<span style=color:#f92672>.</span>from_template(cot_template)

<span style=color:#75715e># 用户的询问</span>
human_template <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;{human_input}&#34;</span>
human_prompt <span style=color:#f92672>=</span> HumanMessagePromptTemplate<span style=color:#f92672>.</span>from_template(human_template)

<span style=color:#75715e># 将以上所有信息结合为一个聊天提示</span>
chat_prompt <span style=color:#f92672>=</span> ChatPromptTemplate<span style=color:#f92672>.</span>from_messages([system_prompt_role, system_prompt_cot, human_prompt])

prompt <span style=color:#f92672>=</span> chat_prompt<span style=color:#f92672>.</span>format_prompt(human_input<span style=color:#f92672>=</span><span style=color:#e6db74>&#34;我想为我的女朋友购买一些花。她喜欢粉色和紫色。你有什么建议吗?&#34;</span>)<span style=color:#f92672>.</span>to_messages()

<span style=color:#75715e># 接收用户的询问，返回回答结果</span>
response <span style=color:#f92672>=</span> llm(prompt)
<span style=color:#66d9ef>print</span>(response)
</code></pre></div><p></p><h2 id=tree-of-thoughttot-思维树>Tree Of Thought(TOT) 思维树<a hidden class=anchor aria-hidden=true href=#tree-of-thoughttot-思维树>#</a></h2><p>ToT 是一种解决复杂问题的框架，它在需要多步骤推理的任务中，引导语言模型搜索一棵由连贯的语言序列（解决问题的中间步骤）组成的思维树，而不是简单地生成一个答案。ToT 框架的核心思想是：让模型生成和评估其思维的能力，并将其与搜索算法（如广度优先搜索和深度优先搜索）结合起来，进行系统性地探索和验证。
<img loading=lazy src=https://raw.githubusercontent.com/lich-Img/blogImg/master/img/20241220155341.png alt=20241220155341>
ToT 框架为每个任务定义具体的思维步骤和每个步骤的候选项数量。例如，要解决一个数学推理任务，先把它分解为 3 个思维步骤，并为每个步骤提出多个方案，并保留最优的 5 个候选方案。然后在多条思维路径中搜寻最优的解决方案。这种方法的优势在于，模型可以通过观察和评估其自身的思维过程，更好地解决问题，而不仅仅是基于输入生成输出。这对于需要深度推理的复杂任务非常有用。此外，通过引入强化学习、集束搜索等技术，可以进一步提高搜索策略的性能，并让模型在解决新问题或面临未知情况时有更好的表现。TOT的参考仓库：<a href=https://github.com/kyegomez/tree-of-thoughts>https://github.com/kyegomez/tree-of-thoughts</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=http://yangchnet.github.io/Dessert/tags/prompt-engine/>prompt engine</a></li></ul><nav class=paginav><a class=prev href=http://yangchnet.github.io/Dessert/posts/llm/%E6%8B%A5%E6%8A%B1%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%B8%89outputparser%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA/><span class=title>« Prev Page</span><br><span>拥抱大模型（三）：OutputParser，格式化输出</span></a>
<a class=next href=http://yangchnet.github.io/Dessert/posts/llm/%E6%8B%A5%E6%8A%B1%E5%A4%A7%E6%A8%A1%E5%9E%8B%E4%BA%94memory%E8%AE%A9%E5%A4%A7%E6%A8%A1%E5%9E%8B%E6%8B%A5%E6%9C%89%E8%AE%B0%E5%BF%86/><span class=title>Next Page »</span><br><span>拥抱大模型（五）：Memory，让大模型拥有记忆</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2024 <a href=http://yangchnet.github.io/Dessert>Linote</a></span>
<script src=https://utteranc.es/client.js repo=yangchnet/Dessert issue-term=pathname theme=github-light crossorigin=anonymous async></script><span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>使用sklearn的贝叶斯分类器进行文本分类 | Linote</title><meta name=keywords content="DL&ML"><meta name=description content="使用sklearn的贝叶斯分类器进行文本分类 1、sklearn简介 sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。
2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利 朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。
2.1、多项式模型 2.2、伯努利模型 2.3、两个模型的区别 3、实战演练 使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。
  读取全部数据，并随机打乱
 import os import random def get_dataset(): data = [] for root, dirs, files in os.walk('../dataset/aclImdb/neg'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r'../dataset/aclImdb/pos'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [(&#34;Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see."><meta name=author content="李昌"><link rel=canonical href=http://yangchnet.github.io/Dessert/posts/dlml/sklearn_%E8%B4%9D%E5%8F%B6%E6%96%AF/><link crossorigin=anonymous href=/Dessert/assets/css/stylesheet.min.7e145c6c051b0f6645e8d84c6faed7fed1214bbe82c223c2c19815bee6ee8403.css integrity="sha256-fhRcbAUbD2ZF6NhMb67X/tEhS76CwiPCwZgVvubuhAM=" rel="preload stylesheet" as=style><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Fira+Mono&display=swap" rel=stylesheet><script defer crossorigin=anonymous src=/Dessert/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon32.ico><link rel=apple-touch-icon href=http://yangchnet.github.io/Dessert/apple-touch-icon.png><link rel=mask-icon href=http://yangchnet.github.io/Dessert/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.81.0"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="使用sklearn的贝叶斯分类器进行文本分类"><meta property="og:description" content="使用sklearn的贝叶斯分类器进行文本分类 1、sklearn简介 sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。
2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利 朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。
2.1、多项式模型 2.2、伯努利模型 2.3、两个模型的区别 3、实战演练 使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。
  读取全部数据，并随机打乱
 import os import random def get_dataset(): data = [] for root, dirs, files in os.walk('../dataset/aclImdb/neg'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r'../dataset/aclImdb/pos'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [(&#34;Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see."><meta property="og:type" content="article"><meta property="og:url" content="http://yangchnet.github.io/Dessert/posts/dlml/sklearn_%E8%B4%9D%E5%8F%B6%E6%96%AF/"><meta property="og:image" content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-02-25T00:00:00+00:00"><meta property="article:modified_time" content="2021-02-25T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta name=twitter:title content="使用sklearn的贝叶斯分类器进行文本分类"><meta name=twitter:description content="使用sklearn的贝叶斯分类器进行文本分类 1、sklearn简介 sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。
2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利 朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。
2.1、多项式模型 2.2、伯努利模型 2.3、两个模型的区别 3、实战演练 使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。
  读取全部数据，并随机打乱
 import os import random def get_dataset(): data = [] for root, dirs, files in os.walk('../dataset/aclImdb/neg'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r'../dataset/aclImdb/pos'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [(&#34;Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"http://yangchnet.github.io/Dessert/posts/"},{"@type":"ListItem","position":3,"name":"使用sklearn的贝叶斯分类器进行文本分类","item":"http://yangchnet.github.io/Dessert/posts/dlml/sklearn_%E8%B4%9D%E5%8F%B6%E6%96%AF/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"使用sklearn的贝叶斯分类器进行文本分类","name":"使用sklearn的贝叶斯分类器进行文本分类","description":"使用sklearn的贝叶斯分类器进行文本分类 1、sklearn简介 sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。\n2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利 朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。\n2.1、多项式模型 2.2、伯努利模型 2.3、两个模型的区别 3、实战演练 使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。\n  读取全部数据，并随机打乱\n import os import random def get_dataset(): data = [] for root, dirs, files in os.walk(\u0026#39;../dataset/aclImdb/neg\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r\u0026#39;../dataset/aclImdb/pos\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [(\u0026quot;Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see.","keywords":["DL\u0026ML"],"articleBody":"使用sklearn的贝叶斯分类器进行文本分类 1、sklearn简介 sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。\n2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利 朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。\n2.1、多项式模型 2.2、伯努利模型 2.3、两个模型的区别 3、实战演练 使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。\n  读取全部数据，并随机打乱\n import os import random def get_dataset(): data = [] for root, dirs, files in os.walk('../dataset/aclImdb/neg'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r'../dataset/aclImdb/pos'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [(\"Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see. What I got was something completely satisfying, and quite a bit more than I expected. Being an artist myself (I work in clay), finding inspiration within our surroundings to make good art is imperative, and it is something Andy Goldsworthy has mastered. Following him over the course of a year, the director captures the spontaneous energy, skill, and devotion to the artists connection with nature with dratic inspiring flair. The music set to the film is embracing and intoxicating. If you are an artist in need of inspiration, or anyone else in need of an uplifting experience, then SEE THIS MOVIE. I for one am glad to know that Andy is somewhere out there. Creating, dancing, wrestling with the forces of nature to make our world more beautiful.\", 1), (\"A film I expected very little from, and only watched to pass a quiet hour - but what an hour it turned out to be. Roll is an excellent if none-too-serious little story of 'country-boy-lost-in-the-big-city-makes-good', it is funny throughout, the characters are endearing and the pace is just right.\nToby Malone is the true star of the film with his endearing portrayal of Matt, said country boy and local Aussie Rules football hero come to the big city to try out for one of the big teams. He is supported superbly by John Batchelor as local gangster Tiny. Watch out for these two.\nHighly recommended.\", 1)]    按照7:3的比例划分训练集和测试集\n def train_and_test_data(data_): filesize = int(0.7 * len(data_)) # 训练集和测试集的比例为7:3 train_data_ = [each[0] for each in data_[:filesize]] train_target_ = [each[1] for each in data_[:filesize]] test_data_ = [each[0] for each in data_[filesize:]] test_target_ = [each[1] for each in data_[filesize:]] return train_data_, train_target_, test_data_, test_target_ train_data, train_target, test_data, test_target = train_and_test_data(data)   使用多项式贝叶斯分类器\n from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer from sklearn import metrics from sklearn.naive_bayes import BernoulliNB nbc = Pipeline([ ('vect', TfidfVectorizer()), ('clf', MultinomialNB(alpha=1.0)), ]) nbc.fit(train_data, train_target) #训练我们的多项式模型贝叶斯分类器 predict = nbc.predict(test_data) #在测试集上预测结果 y_score = nbc.fit(train_data, train_target).predict_proba(test_data) print(y_score) count = 0 #统计预测正确的结果个数 for left , right in zip(predict, test_target): if left == right: count += 1 print(count/len(test_target)) [[0.21379806 0.78620194] [0.61108605 0.38891395] [0.25629837 0.74370163] ... [0.33889503 0.66110497] [0.73665026 0.26334974] [0.1870178 0.8129822 ]] 0.8596    使用伯努利模型分类器\n nbc_1= Pipeline([ ('vect', TfidfVectorizer()), ('clf', BernoulliNB(alpha=0.1)), ]) nbc_1.fit(train_data, train_target) predict = nbc_1.predict(test_data) #在测试集上预测结果 count = 0 #统计预测正确的结果个数 for left , right in zip(predict, test_target): if left == right: count += 1 print(count/len(test_target)) 0.8818635607321131   从分类结果可以看出，和多项式模型相比，使用伯努利模型的贝叶斯分类器，在文本分类方面的精度相比，差别不大，我们可以针对我们面对的具体问题，进行实验，选择最为合适的分类器。\n作业 sklearn中一共提供了四种贝叶斯分类器：\n 高斯朴素贝叶斯 多项式朴素贝叶斯 补充朴素贝叶斯 伯努利朴素贝叶斯  从四种贝叶斯分类器模型中找出具有最佳分类效果的分类器，并用直方图直观表示其分类准确率。\n参考资料 sklearn官方网站\nhttps://scikit-learn.org/stable/index.html\nsklearn:朴素贝叶斯 https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\n","wordCount":"507","inLanguage":"en","datePublished":"2021-02-25T00:00:00Z","dateModified":"2021-02-25T00:00:00Z","author":{"@type":"Person","name":"李昌"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://yangchnet.github.io/Dessert/posts/dlml/sklearn_%E8%B4%9D%E5%8F%B6%E6%96%AF/"},"publisher":{"@type":"Organization","name":"Linote","logo":{"@type":"ImageObject","url":"https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><header class=header><nav class=nav><div class=logo><a href=http://yangchnet.github.io/Dessert accesskey=h title="Linote (Alt + H)">Linote</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=http://yangchnet.github.io/Dessert/archives/ title=存档><span>存档</span></a></li><li><a href=http://yangchnet.github.io/Dessert/categories/ title=分类><span>分类</span></a></li><li><a href=http://yangchnet.github.io/Dessert/search/ title=搜索><span>搜索</span></a></li><li><a href=http://yangchnet.github.io/Dessert/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://yangchnet.github.io/Dessert>Home</a>&nbsp;»&nbsp;<a href=http://yangchnet.github.io/Dessert/posts/>Posts</a></div><h1 class=post-title>使用sklearn的贝叶斯分类器进行文本分类</h1><div class=post-meta><span title="2021-02-25 00:00:00 +0000 UTC">February 25, 2021</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;李昌</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#%e4%bd%bf%e7%94%a8sklearn%e7%9a%84%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%86%e7%b1%bb%e5%99%a8%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb aria-label=使用sklearn的贝叶斯分类器进行文本分类>使用sklearn的贝叶斯分类器进行文本分类</a><ul><li><a href=#1sklearn%e7%ae%80%e4%bb%8b aria-label=1、sklearn简介>1、sklearn简介</a></li><li><a href=#2%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af%e5%9c%a8%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb%e4%b8%ad%e7%9a%84%e5%b8%b8%e7%94%a8%e6%a8%a1%e5%9e%8b%e5%a4%9a%e9%a1%b9%e5%bc%8f%e4%bc%af%e5%8a%aa%e5%88%a9 aria-label=2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利>2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利</a><ul><li><a href=#21%e5%a4%9a%e9%a1%b9%e5%bc%8f%e6%a8%a1%e5%9e%8b aria-label=2.1、多项式模型>2.1、多项式模型</a></li><li><a href=#22%e4%bc%af%e5%8a%aa%e5%88%a9%e6%a8%a1%e5%9e%8b aria-label=2.2、伯努利模型>2.2、伯努利模型</a></li><li><a href=#23%e4%b8%a4%e4%b8%aa%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%8c%ba%e5%88%ab aria-label=2.3、两个模型的区别>2.3、两个模型的区别</a></li></ul></li><li><a href=#3%e5%ae%9e%e6%88%98%e6%bc%94%e7%bb%83 aria-label=3、实战演练>3、实战演练</a></li></ul></li><li><a href=#%e4%bd%9c%e4%b8%9a aria-label=作业>作业</a></li><li><a href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99 aria-label=参考资料>参考资料</a></li></ul></div></details></div><div class=post-content><h1 id=使用sklearn的贝叶斯分类器进行文本分类>使用sklearn的贝叶斯分类器进行文本分类<a hidden class=anchor aria-hidden=true href=#使用sklearn的贝叶斯分类器进行文本分类>#</a></h1><h2 id=1sklearn简介>1、sklearn简介<a hidden class=anchor aria-hidden=true href=#1sklearn简介>#</a></h2><p>sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。</p><h2 id=2朴素贝叶斯在文本分类中的常用模型多项式伯努利>2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利<a hidden class=anchor aria-hidden=true href=#2朴素贝叶斯在文本分类中的常用模型多项式伯努利>#</a></h2><p>朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。</p><h3 id=21多项式模型>2.1、多项式模型<a hidden class=anchor aria-hidden=true href=#21多项式模型>#</a></h3><p><img loading=lazy src=../image/%e5%a4%9a%e9%a1%b9%e5%bc%8f.webp alt=多项式模型></p><h3 id=22伯努利模型>2.2、伯努利模型<a hidden class=anchor aria-hidden=true href=#22伯努利模型>#</a></h3><p><img loading=lazy src=../image/%e4%bc%af%e5%8a%aa%e5%88%a9.webp alt=伯努利模型></p><h3 id=23两个模型的区别>2.3、两个模型的区别<a hidden class=anchor aria-hidden=true href=#23两个模型的区别>#</a></h3><p><img loading=lazy src=../image/%e5%8c%ba%e5%88%ab.webp alt=区别></p><h2 id=3实战演练>3、实战演练<a hidden class=anchor aria-hidden=true href=#3实战演练>#</a></h2><p>使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。</p><hr><blockquote><p>读取全部数据，并随机打乱</p></blockquote><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> os
<span style=color:#f92672>import</span> random
<span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_dataset</span>():
    data <span style=color:#f92672>=</span> []
    <span style=color:#66d9ef>for</span> root, dirs, files <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>walk(<span style=color:#e6db74>&#39;../dataset/aclImdb/neg&#39;</span>):
        <span style=color:#66d9ef>for</span> file <span style=color:#f92672>in</span> files:
            realpath <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(root, file)
            <span style=color:#66d9ef>with</span> open(realpath, errors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ignore&#39;</span>) <span style=color:#66d9ef>as</span> f:
                data<span style=color:#f92672>.</span>append((f<span style=color:#f92672>.</span>read(), <span style=color:#ae81ff>0</span>))
    <span style=color:#66d9ef>for</span> root, dirs, files <span style=color:#f92672>in</span> os<span style=color:#f92672>.</span>walk(<span style=color:#e6db74>r</span><span style=color:#e6db74>&#39;../dataset/aclImdb/pos&#39;</span>):
        <span style=color:#66d9ef>for</span> file <span style=color:#f92672>in</span> files:
            realpath <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(root, file)
            <span style=color:#66d9ef>with</span> open(realpath, errors<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;ignore&#39;</span>) <span style=color:#66d9ef>as</span> f:
                data<span style=color:#f92672>.</span>append((f<span style=color:#f92672>.</span>read(), <span style=color:#ae81ff>1</span>))
    random<span style=color:#f92672>.</span>shuffle(data)

    <span style=color:#66d9ef>return</span> data
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>data <span style=color:#f92672>=</span> get_dataset()
data[:<span style=color:#ae81ff>2</span>]
</code></pre></div><pre><code>[(&quot;Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see. What I got was something completely satisfying, and quite a bit more than I expected. Being an artist myself (I work in clay), finding inspiration within our surroundings to make good art is imperative, and it is something Andy Goldsworthy has mastered. Following him over the course of a year, the director captures the spontaneous energy, skill, and devotion to the artists connection with nature with dratic inspiring flair. The music set to the film is embracing and intoxicating. If you are an artist in need of inspiration, or anyone else in need of an uplifting experience, then SEE THIS MOVIE. I for one am glad to know that Andy is somewhere out there. Creating, dancing, wrestling with the forces of nature to make our world more beautiful.&quot;,
  1),
 (&quot;A film I expected very little from, and only watched to pass a quiet hour - but what an hour it turned out to be. Roll is an excellent if none-too-serious little story of 'country-boy-lost-in-the-big-city-makes-good', it is funny throughout, the characters are endearing and the pace is just right.&lt;br /&gt;&lt;br /&gt;Toby Malone is the true star of the film with his endearing portrayal of Matt, said country boy and local Aussie Rules football hero come to the big city to try out for one of the big teams. He is supported superbly by John Batchelor as local gangster Tiny. Watch out for these two.&lt;br /&gt;&lt;br /&gt;Highly recommended.&quot;,
  1)]
</code></pre><hr><blockquote><p>按照7:3的比例划分训练集和测试集</p></blockquote><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>train_and_test_data</span>(data_):
    filesize <span style=color:#f92672>=</span> int(<span style=color:#ae81ff>0.7</span> <span style=color:#f92672>*</span> len(data_))
    <span style=color:#75715e># 训练集和测试集的比例为7:3</span>
    train_data_ <span style=color:#f92672>=</span> [each[<span style=color:#ae81ff>0</span>] <span style=color:#66d9ef>for</span> each <span style=color:#f92672>in</span> data_[:filesize]]
    train_target_ <span style=color:#f92672>=</span> [each[<span style=color:#ae81ff>1</span>] <span style=color:#66d9ef>for</span> each <span style=color:#f92672>in</span> data_[:filesize]]

    test_data_ <span style=color:#f92672>=</span> [each[<span style=color:#ae81ff>0</span>] <span style=color:#66d9ef>for</span> each <span style=color:#f92672>in</span> data_[filesize:]]
    test_target_ <span style=color:#f92672>=</span> [each[<span style=color:#ae81ff>1</span>] <span style=color:#66d9ef>for</span> each <span style=color:#f92672>in</span> data_[filesize:]]

    <span style=color:#66d9ef>return</span> train_data_, train_target_, test_data_, test_target_
</code></pre></div><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>train_data, train_target, test_data, test_target <span style=color:#f92672>=</span> train_and_test_data(data)
</code></pre></div><hr><blockquote><p>使用多项式贝叶斯分类器</p></blockquote><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>from</span> sklearn.naive_bayes <span style=color:#f92672>import</span> MultinomialNB
<span style=color:#f92672>from</span> sklearn.pipeline <span style=color:#f92672>import</span> Pipeline
<span style=color:#f92672>from</span> sklearn.feature_extraction.text <span style=color:#f92672>import</span> TfidfVectorizer, HashingVectorizer, CountVectorizer
<span style=color:#f92672>from</span> sklearn <span style=color:#f92672>import</span> metrics
<span style=color:#f92672>from</span> sklearn.naive_bayes <span style=color:#f92672>import</span> BernoulliNB

nbc <span style=color:#f92672>=</span> Pipeline([
    (<span style=color:#e6db74>&#39;vect&#39;</span>, TfidfVectorizer()),
    (<span style=color:#e6db74>&#39;clf&#39;</span>, MultinomialNB(alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>1.0</span>)),
])
nbc<span style=color:#f92672>.</span>fit(train_data, train_target)    <span style=color:#75715e>#训练我们的多项式模型贝叶斯分类器</span>
predict <span style=color:#f92672>=</span> nbc<span style=color:#f92672>.</span>predict(test_data)  <span style=color:#75715e>#在测试集上预测结果</span>
y_score <span style=color:#f92672>=</span> nbc<span style=color:#f92672>.</span>fit(train_data, train_target)<span style=color:#f92672>.</span>predict_proba(test_data)
<span style=color:#66d9ef>print</span>(y_score)
count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>                                      <span style=color:#75715e>#统计预测正确的结果个数</span>
<span style=color:#66d9ef>for</span> left , right <span style=color:#f92672>in</span> zip(predict, test_target):
      <span style=color:#66d9ef>if</span> left <span style=color:#f92672>==</span> right:
            count <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
<span style=color:#66d9ef>print</span>(count<span style=color:#f92672>/</span>len(test_target))
</code></pre></div><pre><code>[[0.21379806 0.78620194]
 [0.61108605 0.38891395]
 [0.25629837 0.74370163]
 ...
 [0.33889503 0.66110497]
 [0.73665026 0.26334974]
 [0.1870178  0.8129822 ]]
0.8596
</code></pre><hr><blockquote><p>使用伯努利模型分类器</p></blockquote><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>nbc_1<span style=color:#f92672>=</span> Pipeline([
    (<span style=color:#e6db74>&#39;vect&#39;</span>, TfidfVectorizer()),
    (<span style=color:#e6db74>&#39;clf&#39;</span>, BernoulliNB(alpha<span style=color:#f92672>=</span><span style=color:#ae81ff>0.1</span>)),
])
nbc_1<span style=color:#f92672>.</span>fit(train_data, train_target)
predict <span style=color:#f92672>=</span> nbc_1<span style=color:#f92672>.</span>predict(test_data)  <span style=color:#75715e>#在测试集上预测结果</span>
count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>                                      <span style=color:#75715e>#统计预测正确的结果个数</span>
<span style=color:#66d9ef>for</span> left , right <span style=color:#f92672>in</span> zip(predict, test_target):
      <span style=color:#66d9ef>if</span> left <span style=color:#f92672>==</span> right:
            count <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
<span style=color:#66d9ef>print</span>(count<span style=color:#f92672>/</span>len(test_target))
</code></pre></div><pre><code>0.8818635607321131
</code></pre><hr><p>从分类结果可以看出，和多项式模型相比，使用伯努利模型的贝叶斯分类器，在文本分类方面的精度相比，差别不大，我们可以针对我们面对的具体问题，进行实验，选择最为合适的分类器。</p><h1 id=作业>作业<a hidden class=anchor aria-hidden=true href=#作业>#</a></h1><p>sklearn中一共提供了四种贝叶斯分类器：</p><ul><li>高斯朴素贝叶斯</li><li>多项式朴素贝叶斯</li><li>补充朴素贝叶斯</li><li>伯努利朴素贝叶斯</li></ul><p>从四种贝叶斯分类器模型中找出具有最佳分类效果的分类器，并用直方图直观表示其分类准确率。</p><h1 id=参考资料>参考资料<a hidden class=anchor aria-hidden=true href=#参考资料>#</a></h1><p><a href=https://scikit-learn.org/stable/index.html>sklearn官方网站</a><br><a href=https://scikit-learn.org/stable/index.html>https://scikit-learn.org/stable/index.html</a></p><p><a href=https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes>sklearn:朴素贝叶斯</a><br><a href=https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes>https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes</a></p></div><footer class=post-footer><ul class=post-tags><li><a href=http://yangchnet.github.io/Dessert/tags/dlml/>DL&ML</a></li></ul><nav class=paginav><a class=prev href=http://yangchnet.github.io/Dessert/posts/linux/wordpress%E5%AE%89%E8%A3%85%E8%B8%A9%E5%9D%91/><span class=title>« Prev Page</span><br><span>WordPress安装踩坑</span></a>
<a class=next href=http://yangchnet.github.io/Dessert/posts/dlml/%E5%88%86%E7%B1%BB%E6%8C%87%E6%A0%87%E4%BD%9C%E4%B8%9A%E7%AC%AC%E4%BA%8C%E9%A2%98/><span class=title>Next Page »</span><br><span>分类指标作业（第二题）</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share 使用sklearn的贝叶斯分类器进行文本分类 on twitter" href="https://twitter.com/intent/tweet/?text=%e4%bd%bf%e7%94%a8sklearn%e7%9a%84%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%86%e7%b1%bb%e5%99%a8%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb&url=http%3a%2f%2fyangchnet.github.io%2fDessert%2fposts%2fdlml%2fsklearn_%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f&hashtags=DL%26ML"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 使用sklearn的贝叶斯分类器进行文本分类 on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=http%3a%2f%2fyangchnet.github.io%2fDessert%2fposts%2fdlml%2fsklearn_%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f&title=%e4%bd%bf%e7%94%a8sklearn%e7%9a%84%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%86%e7%b1%bb%e5%99%a8%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb&summary=%e4%bd%bf%e7%94%a8sklearn%e7%9a%84%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%86%e7%b1%bb%e5%99%a8%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb&source=http%3a%2f%2fyangchnet.github.io%2fDessert%2fposts%2fdlml%2fsklearn_%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 使用sklearn的贝叶斯分类器进行文本分类 on reddit" href="https://reddit.com/submit?url=http%3a%2f%2fyangchnet.github.io%2fDessert%2fposts%2fdlml%2fsklearn_%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f&title=%e4%bd%bf%e7%94%a8sklearn%e7%9a%84%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%86%e7%b1%bb%e5%99%a8%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 使用sklearn的贝叶斯分类器进行文本分类 on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2fyangchnet.github.io%2fDessert%2fposts%2fdlml%2fsklearn_%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 使用sklearn的贝叶斯分类器进行文本分类 on whatsapp" href="https://api.whatsapp.com/send?text=%e4%bd%bf%e7%94%a8sklearn%e7%9a%84%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%86%e7%b1%bb%e5%99%a8%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb%20-%20http%3a%2f%2fyangchnet.github.io%2fDessert%2fposts%2fdlml%2fsklearn_%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share 使用sklearn的贝叶斯分类器进行文本分类 on telegram" href="https://telegram.me/share/url?text=%e4%bd%bf%e7%94%a8sklearn%e7%9a%84%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%86%e7%b1%bb%e5%99%a8%e8%bf%9b%e8%a1%8c%e6%96%87%e6%9c%ac%e5%88%86%e7%b1%bb&url=http%3a%2f%2fyangchnet.github.io%2fDessert%2fposts%2fdlml%2fsklearn_%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2022 <a href=http://yangchnet.github.io/Dessert>Linote</a></span>
<script src=https://utteranc.es/client.js repo=yangchnet/Dessert issue-term=pathname theme=github-light crossorigin=anonymous async></script><span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>
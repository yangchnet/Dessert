<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>tf.ones_like() | Linote</title><meta name=keywords content="DL&ML"><meta name=description content="import tensorflow as tf import numpy as np from IPython.display import Image tf.ones_like() 创建一个所有元素设置为1的tensor
tf.subtract() 两个矩阵相减
 decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)
  这一句计算出1-d
 tf.stack 矩阵拼接，例如
a = tf.constant([1,2,3]) b = tf.constant([4,5,6]) c = tf.stack([a, b], axis = 0) d = tf.stack([a, b], axis = 1) sess = tf.Session() print(sess.run(c)) print(sess.run(d)) [[1 2 3] [4 5 6]] [[1 4] [2 5] [3 6]]  tf.expand_dims 在axis位置增加一个维度
tf.tile 在同一维度上进行复制
with tf."><meta name=author content="李昌"><link rel=canonical href=http://yangchnet.github.io/Dessert/posts/dlml/tensorflowapi/><link crossorigin=anonymous href=/Dessert/assets/css/stylesheet.min.2d6dbfc6e0f8a1db1c9d082a76dc11d094328cf63f247bbc2421dfaa7f2bb170.css integrity="sha256-LW2/xuD4odscnQgqdtwR0JQyjPY/JHu8JCHfqn8rsXA=" rel="preload stylesheet" as=style><link rel=preload href=https://raw.githubusercontent.com/lich-Img/blogImg/master/img20210514094119.png as=image><script defer crossorigin=anonymous src=/Dessert/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5+kdJvBz5iKbt6B5PJI=" onload=hljs.initHighlightingOnLoad()></script><link rel=icon href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon32.ico><link rel=apple-touch-icon href=http://yangchnet.github.io/Dessert/apple-touch-icon.png><link rel=mask-icon href=http://yangchnet.github.io/Dessert/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.81.0"><meta property="og:title" content="tf.ones_like()"><meta property="og:description" content="import tensorflow as tf import numpy as np from IPython.display import Image tf.ones_like() 创建一个所有元素设置为1的tensor
tf.subtract() 两个矩阵相减
 decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)
  这一句计算出1-d
 tf.stack 矩阵拼接，例如
a = tf.constant([1,2,3]) b = tf.constant([4,5,6]) c = tf.stack([a, b], axis = 0) d = tf.stack([a, b], axis = 1) sess = tf.Session() print(sess.run(c)) print(sess.run(d)) [[1 2 3] [4 5 6]] [[1 4] [2 5] [3 6]]  tf.expand_dims 在axis位置增加一个维度
tf.tile 在同一维度上进行复制
with tf."><meta property="og:type" content="article"><meta property="og:url" content="http://yangchnet.github.io/Dessert/posts/dlml/tensorflowapi/"><meta property="og:image" content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2021-02-25T00:00:00+00:00"><meta property="article:modified_time" content="2021-02-25T00:00:00+00:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta name=twitter:title content="tf.ones_like()"><meta name=twitter:description content="import tensorflow as tf import numpy as np from IPython.display import Image tf.ones_like() 创建一个所有元素设置为1的tensor
tf.subtract() 两个矩阵相减
 decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)
  这一句计算出1-d
 tf.stack 矩阵拼接，例如
a = tf.constant([1,2,3]) b = tf.constant([4,5,6]) c = tf.stack([a, b], axis = 0) d = tf.stack([a, b], axis = 1) sess = tf.Session() print(sess.run(c)) print(sess.run(d)) [[1 2 3] [4 5 6]] [[1 4] [2 5] [3 6]]  tf.expand_dims 在axis位置增加一个维度
tf.tile 在同一维度上进行复制
with tf."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":2,"name":"Posts","item":"http://yangchnet.github.io/Dessert/posts/"},{"@type":"ListItem","position":3,"name":"tf.ones_like()","item":"http://yangchnet.github.io/Dessert/posts/dlml/tensorflowapi/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"tf.ones_like()","name":"tf.ones_like()","description":"import tensorflow as tf import numpy as np from IPython.display import Image tf.ones_like() 创建一个所有元素设置为1的tensor\ntf.subtract() 两个矩阵相减\n decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)\n  这一句计算出1-d\n tf.stack 矩阵拼接，例如\na = tf.constant([1,2,3]) b = tf.constant([4,5,6]) c = tf.stack([a, b], axis = 0) d = tf.stack([a, b], axis = 1) sess = tf.Session() print(sess.run(c)) print(sess.run(d)) [[1 2 3] [4 5 6]] [[1 4] [2 5] [3 6]]  tf.expand_dims 在axis位置增加一个维度\ntf.tile 在同一维度上进行复制\nwith tf.","keywords":["DL\u0026ML"],"articleBody":"import tensorflow as tf import numpy as np from IPython.display import Image tf.ones_like() 创建一个所有元素设置为1的tensor\ntf.subtract() 两个矩阵相减\n decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)\n  这一句计算出1-d\n tf.stack 矩阵拼接，例如\na = tf.constant([1,2,3]) b = tf.constant([4,5,6]) c = tf.stack([a, b], axis = 0) d = tf.stack([a, b], axis = 1) sess = tf.Session() print(sess.run(c)) print(sess.run(d)) [[1 2 3] [4 5 6]] [[1 4] [2 5] [3 6]]  tf.expand_dims 在axis位置增加一个维度\ntf.tile 在同一维度上进行复制\nwith tf.Graph().as_default(): a = tf.constant([1,2],name='a') b = tf.tile(a,[3]) sess = tf.Session() print(sess.run(b)) [1 2 1 2 1 2]  axis 0 代表行 1 代表列\ntf.reduce_mean 计算张量的各个维度上的元素的平均值。\nx = tf.constant([[1., 1.], [2., 2.]]) tf.reduce_mean(x) # 1.5 tf.reduce_mean(x, 0) # [1.5, 1.5] tf.reduce_mean(x, 1) # [1., 2.]  tf.nn.dropout dropout的作用是为了防止或减轻过拟合，它一般用在全连接层 通过在不同的训练过程中随机扔掉一部分神经元，也就是让某个神经元的激活值以一定的概率p, 让其停止工作，这次训练过程中不更新权值，也不参加神经网络的计算，但是他的权重得保存下来，待下次样本输入时可能会重新工作。 其函数原型： tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None,name=None) 第一个参数为输入，第二个参数设置神经元被选中的概率，\ntf.gather 根据索引，从输入张量中依次取元素，构成一个新的张量\n","wordCount":"124","inLanguage":"en","datePublished":"2021-02-25T00:00:00Z","dateModified":"2021-02-25T00:00:00Z","author":{"@type":"Person","name":"李昌"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://yangchnet.github.io/Dessert/posts/dlml/tensorflowapi/"},"publisher":{"@type":"Organization","name":"Linote","logo":{"@type":"ImageObject","url":"https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><noscript><style type=text/css>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:#1d1e20;--entry:#2e2e33;--primary:rgba(255, 255, 255, 0.84);--secondary:rgba(255, 255, 255, 0.56);--tertiary:rgba(255, 255, 255, 0.16);--content:rgba(255, 255, 255, 0.74);--hljs-bg:#2e2e33;--code-bg:#37383e;--border:#333}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><header class=header><nav class=nav><div class=logo><a href=http://yangchnet.github.io/Dessert accesskey=h title="Linote (Alt + H)">Linote</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=http://yangchnet.github.io/Dessert/archives title=存档><span>存档</span></a></li><li><a href=http://yangchnet.github.io/Dessert/categories/ title=分类><span>分类</span></a></li><li><a href=http://yangchnet.github.io/Dessert/search/ title=搜索><span>搜索</span></a></li><li><a href=http://yangchnet.github.io/Dessert/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://yangchnet.github.io/Dessert>Home</a>&nbsp;»&nbsp;<a href=http://yangchnet.github.io/Dessert/posts/>Posts</a></div><h1 class=post-title>tf.ones_like()</h1><div class=post-meta>February 25, 2021&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</div></header><div class=toc><details open><summary accesskey=c title="(Alt + C)"><div class=details>Table of Contents</div></summary><div class=inner><ul><li><a href=#tfones_like aria-label=tf.ones_like()>tf.ones_like()</a></li><li><a href=#tfsubtract aria-label=tf.subtract()>tf.subtract()</a></li><li><a href=#tfstack aria-label=tf.stack>tf.stack</a></li><li><a href=#tfexpand_dims aria-label=tf.expand_dims>tf.expand_dims</a></li><li><a href=#tftile aria-label=tf.tile>tf.tile</a></li><li><a href=#tfreduce_mean aria-label=tf.reduce_mean>tf.reduce_mean</a></li><li><a href=#tfnndropout aria-label=tf.nn.dropout>tf.nn.dropout</a></li><li><a href=#tfgather aria-label=tf.gather>tf.gather</a></li></ul></div></details></div><div class=post-content><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#f92672>import</span> tensorflow <span style=color:#f92672>as</span> tf
<span style=color:#f92672>import</span> numpy <span style=color:#f92672>as</span> np
<span style=color:#f92672>from</span> IPython.display <span style=color:#f92672>import</span> Image
</code></pre></div><h3 id=tfones_like>tf.ones_like()<a hidden class=anchor aria-hidden=true href=#tfones_like>#</a></h3><p>创建一个所有元素设置为1的tensor</p><h3 id=tfsubtract>tf.subtract()<a hidden class=anchor aria-hidden=true href=#tfsubtract>#</a></h3><p>两个矩阵相减</p><blockquote><p>decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)</p></blockquote><blockquote><p>这一句计算出1-d</p></blockquote><h3 id=tfstack>tf.stack<a hidden class=anchor aria-hidden=true href=#tfstack>#</a></h3><p>矩阵拼接，例如</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>a <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>constant([<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>2</span>,<span style=color:#ae81ff>3</span>])
b <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>constant([<span style=color:#ae81ff>4</span>,<span style=color:#ae81ff>5</span>,<span style=color:#ae81ff>6</span>])
c <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>stack([a, b], axis <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>)
d <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>stack([a, b], axis <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span>)
sess <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>Session()
<span style=color:#66d9ef>print</span>(sess<span style=color:#f92672>.</span>run(c))
<span style=color:#66d9ef>print</span>(sess<span style=color:#f92672>.</span>run(d))
</code></pre></div><pre><code>[[1 2 3]
 [4 5 6]]
[[1 4]
 [2 5]
 [3 6]]
</code></pre><h3 id=tfexpand_dims>tf.expand_dims<a hidden class=anchor aria-hidden=true href=#tfexpand_dims>#</a></h3><p>在axis位置增加一个维度</p><h3 id=tftile>tf.tile<a hidden class=anchor aria-hidden=true href=#tftile>#</a></h3><p>在同一维度上进行复制</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=color:#66d9ef>with</span> tf<span style=color:#f92672>.</span>Graph()<span style=color:#f92672>.</span>as_default():
    a <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>constant([<span style=color:#ae81ff>1</span>,<span style=color:#ae81ff>2</span>],name<span style=color:#f92672>=</span><span style=color:#e6db74>&#39;a&#39;</span>) 
    b <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>tile(a,[<span style=color:#ae81ff>3</span>])
    sess <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>Session()
    <span style=color:#66d9ef>print</span>(sess<span style=color:#f92672>.</span>run(b))
</code></pre></div><pre><code>[1 2 1 2 1 2]
</code></pre><p>axis 0 代表行 1 代表列</p><h3 id=tfreduce_mean>tf.reduce_mean<a hidden class=anchor aria-hidden=true href=#tfreduce_mean>#</a></h3><p>计算张量的各个维度上的元素的平均值。</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python>x <span style=color:#f92672>=</span> tf<span style=color:#f92672>.</span>constant([[<span style=color:#ae81ff>1.</span>, <span style=color:#ae81ff>1.</span>], [<span style=color:#ae81ff>2.</span>, <span style=color:#ae81ff>2.</span>]])
tf<span style=color:#f92672>.</span>reduce_mean(x)  <span style=color:#75715e># 1.5</span>
tf<span style=color:#f92672>.</span>reduce_mean(x, <span style=color:#ae81ff>0</span>)  <span style=color:#75715e># [1.5, 1.5]</span>
tf<span style=color:#f92672>.</span>reduce_mean(x, <span style=color:#ae81ff>1</span>)  <span style=color:#75715e># [1.,  2.]</span>
</code></pre></div><pre><code>&lt;tf.Tensor 'Mean_2:0' shape=(2,) dtype=float32&gt;
</code></pre><h3 id=tfnndropout>tf.nn.dropout<a hidden class=anchor aria-hidden=true href=#tfnndropout>#</a></h3><p>dropout的作用是为了防止或减轻过拟合，它一般用在全连接层
通过在不同的训练过程中随机扔掉一部分神经元，也就是让某个神经元的激活值以一定的概率p, 让其停止工作，这次训练过程中不更新权值，也不参加神经网络的计算，但是他的权重得保存下来，待下次样本输入时可能会重新工作。
其函数原型：
tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None,name=None)
第一个参数为输入，第二个参数设置神经元被选中的概率，</p><h3 id=tfgather>tf.gather<a hidden class=anchor aria-hidden=true href=#tfgather>#</a></h3><p>根据索引，从输入张量中依次取元素，构成一个新的张量</p></div><footer class=post-footer><ul class=post-tags><li><a href=http://yangchnet.github.io/Dessert/tags/dlml/>DL&ML</a></li></ul><nav class=paginav><a class=prev href=http://yangchnet.github.io/Dessert/posts/dlml/svm-primal/><span class=title>« Prev Page</span><br><span>SimpleSupportVectorMachine</span></a>
<a class=next href=http://yangchnet.github.io/Dessert/posts/linux/ubuntu%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7/><span class=title>Next Page »</span><br><span>ubuntu中增加用户</span></a></nav><div class=share-buttons><div class=bshare-custom><a title=分享到微信 class=bshare-weixin></a><a title=分享到QQ好友 class=bshare-qqim></a><a title=分享到复制网址 class=bshare-clipboard></a><a title=分享到QQ空间 class=bshare-qzone></a><a title=分享到新浪微博 class=bshare-sinaminiblog></a><a title=分享到电子邮件 class=bshare-email></a><a title=更多平台 class="bshare-more bshare-more-icon more-style-addthis"></a></div><script type=text/javascript src="http://static.bshare.cn/b/buttonLite.js#style=-1&uuid=&pophcol=2&lang=zh"></script><script type=text/javascript src=http://static.bshare.cn/b/bshareC0.js></script></div></footer></article></main><footer class=footer><span>&copy; 2021 <a href=http://yangchnet.github.io/Dessert>Linote</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span>
<link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.css><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.js></script><script src=https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/contrib/auto-render.min.js></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1}]})})</script></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)"><button class=top-link id=top-link type=button accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></button></a>
<script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>
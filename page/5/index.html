<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Linote</title><meta name=description content><meta name=author content="李昌"><link rel=canonical href=http://yangchnet.github.io/Dessert/><link crossorigin=anonymous href=/Dessert/assets/css/stylesheet.min.7e145c6c051b0f6645e8d84c6faed7fed1214bbe82c223c2c19815bee6ee8403.css integrity="sha256-fhRcbAUbD2ZF6NhMb67X/tEhS76CwiPCwZgVvubuhAM=" rel="preload stylesheet" as=style><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Fira+Mono&display=swap" rel=stylesheet><link rel=icon href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon32.ico><link rel=apple-touch-icon href=http://yangchnet.github.io/Dessert/apple-touch-icon.png><link rel=mask-icon href=http://yangchnet.github.io/Dessert/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.81.0"><link rel=alternate type=application/rss+xml href=http://yangchnet.github.io/Dessert/index.xml><link rel=alternate type=application/json href=http://yangchnet.github.io/Dessert/index.json><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Linote"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="http://yangchnet.github.io/Dessert/"><meta property="og:image" content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta name=twitter:title content="Linote"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"Linote","url":"http://yangchnet.github.io/Dessert","description":"","thumbnailUrl":"https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico","sameAs":["https://github.com/yangchnet"]}</script></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><header class=header><nav class=nav><div class=logo><a href=http://yangchnet.github.io/Dessert accesskey=h title="Linote (Alt + H)">Linote</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=http://yangchnet.github.io/Dessert/archives/ title=存档><span>存档</span></a></li><li><a href=http://yangchnet.github.io/Dessert/categories/ title=分类><span>分类</span></a></li><li><a href=http://yangchnet.github.io/Dessert/search/ title=搜索><span>搜索</span></a></li><li><a href=http://yangchnet.github.io/Dessert/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><article class=post-entry><header class=entry-header><h2>概览Redis篇六：切片集群</h2></header><section class=entry-content><p>极客时间《Redis 核心技术与实战》学习笔记
概览Redis篇一：单线程模型 概览Redis篇二：AOF日志 概览Redis篇三：RDB快照 概览Redis篇四：主从 概览Redis篇五：哨兵 概览Redis篇六：切片集群 什么是切片集群，有什么用 切片集群，也叫分片集群，就是指启动多个 Redis 实例组成一个集群，然后按照一定的规则，把收到的数据划分成多份，每一份用一个实例来保存。
当Redis保存大量数据时，其在进行RDB持久化时需要fork一个子进程，而fork子进程的用时和Redis的数据量是正相关的，而 fork 在执行时会阻塞主线程。数据量越大，fork 操作造成的主线程阻塞的时间越长。因此如果Redis保存了大量数据，会导致Redis响应变慢。
数据切片后，在多个实例之间如何分布 从 3.0 开始，官方提供了一个名为 Redis Cluster 的方案，用于实现切片集群。Redis Cluster 方案中就规定了数据和实例的对应规则。
Redis Cluster 方案采用哈希槽Hash Slot，来处理数据和实例之间的映射关系。在 Redis Cluster 方案中，一个切片集群共有 16384 个哈希槽，这些哈希槽类似于数据分区，每个键值对都会根据它的 key，被映射到一个哈希槽中。
具体的映射过程分为两大步：首先根据键值对的 key，按照CRC16 算法计算一个 16 bit 的值；然后，再用这个 16bit 值对 16384 取模，得到 0~16383 范围内的模数，每个模数代表一个相应编号的哈希槽。
在部署 Redis Cluster 方案时，可以使用 cluster create 命令创建集群，此时，Redis 会自动把这些槽平均分布在集群实例上。例如，如果集群中有 N 个实例，那么，每个实例上的槽个数为 16384/N 个。当然，也可以使用cluster meet命令手动建立实例间的连接，形成集群，再使用cluster addslots 命令，指定每个实例上的哈希槽个数。在手动分配哈希槽时，需要把 16384 个槽都分配完，否则 Redis 集群无法正常工作。...</p></section><footer class=entry-footer><span title="2022-07-22 00:00:00 +0000 UTC">July 22, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 概览Redis篇六：切片集群" href=http://yangchnet.github.io/Dessert/posts/cache/%E6%A6%82%E8%A7%88redis%E7%AF%87%E5%85%AD%E5%88%87%E7%89%87%E9%9B%86%E7%BE%A4/></a></article><article class=post-entry><header class=entry-header><h2>概览Redis篇四：主从</h2></header><section class=entry-content><p>极客时间《Redis 核心技术与实战》学习笔记
概览Redis篇一：单线程模型 概览Redis篇二：AOF日志 概览Redis篇三：RDB快照 概览Redis篇四：主从 概览Redis篇五：哨兵 概览Redis篇六：切片集群 Redis的高可靠性 Redis 具有高可靠性，又是什么意思呢？其实，这里有两层含义：一是数据尽量少丢失，二是服务尽量少中断。
AOF 和 RDB 保证了前者，而对于后者，Redis 的做法就是增加副本冗余量，将一份数据同时保存在多个实例上。即使有一个实例出现了故障，需要过一段时间才能恢复，其他实例也可以对外提供服务，不会影响业务使用。
Redis 提供了主从库模式，以保证数据副本的一致，主从库之间采用的是读写分离的方式。
读操作：主库、从库都可以接收； 写操作：首先到主库执行，然后，主库将写操作同步给从库。 为什么要读写分离
如果在上图中，不管是主库还是从库，都能接收客户端的写操作，那么，一个直接的问题就是：如果客户端对同一个数据（例如 k1）前后修改了三次，每一次的修改请求都发送到不同的实例上，在不同的实例上执行，那么，这个数据在这三个实例上的副本就不一致了（分别是 v1、v2 和 v3）。在读取这个数据的时候，就可能读取到旧的值。
当然我们可以使这个数据在三个实例上保持一致，但这涉及到加锁，实例间协商等一系列操作，会带来巨额的开销。
而主从库模式一旦采用了读写分离，所有数据的修改只会在主库上进行，不用协调三个实例。主库有了最新的数据后，会同步给从库，这样，主从库的数据就是一致的。
主从库如何进行第一次同步 当我们启动多个 Redis 实例的时候，它们相互之间就可以通过 replicaof（Redis 5.0 之前使用 slaveof）命令形成主库和从库的关系，之后会按照三个阶段完成数据的第一次同步。
例如，现在有实例 1（ip：172.16.19.3）和实例 2（ip：172.16.19.5），我们在实例 2 上执行以下这个命令后，实例 2 就变成了实例 1 的从库，并从实例 1 上复制数据：
replicaof 172.16.19.3 6379 主从库间数据第一次同步有三个阶段： 主从库间建立连接、协商同步。主要是为全量复制做准备。在这一步，从库和主库建立起连接，并告诉主库即将进行同步，主库确认回复后，主从库间就可以开始同步了。
具体来说，从库给主库发送 psync 命令，表示要进行数据同步，主库根据这个命令的参数来启动复制。psync 命令包含了主库的 runID 和复制进度 offset 两个参数.
runID，是每个 Redis 实例启动时都会自动生成的一个随机 ID，用来唯一标记这个实例。当从库和主库第一次复制时，因为不知道主库的 runID，所以将 runID 设为“？”。...</p></section><footer class=entry-footer><span title="2022-07-22 00:00:00 +0000 UTC">July 22, 2022</span>&nbsp;·&nbsp;2 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 概览Redis篇四：主从" href=http://yangchnet.github.io/Dessert/posts/cache/%E6%A6%82%E8%A7%88redis%E7%AF%87%E5%9B%9B%E4%B8%BB%E4%BB%8E/></a></article><article class=post-entry><header class=entry-header><h2>实模式和保护模式</h2></header><section class=entry-content><p>8086结构 x86架构中经典的处理器8086的大体结构如下：
其寻址范围为1M
为了暂存数据，8086 处理器内部有 8 个 16 位的通用寄存器，也就是刚才说的 CPU 内部的数据单元，分别是 AX、BX、CX、DX、SP、BP、SI、DI。这些寄存器主要用于在计算过程中暂存数据。这些寄存器比较灵活，其中 AX、BX、CX、DX 可以分成两个 8 位的寄存器来使用，分别是 AH、AL、BH、BL、CH、CL、DH、DL，其中 H 就是 High（高位），L 就是 Low（低位）的意思。
控制单元：
IP 寄存器就是指令指针寄存器（Instruction Pointer Register），指向代码段中下一条指令的位置。CPU 会根据它来不断地将指令从内存的代码段中，加载到 CPU 的指令队列中，然后交给运算单元去执行。
如果需要切换进程，每个进程都分代码段和数据段，为了指向不同进程的地址空间，有四个 16 位的段寄存器，分别是 CS、DS、SS、ES。
其中，CS 就是代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的位置；DS 是数据段的寄存器，通过它可以找到数据在内存中的位置。SS 是栈寄存器（Stack Register）。栈是程序运行中一个特殊的数据结构，数据的存取只能从一端进行，秉承后进先出的原则，push 就是入栈，pop 就是出栈。
存储起始地址的CS和DS都是16位的；存储偏移量的IP寄存器和通用寄存器都是16位的；但8086地址总线是20位的。如何从16位的寄存器寻址到20位的地址？
方法是：起始地址×16+偏移量，也就是把 CS 和 DS 中的值左移 4 位，变成 20 位的，加上 16 位的偏移量，这样就可以得到最终 20 位（1M）的数据地址。
32位处理器 32位处理器必须保持和原来处理器的兼容。
首先，通用寄存器有扩展，可以将 8 个 16 位的扩展到 8 个 32 位的，但是依然可以保留 16 位的和 8 位的使用方式。其中，指向下一条指令的指令指针寄存器 IP，就会扩展成 32 位的，同样也兼容 16 位的。...</p></section><footer class=entry-footer><span title="2022-07-19 00:00:00 +0000 UTC">July 19, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 实模式和保护模式" href=http://yangchnet.github.io/Dessert/posts/os/%E5%AE%9E%E6%A8%A1%E5%BC%8F%E5%92%8C%E4%BF%9D%E6%8A%A4%E6%A8%A1%E5%BC%8F/></a></article><article class=post-entry><header class=entry-header><h2>SOCKET随笔</h2></header><section class=entry-content><p>一个UDP客户可以创建一个套接口并发送一个数据报給一个服务器，然后立即用同一个套接口发送另一个数据报給另一个服务器。同样，一个UDP服务器可以用同一个UDP套接口从5个不同的客户一连串接收5个数据报。
UDP可以是全双工的
TCP连接断开时，主动要求断开的一方会存在TIME_WAIT状态，此状态需要持续60s时间（Linux），在此状态期间，连接未完全断开，依然占用一个socket连接。
存在TIME_WAIT状态的理由：
实现终止TCP全双工连接的可靠性 如果最后一个ACK丢失，服务器将重发最终的FIN，因此客户必须维护状态信息以允许它重发最终的ACK。
允许老的重复分节在网络中消逝。 如果某个连接被关闭后，在以后的某个时刻又重新建立起相同的IP地址可端口之间的TCP连接。后一个连接称为前一个连接的化身（incarnation），因为它们的IP地址和端口号都相同，TCP必须防止来自某个连接的老重复分组在连接终止后再现，从而被误解成属于同一连接的化身。 也就是说，某一个Socket对失效后，在网络中还有针对这个Socket对的分组的情况下又建立了一个一样的Socket对，为了防止网络中针对上一个socket对的分组被误认为是当前连接的分组，必须存在一个时间间隔，使得网络中针对上一个socket对的分组失效。
TCP连接耗尽： 对于客户端来说，其端口耗尽后，就不能再建立连接。 对于服务端来说，其使用socket对server_ip.server_port:client_ip.client_port来标识一个socket连接，对于某个特定服务来说，其server_ip和server_port是不变的，每次有一个连接进来，服务端都会fork出一个自身的子进程来对连接进行服务。这样，可服务的连接数就由client_ip和client_port两个共同决定，client_ip最多有$2^32$个，client_port最多有$2^16$个，因此理论上最多可服务连接数为$2^48$个。但每一个socket连接都需要消耗一个文件描述符，因此最大连接数还收到文件描述符数目的限制。除此之外，socket连接还会占用内存等资源，这些资源也限制了最大连接数。
Unix系统有保留端口的概念，它是小于1024的任何端口。这些端口只能分配給超级用户进程的套接口，所有众所周知的端口（0-1023）都为保留端口，因此分配这些端口的服务器启动时必须具有超级用户的特权。
TCP套接口编程 socket函数 为了执行网络I/O，一个进程必须做的第一件事就是调用socket函数，指定期望的通信协议类型。
#include &lt;sys/socket.h> int socket(int family, int type, int protocol); 其中family指明协议族，type是某个常值，参数protocol一般设为0，除非用在原始套接口上。
对于family，其是以下常值之一：
族 解释 AF_INET IPv4协议 AF_INET6 IPv6协议 AF_LOCAL Unix域协议 AF_ROUTE 路由套接口 AF_KEY 密钥套接口 对于type，其是以下常值之一：...</p></section><footer class=entry-footer><span title="2022-07-18 00:00:00 +0000 UTC">July 18, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to SOCKET随笔" href=http://yangchnet.github.io/Dessert/posts/net/socket%E9%9A%8F%E7%AC%94/></a></article><article class=post-entry><header class=entry-header><h2>概览Redis篇二：AOF日志</h2></header><section class=entry-content><p>极客时间《Redis 核心技术与实战》学习笔记
概览Redis篇一：单线程模型 概览Redis篇二：AOF日志 概览Redis篇三：RDB快照 概览Redis篇四：主从 概览Redis篇五：哨兵 概览Redis篇六：切片集群 AOF: Append Only File
AOF日志的WAL 数据库中的WAL是Write-Ahead Logging, 为先写日志后执行。而Redis中的WAL为Write Ahead Log,先执行后写日志。
为了避免额外的开销，Redis在向AOF里面记录日志时，不回去对这些命令进行语法检查，因此，如果先记录日志再执行命令的话，日志中有可能记录了错误的命令，Redis在使用日志恢复数据时，就可能会出错。
AOF日志中记录了什么内容 有如下命令：
set testkey testvalue 则AOF日志内容为：
*3 $3 set $7 testkey $9 testvalue 其中“*3”表示当前命令有3个部分，每部分都由“$+数字”开头，后面紧跟具体的命令、键或值。
AOF的潜在风险 AOF使用先执行，再写日志的方式，这样可以避免记录错误的命令，同时不会阻塞当前的写操作。
但这样也带来了一些潜在风险：
刚执行完一个命令，没来得及记日志就宕机了，这个命令和相应的数据就有丢失的风险。 AOF避免了对当前命令的阻塞，但AOF写日志是在主线程中执行的，可能会给下一个操作带来阻塞风险。 这就需要我们对AOF写日志的实际进行把控。
AOF的三种写回策略 Always，同步写回：每个写命令执行完，立马同步地将日志写回磁盘；
Everysec，每秒写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，每隔一秒把缓冲区中的内容写入磁盘；
No，操作系统控制的写回：每个写命令执行完，只是先把日志写到 AOF 文件的内存缓冲区，由操作系统决定何时将缓冲区内容写回磁盘。
针对避免主线程阻塞和减少数据丢失问题，这三种写回策略都无法做到两全其美。原因如下：
“同步写回”可以做到基本不丢数据，但是它在每一个写命令后都有一个慢速的落盘操作，不可避免地会影响主线程性能； 虽然“操作系统控制的写回”在写完缓冲区后，就可以继续执行后续的命令，但是落盘的时机已经不在 Redis 手中了，只要 AOF 记录没有写回磁盘，一旦宕机对应的数据就丢失了； “每秒写回”采用一秒写回一次的频率，避免了“同步写回”的性能开销，虽然减少了对系统性能的影响，但是如果发生宕机，上一秒内未落盘的命令操作仍然会丢失。所以，这只能算是，在避免影响主线程性能和避免数据丢失两者间取了个折中。 总结一下：...</p></section><footer class=entry-footer><span title="2022-07-18 00:00:00 +0000 UTC">July 18, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 概览Redis篇二：AOF日志" href=http://yangchnet.github.io/Dessert/posts/cache/%E6%A6%82%E8%A7%88redis%E7%AF%87%E4%BA%8Caof%E6%97%A5%E5%BF%97/></a></article><article class=post-entry><header class=entry-header><h2>概览容器篇一：镜像</h2></header><section class=entry-content><p>1. 分层的镜像 在我们启动一个容器之前，通常需要下载这个容器对应的镜像，以这个镜像为基础启动容器。镜像中包含了对应的程序的二进制文件与其所依赖的文件，程序在启动后看到的rootfs只是这个镜像中存在的文件。这样，我们就可以为容器中的进程提供一个干净的文件系统。
创建一个镜像（image）的最简单方法是使用Dockerfile。
FROMscratchCOPY hello /CMD ["/hello"]scratch是docker为我们提供的一个空镜像，我们可以在此基础上构建任何我们想要的镜像。
在书写Dockerfile时，想必你听说过这么一句话，不要在Dockerfile中创建太多层.
在Dockerfile中，每一个指令都会创建一个新的“层”，这里的层，指的是UnionFS中的一个文件目录。当我们创建了过多的层，会导致镜像体积变大，除此之外，Union FS 也会有最大层数限制。
因此对于如下的Dockerfile文件写法，应尽量避免：
FROMdebian:stretchRUN apt-get updateRUN apt-get install -y gcc libc6-dev make wgetRUN wget -O redis.tar.gz "http://download.redis.io/releases/redis-5.0.3.tar.gz"RUN mkdir -p /usr/src/redisRUN tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1RUN make -C /usr/src/redisRUN make -C /usr/src/redis install可优化为如下写法
FROMdebian:stretchRUN set -x; buildDeps='gcc libc6-dev make wget' \ && apt-get update \ && apt-get install -y $buildDeps \ && wget -O redis.tar.gz "http://download.redis.io/releases/redis-5.0.3.tar.gz" \ && mkdir -p /usr/src/redis \ && tar -xzf redis....</p></section><footer class=entry-footer><span title="2022-07-10 00:00:00 +0000 UTC">July 10, 2022</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 概览容器篇一：镜像" href=http://yangchnet.github.io/Dessert/posts/container/%E6%A6%82%E8%A7%88%E5%AE%B9%E5%99%A8%E7%AF%87%E4%B8%80%E9%95%9C%E5%83%8F/></a></article><article class=post-entry><header class=entry-header><h2>概览Redis篇一：单线程模型</h2></header><section class=entry-content><p>极客时间《Redis 核心技术与实战》学习笔记
概览Redis篇一：单线程模型 概览Redis篇二：AOF日志 概览Redis篇三：RDB快照 概览Redis篇四：主从 概览Redis篇五：哨兵 概览Redis篇六：切片集群 Redis单线程模型 Redis 是单线程，主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。
为什么Redis采用单线程 通常的程序设计都采用多线程来提高性能，获得更快的响应速度。
但采用多线程模型将不可避免地面对以下问题：
多个线程对同一资源的数据竞争 因解决数据竞争而导致的性能损耗 增加系统复杂度，降低系统代码的易调试性和可维护性 为啥Redis单线程还这么快 主要是两点：
Redis大部分操作在内存上完成，并采用了高效的数据结构 Redis采用了多路复用机制</p></section><footer class=entry-footer><span title="2022-07-09 00:00:00 +0000 UTC">July 9, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 概览Redis篇一：单线程模型" href=http://yangchnet.github.io/Dessert/posts/cache/%E6%A6%82%E8%A7%88redis%E7%AF%87%E4%B8%80%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B/></a></article><article class=post-entry><header class=entry-header><h2>inotify</h2></header><section class=entry-content><p>1. 什么是inotify Inotify API提供了一种监视文件系统的机制事件。 Inotify可用于监视单个文件或监视目录。当监视目录时，Inotify将返回目录本身的事件，以及内部的文件目录。
简单的说，就是inotify可以为你监控文件系统的变化，在发生一些事件时通知你。
2. 实验 需要安装inotify-tools包
# arch系统 yay -S inotify-tools inotify-tools提供了两个命令：inotifywait和inotifywatch
2.1 inotifywait 先来看inotifywait,它被用来"Wait for a particular event on a file or set of files.", 也就是说等待在文件上的某些事件发生。使用inotifywait -h查看其支持的参数：
-h show this help info --exclude &lt;pattern> 排除匹配所给正则的所有事件 --excludei &lt;pattern> 类似前一个命令但非敏感 --include &lt;pattern> 排除除匹配正则之外的所有事件 --includei &lt;pattern> 类似前一个命令但非敏感 -m|--monitor 在timeout之前保持监听，若不设置此标志，inotifywait将在一个事件后退出。 -d|--daemon 类似前一个命令但在后台运行，将日志输出到`--outfile`所指定的文件 -P|--no-dereference 不跟踪符号链接 -r|--recursive 递归的监听、 --fromfile &lt;file> Read files to watch from &lt;file> or `-' for stdin. -o|--outfile &lt;file> 输出到&lt;file>而不是标准输出 -s|--syslog 向syslog发送错误而不是Stderr -q|--quiet 只输出事件 -qq 啥也不输出 --format &lt;fmt> 以特定格式输出 --no-newline 在格式化输出后不打印换行符 --timefmt &lt;fmt> strftime-compatible format string for use with %T in --format string....</p></section><footer class=entry-footer><span title="2022-07-04 00:00:00 +0000 UTC">July 4, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to inotify" href=http://yangchnet.github.io/Dessert/posts/linux/inotify/></a></article><article class=post-entry><header class=entry-header><h2>概览MySQL篇〇：MySQL架构</h2></header><section class=entry-content><p>极客时间《MySQL实战45讲》笔记
MySQL的基本结构 大体来说，MySQL 可以分为 Server 层和存储引擎层两部分。
Server 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。
现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。
从一条查询语句看各个模块的执行过程 对于如下语句：
mysql> select * from T where ID=10； 连接器 第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：
mysql -h$ip -P$port -u$user -p 这里要注意的一个问题是：一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。
因为一个连接的权限实在用户名密码认证通过后，连接器到权限表中查出的，之后这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。
查询缓存 连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。
之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果在缓存中可以找到查询结果，可以直接返回结果，如果找不到，就会继续后面的执行阶段。
但大多数情况下缓存往往弊大于利，因为查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。
可以将query_cache_type参数设置为DEMAND,这样对于默认的SQL查询语句都不使用缓存。
需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。
分析器 如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。
分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。
做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。
优化器 经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。...</p></section><footer class=entry-footer><span title="2022-07-02 00:00:00 +0000 UTC">July 2, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 概览MySQL篇〇：MySQL架构" href=http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%A6%82%E8%A7%88mysql%E7%AF%87mysql%E6%9E%B6%E6%9E%84/></a></article><article class=post-entry><header class=entry-header><h2>概览消息队列篇一：不同的mq的消息模型</h2></header><section class=entry-content><p>极客时间《消息队列高手课》笔记
概览消息队列篇〇：为什么需要消息队列 概览消息队列篇一：不同的mq的消息模型 概览消息队列篇二：如何确保消息不丢失 概览消息队列篇三：重复消息的处理 1. 主题和队列 最基本的队列模型，是按照“队列”的数据结构来设计的，即先进先出。生产者发送消息（入队），消费者获取消息（出队）。
当有多个生产者往同一个队列中发送消息，则这个队列中可以消费到的消息，就是这些生产者生产的所有消息的合集。消息的顺序就是这些生产者发送消息的自然顺序。如果有多个消费者接收同一个队列的消息，这些消费者之间实际上是竞争的关系，每个消费者只能收到队列中的一部分消息，也就是说任何一条消息只能被其中的一个消费者收到。
这时候问题就出现了，如果一份消息需要被多个消费者消费，比如，对于一个订单，它需要被风控系统、支付系统等系统消费，显然上述的模型不能满足这个需求。这时候一个可行的解决方案是：为每个消费者创建一个单独的队列，让生产者发送多份。
但显然这样会浪费较多的资源，同一个消息复制了多份。更重要的是，生产者必须知道有多少个消费者。为每个消费者单独发送一份消息，这实际上违背了消息队列“解耦”这个设计初衷。
为了解决这个问题，演化出“发布-订阅”(pub-sub)模型。
在发布-订阅模型中，消息的发送方称为发布者（Publisher），消息的接收方称为订阅者（Subscriber），服务端存放消息的容器称为主题（Topic）。发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。“订阅”在这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。
当发布-订阅模型中只有一个订阅者时，那它和队列模型就基本上是一样的了。也就是说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。
2. 常见mq的消息模型 2.1 RabbitMQ的消息模型 RabbitMQ是少数仍坚持使用队列模型的产品之一。
那么RabbitMQ是如何解决多个消费者的问题呢？
RabbitMQ有一个Exchange模块，在 RabbitMQ 中，Exchange 位于生产者和队列之间，生产者并不关心将消息发送给哪个队列，而是将消息发送给 Exchange，由 Exchange 上配置的策略来决定将消息投递到哪些队列中。
同一份消息如果需要被多个消费者来消费，需要配置 Exchange 将消息发送到多个队列，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。
2.2 RocketMQ的消息模型 RocketMQ 使用的消息模型是标准的发布-订阅模型
但是，在 RocketMQ 也有队列（Queue）这个概念，并且队列在 RocketMQ 中是一个非常重要的概念，要了解队列在RocketMQ中的作用，我们首先要了解消息确认机制及其带来的问题
为了确保消息不会在传递过程中由于网络或服务器故障丢失，消息队列一般采用“请求-确认”机制来确认消息的成功消费。消费者在成功消费一条消息，完成自己的业务逻辑后，会发送确认給消息队列。消息队列只有收到确认后，才认为一条消息被成功消费。
这种机制很好地保证了消息传递过程中的可靠性，但是其带来另一个问题：在某一条消息被成功消费之前，下一条消息是不能被消费的，否则就会出现消息空洞，违背了有序性这个原则。
也就是说，每个主题在任意时刻，至多只能有一个消费者实例在进行消费，那就没法通过水平扩展消费者的数量来提升消费端总体的消费性能。
为了解决这个问题，RocketMQ在主题下增加了队列的概念，每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。
RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的。
RocketMQ 中，订阅者的概念是通过消费组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。
同时，一个消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。如果一条消息被消费者 Consumer1 消费了，那同组的其他消费者就不会再收到这条消息。
在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。
2.3 Kafka的消息模型 Kafka 的消息模型和 RocketMQ 是完全一样的，唯一的区别是，在 Kafka 中，队列这个概念的名称不一样，Kafka 中对应的名称是“分区（Partition）”，含义和功能是没有任何区别的。</p></section><footer class=entry-footer><span title="2022-06-30 00:00:00 +0000 UTC">June 30, 2022</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 概览消息队列篇一：不同的mq的消息模型" href=http://yangchnet.github.io/Dessert/posts/mq/%E6%A6%82%E8%A7%88%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%AF%87%E4%B8%80%E4%B8%8D%E5%90%8C%E7%9A%84mq%E7%9A%84%E6%B6%88%E6%81%AF%E6%A8%A1%E5%9E%8B/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=http://yangchnet.github.io/Dessert/page/4/>« Prev Page</a>
<a class=next href=http://yangchnet.github.io/Dessert/page/6/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2024 <a href=http://yangchnet.github.io/Dessert>Linote</a></span>
<script src=https://utteranc.es/client.js repo=yangchnet/Dessert issue-term=pathname theme=github-light crossorigin=anonymous async></script><span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu');menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>
<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>朴素贝叶斯 | Linote</title>
<meta name="keywords" content="DL&amp;ML" />
<meta name="description" content="朴素贝叶斯 1、理论部分 1.1、贝叶斯公式 $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad\dots(1)$$
其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$
类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。
对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。
基于属性条件独立性假设，贝叶斯公式可重写为： $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad=\frac{P(c)}{P(x)}\prod_{i=1}^d{P(x_i|c)}\dots(2)$$ 其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值
由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\in y}P(c)\prod_{i=1}^d{P(x_i|c)}\dots(3)$$
显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$
令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\frac{|D_c|}{|D|}\dots(4)$$
对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\frac{|D_{c,x_i}|}{|D_c|}\qquad\dots(5)$$ 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\hat{P}(c)=\frac{D_c&#43;1}{|D|&#43;N}\qquad\dots(6)$$ $$\hat{P}(x_i|c)=\frac{D_{c,x_i}&#43;1}{|D|&#43;N}\qquad\dots(7)$$
2、实战演练 2.1、加载数据集 import numpy as np def loadDataSet(): &#34;&#34;&#34; 导入数据， 1代表脏话 @ return postingList: 数据集 @ return classVec: 分类向量 &#34;&#34;&#34; postingList = [[&#39;my&#39;, &#39;dog&#39;, &#39;has&#39;, &#39;flea&#39;, &#39;problems&#39;, &#39;help&#39;, &#39;please&#39;], [&#39;maybe&#39;, &#39;not&#39;, &#39;take&#39;, &#39;him&#39;, &#39;to&#39;, &#39;dog&#39;, &#39;park&#39;, &#39;stupid&#39;], [&#39;my&#39;, &#39;dalmation&#39;, &#39;is&#39;, &#39;so&#39;, &#39;cute&#39;, &#39;I&#39;, &#39;love&#39;, &#39;him&#39;], [&#39;stop&#39;, &#39;posting&#39;, &#39;stupid&#39;, &#39;worthless&#39;, &#39;garbage&#39;], [&#39;mr&#39;, &#39;licks&#39;, &#39;ate&#39;, &#39;my&#39;, &#39;steak&#39;, &#39;how&#39;, &#39;to&#39;, &#39;stop&#39;, &#39;him&#39;], [&#39;quit&#39;, &#39;buying&#39;, &#39;worthless&#39;, &#39;dog&#39;, &#39;food&#39;, &#39;stupid&#39;]] classVec = [0, 1, 0, 1, 0, 1] return postingList, classVec 导入训练集及其分类，1代表是脏话，0代表不是">
<meta name="author" content="李昌">
<link rel="canonical" href="http://lichang.tech/tem/dlml/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" />
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.2d6dbfc6e0f8a1db1c9d082a76dc11d094328cf63f247bbc2421dfaa7f2bb170.css" integrity="sha256-LW2/xuD4odscnQgqdtwR0JQyjPY/JHu8JCHfqn8rsXA=" rel="preload stylesheet" as="style">
<link rel="preload" href="https://raw.githubusercontent.com/lich-Img/blogImg/master/img20210514094119.png" as="image">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.7680afc38aa6b15ddf158a4f3780b7b1f7dde7e91d26f073e6229bb7a0793c92.js" integrity="sha256-doCvw4qmsV3fFYpPN4C3sffd5&#43;kdJvBz5iKbt6B5PJI="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico">
<link rel="icon" type="image/png" sizes="32x32" href="https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon32.ico">
<link rel="apple-touch-icon" href="http://lichang.tech/apple-touch-icon.png">
<link rel="mask-icon" href="http://lichang.tech/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<meta name="generator" content="Hugo 0.81.0" />
<meta property="og:title" content="朴素贝叶斯" />
<meta property="og:description" content="朴素贝叶斯 1、理论部分 1.1、贝叶斯公式 $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad\dots(1)$$
其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$
类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。
对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。
基于属性条件独立性假设，贝叶斯公式可重写为： $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad=\frac{P(c)}{P(x)}\prod_{i=1}^d{P(x_i|c)}\dots(2)$$ 其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值
由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\in y}P(c)\prod_{i=1}^d{P(x_i|c)}\dots(3)$$
显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$
令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\frac{|D_c|}{|D|}\dots(4)$$
对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\frac{|D_{c,x_i}|}{|D_c|}\qquad\dots(5)$$ 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\hat{P}(c)=\frac{D_c&#43;1}{|D|&#43;N}\qquad\dots(6)$$ $$\hat{P}(x_i|c)=\frac{D_{c,x_i}&#43;1}{|D|&#43;N}\qquad\dots(7)$$
2、实战演练 2.1、加载数据集 import numpy as np def loadDataSet(): &#34;&#34;&#34; 导入数据， 1代表脏话 @ return postingList: 数据集 @ return classVec: 分类向量 &#34;&#34;&#34; postingList = [[&#39;my&#39;, &#39;dog&#39;, &#39;has&#39;, &#39;flea&#39;, &#39;problems&#39;, &#39;help&#39;, &#39;please&#39;], [&#39;maybe&#39;, &#39;not&#39;, &#39;take&#39;, &#39;him&#39;, &#39;to&#39;, &#39;dog&#39;, &#39;park&#39;, &#39;stupid&#39;], [&#39;my&#39;, &#39;dalmation&#39;, &#39;is&#39;, &#39;so&#39;, &#39;cute&#39;, &#39;I&#39;, &#39;love&#39;, &#39;him&#39;], [&#39;stop&#39;, &#39;posting&#39;, &#39;stupid&#39;, &#39;worthless&#39;, &#39;garbage&#39;], [&#39;mr&#39;, &#39;licks&#39;, &#39;ate&#39;, &#39;my&#39;, &#39;steak&#39;, &#39;how&#39;, &#39;to&#39;, &#39;stop&#39;, &#39;him&#39;], [&#39;quit&#39;, &#39;buying&#39;, &#39;worthless&#39;, &#39;dog&#39;, &#39;food&#39;, &#39;stupid&#39;]] classVec = [0, 1, 0, 1, 0, 1] return postingList, classVec 导入训练集及其分类，1代表是脏话，0代表不是" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://lichang.tech/tem/dlml/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/" /><meta property="og:image" content="http://lichang.tech/papermod-cover.png"/><meta property="article:section" content="Tem" />
<meta property="article:published_time" content="2021-02-25T00:00:00&#43;00:00" />
<meta property="article:modified_time" content="2021-02-25T00:00:00&#43;00:00" />

<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content="http://lichang.tech/papermod-cover.png"/>

<meta name="twitter:title" content="朴素贝叶斯"/>
<meta name="twitter:description" content="朴素贝叶斯 1、理论部分 1.1、贝叶斯公式 $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad\dots(1)$$
其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$
类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。
对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。
基于属性条件独立性假设，贝叶斯公式可重写为： $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad=\frac{P(c)}{P(x)}\prod_{i=1}^d{P(x_i|c)}\dots(2)$$ 其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值
由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\in y}P(c)\prod_{i=1}^d{P(x_i|c)}\dots(3)$$
显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$
令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\frac{|D_c|}{|D|}\dots(4)$$
对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\frac{|D_{c,x_i}|}{|D_c|}\qquad\dots(5)$$ 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\hat{P}(c)=\frac{D_c&#43;1}{|D|&#43;N}\qquad\dots(6)$$ $$\hat{P}(x_i|c)=\frac{D_{c,x_i}&#43;1}{|D|&#43;N}\qquad\dots(7)$$
2、实战演练 2.1、加载数据集 import numpy as np def loadDataSet(): &#34;&#34;&#34; 导入数据， 1代表脏话 @ return postingList: 数据集 @ return classVec: 分类向量 &#34;&#34;&#34; postingList = [[&#39;my&#39;, &#39;dog&#39;, &#39;has&#39;, &#39;flea&#39;, &#39;problems&#39;, &#39;help&#39;, &#39;please&#39;], [&#39;maybe&#39;, &#39;not&#39;, &#39;take&#39;, &#39;him&#39;, &#39;to&#39;, &#39;dog&#39;, &#39;park&#39;, &#39;stupid&#39;], [&#39;my&#39;, &#39;dalmation&#39;, &#39;is&#39;, &#39;so&#39;, &#39;cute&#39;, &#39;I&#39;, &#39;love&#39;, &#39;him&#39;], [&#39;stop&#39;, &#39;posting&#39;, &#39;stupid&#39;, &#39;worthless&#39;, &#39;garbage&#39;], [&#39;mr&#39;, &#39;licks&#39;, &#39;ate&#39;, &#39;my&#39;, &#39;steak&#39;, &#39;how&#39;, &#39;to&#39;, &#39;stop&#39;, &#39;him&#39;], [&#39;quit&#39;, &#39;buying&#39;, &#39;worthless&#39;, &#39;dog&#39;, &#39;food&#39;, &#39;stupid&#39;]] classVec = [0, 1, 0, 1, 0, 1] return postingList, classVec 导入训练集及其分类，1代表是脏话，0代表不是"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Tems",
      "item": "http://lichang.tech/tem/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "朴素贝叶斯",
      "item": "http://lichang.tech/tem/dlml/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "朴素贝叶斯",
  "name": "朴素贝叶斯",
  "description": "朴素贝叶斯 1、理论部分 1.1、贝叶斯公式 $$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\qquad\\dots(1)$$\n其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$\n类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。\n对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。\n基于属性条件独立性假设，贝叶斯公式可重写为： $$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\qquad=\\frac{P(c)}{P(x)}\\prod_{i=1}^d{P(x_i|c)}\\dots(2)$$ 其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值\n由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\\in y}P(c)\\prod_{i=1}^d{P(x_i|c)}\\dots(3)$$\n显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$\n令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\\frac{|D_c|}{|D|}\\dots(4)$$\n对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\\qquad\\dots(5)$$ 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\\hat{P}(c)=\\frac{D_c+1}{|D|+N}\\qquad\\dots(6)$$ $$\\hat{P}(x_i|c)=\\frac{D_{c,x_i}+1}{|D|+N}\\qquad\\dots(7)$$\n2、实战演练 2.1、加载数据集 import numpy as np def loadDataSet(): \u0026#34;\u0026#34;\u0026#34; 导入数据， 1代表脏话 @ return postingList: 数据集 @ return classVec: 分类向量 \u0026#34;\u0026#34;\u0026#34; postingList = [[\u0026#39;my\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;has\u0026#39;, \u0026#39;flea\u0026#39;, \u0026#39;problems\u0026#39;, \u0026#39;help\u0026#39;, \u0026#39;please\u0026#39;], [\u0026#39;maybe\u0026#39;, \u0026#39;not\u0026#39;, \u0026#39;take\u0026#39;, \u0026#39;him\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;park\u0026#39;, \u0026#39;stupid\u0026#39;], [\u0026#39;my\u0026#39;, \u0026#39;dalmation\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;so\u0026#39;, \u0026#39;cute\u0026#39;, \u0026#39;I\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;him\u0026#39;], [\u0026#39;stop\u0026#39;, \u0026#39;posting\u0026#39;, \u0026#39;stupid\u0026#39;, \u0026#39;worthless\u0026#39;, \u0026#39;garbage\u0026#39;], [\u0026#39;mr\u0026#39;, \u0026#39;licks\u0026#39;, \u0026#39;ate\u0026#39;, \u0026#39;my\u0026#39;, \u0026#39;steak\u0026#39;, \u0026#39;how\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;stop\u0026#39;, \u0026#39;him\u0026#39;], [\u0026#39;quit\u0026#39;, \u0026#39;buying\u0026#39;, \u0026#39;worthless\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;food\u0026#39;, \u0026#39;stupid\u0026#39;]] classVec = [0, 1, 0, 1, 0, 1] return postingList, classVec 导入训练集及其分类，1代表是脏话，0代表不是",
  "keywords": [
    "DL\u0026ML"
  ],
  "articleBody": "朴素贝叶斯 1、理论部分 1.1、贝叶斯公式 $$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\qquad\\dots(1)$$\n其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$\n类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。\n对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。\n基于属性条件独立性假设，贝叶斯公式可重写为： $$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\qquad=\\frac{P(c)}{P(x)}\\prod_{i=1}^d{P(x_i|c)}\\dots(2)$$ 其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值\n由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\\in y}P(c)\\prod_{i=1}^d{P(x_i|c)}\\dots(3)$$\n显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$\n令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\\frac{|D_c|}{|D|}\\dots(4)$$\n对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\\qquad\\dots(5)$$ 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\\hat{P}(c)=\\frac{D_c+1}{|D|+N}\\qquad\\dots(6)$$ $$\\hat{P}(x_i|c)=\\frac{D_{c,x_i}+1}{|D|+N}\\qquad\\dots(7)$$\n2、实战演练 2.1、加载数据集 import numpy as np def loadDataSet(): \"\"\" 导入数据， 1代表脏话 @ return postingList: 数据集 @ return classVec: 分类向量 \"\"\" postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] classVec = [0, 1, 0, 1, 0, 1] return postingList, classVec 导入训练集及其分类，1代表是脏话，0代表不是\nloadDataSet() ([['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']], [0, 1, 0, 1, 0, 1])  2.2、创建单词表 将训练数据中的每一个词都存储到词库中。\ndef createVocabList(dataSet): \"\"\" 创建词库 @ param dataSet: 数据集 @ return vocabSet: 词库 \"\"\" vocabSet = set([]) for document in dataSet: # 求并集 vocabSet = vocabSet | set(document) return list(vocabSet) listOPosts, listClasses = loadDataSet() myVocabList = createVocabList(listOPosts) myVocabList ['quit', 'how', 'problems', 'mr', 'dalmation', 'garbage', 'love', 'stop', 'maybe', 'him', 'take', 'to', 'stupid', 'food', 'not', 'cute', 'buying', 'flea', 'park', 'help', 'ate', 'dog', 'licks', 'please', 'so', 'has', 'my', 'is', 'posting', 'I', 'steak', 'worthless']  2.3、生成词向量 def setOfWords2Vec(vocabList, inputSet): \"\"\" 文本词向量.词库中每个词当作一个特征，文本中有该词，该词特征就是1，没有就是0 @ param vocabList: 词表 @ param inputSet: 输入的数据集 @ return returnVec: 返回的向量 \"\"\" returnVec = [0] * len(vocabList) for word in inputSet: if word in vocabList: returnVec[vocabList.index(word)] = 1 else: print(\"单词: %s不在词库中!\" % word) return returnVec testEntry = ['love', 'my', 'dalmation'] thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry)) thisDoc array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])  2.4、训练分类器 def trainNB0(trainMatrix, trainCategory): \"\"\" 训练 @ param trainMatrix: 训练集 @ param trainCategory: 分类 \"\"\" numTrainDocs = len(trainMatrix) # 训练数据的长度 numWords = len(trainMatrix[0]) # 训练数据的词汇量 pAbusive = sum(trainCategory) / float(numTrainDocs) # 防止某个类别计算出的概率为0，导致最后相乘都为0，所以初始词都赋值1，分母赋值为2. 拉普拉斯修正 p0Num = np.ones(numWords) # 分子 p1Num = np.ones(numWords) p0Denom = 2 # 分母 p1Denom = 2 for i in range(numTrainDocs): if trainCategory[i] == 1: p1Num += trainMatrix[i] p1Denom += sum(trainMatrix[i]) else: p0Num += trainMatrix[i] p0Denom += sum(trainMatrix[i]) # 这里使用log函数，方便计算，因为最后是比较大小，所有对结果没有影响。 p1Vect = np.log(p1Num / p1Denom) # P^(x_1|c) p0Vect = np.log(p0Num / p0Denom) # P^(x_2|c) return p0Vect, p1Vect, pAbusive 2.5、 进行分类 def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1): \"\"\" 判断大小 \"\"\" p1 = sum(vec2Classify * p1Vec) # P(c)*P(x_1|c) p0 = sum(vec2Classify * p0Vec) # P(c)*P(x_2|c) if p1  p0: return 1 else: return 0 2.6、测试 def testingNB(): listOPosts, listClasses = loadDataSet() myVocabList = createVocabList(listOPosts) trainMat = [] for postinDoc in listOPosts: trainMat.append(setOfWords2Vec(myVocabList, postinDoc)) print(trainMat) # 查看训练集矩阵 p0V, p1V, pAb = trainNB0(np.array(trainMat), np.array(listClasses)) testEntry = ['love', 'my', 'dalmation'] thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry)) print(testEntry, 'classified as: ', classifyNB(thisDoc, p0V, p1V, pAb)) testEntry = ['stupid', 'garbage'] thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry)) print(testEntry, 'classified as: ', classifyNB(thisDoc, p0V, p1V, pAb)) testingNB() [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1], [0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]] ['love', 'my', 'dalmation'] classified as: 0 ['stupid', 'garbage'] classified as: 1  ",
  "wordCount" : "688",
  "inLanguage": "en",
  "datePublished": "2021-02-25T00:00:00Z",
  "dateModified": "2021-02-25T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "李昌"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "http://lichang.tech/tem/dlml/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Linote",
    "logo": {
      "@type": "ImageObject",
      "url": "https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<noscript>
    <style type="text/css">
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: #1d1e20;
                --entry: #2e2e33;
                --primary: rgba(255, 255, 255, 0.84);
                --secondary: rgba(255, 255, 255, 0.56);
                --tertiary: rgba(255, 255, 255, 0.16);
                --content: rgba(255, 255, 255, 0.74);
                --hljs-bg: #2e2e33;
                --code-bg: #37383e;
                --border: #333;
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://lichang.tech/" accesskey="h" title="Linote (Alt + H)">Linote</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="http://lichang.tech/archives" title="存档">
                    <span>存档</span>
                </a>
            </li>
            <li>
                <a href="http://lichang.tech/categories/" title="分类">
                    <span>分类</span>
                </a>
            </li>
            <li>
                <a href="http://lichang.tech/search/" title="搜索">
                    <span>搜索</span>
                </a>
            </li>
            <li>
                <a href="http://lichang.tech/tags/" title="标签">
                    <span>标签</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="http://lichang.tech/">Home</a>&nbsp;»&nbsp;<a href="http://lichang.tech/tem/">Tems</a></div>
    <h1 class="post-title">
      朴素贝叶斯
    </h1>
    <div class="post-meta">February 25, 2021&nbsp;·&nbsp;4 min&nbsp;·&nbsp;李昌
</div>
  </header> <div class="toc">
    <details  open>
        <summary accesskey="c" title="(Alt + C)">
            <div class="details">Table of Contents</div>
        </summary>
        <div class="inner"><ul>
                <li>
                    <a href="#%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af" aria-label="朴素贝叶斯">朴素贝叶斯</a><ul>
                        
                <li>
                    <a href="#1%e7%90%86%e8%ae%ba%e9%83%a8%e5%88%86" aria-label="1、理论部分">1、理论部分</a><ul>
                        
                <li>
                    <a href="#11%e8%b4%9d%e5%8f%b6%e6%96%af%e5%85%ac%e5%bc%8f" aria-label="1.1、贝叶斯公式">1.1、贝叶斯公式</a></li></ul>
                </li>
                <li>
                    <a href="#2%e5%ae%9e%e6%88%98%e6%bc%94%e7%bb%83" aria-label="2、实战演练">2、实战演练</a><ul>
                        
                <li>
                    <a href="#21%e5%8a%a0%e8%bd%bd%e6%95%b0%e6%8d%ae%e9%9b%86" aria-label="2.1、加载数据集">2.1、加载数据集</a></li>
                <li>
                    <a href="#22%e5%88%9b%e5%bb%ba%e5%8d%95%e8%af%8d%e8%a1%a8" aria-label="2.2、创建单词表">2.2、创建单词表</a></li>
                <li>
                    <a href="#23%e7%94%9f%e6%88%90%e8%af%8d%e5%90%91%e9%87%8f" aria-label="2.3、生成词向量">2.3、生成词向量</a></li>
                <li>
                    <a href="#24%e8%ae%ad%e7%bb%83%e5%88%86%e7%b1%bb%e5%99%a8" aria-label="2.4、训练分类器">2.4、训练分类器</a></li>
                <li>
                    <a href="#25-%e8%bf%9b%e8%a1%8c%e5%88%86%e7%b1%bb" aria-label="2.5、 进行分类">2.5、 进行分类</a></li>
                <li>
                    <a href="#26%e6%b5%8b%e8%af%95" aria-label="2.6、测试">2.6、测试</a>
                </li>
            </ul>
            </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="朴素贝叶斯">朴素贝叶斯<a hidden class="anchor" aria-hidden="true" href="#朴素贝叶斯">#</a></h1>
<h2 id="1理论部分">1、理论部分<a hidden class="anchor" aria-hidden="true" href="#1理论部分">#</a></h2>
<h3 id="11贝叶斯公式">1.1、贝叶斯公式<a hidden class="anchor" aria-hidden="true" href="#11贝叶斯公式">#</a></h3>
<p>$$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad\dots(1)$$<br>
其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$<br>
类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。<br>
对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。<br>
基于属性条件独立性假设，贝叶斯公式可重写为：  $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad=\frac{P(c)}{P(x)}\prod_{i=1}^d{P(x_i|c)}\dots(2)$$
其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值<br>
由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\in y}P(c)\prod_{i=1}^d{P(x_i|c)}\dots(3)$$<br>
显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$<br>
令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\frac{|D_c|}{|D|}\dots(4)$$<br>
对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\frac{|D_{c,x_i}|}{|D_c|}\qquad\dots(5)$$
为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\hat{P}(c)=\frac{D_c+1}{|D|+N}\qquad\dots(6)$$  $$\hat{P}(x_i|c)=\frac{D_{c,x_i}+1}{|D|+N}\qquad\dots(7)$$</p>
<h2 id="2实战演练">2、实战演练<a hidden class="anchor" aria-hidden="true" href="#2实战演练">#</a></h2>
<h3 id="21加载数据集">2.1、加载数据集<a hidden class="anchor" aria-hidden="true" href="#21加载数据集">#</a></h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#f92672">import</span> numpy <span style="color:#f92672">as</span> np
<span style="color:#66d9ef">def</span> <span style="color:#a6e22e">loadDataSet</span>():
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    导入数据， 1代表脏话
</span><span style="color:#e6db74">    @ return postingList: 数据集
</span><span style="color:#e6db74">    @ return classVec: 分类向量
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    postingList <span style="color:#f92672">=</span> [[<span style="color:#e6db74">&#39;my&#39;</span>, <span style="color:#e6db74">&#39;dog&#39;</span>, <span style="color:#e6db74">&#39;has&#39;</span>, <span style="color:#e6db74">&#39;flea&#39;</span>, <span style="color:#e6db74">&#39;problems&#39;</span>, <span style="color:#e6db74">&#39;help&#39;</span>, <span style="color:#e6db74">&#39;please&#39;</span>],
                   [<span style="color:#e6db74">&#39;maybe&#39;</span>, <span style="color:#e6db74">&#39;not&#39;</span>, <span style="color:#e6db74">&#39;take&#39;</span>, <span style="color:#e6db74">&#39;him&#39;</span>, <span style="color:#e6db74">&#39;to&#39;</span>, <span style="color:#e6db74">&#39;dog&#39;</span>, <span style="color:#e6db74">&#39;park&#39;</span>, <span style="color:#e6db74">&#39;stupid&#39;</span>],
                   [<span style="color:#e6db74">&#39;my&#39;</span>, <span style="color:#e6db74">&#39;dalmation&#39;</span>, <span style="color:#e6db74">&#39;is&#39;</span>, <span style="color:#e6db74">&#39;so&#39;</span>, <span style="color:#e6db74">&#39;cute&#39;</span>, <span style="color:#e6db74">&#39;I&#39;</span>, <span style="color:#e6db74">&#39;love&#39;</span>, <span style="color:#e6db74">&#39;him&#39;</span>],
                   [<span style="color:#e6db74">&#39;stop&#39;</span>, <span style="color:#e6db74">&#39;posting&#39;</span>, <span style="color:#e6db74">&#39;stupid&#39;</span>, <span style="color:#e6db74">&#39;worthless&#39;</span>, <span style="color:#e6db74">&#39;garbage&#39;</span>],
                   [<span style="color:#e6db74">&#39;mr&#39;</span>, <span style="color:#e6db74">&#39;licks&#39;</span>, <span style="color:#e6db74">&#39;ate&#39;</span>, <span style="color:#e6db74">&#39;my&#39;</span>, <span style="color:#e6db74">&#39;steak&#39;</span>, <span style="color:#e6db74">&#39;how&#39;</span>, <span style="color:#e6db74">&#39;to&#39;</span>, <span style="color:#e6db74">&#39;stop&#39;</span>, <span style="color:#e6db74">&#39;him&#39;</span>],
                   [<span style="color:#e6db74">&#39;quit&#39;</span>, <span style="color:#e6db74">&#39;buying&#39;</span>, <span style="color:#e6db74">&#39;worthless&#39;</span>, <span style="color:#e6db74">&#39;dog&#39;</span>, <span style="color:#e6db74">&#39;food&#39;</span>, <span style="color:#e6db74">&#39;stupid&#39;</span>]]
    classVec <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>]
    <span style="color:#66d9ef">return</span> postingList, classVec
</code></pre></div><p>导入训练集及其分类，1代表是脏话，0代表不是</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">loadDataSet()
</code></pre></div><pre><code>([['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'],
  ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'],
  ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'],
  ['stop', 'posting', 'stupid', 'worthless', 'garbage'],
  ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'],
  ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']],
 [0, 1, 0, 1, 0, 1])
</code></pre>
<h3 id="22创建单词表">2.2、创建单词表<a hidden class="anchor" aria-hidden="true" href="#22创建单词表">#</a></h3>
<p>将训练数据中的每一个词都存储到词库中。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">createVocabList</span>(dataSet):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    创建词库
</span><span style="color:#e6db74">    @ param dataSet: 数据集
</span><span style="color:#e6db74">    @ return vocabSet: 词库
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    vocabSet <span style="color:#f92672">=</span> set([])
    <span style="color:#66d9ef">for</span> document <span style="color:#f92672">in</span> dataSet:
        <span style="color:#75715e"># 求并集</span>
        vocabSet <span style="color:#f92672">=</span> vocabSet <span style="color:#f92672">|</span> set(document)
    <span style="color:#66d9ef">return</span> list(vocabSet)
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">listOPosts, listClasses <span style="color:#f92672">=</span> loadDataSet()
myVocabList <span style="color:#f92672">=</span> createVocabList(listOPosts)
myVocabList
</code></pre></div><pre><code>['quit',
 'how',
 'problems',
 'mr',
 'dalmation',
 'garbage',
 'love',
 'stop',
 'maybe',
 'him',
 'take',
 'to',
 'stupid',
 'food',
 'not',
 'cute',
 'buying',
 'flea',
 'park',
 'help',
 'ate',
 'dog',
 'licks',
 'please',
 'so',
 'has',
 'my',
 'is',
 'posting',
 'I',
 'steak',
 'worthless']
</code></pre>
<h3 id="23生成词向量">2.3、生成词向量<a hidden class="anchor" aria-hidden="true" href="#23生成词向量">#</a></h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">setOfWords2Vec</span>(vocabList, inputSet):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    文本词向量.词库中每个词当作一个特征，文本中有该词，该词特征就是1，没有就是0
</span><span style="color:#e6db74">    @ param vocabList: 词表
</span><span style="color:#e6db74">    @ param inputSet: 输入的数据集
</span><span style="color:#e6db74">    @ return returnVec: 返回的向量
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    returnVec <span style="color:#f92672">=</span> [<span style="color:#ae81ff">0</span>] <span style="color:#f92672">*</span> len(vocabList)
    <span style="color:#66d9ef">for</span> word <span style="color:#f92672">in</span> inputSet:
        <span style="color:#66d9ef">if</span> word <span style="color:#f92672">in</span> vocabList:
            returnVec[vocabList<span style="color:#f92672">.</span>index(word)] <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>
        <span style="color:#66d9ef">else</span>:
            <span style="color:#66d9ef">print</span>(<span style="color:#e6db74">&#34;单词: </span><span style="color:#e6db74">%s</span><span style="color:#e6db74"> 不在词库中!&#34;</span> <span style="color:#f92672">%</span> word)
    <span style="color:#66d9ef">return</span> returnVec
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">testEntry <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;love&#39;</span>, <span style="color:#e6db74">&#39;my&#39;</span>, <span style="color:#e6db74">&#39;dalmation&#39;</span>]
thisDoc <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(setOfWords2Vec(myVocabList, testEntry))
thisDoc
</code></pre></div><pre><code>array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
       0, 0, 0, 0, 1, 0, 0, 0, 0, 0])
</code></pre>
<h3 id="24训练分类器">2.4、训练分类器<a hidden class="anchor" aria-hidden="true" href="#24训练分类器">#</a></h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">trainNB0</span>(trainMatrix, trainCategory):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    训练
</span><span style="color:#e6db74">    @ param trainMatrix: 训练集
</span><span style="color:#e6db74">    @ param trainCategory: 分类
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    numTrainDocs <span style="color:#f92672">=</span> len(trainMatrix)   <span style="color:#75715e"># 训练数据的长度</span>
    numWords <span style="color:#f92672">=</span> len(trainMatrix[<span style="color:#ae81ff">0</span>])    <span style="color:#75715e"># 训练数据的词汇量</span>
    pAbusive <span style="color:#f92672">=</span> sum(trainCategory) <span style="color:#f92672">/</span> float(numTrainDocs)
    <span style="color:#75715e"># 防止某个类别计算出的概率为0，导致最后相乘都为0，所以初始词都赋值1，分母赋值为2.  拉普拉斯修正</span>
    p0Num <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>ones(numWords)   <span style="color:#75715e"># 分子</span>
    p1Num <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>ones(numWords)
    p0Denom <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>   <span style="color:#75715e"># 分母</span>
    p1Denom <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>
    <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(numTrainDocs):
        <span style="color:#66d9ef">if</span> trainCategory[i] <span style="color:#f92672">==</span> <span style="color:#ae81ff">1</span>:
            p1Num <span style="color:#f92672">+=</span> trainMatrix[i]
            p1Denom <span style="color:#f92672">+=</span> sum(trainMatrix[i])
        <span style="color:#66d9ef">else</span>:
            p0Num <span style="color:#f92672">+=</span> trainMatrix[i]
            p0Denom <span style="color:#f92672">+=</span> sum(trainMatrix[i])
    <span style="color:#75715e"># 这里使用log函数，方便计算，因为最后是比较大小，所有对结果没有影响。</span>
    p1Vect <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log(p1Num <span style="color:#f92672">/</span> p1Denom)   <span style="color:#75715e"># P^(x_1|c)</span>
    p0Vect <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>log(p0Num <span style="color:#f92672">/</span> p0Denom)   <span style="color:#75715e"># P^(x_2|c)</span>
    <span style="color:#66d9ef">return</span> p0Vect, p1Vect, pAbusive
</code></pre></div><h3 id="25-进行分类">2.5、 进行分类<a hidden class="anchor" aria-hidden="true" href="#25-进行分类">#</a></h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">classifyNB</span>(vec2Classify, p0Vec, p1Vec, pClass1):
    <span style="color:#e6db74">&#34;&#34;&#34;
</span><span style="color:#e6db74">    判断大小
</span><span style="color:#e6db74">    &#34;&#34;&#34;</span>
    p1 <span style="color:#f92672">=</span> sum(vec2Classify <span style="color:#f92672">*</span> p1Vec)  <span style="color:#75715e"># P(c)*P(x_1|c)</span>
    p0 <span style="color:#f92672">=</span> sum(vec2Classify <span style="color:#f92672">*</span> p0Vec)  <span style="color:#75715e"># P(c)*P(x_2|c)</span>
    <span style="color:#66d9ef">if</span> p1 <span style="color:#f92672">&gt;</span> p0:
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">1</span>
    <span style="color:#66d9ef">else</span>:
        <span style="color:#66d9ef">return</span> <span style="color:#ae81ff">0</span>
</code></pre></div><h3 id="26测试">2.6、测试<a hidden class="anchor" aria-hidden="true" href="#26测试">#</a></h3>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python"><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">testingNB</span>():
    listOPosts, listClasses <span style="color:#f92672">=</span> loadDataSet()
    myVocabList <span style="color:#f92672">=</span> createVocabList(listOPosts)
    trainMat <span style="color:#f92672">=</span> []
    <span style="color:#66d9ef">for</span> postinDoc <span style="color:#f92672">in</span> listOPosts:
        trainMat<span style="color:#f92672">.</span>append(setOfWords2Vec(myVocabList, postinDoc))
    <span style="color:#66d9ef">print</span>(trainMat)   <span style="color:#75715e"># 查看训练集矩阵</span>
    p0V, p1V, pAb <span style="color:#f92672">=</span> trainNB0(np<span style="color:#f92672">.</span>array(trainMat), np<span style="color:#f92672">.</span>array(listClasses))
    testEntry <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;love&#39;</span>, <span style="color:#e6db74">&#39;my&#39;</span>, <span style="color:#e6db74">&#39;dalmation&#39;</span>]
    thisDoc <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(setOfWords2Vec(myVocabList, testEntry))
    <span style="color:#66d9ef">print</span>(testEntry, <span style="color:#e6db74">&#39;classified as: &#39;</span>, classifyNB(thisDoc, p0V, p1V, pAb))
    testEntry <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;stupid&#39;</span>, <span style="color:#e6db74">&#39;garbage&#39;</span>]
    thisDoc <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(setOfWords2Vec(myVocabList, testEntry))
    <span style="color:#66d9ef">print</span>(testEntry, <span style="color:#e6db74">&#39;classified as: &#39;</span>, classifyNB(thisDoc, p0V, p1V, pAb))
</code></pre></div><div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-python" data-lang="python">testingNB()
</code></pre></div><pre><code>[[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1], [0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]]
['love', 'my', 'dalmation'] classified as:  0
['stupid', 'garbage'] classified as:  1
</code></pre>

</div>
  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="http://lichang.tech/tags/dlml/">DL&amp;ML</a></li>
    </ul>

<div class="share-buttons">
    <a target="_blank" rel="noopener noreferrer" aria-label="share 朴素贝叶斯 on twitter"
        href="https://twitter.com/intent/tweet/?text=%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af&amp;url=http%3a%2f%2flichang.tech%2ftem%2fdlml%2f%25E6%259C%25B4%25E7%25B4%25A0%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f&amp;hashtags=DL%26ML">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-253.927,424.544c135.939,0 210.268,-112.643 210.268,-210.268c0,-3.218 0,-6.437 -0.153,-9.502c14.406,-10.421 26.973,-23.448 36.935,-38.314c-13.18,5.824 -27.433,9.809 -42.452,11.648c15.326,-9.196 26.973,-23.602 32.49,-40.92c-14.252,8.429 -30.038,14.56 -46.896,17.931c-13.487,-14.406 -32.644,-23.295 -53.946,-23.295c-40.767,0 -73.87,33.104 -73.87,73.87c0,5.824 0.613,11.494 1.992,16.858c-61.456,-3.065 -115.862,-32.49 -152.337,-77.241c-6.284,10.881 -9.962,23.601 -9.962,37.088c0,25.594 13.027,48.276 32.95,61.456c-12.107,-0.307 -23.448,-3.678 -33.41,-9.196l0,0.92c0,35.862 25.441,65.594 59.311,72.49c-6.13,1.686 -12.72,2.606 -19.464,2.606c-4.751,0 -9.348,-0.46 -13.946,-1.38c9.349,29.426 36.628,50.728 68.965,51.341c-25.287,19.771 -57.164,31.571 -91.8,31.571c-5.977,0 -11.801,-0.306 -17.625,-1.073c32.337,21.15 71.264,33.41 112.95,33.41Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 朴素贝叶斯 on linkedin"
        href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flichang.tech%2ftem%2fdlml%2f%25E6%259C%25B4%25E7%25B4%25A0%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f&amp;title=%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af&amp;summary=%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af&amp;source=http%3a%2f%2flichang.tech%2ftem%2fdlml%2f%25E6%259C%25B4%25E7%25B4%25A0%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 朴素贝叶斯 on reddit"
        href="https://reddit.com/submit?url=http%3a%2f%2flichang.tech%2ftem%2fdlml%2f%25E6%259C%25B4%25E7%25B4%25A0%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f&title=%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 朴素贝叶斯 on facebook"
        href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flichang.tech%2ftem%2fdlml%2f%25E6%259C%25B4%25E7%25B4%25A0%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 朴素贝叶斯 on whatsapp"
        href="https://api.whatsapp.com/send?text=%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af%20-%20http%3a%2f%2flichang.tech%2ftem%2fdlml%2f%25E6%259C%25B4%25E7%25B4%25A0%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f">
        <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve">
            <path
                d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
        </svg>
    </a>
    <a target="_blank" rel="noopener noreferrer" aria-label="share 朴素贝叶斯 on telegram"
        href="https://telegram.me/share/url?text=%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af&amp;url=http%3a%2f%2flichang.tech%2ftem%2fdlml%2f%25E6%259C%25B4%25E7%25B4%25A0%25E8%25B4%259D%25E5%258F%25B6%25E6%2596%25AF%2f">
        <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28">
            <path
                d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
        </svg>
    </a>
</div>

  </footer>
</article>
    </main>
    <footer class="footer">
    <span>&copy; 2021 <a href="http://lichang.tech/">Linote</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/contrib/auto-render.min.js"></script>

    <script>
    document.addEventListener("DOMContentLoaded", function() {
	          renderMathInElement(document.body, {
			                delimiters: [
						                  {left: "$$", right: "$$", display: true},
								                    {left: "$", right: "$", display: false}
					              ]
							                });
		      });
    </script>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)">
    <button class="top-link" id="top-link" type="button" accesskey="g">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z" />
        </svg>
    </button>
</a>

<script>
    let menu = document.getElementById('menu')
    menu.scrollLeft = localStorage.getItem("menu-scroll-position");
    menu.onscroll = function () {
        localStorage.setItem("menu-scroll-position", menu.scrollLeft);
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>

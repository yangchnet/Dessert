<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>DL&ML | Linote</title><meta name=keywords content><meta name=description content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"><meta name=author content="李昌"><link rel=canonical href=http://yangchnet.github.io/Dessert/tags/dlml/><link crossorigin=anonymous href=/Dessert/assets/css/stylesheet.min.5e2b4101351c21e906f398ae96901791830f58d430f96f2659dab7eaef7b3cb7.css integrity="sha256-XitBATUcIekG85iulpAXkYMPWNQw+W8mWdq36u97PLc=" rel="preload stylesheet" as=style><link rel=icon href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon.ico><link rel=icon type=image/png sizes=32x32 href=https://raw.githubusercontent.com/lich-Img/blogImg/master/favicon32.ico><link rel=apple-touch-icon href=http://yangchnet.github.io/Dessert/apple-touch-icon.png><link rel=mask-icon href=http://yangchnet.github.io/Dessert/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.81.0"><link rel=alternate type=application/rss+xml href=http://yangchnet.github.io/Dessert/tags/dlml/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="DL&ML"><meta property="og:description" content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"><meta property="og:type" content="website"><meta property="og:url" content="http://yangchnet.github.io/Dessert/tags/dlml/"><meta property="og:image" content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://yangchnet.github.io/Dessert/papermod-cover.png"><meta name=twitter:title content="DL&ML"><meta name=twitter:description content="Theme PaperMod - https://github.com/adityatelange/hugo-PaperMod"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add('dark'):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove('dark'):window.matchMedia('(prefers-color-scheme: dark)').matches&&document.body.classList.add('dark')</script><header class=header><nav class=nav><div class=logo><a href=http://yangchnet.github.io/Dessert accesskey=h title="Linote (Alt + H)">Linote</a>
<span class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></span></div><ul id=menu><li><a href=http://yangchnet.github.io/Dessert/archives/ title=存档><span>存档</span></a></li><li><a href=http://yangchnet.github.io/Dessert/categories/ title=分类><span>分类</span></a></li><li><a href=http://yangchnet.github.io/Dessert/search/ title=搜索><span>搜索</span></a></li><li><a href=http://yangchnet.github.io/Dessert/tags/ title=标签><span>标签</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=http://yangchnet.github.io/Dessert>Home</a>&nbsp;»&nbsp;<a href=http://yangchnet.github.io/Dessert/tags/>Tags</a></div><h1>DL&ML</h1></header><article class="post-entry tag-entry"><header class=entry-header><h2>Importsomedatatoplaywith</h2></header><section class=entry-content><p>%matplotlib inline ======================================= Receiver Operating Characteristic (ROC) Example of Receiver Operating Characteristic (ROC) metric to evaluate classifier output quality.
ROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the “ideal” point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better....</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;4 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to Importsomedatatoplaywith" href=http://yangchnet.github.io/Dessert/posts/dlml/plot_roc/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>Keras函数式API</h2></header><section class=entry-content><p>Keras函数式API 使用函数式API，你可以直接操作张量，也可以把层当做函数来使用，接收张量并返回张量。
# 简单的实例 import os # **** change the warning level **** os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' from keras.models import Sequential, Model from keras import layers from keras import Input # 使用Sequential模型 seq_model = Sequential() seq_model.add(layers.Dense(32, activation='relu', input_shape=(64,))) seq_model.add(layers.Dense(32, activation='relu')) seq_model.add(layers.Dense(10, activation='softmax')) # 对应的函数式API实现 input_tensor = Input(shape=(64,)) x = layers.Dense(32, activation='relu')(input_tensor) x = layers.Dense(32, activation='softmax')(x) output_tensor = layers.Dense(10, activation='softmax')(x) model = Model(input_tensor, output_tensor) model.summary() Model: "model_2" _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) (None, 64) 0 _________________________________________________________________ dense_10 (Dense) (None, 32) 2080 _________________________________________________________________ dense_11 (Dense) (None, 32) 1056 _________________________________________________________________ dense_12 (Dense) (None, 10) 330 ================================================================= Total params: 3,466 Trainable params: 3,466 Non-trainable params: 0 _________________________________________________________________ Keras会在后台检索从input_tensor到output_tensor所包含的每一层，并将这些层组合成一个类图的数据结构，即一个Model。这种方法有效的原因在于，output_tensor是通过对input_tensor进行多次变换得到的。如果你试图利用不相关的输入和输出来构建一个模型，那么会得到RuntimeError...</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;2 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to Keras函数式API" href=http://yangchnet.github.io/Dessert/posts/dlml/keras%E5%87%BD%E6%95%B0%E5%BC%8Fapi/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>SimpleSupportVectorMachine</h2></header><section class=entry-content><p>Simple Support Vector Machine First we will import numpy to easily manage linear algebra and calculus operations in python. To plot the learning progress later on, we will use matplotlib.
import numpy as np from matplotlib import pyplot as plt %matplotlib inline Stochastic Gradient Descent The svm will learn using the stochastic gradient descent algorithm (SGD). Gradient Descent minimizes a function by following the gradients of the cost function.
Calculating the Error To calculate the error of a prediction we first need to define the objective function of the svm....</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;5 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to SimpleSupportVectorMachine" href=http://yangchnet.github.io/Dessert/posts/dlml/svm-primal/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>tf.ones_like()</h2></header><section class=entry-content><p>import tensorflow as tf import numpy as np from IPython.display import Image tf.ones_like() 创建一个所有元素设置为1的tensor
tf.subtract() 两个矩阵相减
decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)
这一句计算出1-d
tf.stack 矩阵拼接，例如
a = tf.constant([1,2,3]) b = tf.constant([4,5,6]) c = tf.stack([a, b], axis = 0) d = tf.stack([a, b], axis = 1) sess = tf.Session() print(sess.run(c)) print(sess.run(d)) [[1 2 3] [4 5 6]] [[1 4] [2 5] [3 6]] tf.expand_dims 在axis位置增加一个维度
tf.tile 在同一维度上进行复制
with tf....</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;1 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to tf.ones_like()" href=http://yangchnet.github.io/Dessert/posts/dlml/tensorflowapi/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>使用sklearn的贝叶斯分类器进行文本分类</h2></header><section class=entry-content><p>使用sklearn的贝叶斯分类器进行文本分类 1、sklearn简介 sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。
2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利 朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。
2.1、多项式模型 2.2、伯努利模型 2.3、两个模型的区别 3、实战演练 使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。
读取全部数据，并随机打乱
import os import random def get_dataset(): data = [] for root, dirs, files in os.walk('../dataset/aclImdb/neg'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r'../dataset/aclImdb/pos'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [("Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see....</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;3 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 使用sklearn的贝叶斯分类器进行文本分类" href=http://yangchnet.github.io/Dessert/posts/dlml/sklearn_%E8%B4%9D%E5%8F%B6%E6%96%AF/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>分类指标作业（第二题）</h2></header><section class=entry-content><p>分类指标作业（第二题） 题目 给定完整数据集，分别计算在使用完整数据集的10%,30%,50%,80%,100%数据时的查准率、查全率，f1度量和ROC，使用折线图表现出这些指标的变化情况，并画出在不同数据量下的ROC曲线
加载数据集 import os import random def get_dataset(): data = [] for root, dirs, files in os.walk('../dataset/aclImdb/neg'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r'../dataset/aclImdb/pos'): for file in files: realpath = os.path.join(root, file) with open(realpath, errors='ignore') as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [('Unless you are between the ages of 10 and 14 (except for the R rating), there are very few things to like here....</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;5 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 分类指标作业（第二题）" href=http://yangchnet.github.io/Dessert/posts/dlml/%E5%88%86%E7%B1%BB%E6%8C%87%E6%A0%87%E4%BD%9C%E4%B8%9A%E7%AC%AC%E4%BA%8C%E9%A2%98/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>基于卷积神经网络和决策树的体域网数据融合方法</h2></header><section class=entry-content><p>基于卷积神经网络和决策树的体域网数据融合方法 现阶段想法:在softmax层后接随机森林，通过种树增加分类准确率
import tensorflow as tf import numpy as np import tensorflow.examples.tutorials.mnist.input_data as input_data import scipy as sp %matplotlib inline sess = tf.Session() DEPTH = 3 # Depth of a tree N_LEAF = 2 ** (DEPTH + 1) # Number of leaf node N_LABEL = 10 # Number of classes N_TREE = 5 # Number of trees (ensemble) N_BATCH = 128 # Number of data points per mini-batch 分批训练，每一批128个 初始化矩阵 def init_weights(shape): return tf....</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;3 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 基于卷积神经网络和决策树的体域网数据融合方法" href=http://yangchnet.github.io/Dessert/posts/dlml/dnf/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>处理文本数据</h2></header><section class=entry-content><p>处理文本数据 1. 单词和字符的one-hot编码 one-hot编码是将标记转换为向量的最常用，最基本的方法。它将每个单词与一个唯一的整数索引相关联，然后将这个整数索引i转换为长度为N的二进制向量（N是词表大小），这个向量只有第i个元素是1，其余元素都是0.
当然，也可以进行字符级的one-hot编码。
1.1. 单词级的one-hot编码 import numpy as np samples = ['The cat sat on the mat.', 'The dog ate my homework.'] token_index = {} for sample in samples: for word in sample.split(): if word not in token_index: token_index[word] = len(token_index) + 1 # 为每个唯一单词指定一个唯一索引，没有为0索引指定单词 max_length = 10 results = np.zeros(shape=(len(samples), max_length, max(token_index.values())+1)) for i, sample in enumerate(samples): for j, word in list(enumerate(sample.split()))[:max_length]: index = token_index.get(word) results[i, j, index] = 1 results array([[[0....</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;7 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 处理文本数据" href=http://yangchnet.github.io/Dessert/posts/dlml/%E5%A4%84%E7%90%86%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>多输入模型</h2></header><section class=entry-content><p>多输入模型 函数式API可以用于构建具有多个输入的模型，通常情况下，这种模型会在某一时刻用一个可以组合多个张量的层将不同的输入分支合并，张量组合方式可能是相加，连接等。这通常利用Keras的合并运算来实现，比如keras.layers.add, keras.layers.concatenate等。
下面来看一个非常简单的多输入模型示例：一个问答模型
典型的问答模型有两个输入，一个自然语言描述的问题和一个文本片段（比如新闻文章），后者提供用于回答问题的信息。然后模型要生成一个回答，在最简单的情况下，这个回答只包含一个词，可以通过对某个预定义的词表做softmax得到。
# 具有两个输入的模型 from keras.models import Model from keras import layers from keras import Input text_vocabulary_size = 10000 question_vocabulary_size = 10000 answer_vocabulary_size = 500 text_input = Input(shape=(None, ), dtype='int32', name='text') embedded_text = layers.Embedding( text_vocabulary_size, 64) (text_input) # 将输入嵌入到长度为64的向量 encoded_text = layers.LSTM(32)(embedded_text) # 对问题进行相同的处理，使用不同的层实例 question_input = Input(shape=(None, ), dtype='int32', name='question') embedded_question = layers.Embedding( question_vocabulary_size, 32)(question_input) encoded_question = layers.LSTM(16)(embedded_question) # 将编码后的问题和文本连接起来 concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1) # 在上面添加一个softmax分类器 answer = layers....</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;2 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 多输入模型" href=http://yangchnet.github.io/Dessert/posts/dlml/%E5%A4%9A%E8%BE%93%E5%85%A5%E6%A8%A1%E5%9E%8B/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2>朴素贝叶斯</h2></header><section class=entry-content><p>朴素贝叶斯 1、理论部分 1.1、贝叶斯公式 $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad\dots(1)$$
其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$
类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。
对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。
基于属性条件独立性假设，贝叶斯公式可重写为： $$P(c|x)=\frac{P(c)P(x|c)}{P(x)}\qquad=\frac{P(c)}{P(x)}\prod_{i=1}^d{P(x_i|c)}\dots(2)$$ 其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值
由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\in y}P(c)\prod_{i=1}^d{P(x_i|c)}\dots(3)$$
显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$
令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\frac{|D_c|}{|D|}\dots(4)$$
对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\frac{|D_{c,x_i}|}{|D_c|}\qquad\dots(5)$$ 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\hat{P}(c)=\frac{D_c+1}{|D|+N}\qquad\dots(6)$$ $$\hat{P}(x_i|c)=\frac{D_{c,x_i}+1}{|D|+N}\qquad\dots(7)$$
2、实战演练 2.1、加载数据集 import numpy as np def loadDataSet(): """ 导入数据， 1代表脏话 @ return postingList: 数据集 @ return classVec: 分类向量 """ postingList = [['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']] classVec = [0, 1, 0, 1, 0, 1] return postingList, classVec 导入训练集及其分类，1代表是脏话，0代表不是...</p></section><footer class=entry-footer>February 25, 2021&nbsp;·&nbsp;4 min&nbsp;·&nbsp;李昌</footer><a class=entry-link aria-label="post link to 朴素贝叶斯" href=http://yangchnet.github.io/Dessert/posts/dlml/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/></a></article><footer class=page-footer><nav class=pagination><a class=next href=http://yangchnet.github.io/Dessert/tags/dlml/page/2/>Next Page »</a></nav></footer></main><footer class=footer><span>&copy; 2021 <a href=http://yangchnet.github.io/Dessert>Linote</a></span>
<script src=https://utteranc.es/client.js repo=yangchnet/Dessert issue-term=pathname theme=github-light crossorigin=anonymous async></script><span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById('menu');menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)},document.querySelectorAll('a[href^="#"]').forEach(a=>{a.addEventListener("click",function(b){b.preventDefault();var a=this.getAttribute("href").substr(1);window.matchMedia('(prefers-reduced-motion: reduce)').matches?document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(a)}']`).scrollIntoView({behavior:"smooth"}),a==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${a}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove('dark'),localStorage.setItem("pref-theme",'light')):(document.body.classList.add('dark'),localStorage.setItem("pref-theme",'dark'))})</script></body></html>
[{"content":"1. evm虚拟机 交易的执行是区块链节点上的一个重要的功能。是把交易中的智能合约二进制代码取出来，用执行器（Executor）执行。在交易的执行过程中，会对区块链的状态（State）进行修改，形成新区块的状态储存下来（Storage）。执行器在这个过程中，类似于一个黑盒，输入是智能合约代码，输出是状态的改变.\n以太坊虚拟机（environment virtual machine，简称EVM），作用是将智能合约代码编译成可在以太坊上执行的机器码，并提供智能合约的运行环境。它是一个对外完全隔离的沙盒环境，在运行期间不能访问网络、文件，即使不同合约之间也有有限的访问权限。以太坊虚拟机提供了面向合约的高级编程语言solidity，这使得开发者可以专注于应用本身，更方便、快捷的开发去中心化应用程序，同时也大大降低了开发难度。\nEVM是一种基于栈的虚拟机（区别于基于寄存器的虚拟机），用于执行智能合约，同时EVM是图灵完备的，EVM操作数栈调用深度为1024,EVM机器码长度一个字节，最多可以有256个操作码，目前已经定义了144个操作码，还有100多个操作码可以扩展，每个操作码都根据其弹栈数、压栈数定义了相应的gas消耗数量。泰岳链应用了以太坊EVM机制来实现智能合约，并增加了对国密算法的支持(SM3)。\n2. solidity语言 Solidity 是一门面向合约的、为实现智能合约而创建的高级编程语言。这门语言受到了 C++，Python 和 Javascript 语言的影响，设计的目的是能在 以太坊虚拟机（EVM） 上运行。\nSolidity 是静态类型语言，支持继承、库和复杂的用户定义类型等特性。\n直接看这里：Solidity最新中文文档\n3. 使用Ganache与truffle进行合约开发 Ganache\nganache可以快速的在本机上启动一条以太坊链，用户可以方便的在上面部署合约，调用合约，完成各种与合约之间的交互。\nganache提供了Windows、Linux以及Mac三种系统的版本，直接到其官网或GitHub页面下载安装即可。\n安装完成后，即可以快速部署一条链 使用QUICKSTART模式部署的链只会在本次会话中存在，关闭当前会话或注销当前用户都会导致链的撤销，如果只是写个小demo的话，那么使用这种方式即可。\nNEW WORKSPACE则会创建一条持久化的链，不会因会话结束或用户注销而撤销链。\n 使用QUICKSTART模式启动\n ganache会自动创建10个测试账号，每个账号分配了100个原生币，交易需要消耗这些原生币。 在页面的上方，还有其他一些选项卡，可以方便的查看当前区块、交易、事件、日志等。需要注意的是在这些选项卡的下方，还标注了本链的一些信息，如它的端口，网络ID等。 truffle\ntruffle提供了合约开发、测试、部署等一系列工具，通过与Ganache配合可以十分方便的测试你的合约。\n安装truffle\nnpm install -g truffle 新建一个truffle项目\nmkdir MyContract truffle init truffle会创建如下的目录结构：\n├── contracts │ └── Migrations.sol ├── migrations │ └── 1_initial_migration.js ├── test └── truffle-config.js contract目录中存放我们的合约;migrations目录中存放migrate文件，功能类似数据库migrate文件，简单来说，就是让你的应用从一个状态迁移到另一个状态;test目录中存放测试文件（还未创建）;truffle-config.js是配置文件，其中配置了链的地址等信息。\n根据提示我们来创建一个简单的合约模板：\ntruffle create contract Counter truffle创建了Counter.sol文件，再次查看目录结构：\n├── contracts │ ├── Counter.sol │ └── Migrations.sol ├── migrations │ └── 1_initial_migration.js ├── test └── truffle-config.js 打开Counter.sol\n// SPDX-License-Identifier: MIT pragma solidity \u0026gt;=0.4.22 \u0026lt;0.9.0; contract Counter { constructor() public { } } 为我们提供了一个合约模板，修改合约：\n// SPDX-License-Identifier: MIT pragma solidity \u0026gt;=0.4.22 \u0026lt;0.9.0; contract counter { address owner; mapping (string =\u0026gt; uint256) values; constructor() public { owner = msg.sender; } function increase(string memory key) public payable { values[key] = values[key] + 1; } function get(string memory key) view public returns (uint) { return values[key]; } function getOwner()view public returns (address) { return owner; } } 以上合约是一个非常简单的计数器合约，提供了increase, get, getOwner三个方法，分别用来增加计数、获取计数值、获取合约所有者。\n编译合约\ntruffle compile 编辑migrate文件\nvim migrations/2_deploy_contracts.js const Counter = artifacts.require(\u0026#34;Counter\u0026#34;) module.exports = function(deployer) { deployer.deploy(Counter); } 现在准备工作已经完成了，开始让我们的合约上链。\n配置truffle-config.js文件，主要是要配置network：\nnetworks: { development: { host: \u0026#34;127.0.0.1\u0026#34;, // Localhost (default: none)  port: 7545, // Standard Ethereum port (default: none)  network_id: \u0026#34;*\u0026#34;, // Any network (default: none)  }, }, networks有很详细的注释，这里的关键是需要与Ganache中显示的端口号等一致。 配置完成，终于到了激动人心的一步，合约上链。\ntruffle migrate Compiling your contracts... =========================== \u0026gt; Everything is up to date, there is nothing to compile. Starting migrations... ====================== \u0026gt; Network name: 'development' \u0026gt; Network id: 5777 \u0026gt; Block gas limit: 6721975 (0x6691b7) 1_initial_migration.js ====================== Deploying 'Migrations' ---------------------- \u0026gt; transaction hash: 0x75050e06c2f6f1097257de17ea1370a86225c35909e8319ed62407424b21587e \u0026gt; Blocks: 0 Seconds: 0 \u0026gt; contract address: 0xd366fCAF0F7A2b1A2Ebde67E89f1bbC2ED708c55 \u0026gt; block number: 112 \u0026gt; block timestamp: 1623909962 \u0026gt; account: 0x128F3853c98671ac43e8358e3A043f3A7bD0Ca18 \u0026gt; balance: 99.72713514 \u0026gt; gas used: 191943 (0x2edc7) \u0026gt; gas price: 20 gwei \u0026gt; value sent: 0 ETH \u0026gt; total cost: 0.00383886 ETH 2_deploy_contracts.js ===================== Deploying 'Counter' ------------------- \u0026gt; transaction hash: 0x692c27b1b9a7f04301c10a2b3ece8c5f7737581d4de9f01e88653a907eb4b711 \u0026gt; Blocks: 0 Seconds: 0 \u0026gt; contract address: 0x76607048A6628A43d981811a35a629Ff049c2B11 \u0026gt; block number: 114 \u0026gt; block timestamp: 1623910129 \u0026gt; account: 0x128F3853c98671ac43e8358e3A043f3A7bD0Ca18 \u0026gt; balance: 99.72055518 \u0026gt; gas used: 286660 (0x45fc4) \u0026gt; gas price: 20 gwei \u0026gt; value sent: 0 ETH \u0026gt; total cost: 0.0057332 ETH \u0026gt; Saving migration to chain. \u0026gt; Saving artifacts ------------------------------------- \u0026gt; Total cost: 0.0057332 ETH Summary ======= \u0026gt; Total deployments: 2 \u0026gt; Final cost: 0.00957206 ETH 从输出的日志信息中可以看到部署的合约及其消耗的资源。\n查看Ganache可看到，链增长了4个区块 消耗的原生币也显示了出来 执行的所有交易 现在我们完成了合约编写，合约上链等步骤，但到这里只能证明合约语法的正确性，我们还需要进行一系列的测试来保证我们的合约逻辑是无误的，可以按照我们预定的逻辑执行。\n生成测试代码(可选)\ntruffle create test Counter cat test/counter.js const Counter = artifacts.require(\u0026#34;Counter\u0026#34;); /* * uncomment accounts to access the test accounts made available by the * Ethereum client * See docs: https://www.trufflesuite.com/docs/truffle/testing/writing-tests-in-javascript */ contract(\u0026#34;Counter\u0026#34;, function (/* accounts */) { it(\u0026#34;should assert true\u0026#34;, async function () { await Counter.deployed(); return assert.isTrue(true); }); }); 如果你不想自动生成代码，那么可以手动创建自己的测试文件\nvim test/counter.test.js 内容同上\n开始测试\n$ truffle test Using network \u0026#39;development\u0026#39;. Compiling your contracts... =========================== \u0026gt; Compiling ./contracts/Counter.sol \u0026gt; Artifacts written to /tmp/test--10676-pZQ9laXW37D3 \u0026gt; Compiled successfully using: - solc: 0.5.16+commit.9c3226ce.Emscripten.clang Contract: Counter ✓ should assert true 1 passing (74ms) 以上的测试文件中，断言永远为真，所以只要这个测试可以跑起来，就肯定不会fail，这只是官方给我们生成的测试代码模板，真正的测试代码还需要我们自己来编写。 修改测试代码：\nconst Counter = artifacts.require(\u0026#34;Counter\u0026#34;); contract(\u0026#34;counter\u0026#34;, async account =\u0026gt; { contract(\u0026#34;counter 1st test\u0026#34;, async account =\u0026gt; { let c; before(\u0026#34;deploy contract\u0026#34;, async () =\u0026gt; { c = await Counter.deployed(); }) it(\u0026#34;test getOwner\u0026#34;, async () =\u0026gt; { const owner = await c.getOwner(); expectedOwner = \u0026#34;0x128F3853c98671ac43e8358e3A043f3A7bD0Ca18\u0026#34; assert.equal(owner, expectedOwner, \u0026#34;owner is wrong\u0026#34;) }) it(\u0026#34;test increase\u0026#34;, async () =\u0026gt; { await c.increase(\u0026#34;0x128F3853c98671ac43e8358e3A043f3A7bD0Ca18\u0026#34;) const num = await c.get(\u0026#34;0x128F3853c98671ac43e8358e3A043f3A7bD0Ca18\u0026#34;) let expectedNum = 1; assert.equal(expectedNum, num, \u0026#34;error occur\u0026#34;); }) }) }); 重新运行测试：\ntruffle test Using network 'development'. Compiling your contracts... =========================== \u0026gt; Compiling ./contracts/Counter.sol \u0026gt; Artifacts written to /tmp/test--10825-NWIGDIdS1RrG \u0026gt; Compiled successfully using: - solc: 0.5.16+commit.9c3226ce.Emscripten.clang Contract: counter Contract: counter 1st test ✓ test getOwner ✓ test increase (81ms) 2 passing (184ms) 测试通过，完美。\n更多资料，请参考官网文档：TRUFFLE SUITE\n","permalink":"http://yangchnet.github.io/Dessert/posts/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%8D%81%E5%88%86%E9%92%9F%E5%AD%A6%E4%BC%9A%E5%8C%BA%E5%9D%97%E9%93%BE%E5%90%88%E7%BA%A6%E5%BC%80%E5%8F%91/","summary":"1. evm虚拟机 交易的执行是区块链节点上的一个重要的功能。是把交易中的智能合约二进制代码取出来，用执行器（Executor）执行。在交易的执行过程中，会对区块链的状态（State）进行修改，形成新区块的状态储存下来（Storage）。执行器在这个过程中，类似于一个黑盒，输入是智能合约代码，输出是状态的改变.\n以太坊虚拟机（environment virtual machine，简称EVM），作用是将智能合约代码编译成可在以太坊上执行的机器码，并提供智能合约的运行环境。它是一个对外完全隔离的沙盒环境，在运行期间不能访问网络、文件，即使不同合约之间也有有限的访问权限。以太坊虚拟机提供了面向合约的高级编程语言solidity，这使得开发者可以专注于应用本身，更方便、快捷的开发去中心化应用程序，同时也大大降低了开发难度。\nEVM是一种基于栈的虚拟机（区别于基于寄存器的虚拟机），用于执行智能合约，同时EVM是图灵完备的，EVM操作数栈调用深度为1024,EVM机器码长度一个字节，最多可以有256个操作码，目前已经定义了144个操作码，还有100多个操作码可以扩展，每个操作码都根据其弹栈数、压栈数定义了相应的gas消耗数量。泰岳链应用了以太坊EVM机制来实现智能合约，并增加了对国密算法的支持(SM3)。\n2. solidity语言 Solidity 是一门面向合约的、为实现智能合约而创建的高级编程语言。这门语言受到了 C++，Python 和 Javascript 语言的影响，设计的目的是能在 以太坊虚拟机（EVM） 上运行。\nSolidity 是静态类型语言，支持继承、库和复杂的用户定义类型等特性。\n直接看这里：Solidity最新中文文档\n3. 使用Ganache与truffle进行合约开发 Ganache\nganache可以快速的在本机上启动一条以太坊链，用户可以方便的在上面部署合约，调用合约，完成各种与合约之间的交互。\nganache提供了Windows、Linux以及Mac三种系统的版本，直接到其官网或GitHub页面下载安装即可。\n安装完成后，即可以快速部署一条链 使用QUICKSTART模式部署的链只会在本次会话中存在，关闭当前会话或注销当前用户都会导致链的撤销，如果只是写个小demo的话，那么使用这种方式即可。\nNEW WORKSPACE则会创建一条持久化的链，不会因会话结束或用户注销而撤销链。\n 使用QUICKSTART模式启动\n ganache会自动创建10个测试账号，每个账号分配了100个原生币，交易需要消耗这些原生币。 在页面的上方，还有其他一些选项卡，可以方便的查看当前区块、交易、事件、日志等。需要注意的是在这些选项卡的下方，还标注了本链的一些信息，如它的端口，网络ID等。 truffle\ntruffle提供了合约开发、测试、部署等一系列工具，通过与Ganache配合可以十分方便的测试你的合约。\n安装truffle\nnpm install -g truffle 新建一个truffle项目\nmkdir MyContract truffle init truffle会创建如下的目录结构：\n├── contracts │ └── Migrations.sol ├── migrations │ └── 1_initial_migration.js ├── test └── truffle-config.js contract目录中存放我们的合约;migrations目录中存放migrate文件，功能类似数据库migrate文件，简单来说，就是让你的应用从一个状态迁移到另一个状态;test目录中存放测试文件（还未创建）;truffle-config.js是配置文件，其中配置了链的地址等信息。\n根据提示我们来创建一个简单的合约模板：\ntruffle create contract Counter truffle创建了Counter.sol文件，再次查看目录结构：\n├── contracts │ ├── Counter.","title":"十分钟学会区块链合约开发"},{"content":"前置条件 浏览器部署需要依赖一个ChainMaker运行环境。具体的ChainMaker环境安装部署请参考对应的文档。\n1. 下载源码 mkdir -p ~/chainmaker/chainmaker-explorer \\ \u0026amp;\u0026amp; cd ~/chainmaker/chainmaker-explorer \\ \u0026amp;\u0026amp; git clone --recursive https://git.chainmaker.org.cn/chainmaker/chainmaker-explorer.git \\ \u0026amp;\u0026amp; git clone --recursive https://git.chainmaker.org.cn/chainmaker/chainmaker-explorer-web.git 2. 安装npm及node.js  版本要求： npm\u0026gt;=6.14.13 node.js\u0026gt;=v14.17.0\n  这里推荐使用nvm方式安装\n curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | bash # 安装nvm nvm --version # 查看nvm是否安装成功 nvm install 14 # 安装node.js v14.17.0 3. 安装nginx  版本要求： nginx\u0026gt;=1.18.0, 这里先暂时用低版本的试试\n apt-get update apt-get install nginx 4. 数据库初始化 mkdir -p ~/chainmaker/chainmaker-explorer/explorer-mysql docker run --name explorerMysql -p 3306:3306 -v ~/chainmaker/chainmaker-explorer/explorer-mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=Yuhu8888 -d mysql:5.7 创建数据库表 创建数据库表的sql文件路径是~/chainmaker/chainmaker-explorer/docs/chainmaker-browser.sql\ncp ~/chainmaker/chainmaker-explorer/docs/chainmaker-browser.sql ~/chainmaker/chainmaker-explorer/explorer-mysql /home/lc/go/src/github.com/chainmaker/explorer-mysql docker run \u0026ndash;name explorerMysql -p 3306:3307 -v ~/go/src/github.com/chainmaker/explorer-mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=Yuhu8888 -d mysql:5.7 cp /home/lc/go/src/github.com/chainmaker/chainmaker-explorer/docs/chainmaker-browser.sql /home/lc/go/src/github.com/chainmaker/explorer-mysql\ndocker exec -it explorerMysql /bin/bash # 进入docker容器中 mysql -u root -p mysql\u0026gt; CREATE DATABASE chainmaker_browser_db2 DEFAULT CHARACTER SET utf8 DEFAULT COLLATE utf8_general_ci; mysql\u0026gt; use chainmaker_browser_db2; mysql\u0026gt; source /var/lib/mysql/chainmaker-browser.sql; mysql\u0026gt; exit; 5. 后端模块部署 cd ~/chainmaker/chainmaker-explorer vim ./configs/config.yml # 调整你的设置 ./scripts/startup.sh 6. 前端模块部署 cd ~/chainmaker/chainmaker-explorer-web vim ./public/config.js # 修改前端请求地址，根据后台地址配置 npm install npm run build 将打包构建好的build包里index.html页面的路径配置到nginx中，打开nginx的配置（默认路径为：/etc/nginx/nginx.conf），修改以下标注的配置：\nlisten 8080; #监听端口\rserver_name localhost; #ServerName\rlocation / {\rroot /data/cmb-front/dist; #index.html所在路径\rindex index.html; #index.html文件\rtry_files $uri $uri/ /index.html; #跳转需要\r}\rlocation ^~/chainmaker/ { #后端跳转过滤字段\rproxy_pass http://127.0.0.1:8080; #跳转到后端的请求\r}\r配置完成，重启nginx\nservice nginx restart ","permalink":"http://yangchnet.github.io/Dessert/posts/%E5%8C%BA%E5%9D%97%E9%93%BE/%E9%95%BF%E5%AE%89%E9%93%BE%E5%8C%BA%E5%9D%97%E9%93%BE%E6%B5%8F%E8%A7%88%E5%99%A8%E9%83%A8%E7%BD%B2/","summary":"前置条件 浏览器部署需要依赖一个ChainMaker运行环境。具体的ChainMaker环境安装部署请参考对应的文档。\n1. 下载源码 mkdir -p ~/chainmaker/chainmaker-explorer \\ \u0026amp;\u0026amp; cd ~/chainmaker/chainmaker-explorer \\ \u0026amp;\u0026amp; git clone --recursive https://git.chainmaker.org.cn/chainmaker/chainmaker-explorer.git \\ \u0026amp;\u0026amp; git clone --recursive https://git.chainmaker.org.cn/chainmaker/chainmaker-explorer-web.git 2. 安装npm及node.js  版本要求： npm\u0026gt;=6.14.13 node.js\u0026gt;=v14.17.0\n  这里推荐使用nvm方式安装\n curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.38.0/install.sh | bash # 安装nvm nvm --version # 查看nvm是否安装成功 nvm install 14 # 安装node.js v14.17.0 3. 安装nginx  版本要求： nginx\u0026gt;=1.18.0, 这里先暂时用低版本的试试\n apt-get update apt-get install nginx 4. 数据库初始化 mkdir -p ~/chainmaker/chainmaker-explorer/explorer-mysql docker run --name explorerMysql -p 3306:3306 -v ~/chainmaker/chainmaker-explorer/explorer-mysql:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=Yuhu8888 -d mysql:5.","title":"长安链区块链浏览器部署"},{"content":"1. WSL的安装 1.1 升级Windows WSL需要高版本的windows，可使用微软官方的易升工具或直接从设置中升级，升级需要一定的时间。\n1.2 安装WSL  使用管理员模式打开power shell， 使用如下命令开启WSL功能  dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 重启你的机器\n启用虚拟机功能 以管理员身份打开powershell，使用如下命令：  dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 重新启动电脑\n下载Linux内核更新包 适用于 x64 计算机的 WSL2 Linux 内核更新包  运行你下载的更新包。\n将WSL2设置为默认版本 以管理员身份打开powershell，使用如下命令：  wsl --set-default-version 2 选择你要安装的发行版  这里我选择了Ubuntu18.04，获取后安装\n启动安装的发行版即可  2. 使用WSL图形界面  设置环境变量  export DISPLAY=$(awk \u0026#39;/nameserver / {print $2; exit}\u0026#39; /etc/resolv.conf 2\u0026gt;/dev/null):0 export LIBGL_ALWAYS_INDIRECT=1  安装Xserver，这里选择的软件是vcxsrv， 可在sourceforge中下载安装。\n  安装完成后直接启动即可\n   每次重新启动电脑都要重新打开一下，略烦。微软官方的WSLg已经发布，不过需要Windows Insider,先等等吧\n 在wsl中安装gedit  sudo apt install gedit 尝试启动gedit：\ngedit 完成！！！\n3. WSL中文 3.1 WSL中文显示  安装语言包  sudo apt-get -y install locales xfonts-intl-chinese fonts-wqy-microhei 语言环境设置  sudo dpkg-reconfigure locales 使用空格键选中en_US.UTF-8 UTF-8、zh_CN.UTF-8 UTF-8，使用Tab键切换至OK，再将en_US.UTF-8选为默认。 重启系统  exit ... wsl --shutdown wsl 3.2 WSL中文输入法配置  安装fcitx及输入法\n安装fcitx核心及CJK字体  sudo apt install fcitx fonts-noto-cjk fonts-noto-color-emoji dbus-x11 安装搜狗输入法，直接到搜狗输入法官网网站下载并按照说明安装即可\n配置输入环境  首先使用root账号生成dbus机器码\ndbus-uuidgen \u0026gt; /var/lib/dbus/machine-id 用root账号创建/etc/profile.d/fcitx.sh文件，内容如下：\n#!/bin/bash export QT_IM_MODULE=fcitx export GTK_IM_MODULE=fcitx export XMODIFIERS=@im=fcitx export DefaultIMModule=fcitx #可选，fcitx 自启 fcitx-autostart \u0026amp;\u0026gt;/dev/null 其他配置 将以下内容添加到你的bashrc配置文件中  vim ~/.bashrc export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx export XMODIFIERS=@im=fcitx export DefaultIMModule=fcitx fcitx-autostart \u0026amp;\u0026gt;/dev/null source ~/.bashrc 运行fcitx-config-gtk3,会出现如图的界面：\n按照提示将键盘布局放在第一位，输入法放在第二位。\n为防止和Windows上的输入法切换快捷键冲突，这里将快捷键切换更改为ctrl+shift(Windows上为shift)\n到这里，配置就完成了。\n开始输入\n  FAQ  打开的图形界面字体很模糊 找到自己的VcXsrv安装位置，找到vsxsrc.exe和xlaunch.exe两个应用程序文件，右键属性\u0026gt;兼容性\u0026gt;更改高DPI设置\u0026gt;勾选替代高DPI缩放行为（应用程序）\u0026gt; 确定。  Reference 在WSL上配置输入法\nwsl下Ubuntu中文显示方法\nWSL 下 Ubuntu 20.04 中文显示设置\n","permalink":"http://yangchnet.github.io/Dessert/posts/windows/wsl2%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/","summary":"1. WSL的安装 1.1 升级Windows WSL需要高版本的windows，可使用微软官方的易升工具或直接从设置中升级，升级需要一定的时间。\n1.2 安装WSL  使用管理员模式打开power shell， 使用如下命令开启WSL功能  dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart 重启你的机器\n启用虚拟机功能 以管理员身份打开powershell，使用如下命令：  dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart 重新启动电脑\n下载Linux内核更新包 适用于 x64 计算机的 WSL2 Linux 内核更新包  运行你下载的更新包。\n将WSL2设置为默认版本 以管理员身份打开powershell，使用如下命令：  wsl --set-default-version 2 选择你要安装的发行版  这里我选择了Ubuntu18.04，获取后安装\n启动安装的发行版即可  2. 使用WSL图形界面  设置环境变量  export DISPLAY=$(awk \u0026#39;/nameserver / {print $2; exit}\u0026#39; /etc/resolv.conf 2\u0026gt;/dev/null):0 export LIBGL_ALWAYS_INDIRECT=1  安装Xserver，这里选择的软件是vcxsrv， 可在sourceforge中下载安装。\n  安装完成后直接启动即可","title":"WSL2开发环境配置"},{"content":"1. go generate go generate命令运行时，将找到源代码中所有包含//go:generate的特殊注释，提取并执行//go:generate后附加的命令。\n基本语法：\n//go:generate [-run regexp] [-n] [-v] [-x] [build flags] [file.go... | packages] 需要注意的几点：\n 该特殊注释必须在.go源码文件中。 每个源码文件可以包含多个generate特殊注释。 go generate只在运行go generate命令时运行，go build, go get, go test等其他命令不会运行它。 命令串行执行的，如果出错，就终止后面的执行。 特殊注释必须以\u0026quot;//go:generate\u0026quot;开头，双斜线后面没有空格。  简单的例子：\npackage main import \u0026#34;fmt\u0026#34; //go:generate echo \u0026#34;world\u0026#34; func main() { fmt.Println(\u0026#34;hello\u0026#34;) } 运行结果：\n在go generate命令中，还可以使用一些环境变量：\n $GOARCH The execution architecture (arm, amd64, etc.) $GOOS The execution operating system (linux, windows, etc.) $GOFILE The base name of the file. $GOLINE The line number of the directive in the source file. $GOPACKAGE The name of the package of the file containing the directive. $DOLLAR A dollar sign. go generate的参数\n-run 正则表达式匹配命令行，仅执行匹配的命令 -v 输出被处理的包名和源文件名 -n 只显示要执行的命令，但不执行 -x 显示要执行的命令并执行 2. 使用go generate自动生成mock接口 在我们对代码进行单元测试时，某段代码可能有一些依赖项，一般情况下我们可以手动去构建这些依赖项。但当依赖项过多时，手动去构建每一个依赖项就是一项复杂、艰巨且无聊的工作。这时候，就到了mock大显身手的时候。mock会为你提供一些虚拟的依赖项，并规定它们的行为，从而你可以方便的在自己的测试中使用它。\ngomock针对接口进行mock操作。\n例如：我们有一个Client接口，这个接口的Address方法返回其地址，Serve方法中需要用到这个Client的Address。假设现在我们还没有配置完成Client，但需要先对Serve的行为进行测试。这时我们可以\u0026quot;mock\u0026quot;出一个Client。\ntype Client interface { Address() string } func Serve(c Client) { // ...  address := client.Address() // ... } 接下来我们应该怎么做呢？\n  安装gomock\n  生成mock文件\n  在单元测试中规定Client的操作以检查Serve的行为\n  安装gomock\n  $ go install github.com/golang/mock/mockgen@v1.5.0 生成mock文件 在你的项目目录中运行如下命令：  $ mockgen -destination=mock_client.go -package=mock . Client 其中-destination指定了需要生成的文件名， -package指定了生成的mock文件的包名，若不指定，则默认为mock_后跟输入文件的包名, 点.指定了源目录，最后的Client指需要mock该接口。\n运行上面命令后，就可以在本地生成mock_client.go文件。\n在单元测试中规定Client的操作以检查Serve的行为  func Test_Serve(t *testing.T) { ctrl := gomock.NewController(t) defer ctrl.Finish() c := NewMockClient(ctrl) // 构建出mock的Client  c.EXCEPT().Address().RETURN(\u0026#34;127.0.0.1\u0026#34;).AnyTimes() // 当使用Client.Address()方法时返回”127.0.0.1“，可使用任意次  Server(c) // ... }  每次使用c.EXCEPT().Address().RETURN()仅能为一次Address()指定返回，可多次使用该方法以返回不同的值。\n 最后，mock和go generate有啥关系？\n我们可以将go generate特殊注释写在接口的头部，然后直接使用go generate命令来方便快捷的生成mock文件。如下：\n//go:generate mockgen -destination=mock_client.go -package=mock . Clien type Client interface { Address() string } 3. 使用go generate生成错误码 stringer是用于自动创建满足fmt.Stringer方法的工具。给定一个变量/常量名T, stringer可以生成类似下面方法的代码：\nfunc (t T) String string  以下内容主要参考了： 深入理解Go之generate\n 在我们的服务中，经常会使用一些错误码，这时就需要我们去定义errCode和ErrMsg, 这里介绍一种优雅的方法解决这个问题。\n定义错误码的传统方式\n定义错误码：\npackage errcode import \u0026#34;fmt\u0026#34; // 定义错误码 const ( ERR_CODE_OK = 0 // OK  ERR_CODE_INVALID_PARAMS = 1 // 无效参数  ERR_CODE_TIMEOUT = 2 // 超时  // ... ) // 定义错误码与描述信息的映射 var mapErrDesc = map[int]string { ERR_CODE_OK: \u0026#34;OK\u0026#34;, ERR_CODE_INVALID_PARAMS: \u0026#34;无效参数\u0026#34;, ERR_CODE_TIMEOUT: \u0026#34;超时\u0026#34;, // ... } // 根据错误码返回描述信息 func GetDescription(errCode int) string { if desc, exist := mapErrDesc[errCode]; exist { return desc } return fmt.Sprintf(\u0026#34;error code: %d\u0026#34;, errCode) } 使用错误码：\npackage main import ( \u0026#34;github.com/darjun/errcode\u0026#34; ) func main() { code := errcode.ERR_CODE_INVALID_PARAMS fmt.Println(code, errcode.GetDescription(errCode)) // 输出: 1 无效参数 } 为了使用方便，我们可以为错误码定义一个新的类型，然后为该类型定义String()方法，这样就不用手动调用GetDescription函数了。修改如下：\ntype ErrCode int const ( ERR_CODE_OK ErrCode = 0 // OK  ERR_CODE_INVALID_PARAMS ErrCode = 1 // 无效参数  ERR_CODE_TIMEOUT ErrCode = 2 // 超时 ) func (e ErrCode) String() string { return GetDescription(e) } 这种方式有什么问题呢？ 每次增加错误码时，都需要修改错误码到错误信息的map，有时候可能会忘， 另外，错误信息在注释和map中都出现了，有一定的冗余。 那能不能只写注释，然后自动生成代码呢？\n使用\nstringer有两种模式，默认是根据变量/常量名来生成字符串描述。我们在常量定义上增加注释：\n//go:generate stringer -type ErrCode 选项-type指定stringer命令作用的类型名。 然后在同一个目录下执行：\n$ go generate 这会在同一个目录下生成一个文件errcode_string.go。文件名格式是类型名小写_string.go。也可以通过-output选项指定输出文件名，例如下面就是指定输出文件名为code_string.go：\n//go:generate stringer -type ErrCode -output code_string.go 我们来看看这个文件的内容：\n// Code generated by \u0026#34;stringer -type ErrCode -output errcode_string.go\u0026#34;; DO NOT EDIT.  package errcode import \u0026#34;strconv\u0026#34; const _ErrCode_name = \u0026#34;ERR_CODE_OKERR_CODE_INVALID_PARAMSERR_CODE_TIMEOUT\u0026#34; var _ErrCode_index = [...]uint8{0, 11, 34, 50} func (i ErrCode) String() string { if i \u0026lt; 0 || i \u0026gt;= ErrCode(len(_ErrCode_index)-1) { return \u0026#34;ErrCode(\u0026#34; + strconv.FormatInt(int64(i), 10) + \u0026#34;)\u0026#34; } return _ErrCode_name[_ErrCode_index[i]:_ErrCode_index[i+1]] } 复制代码生成的代码做了一些优化，减少了字符串对象的数量。\n这时ERR_CODE_INVALID_PARAMS.String()返回的描述信息是ERR_CODE_INVALID_PARAMS。在一些上下文中甚至不需要自己调用String()方法，如fmt.Println。因为ErrCode实现了fmt.Stringer，一些上下文中会自动调用。\n这样errcode.go文件中mapErrDesc全局变量和getDescription函数都可以去掉了。\n但是我们更希望的是能返回后面的注释作为错误描述。\n这就需要使用stringer的-linecomment选项。修改go:generate如下：\n//go:generate stringer -type ErrCode -linecomment -output code_string.go 复制代码然后，执行go generate命令。生成的code_string.go与之前的有所不同，如下：\nconst _ErrCode_name = \u0026#34;OK无效参数超时\u0026#34; var _ErrCode_index = [...]uint8{0, 2, 14, 20} 复制代码可以看到确实通过注释生成了错误消息。\nReference 深入理解Go之generate\nGoMock\nstringer\nPackage generate\ngo generate介绍\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/go-generate%E5%B7%A5%E5%85%B7/","summary":"1. go generate go generate命令运行时，将找到源代码中所有包含//go:generate的特殊注释，提取并执行//go:generate后附加的命令。\n基本语法：\n//go:generate [-run regexp] [-n] [-v] [-x] [build flags] [file.go... | packages] 需要注意的几点：\n 该特殊注释必须在.go源码文件中。 每个源码文件可以包含多个generate特殊注释。 go generate只在运行go generate命令时运行，go build, go get, go test等其他命令不会运行它。 命令串行执行的，如果出错，就终止后面的执行。 特殊注释必须以\u0026quot;//go:generate\u0026quot;开头，双斜线后面没有空格。  简单的例子：\npackage main import \u0026#34;fmt\u0026#34; //go:generate echo \u0026#34;world\u0026#34; func main() { fmt.Println(\u0026#34;hello\u0026#34;) } 运行结果：\n在go generate命令中，还可以使用一些环境变量：\n $GOARCH The execution architecture (arm, amd64, etc.) $GOOS The execution operating system (linux, windows, etc.) $GOFILE The base name of the file.","title":"go generate工具"},{"content":" context包定义了Context类型，这个类型在API边界即进程中传递截止日期、同步信号，请求值等相关信息。\n 1. 对context包的介绍 在服务器的传入请求中应包含context，而对服务器的传出调用应接收一个context。它们之间的调用链必须包含context，或是衍生的WithCancel, WithDeadline, WithTimeout, WithValue。当一个WithCancel Context被“cancel”，那么当前context所派生的所有context也都将被取消。\nWithCancel, WithDeadline, WithTimeout接收一个Context对象（父对象），并返回其父对象的一个携带有cancel/deadline/timeout的一个拷贝（子对象）。调用CancelFunc会取消其子对象及子对象的子对象等，删除父对象对子对象的引用，并停止所有关联的计时器。未能调用CancelFunc将造成父对象结束前或计时器被触发前子对象的泄露。使用go vet工具可以检查所有控制流路径上是否都使用了CancelFunc\n使用context的程序应遵循以下规则，以使各个包之间的接口保持一致，并启用静态分析工具来检查上下文传播：\n 不要将context存储在结构类型中，而是将context明确传递给需要它的每个函数。Context应该是第一个函数，通常命名为ctx。  func DoSomething(ctx context.Context, arg Arg) error { // ...use ctx... } 不要传递一个值为nil的context，即使一个函数允许这样做。如果你不确定Context的作用那就请传递context.TODO。 只在进程和API间传递请求范围数据时使用context值，不要用于将可选参数传递给函数。 同样的Context可以传递给运行在不同goroutine中的函数，Context是线程安全的。  2. Context接口 type Context interface { Done() \u0026lt;-chan struct{} Err() error Deadline() (deadline time.Time, ok bool) Value(key interface{}) interface{} } Context是一个接口，其定义非常的简单，只包含4个方法：\n  Done() \u0026lt;-chan struct{} Done()方法将一个channel作为取消信号返回给持有context的函数，当该channel被关闭（即Done()被调用），这些函数应该立即停止其工作并返回。\n  Err() error Err()返回一个Error，说明为什么取消context。如果Done()没有被调用，那么Err返回nil。\n  Deadline() (deadline time.Time, ok bool) Deadline()方法返回持有这个context的函数的预期结束时间。如果并没有设置deadline，那么返回的ok将被设置为false。\n  Value(key interface{}) interface{} Value()方法返回与此context关联的key，如果没有与key对应的值那么返回nil。\nkey可以是任何支持比较的类型，为了避免冲突，应将key定义为不可导出的。\n示例：\npackage user import \u0026#34;context\u0026#34; type User struct{...} type key int var userKey key func NewContext(ctx context.Context, u *User) context.Context { return context.WithValue(ctx, userKey, u) } func FromContext(ctx context.Context)(*User, bool){ u, ok := ctx.Value(userKey).(*User) return u, ok }   3. Context构造 构造一个context对象有两种方法。\nfunc Background() Context func TODO() Context 上面两个方法都会返回一个非nil，非空的Context对象。Background()一般用于构造出最初的Context，所有的Context都派生自它。TODO()用当传入的方法不确定是哪种类型的Context时，为了避免Context参数为nil而初始化的Context。\n构造出Context对象后，我们就可以使用WithCancel, WithDeadline, WithTimeout, WithValue来进一步的设置Context，构造出的Context都派生自Background或是TODO 4. context.With\u0026hellip; 4.1 context.WithCancel() func WithCancel(parent Context) (ctx Context, cancel CancelFunc) WithCancel接收一个父context并返回该父context的一个持有Done channel的子context和一个cancel方法，当cancel方法被调用时或是父context的Done channel被关闭时，当前context的Done channel将被关闭。\nWithCancel常被用于通知goroutine退出。\nfunc fibonacci(c chan int, ctx context.Context) { x, y := 0, 1 for{ select { case c \u0026lt;- x: x, y = y, x+y case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;quit\u0026#34;) return } } } func main() { defer func() { time.Sleep(time.Second) fmt.Println(\u0026#34;the number of goroutines: \u0026#34;, runtime.NumGoroutine()) }() ctx, cancel := context.WithCancel(context.Background()) defer cancel() c := make(chan int) go fibonacci(c, ctx) for i := 0; i \u0026lt; 10; i++{ fmt.Println(\u0026lt;- c) } } 4.2 context.WithValue() func WithValue(parent Context, key, val interface{}) Context WithValue方法接收一个父context，以及一个键值对，返回一个包含这个键值对的子context。可使用context.Value(key)方法取出其中保存的值。\nfunc main() { ctx, cancel := context.WithCancel(context.Background()) valueCtx := context.WithValue(ctx, key, \u0026#34;add value\u0026#34;) go watch(valueCtx) time.Sleep(10 * time.Second) cancel() time.Sleep(5 * time.Second) } func watch(ctx context.Context) { for { select { case \u0026lt;-ctx.Done(): //get value \tfmt.Println(ctx.Value(key), \u0026#34;is cancel\u0026#34;) return default: //get value \tfmt.Println(ctx.Value(key), \u0026#34;int goroutine\u0026#34;) time.Sleep(2 * time.Second) } } } 4.3 context.WithDeadline() func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) WithDeadline方法接收一个父context和一个截止时间d，返回子context并为其设置一个不晚于d的截止时间。如果父context的截止时间已经早于d, 那么WithDeadline在语义上与父context相同。当以下三种情况发生时：1.截止时间到来，2.cancelFunc被调用，3.父context的Done channel被关闭，当前context的Done channel将被关闭。\nfunc main() { d := time.Now().Add(5 * time.Second) // 5秒后到期 \tctx, cancel := context.WithDeadline(context.Background(), d) defer cancel() // 一个好的习惯是调用cancel()以防止goroutine泄露  go doSomething(ctx) time.Sleep(10 * time.Second) } func doSomething(ctx context.Context) { for { select { case \u0026lt;-time.After(time.Second): fmt.Println(\u0026#34;I\u0026#39;m doing some funny things\u0026#34;) case \u0026lt;-ctx.Done(): // 5秒时到期 \tfmt.Println(ctx.Err()) return } } } I'm doing some funny things I'm doing some funny things I'm doing some funny things I'm doing some funny things context deadline exceeded 4.4 context.WithTimeout() func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } 从其实现就可以看出，WithTimeout只是对WithDeadline的进一步封装，这层封装为context设置了一个截止时间，也就是规定了其超时时间。\nfunc main() { ctx, cancel := context.WithTimeout(context.Background(), time.Duration(2*time.Second)) // 超过两秒就退出，不再continue \tdefer cancel() // 一个好的习惯是调用cancel()以防止goroutine泄露  go seek(ctx) time.Sleep(5 * time.Second) } func seek(ctx context.Context) { for { select { case \u0026lt;-time.After(time.Second): fmt.Println(\u0026#34;I\u0026#39;m looking for something\u0026#34;) case \u0026lt;-ctx.Done(): fmt.Println(ctx.Err()) return } } } 5. context包的其他函数 5.1 context.String() 实现fmt.Stringer接口，用于打印context\nfunc main() { backgroundCtx := context.Background() fmt.Println(backgroundCtx) withValueCtx := context.WithValue(backgroundCtx, \u0026#34;one\u0026#34;, 1) fmt.Println(withValueCtx) withCancelCtx, cancel := context.WithCancel(withValueCtx) defer cancel() fmt.Println(withCancelCtx) d := time.Now().Add(2 * time.Second) withDeadlineCtx, cancel := context.WithDeadline(withCancelCtx, d) defer cancel() fmt.Println(withDeadlineCtx) withTimeoutCtx, cancel := context.WithTimeout(withDeadlineCtx, time.Duration(2 * time.Second)) defer cancel() fmt.Println(withTimeoutCtx) } context.Background context.Background.WithValue(type string, val \u0026lt;not Stringer\u0026gt;) context.Background.WithValue(type string, val \u0026lt;not Stringer\u0026gt;).WithCancel context.Background.WithValue(type string, val \u0026lt;not Stringer\u0026gt;).WithCancel.WithDeadline(2021-05-23 15:49:31.513587636 +0800 CST m=+2.000147913 [1.999897372s]) context.Background.WithValue(type string, val \u0026lt;not Stringer\u0026gt;).WithCancel.WithDeadline(2021-05-23 15:49:31.513587636 +0800 CST m=+2.000147913 [1.999881255s]).WithCancel 5.2 context.Value() 用于从WithValue context中根据key取值\nfunc main() { ctx := context.WithValue(context.Background(), \u0026#34;one\u0026#34;, 1) fmt.Println(ctx.Value(\u0026#34;one\u0026#34;)) } 值取出后context不会删除它，可重复取值，对一个不存在的key取值会返回nil。\nReference Package context Go Concurrency Patterns: Context Golang Context深入理解\nGolang Context 原理与实战 Go 语言设计与实现\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/golang%E4%B8%ADcontext%E5%8C%85%E7%9A%84%E4%BD%BF%E7%94%A8/","summary":"context包定义了Context类型，这个类型在API边界即进程中传递截止日期、同步信号，请求值等相关信息。\n 1. 对context包的介绍 在服务器的传入请求中应包含context，而对服务器的传出调用应接收一个context。它们之间的调用链必须包含context，或是衍生的WithCancel, WithDeadline, WithTimeout, WithValue。当一个WithCancel Context被“cancel”，那么当前context所派生的所有context也都将被取消。\nWithCancel, WithDeadline, WithTimeout接收一个Context对象（父对象），并返回其父对象的一个携带有cancel/deadline/timeout的一个拷贝（子对象）。调用CancelFunc会取消其子对象及子对象的子对象等，删除父对象对子对象的引用，并停止所有关联的计时器。未能调用CancelFunc将造成父对象结束前或计时器被触发前子对象的泄露。使用go vet工具可以检查所有控制流路径上是否都使用了CancelFunc\n使用context的程序应遵循以下规则，以使各个包之间的接口保持一致，并启用静态分析工具来检查上下文传播：\n 不要将context存储在结构类型中，而是将context明确传递给需要它的每个函数。Context应该是第一个函数，通常命名为ctx。  func DoSomething(ctx context.Context, arg Arg) error { // ...use ctx... } 不要传递一个值为nil的context，即使一个函数允许这样做。如果你不确定Context的作用那就请传递context.TODO。 只在进程和API间传递请求范围数据时使用context值，不要用于将可选参数传递给函数。 同样的Context可以传递给运行在不同goroutine中的函数，Context是线程安全的。  2. Context接口 type Context interface { Done() \u0026lt;-chan struct{} Err() error Deadline() (deadline time.Time, ok bool) Value(key interface{}) interface{} } Context是一个接口，其定义非常的简单，只包含4个方法：\n  Done() \u0026lt;-chan struct{} Done()方法将一个channel作为取消信号返回给持有context的函数，当该channel被关闭（即Done()被调用），这些函数应该立即停止其工作并返回。\n  Err() error Err()返回一个Error，说明为什么取消context。如果Done()没有被调用，那么Err返回nil。\n  Deadline() (deadline time.Time, ok bool) Deadline()方法返回持有这个context的函数的预期结束时间。如果并没有设置deadline，那么返回的ok将被设置为false。","title":"golang中context包的使用"},{"content":" 在计算机领域，反射是指一类应用，它们能够自描述和自控制。也即是说，这类应用通过采用某种机制来实现对自己行为的描述和监测，并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。 反射（reflect）让我们能在运行期探知对象的类型信息和内存结构，这从一定程度上弥(mi)补了静态语言在动态行为上的不足。 反射（reflect）是在计算机程序运行时，访问，检查，修改它自身的一种能力，是元编程的一种形式。 Go语音提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法和它们支持的内在操作，但是在编译时并不知道这些变量的具体类型。这种机制被称为反射。反射也可以让我们将类型本身作为第一类的值类型处理。\n 1. 为何我们需要反射？ fmt.Fprintf函数提供字符串格式化处理逻辑，它可以对任意类型的值格式化并打印，甚至支持用户自定义的类型。\n让我们也来尝试实现一个类似功能的函数。为了简单起见，我们的函数只接收一个参数，然后返回和fmt.Sprint类似的格式化后的字符串。我们实现的函数名也叫Sprint。 这里我们使用switch类型分支来对不同的类型进行处理。\nfunc Sprint(x interface{}) string { type stringer interface { String() string } switch x := x.(type) { case stringer: return x.String() case string: return x case int: return strconv.Itoa(x) // ...similar cases for int16, uint32, and so on...  case bool: if x { return \u0026#34;true\u0026#34; } return \u0026#34;false\u0026#34; default: // array, chan, func, map, pointer, slice, struct  return \u0026#34;???\u0026#34; } } 但是我们如何处理其它类似[]float64、map[string][]string等类型呢？我们当然可以添加更多的测试分支，但是这些组合类型的数目基本是无穷的。还有如何处理url.Values等命名的类型呢？虽然类型分支可以识别出底层的基础类型是map[string][]string，但是它并不匹配url.Values类型，因为它们是两种不同的类型，而且switch类型分支也不可能包含每个类似url.Values的类型，这会导致对这些库的循环依赖。\n没有一种方法来检查未知类型的表示方式，我们被卡住了，这就是我们为何需要反射的原因。\n2. reflect.Type和reflect.Values 2.1 interface{}和反射 接口值 概念上讲一个接口的值，由两部分组成，一个具体的类型和那个类型的值, 它们被称为接口的动态类型和动态值。在Go的概念模型中，一些提供每个类型信息的值被称为类型描述符，比如类型的名称和方法。在一个接口值中，类型部分代表与之相关类型的描述符。\n下面4个语句中，变量w得到了3个不同的值（第一个和最后一个是相同的）\nvar w io.Writer w = os.Stdout w = new(bytes.Buffer) w = nil 进一步观察在每一个语句后的w变量的值和动态行为。\n 第一个语句定义了变量w:  var w io.Writer 在Go语言中，变量总是被一个定义明确的值初始化，即使接口类型也不例外。对于一个接口的零值就是它的类型和值的部分都是nil.如下图： 一个接口值基于它的动态类型被描述为空或非空，所以这是一个空的接口值。\n第二个语句将一个*os.File类型的值赋给变量w  w = os.Stdout 这个赋值过程调用了一个具体类型到接口类型的隐式转换，这和显式的使用io.Writer(os.Stdout)是等价的.这个接口值的动态类型被设为*os.Stdout指针的类型描述符，它的动态值持有os.Stdout的拷贝；这是一个代表处理标准输出的os.File类型变量的指针 调用一个包含*os.File类型指针的接口值的Write方法，使得(*os.File).Write方法被调用。这个调用输出“hello”。\nw.Write([]byte(\u0026#34;hello\u0026#34;)) 通常在编译期，我们不知道接口值的动态类型是什么，所以一个接口上的调用必须使用动态分配(即运行时分配)。因为不是直接进行调用，所以编译器必须把代码生成在类型描述符的方法Write上，然后间接调用那个地址。这个调用的接收者是一个接口动态值的拷贝：os.Stdout(参照上图)。效果和下面这个直接调用一样：\nos.Stdout.Write([]byte(\u0026#34;hello\u0026#34;)) // \u0026#34;hello\u0026#34; 第三个语句给接口值赋了一个*bytes.Buffer类型的值  w = new(bytes.Buffer) 现在动态类型是*bytes.Buffer并且动态值是一个指向新分配的缓冲区的指针。 Write方法的调用也使用了和之前一样的机制。\nw.Write([]byte(\u0026#34;hello\u0026#34;)) // write \u0026#34;hello\u0026#34; to the bytes.Buffers 这次类型描述符是*bytes.Buffer，所以调用了(*bytes.Buffer).Write方法，并且接收者是该缓冲区的地址。这个调用把字符串“hello”添加到缓冲区中。\n最后，第四个语句将nil赋给了接口值  w = nil 这个重置将它所有的部分都设为nil值，把变量w恢复到和它之前定义时相同的状态图。 interface及其动态类型，动态值的存在，是Golang中实现反射的前提，理解了接口的动态类型的动态值，就更容易理解反射。反射就是用来检测存储在接口变量内部动态类型，动态值的一种机制。\n2.2 类型（Type） 一个Type表示一个Go类型，它是一个接口:reflect.Type()。\n函数reflect.TypeOf接受任意的interface{}类型，并返回对应动态类型的reflect.Type:\nt := reflect.TypeOf(3) // a reflect.Type fmt.Println(t.String()) // int fmt.Println(t) // int TypeOf(3)调用将3作为interface{}类型参数传入。按[2.1节](### 2.1 interface{}和反射)所述，将一个具体的值转为接口类型会有一个隐式的接口转换操作，它会创建一个包含两个信息的接口值：操作数的动态类型（这里是int）和它的动态的值（这里是3）。\n因为reflect.TypeOf返回的是一个接口的动态类型值，它总是返回具体的类型，因此下面的代码将打印“*os.File”而不是“io.Writer”.\nvar w io.Writer = os.Stdout fmt.Println(reflect.TypeOf(w)) // \u0026#34;*os.File\u0026#34; reflect.Type接口是满足fmt.Stringer接口的。因为打印动态类型值对于调试和日志是很有帮助的，fmt.Printf提供了一个简短的%T标志参数，内部使用reflect.TypeOf的结果输出。\nfmt.Printf(\u0026#34;%T\\n\u0026#34;, 3) // \u0026#34;int\u0026#34; 2.3 值（Value） 一个reflect.Value可以持有一个任意类型的值，函数reflect.ValueOf接受任意的interface{}类型，并返回对应动态类型的reflect。Value。\n与reflect.TypeOf类似，reflect.ValueOf返回的结果也是对于具体的类型，但是reflect.Value也可以持有一个接口值。\nv := reflect.ValueOf(3) // a reflect.Value fmt.Println(v) // \u0026#34;3\u0026#34; fmt.Printf(\u0026#34;%v\\n\u0026#34;, v) // \u0026#34;3\u0026#34; fmt.Println(v.String()) // NOTE: \u0026#34;\u0026lt;int Value\u0026gt; 和reflect.Type 类似, reflect.Value 也满足 fmt.Stringer 接口, 但是除非 Value 持有的是字符串,否则 String 只是返回具体的类型. 相同, 使用 fmt 包的 %v 标志参数, 将使用 reflect.Values 的结果格式化.\n调用Value的Type方法将返回具体类型所对应的reflect.Type\nt := v.Type() fmt.Println(t.String()) // int 逆操作是调用 reflect.ValueOf 对应的 reflect.Value.Interface 方法. 它返回一个 interface{} 类型 表示 reflect.Value 对应类型的具体值:\nv := reflect.ValueOf(3) // a reflect.Value x := v.Interface() // an interface{} i := x.(int) // an int fmt.Printf(\u0026#34;%d\\n\u0026#34;, i) // \u0026#34;3\u0026#34; 一个 reflect.Value 和 interface{} 都能保存任意的值. 所不同的是, 一个空的接口隐藏了值对应的表示方式和所有的公开的方法, 因此只有我们知道具体的动态类型才能使用类型断言来访问内部的值(就像上面那样), 对于内部值并没有特别可做的事情. 相比之下, 一个 Value 则有很多方法来检查其内容, 无论它的具体类型是什么.\n2.4 再次尝试format.Any 我们使用 reflect.Value 的 Kind 方法来替代之前的类型switch. 虽然还是有无穷多的类型, 但是它们的kinds类型却是有限的: Bool, String 和 所有数字类型的基础类型; Array 和 Struct 对应的聚合类型; Chan, Func, Ptr, Slice, 和 Map 对应的引用类似; 接口类型; 还有表示空值的无效类型. (空的 reflect.Value 对应 Invalid 无效类型.\nreflect.Value.Kind()返回reflect.Value的基类型。即对应类型的底层表示。\nvar f func(string)int v := reflect.TypeOf(f) fmt.Println(v, v.Kind()) // \u0026#34;func(string)int\u0026#34; \u0026#34;int\u0026#34; v.Kind() == reflect.Func // true package format import ( \u0026#34;reflect\u0026#34; \u0026#34;strconv\u0026#34; ) // Any formats any value as a string. func Any(value interface{}) string { return formatAtom(reflect.ValueOf(value)) } // formatAtom formats a value without inspecting its internal structure. func formatAtom(v reflect.Value) string { switch v.Kind() { case reflect.Invalid: return \u0026#34;invalid\u0026#34; case reflect.Int, reflect.Int8, reflect.Int16, reflect.Int32, reflect.Int64: return strconv.FormatInt(v.Int(), 10) case reflect.Uint, reflect.Uint8, reflect.Uint16, reflect.Uint32, reflect.Uint64, reflect.Uintptr: return strconv.FormatUint(v.Uint(), 10) // ...floating-point and complex cases omitted for brevity... \tcase reflect.Bool: return strconv.FormatBool(v.Bool()) case reflect.String: return strconv.Quote(v.String()) case reflect.Chan, reflect.Func, reflect.Ptr, reflect.Slice, reflect.Map: return v.Type().String() + \u0026#34; 0x\u0026#34; + strconv.FormatUint(uint64(v.Pointer()), 16) default: // reflect.Array, reflect.Struct, reflect.Interface \treturn v.Type().String() + \u0026#34; value\u0026#34; } } 3. 三大法则 3.1 从interface{}变量可以反射出反射对象 当我们执行 reflect.ValueOf(1) 时，虽然看起来是获取了基本类型 int 对应的反射类型，但是由于 reflect.TypeOf、reflect.ValueOf 两个方法的入参都是 interface{} 类型，所以在方法执行的过程中发生了类型转换。\n因为Go 语言的函数调用都是值传递的，所以变量会在函数调用时进行类型转换。基本类型 int 会转换成 interface{} 类型，这也就是为什么第一条法则是从接口到反射对象。\n上面提到的 reflect.TypeOf 和 reflect.ValueOf 函数就能完成这里的转换，如果我们认为 Go 语言的类型和反射类型处于两个不同的世界，那么这两个函数就是连接这两个世界的桥梁。 请看以下例子：\nauthor := \u0026#34;Bob\u0026#34; fmt.Println(\u0026#34;TypeOf author:\u0026#34;, reflect.TypeOf(author)) // TypeOf author: string  fmt.Println(\u0026#34;ValueOf author:\u0026#34;, reflect.ValueOf(author)) // ValueOf author: Bob 有了变量的类型之后，我们可以通过 Method 方法获得类型实现的方法，通过 Field 获取类型包含的全部字段。对于不同的类型，我们也可以调用不同的方法获取相关信息：\n 结构体：获取字段的数量并通过下标和字段名获取字段 StructField； 哈希表：获取哈希表的 Key 类型； 函数或方法：获取入参和返回值的类型； … 总而言之，使用 reflect.TypeOf和 reflect.ValueOf 能够获取 Go 语言中的变量对应的反射对象。一旦获取了反射对象，我们就能得到跟当前类型相关数据和操作，并可以使用这些运行时获取的结构执行方法。  3.2 从反射对象可以获取interface{}变量 既然能够将接口类型的变量转换成反射对象，那么一定需要其他方法将反射对象还原成接口类型的变量，reflect包中的reflect.Value.Interface就能完成这项工作：\nv := reflect.ValueOf(3) // a reflect.Value x := v.Interface() // an interface{} i := x.(int) // an int fmt.Printf(\u0026#34;%d\\n\u0026#34;, i) // \u0026#34;3\u0026#34; reflect.ValueOf、reflect.TypeOf与Interface方法可以说是一个互逆的过程。reflect.ValueOf、reflect.TypeOf将interface{}转化为reflect对象，而Interface将一个reflect对象重新转化为一个接口值。 3.3 要修改反射对象，其值必须可设置 假如我们想要更新一个reflect.Value,那么它持有的值一定是可以被更新的，假设有如下代码：\ni := 1 v := reflect.ValueOf(i) v.SetInt(10) fmt.Println(i) // panic: reflect: reflect.flag.mustBeAssignable using unaddressable value 运行上述代码会导致程序崩溃并报出 “reflect: reflect.flag.mustBe Assignableusing unaddressable value” 错误，仔细思考一下就能够发现出错的原因：由于 Go 语言的函数调用都是传值的，所以我们得到的反射对象跟最开始的变量没有任何关系，那么直接修改反射对象无法改变原始变量，程序为了防止错误就会崩溃。\n想要修改原变量只能使用如下方法：\ni := 1 v := reflect.ValueOf(\u0026amp;i) v.Elem().SetInt(10) fmt.Println(i) reflect.Value.Elem()方法获取指针指向的变量\n4. reflect场景实践  动态调用函数(无参数)  type T struct {} func main() { name := \u0026#34;Do\u0026#34; t := \u0026amp;T{} reflect.ValueOf(t).MethodByName(name).Call(nil) } func (t *T) Do() { fmt.Println(\u0026#34;hello\u0026#34;) } 动态调用函数(有参数)  type T struct{} func main() { name := \u0026#34;Do\u0026#34; t := \u0026amp;T{} a := reflect.ValueOf(1111) b := reflect.ValueOf(\u0026#34;world\u0026#34;) in := []reflect.Value{a, b} reflect.ValueOf(t).MethodByName(name).Call(in) } func (t *T) Do(a int, b string) { fmt.Println(\u0026#34;hello\u0026#34; + b, a) } 处理返回值中的错误  返回值也是 Value 类型，对于错误，可以转为 interface 之后断言\ntype T struct{} func main() { name := \u0026#34;Do\u0026#34; t := \u0026amp;T{} ret := reflect.ValueOf(t).MethodByName(name).Call(nil) fmt.Printf(\u0026#34;strValue: %[1]v\\nerrValue: %[2]v\\nstrType: %[1]T\\nerrType: %[2]T\u0026#34;, ret[0], ret[1].Interface().(error)) } func (t *T) Do() (string, error) { return \u0026#34;hello\u0026#34;, errors.New(\u0026#34;new error\u0026#34;) } struct tag 解析  type T struct { A int `json:\u0026#34;aaa\u0026#34; test:\u0026#34;testaaa\u0026#34;` B string `json:\u0026#34;bbb\u0026#34; test:\u0026#34;testbbb\u0026#34;` } func main() { t := T{ A: 123, B: \u0026#34;hello\u0026#34;, } tt := reflect.TypeOf(t) for i := 0; i \u0026lt; tt.NumField(); i++ { field := tt.Field(i) if json, ok := field.Tag.Lookup(\u0026#34;json\u0026#34;); ok { fmt.Println(json) } test := field.Tag.Get(\u0026#34;test\u0026#34;) fmt.Println(test) } } 类型转换和赋值  type T struct { A int `newT:\u0026#34;AA\u0026#34;` B string `newT:\u0026#34;BB\u0026#34;` } type newT struct { AA int BB string } func main() { t := T{ A: 123, B: \u0026#34;hello\u0026#34;, } tt := reflect.TypeOf(t) tv := reflect.ValueOf(t) newT := \u0026amp;newT{} newTValue := reflect.ValueOf(newT) for i := 0; i \u0026lt; tt.NumField(); i++ { field := tt.Field(i) newTTag := field.Tag.Get(\u0026#34;newT\u0026#34;) tValue := tv.Field(i) newTValue.Elem().FieldByName(newTTag).Set(tValue) } fmt.Println(newT) } 通过 kind（）处理不同分支  func main() { a := 1 t := reflect.TypeOf(a) switch t.Kind() { case reflect.Int: fmt.Println(\u0026#34;int\u0026#34;) case reflect.String: fmt.Println(\u0026#34;string\u0026#34;) } } 判断实例是否实现了某接口  type IT interface { test1() } type T struct { A string } func (t *T) test1() {} func main() { t := \u0026amp;T{} ITF := reflect.TypeOf((*IT)(nil)).Elem() tv := reflect.TypeOf(t) fmt.Println(tv.Implements(ITF)) } Reference 《The Go Programmer Language》\nGolang的反射reflect深入理解和示例 Go 语言设计与实现 《Go学习笔记 . 雨痕》反射 Go Reflect 高级实践 Package reflect 这是一个测试\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/golang%E4%B8%AD%E5%8F%8D%E5%B0%84reflect%E7%9A%84%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8/","summary":"在计算机领域，反射是指一类应用，它们能够自描述和自控制。也即是说，这类应用通过采用某种机制来实现对自己行为的描述和监测，并能根据自身行为的状态和结果，调整或修改应用所描述行为的状态和相关的语义。 反射（reflect）让我们能在运行期探知对象的类型信息和内存结构，这从一定程度上弥(mi)补了静态语言在动态行为上的不足。 反射（reflect）是在计算机程序运行时，访问，检查，修改它自身的一种能力，是元编程的一种形式。 Go语音提供了一种机制在运行时更新变量和检查它们的值、调用它们的方法和它们支持的内在操作，但是在编译时并不知道这些变量的具体类型。这种机制被称为反射。反射也可以让我们将类型本身作为第一类的值类型处理。\n 1. 为何我们需要反射？ fmt.Fprintf函数提供字符串格式化处理逻辑，它可以对任意类型的值格式化并打印，甚至支持用户自定义的类型。\n让我们也来尝试实现一个类似功能的函数。为了简单起见，我们的函数只接收一个参数，然后返回和fmt.Sprint类似的格式化后的字符串。我们实现的函数名也叫Sprint。 这里我们使用switch类型分支来对不同的类型进行处理。\nfunc Sprint(x interface{}) string { type stringer interface { String() string } switch x := x.(type) { case stringer: return x.String() case string: return x case int: return strconv.Itoa(x) // ...similar cases for int16, uint32, and so on...  case bool: if x { return \u0026#34;true\u0026#34; } return \u0026#34;false\u0026#34; default: // array, chan, func, map, pointer, slice, struct  return \u0026#34;?","title":"Golang中反射reflect的基本使用"},{"content":"1. 按照Oh my zsh $ sh -c \u0026#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 2. 配置Oh my zsh   将zsh设置为默认Shell (脚本的最后一般会问你是否切换)\nchsh -s /bin/zsh # 不需要使用root权限   更换主题\nvim ~/.zshrc 找到ZSH_THEME='robbyrussell', 更换为你想要使用的主题，可以在这里找到你想要的主题\n  安装插件\nvim ~/.zshrc 找到plugins=(), 添加插件名称，我这里添加的插件有：\nplugins=(git zsh-autosuggestions zsh-syntax-highlighting) git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions   完成\nsource ~/.zshrc # 启动zsh   3. 使用主题powerlevel10k 下载主题\ngit clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 打开你的~/.zshrc,将主题换为：powerlevel10k/powerlevel10k\n更改保存并使用主题\nsource ~/.zshrc 这时powerlevel10k会自动启动，询问你想要的配置 按照提示配置你想要的风格即可\n","permalink":"http://yangchnet.github.io/Dessert/posts/tool/zsh%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/","summary":"1. 按照Oh my zsh $ sh -c \u0026#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 2. 配置Oh my zsh   将zsh设置为默认Shell (脚本的最后一般会问你是否切换)\nchsh -s /bin/zsh # 不需要使用root权限   更换主题\nvim ~/.zshrc 找到ZSH_THEME='robbyrussell', 更换为你想要使用的主题，可以在这里找到你想要的主题\n  安装插件\nvim ~/.zshrc 找到plugins=(), 添加插件名称，我这里添加的插件有：\nplugins=(git zsh-autosuggestions zsh-syntax-highlighting) git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions   完成\nsource ~/.zshrc # 启动zsh   3. 使用主题powerlevel10k 下载主题\ngit clone --depth=1 https://gitee.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k 打开你的~/.zshrc,将主题换为：powerlevel10k/powerlevel10k\n更改保存并使用主题\nsource ~/.zshrc 这时powerlevel10k会自动启动，询问你想要的配置 按照提示配置你想要的风格即可","title":"zsh的基本配置"},{"content":"1. 按照Oh my zsh $ sh -c \u0026#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 2. 配置Oh my zsh  将zsh设置为默认Shell chsh -s /bin/zsh # 不需要使用root权限  更换主题 vim ~/.zshrc 找到ZSH_THEME='robbyrussell', 更换为你想要使用的主题，可以在这里找到你想要的主题\n 安装插件 vim ~/.zshrc 找到plugins=(), 添加插件名称，我这里添加的插件有：\nplugins=(git zsh-autosuggestions zsh-syntax-highlighting)  完成 source ~/.zshrc # 启动zsh    推荐主题powerlevel10k\n ","permalink":"http://yangchnet.github.io/Dessert/posts/windows/zsh%E7%9A%84%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE/","summary":"1. 按照Oh my zsh $ sh -c \u0026#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\u0026#34; 2. 配置Oh my zsh  将zsh设置为默认Shell chsh -s /bin/zsh # 不需要使用root权限  更换主题 vim ~/.zshrc 找到ZSH_THEME='robbyrussell', 更换为你想要使用的主题，可以在这里找到你想要的主题\n 安装插件 vim ~/.zshrc 找到plugins=(), 添加插件名称，我这里添加的插件有：\nplugins=(git zsh-autosuggestions zsh-syntax-highlighting)  完成 source ~/.zshrc # 启动zsh    推荐主题powerlevel10k\n ","title":"zsh的基本配置"},{"content":"1. Anaconda下载地址  官方下载地址：https://www.anaconda.com/distribution/#linux 清华大学镜像：https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/ # 选择你想安装的版本下载  2. 安装 $ bash Anaconda3-2021.05-Linux-x86_64.sh # 中间会有一些选择，按照自己的意愿选择即可  关闭并重新打开你的终端来激活conda\n3. 使用  更新自己  # 更新conda conda update conda conda update anaconda  更新时出现了ValueError: check_hostname requires server_hostname错误，经查发现是代理的问题，可尝试关闭或开启代理再次尝试\n  对包的操作\n 更新包  conda update --all # 更新所有包  安装包  conda install [包名]   对环境的操作\n 创建环境  conda create --name [环境名字] # 使用默认的Python版本  激活环境  conda activate [环境名字]  退出环境  conda deactivate  查看环境名字  conda env list # conda info -e  删除环境中某个包  conda remove [环境名] [包名]  修改环境名字  conda create -n [新环境名] --clone [旧环境名] # 克隆旧的 conda remove -n [旧环境名] # 删除旧的  删除环境  conda remove -n [环境名] --all   4. 配置 #1、换源,添加清华源 方法一 vim ~/.condarc #添加以下内容 channels: - https://mirrors.ustc.edu.cn/anaconda/pkgs/main/ - https://mirrors.ustc.edu.cn/anaconda/cloud/conda-forge/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - defaults show_channel_urls: true #2、换源,添加清华源 方法二 onda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --set show_channel_urls yes #换回默认源 conda config --remove-key channels ","permalink":"http://yangchnet.github.io/Dessert/posts/python/deepin15%E5%AE%89%E8%A3%85anaconda/","summary":"1. Anaconda下载地址  官方下载地址：https://www.anaconda.com/distribution/#linux 清华大学镜像：https://mirrors.tuna.tsinghua.edu.cn/anaconda/archive/ # 选择你想安装的版本下载  2. 安装 $ bash Anaconda3-2021.05-Linux-x86_64.sh # 中间会有一些选择，按照自己的意愿选择即可  关闭并重新打开你的终端来激活conda\n3. 使用  更新自己  # 更新conda conda update conda conda update anaconda  更新时出现了ValueError: check_hostname requires server_hostname错误，经查发现是代理的问题，可尝试关闭或开启代理再次尝试\n  对包的操作\n 更新包  conda update --all # 更新所有包  安装包  conda install [包名]   对环境的操作\n 创建环境  conda create --name [环境名字] # 使用默认的Python版本  激活环境  conda activate [环境名字]  退出环境  conda deactivate  查看环境名字  conda env list # conda info -e  删除环境中某个包  conda remove [环境名] [包名]  修改环境名字  conda create -n [新环境名] --clone [旧环境名] # 克隆旧的 conda remove -n [旧环境名] # 删除旧的  删除环境  conda remove -n [环境名] --all   4.","title":"Deepin15安装Anaconda"},{"content":"1. goroutine中panic无法恢复 正常的函数中panic的recover\nimport ( \u0026#34;fmt\u0026#34; ) func main(){ defer func(){ if err := recover(); err != nil{ fmt.Println(err) } }() var bar = []int{1} fmt.Println(bar[1]) } reflect: slice index out of range goroutine中panic的恢复\nfunc main(){ defer func(){ if err := recover(); err != nil { // 在这里使用recover(),不能捕获panic \tfmt.Println(\u0026#34;catch you, bad guy\u0026#34;) } }() go func(){ fmt.Println(\u0026#34;I\u0026#39;m in a goroutine\u0026#34;) panic(\u0026#34;come to catch me\u0026#34;) }() time.Sleep(10 * time.Second) // 主进程做其他事 } I'm in a goroutine panic: come to catch me goroutine 6 [running]: main.foo.func2() /home/lc/Workspace/lab/main/main.go:22 +0x95 created by main.foo /home/lc/Workspace/lab/main/main.go:15 +0x5b Process finished with the exit code 2 上面的程序在goroutine中触发了一个panic，现在假设foo()主进程是我们的服务，我们在服务的main()中使用recover()尝试捕获程序中发生的panic，但程序运行后发现，goroutine中触发的panic没有被捕获，程序直接退出，代表我们的服务挂掉了。显然在正式环境中，我们不可能容忍这样的事情发生，因此需要对goroutine中触发的panic进行捕获处理。\n显然最简单的方法是在goroutine中添加recover(), 进行异常捕获，如下：\nfunc main(){ go func(){ defer func(){ if err := recover(); err != nil { // 在这里使用recover(),不能捕获panic  fmt.Println(\u0026#34;catch you, bad guy\u0026#34;) } }() fmt.Println(\u0026#34;I\u0026#39;m in a goroutine\u0026#34;) panic(\u0026#34;come to catch me\u0026#34;) }() time.Sleep(10 * time.Second) // 主进程做其他事 } I'm in a goroutine catch you, bad guy Process finished with the exit code 0 这时程序正常退出，服务没有挂掉。但每次使用goroutine都要加recover()稍显麻烦。我们可以使用函数式编程的思想来对goroutine进行一下封装：\nfunc Go(f func()){ go func(){ defer func(){ if err := recover(); err != nil{ fmt.Println(\u0026#34;catch you, bad guy\u0026#34;) } }() f() }() } func main(){ Go(func(){ fmt.Printf(\u0026#34;I\u0026#39;m in a goroutine\u0026#34;) panic(\u0026#34;come to catch me\u0026#34;) }) time.Sleep(10 * time.Second) // 主进程做其他事 } I'm in a goroutine catch you, bad guy Process finished with the exit code 0 显然，这样封装过后我们捕获到了panic，但实际上我们仍然是在goroutine内部捕获的panic，A goroutine cannot recover from a panic in another goroutine.\n2. goroutine的泄露问题 2.1 什么是goroutine泄露 如果你启动了一个goroutine，但并没有符合预期的退出，而是直到程序结束，此goroutine才退出，这种情况就是goroutine泄露。当goroutine泄露发生时，该goroutine所占用的内存不能得到释放，可用内存持续减少，最终将导致系统崩溃。\npackage main import \u0026#34;fmt\u0026#34; func main(){ for{ go sayHello() } } func sayHello(){ for{ fmt.Println(\u0026#34;hello\u0026#34;) } } 以上代码是一个最简单的goroutine泄露场景，所有的goroutine都没有退出，而是一直在后台执行。在我的电脑上执行以上代码后，内存占用达到98%。\n2.2 goroutine泄露发生的原因 2.2.1 channel导致的泄露 1. 只读不发\nfunc leak() { ch := make(chan int) go func() { val := \u0026lt;-ch fmt.Println(\u0026#34;We received a value:\u0026#34;, val) }() } 在这个函数中，leak创建了一个goroutine，其在从ch中读取一个值之前一直阻塞，但leak并没有往ch中发送值，因此goroutine将一直阻塞，在函数结束前不能得到释放。\n 解决方案\n 记得发送\nfunc unleak() { ch := make(chan int) go func() { val := \u0026lt;-ch fmt.Println(\u0026#34;We received a value:\u0026#34;, val) }() ch \u0026lt;- 1 } 2. 只发不读\nfunc gen(nums ...int) \u0026lt;-chan int { out := make(chan int) go func() { for _, n := range nums { out \u0026lt;- n } close(out) }() return out } func main() { defer func() { time.Sleep(time.Second) fmt.Println(\u0026#34;the number of goroutines: \u0026#34;, runtime.NumGoroutine()) }() _ = gen(2, 3) } the number of goroutines: 2 在这段代码中，gen向channel中发送数据，但由于没有对channel做接收，因此这个channel将会被阻塞，从而goroutine也不能正常退出，发生了goroutine泄露。\n 解决方案\n 利用channel向接收者发送停止消息,goroutine中使用select多路复用接收退出信号。但如果我们想要退出多个goroutine怎么办呢。这时一种可行的方法是使用channel的广播机制向所有goroutine广播消息。\n当一个被关闭的channel中已经发送的数据都被成功接收后，后续的接收操作将不再阻塞，它们会立即返回一个零值。将这个机制拓展一下，不要向channel发送值，而是用关闭一个channel来进行广播。\nfunc gen(done chan struct{}, nums ...int) \u0026lt;-chan int { out := make(chan int) go func() { defer close(out) for _, n := range nums { select{ case out \u0026lt;- n: case \u0026lt;- done: return } } }() return out } func main() { defer func() { time.Sleep(time.Second) fmt.Println(\u0026#34;the number of goroutines: \u0026#34;, runtime.NumGoroutine()) }() done := make(chan struct{}) defer close(done) gen(done, 2, 3) gen(done, 2, 3) // 调用两次，代表创建多个goroutine } the number of goroutines: 1 3. select操作在所有case上阻塞\nfunc fibonacci(c, quit chan int) { x, y := 0, 1 for{ select { case c \u0026lt;- x: x, y = y, x+y case \u0026lt;-quit: fmt.Println(\u0026#34;quit\u0026#34;) return } } } func main() { defer func() { time.Sleep(time.Second) fmt.Println(\u0026#34;the number of goroutines: \u0026#34;, runtime.NumGoroutine()) }() c := make(chan int) quit := make(chan int) go fibonacci(c, quit) for i := 0; i \u0026lt; 10; i++{ fmt.Println(\u0026lt;- c) } // close(quit) } the number of goroutines: 2 在上面的代码中，我们用一个独立的goroutine作为斐波那契数列的生成器，但是若在主函数的最后忘记向quit发送或关闭quit，那么显然fibonacci将一直运行到main退出，造成goroutine泄露。\n 解决方案\n  使用defer或在程序的最后往quit中发送或关闭quit 使用context包  func fibonacci(c chan int, ctx context.Context) { x, y := 0, 1 for{ select { case c \u0026lt;- x: x, y = y, x+y case \u0026lt;-ctx.Done(): fmt.Println(\u0026#34;quit\u0026#34;) return } } } func main() { defer func() { time.Sleep(time.Second) fmt.Println(\u0026#34;the number of goroutines: \u0026#34;, runtime.NumGoroutine()) }() ctx, cancel := context.WithCancel(context.Background()) defer cancel() c := make(chan int) go fibonacci(c, ctx) for i := 0; i \u0026lt; 10; i++{ fmt.Println(\u0026lt;- c) } } the number of goroutines: 1 context.WithCancel接收一个context.Context作为参数，返回一个附带Done channel的concext.Context的拷贝和一个cancel函数，当cancel被调用时，附带的Done channel就会被关闭。goroutine中通过检查ctx.Done()，就可以得知是否应该退出。\n4. nil channel 向nil channel发送和接收数据都将会导致阻塞。这种情况可能在我们定义 channel 时忘记初始化的时候发生。\nfunc main() { defer func() { time.Sleep(time.Second) fmt.Println(\u0026#34;the number of goroutines: \u0026#34;, runtime.NumGoroutine()) }() var ch chan int go func() { \u0026lt;-ch // ch \u0026lt;- 1 \t}() } the number of goroutines: 2 无论是向nil channel中发送还是接受，都会导致阻塞\n 解决方案\n 不要忘记初始化\n5. 死循环 同[2.1小节](### 2.1 什么是goroutine泄露)中的情况\n2.2.2 同步机制导致的泄露 1. 锁导致的goroutine泄露\nfunc main() { total := 0 defer func() { time.Sleep(time.Second) fmt.Println(\u0026#34;the number of goroutines: \u0026#34;, runtime.NumGoroutine()) }() var mutex sync.Mutex for i := 0; i \u0026lt; 2; i++ { go func() { mutex.Lock() total += 1 }() } } 在这段代码中，创建了两个goroutine，两个goroutine都要对total进行独占访问，但由于第一个goroutine没有解锁，导致第二个goroutine一直阻塞。\n 解决方案\n Lock()之后马上defer Unlock()\n2. WaitGroup导致的内存泄露\nfunc handle() { var wg sync.WaitGroup wg.Add(4) go func() { wg.Done() }() go func() { wg.Done() }() go func() { wg.Done() }() wg.Wait() } func main() { defer func() { time.Sleep(time.Second * 2) fmt.Println(\u0026#34;the number of goroutines: \u0026#34;, runtime.NumGoroutine()) }() go handle() } the number of goroutines: 2 在以上代码中，设置并发任务数为4，但其实只有3个任务，所以wg.Wait永远不可能满足。handle将一直被阻塞。\n 解决方案\n 建议不要一次性设置任务数量，尽量在任务启动时通过wg.Add(1)的方式来增加任务数。\n2.3 goroutine泄露的排查 2.3.1 使用pprof进行排查 参考Golang 大杀器之性能剖析 PProf\n2.3.2 使用prometheus进行排查 本小节请转至prometheus的使用查看\n3 使用池来管理goroutine 3.1 池 本小节转至线程池\n3.2 goroutine池的设计 经过3.1小节的介绍我们知道，一个线程池或者说一个goroutine池实际上就是一个生产者-消费者模型，生产者生产的是需要并发执行的任务，消费者从任务队列中取出任务后进行“消费”的过程，就是完成任务的过程。\n3.2.1 任务（task）的设计 一个最简单的任务就是一个func()类型，即：\ntype Task func() 但这显然不能满足多样化的需求。但太过具体的函数签名也不能满足抽象的要求，一种可行的方案是：\ntype Task struct { f func (...interface{}) params []interface{} } 3.2.2 任务队列 使用channel来实现任务队列，Worker从队列中获取任务\nvar task chan Task 3.2.3 工人（Worker）的设计 由线程池的2.4.1小节可知，一个Worker持有一个工作线程（goroutine）和任务。\ntype Worker struct { task chan Task pool *Pool } 3.2.4 池（Pool）的设计 经过前面的分析可知，一个池中需要有一定数量的worker， 相应的也应保存worker的数目，包括最大限制数目与正在运行数目，为了实现Pool的正常退出，还应提供退出信号与同步信号量保证每个worker都正常退出。\ntype sig struct{} type Pool struct { capacity uint64 free uint64 workers []*Worker destory sig m sync.Mutex wg *sync.WaitGroup } 详细代码在：\n参考  线程池 Java线程池实现原理及其在美团业务中的实践 新手一看就懂的线程池！ 线程池学习看这篇就够了,万字总结线程池!!!\n  goroutine泄露 Golang中的goroutine泄漏问题 跟读者聊 Goroutine 泄露的 N 种方法，真刺激！ 如何防止 goroutine 泄露 技术解析系列 | PouchContainer Goroutine Leak 检测实践 goroutine泄露：原理、场景、检测和防范\n  其他 Go语言野生goroutine的处理 goroutine 到底该怎么用 如何查看golang程序中有哪些goroutine 正在执行 Go 语言踩坑记——panic 与 recover Handling panics in go routines\n  监控工具 INSTRUMENTING A GO APPLICATION FOR PROMETHEUS Package pprof\n ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/%E9%87%8E%E7%94%9Fgoroutine%E5%B8%A6%E6%9D%A5%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","summary":"1. goroutine中panic无法恢复 正常的函数中panic的recover\nimport ( \u0026#34;fmt\u0026#34; ) func main(){ defer func(){ if err := recover(); err != nil{ fmt.Println(err) } }() var bar = []int{1} fmt.Println(bar[1]) } reflect: slice index out of range goroutine中panic的恢复\nfunc main(){ defer func(){ if err := recover(); err != nil { // 在这里使用recover(),不能捕获panic \tfmt.Println(\u0026#34;catch you, bad guy\u0026#34;) } }() go func(){ fmt.Println(\u0026#34;I\u0026#39;m in a goroutine\u0026#34;) panic(\u0026#34;come to catch me\u0026#34;) }() time.Sleep(10 * time.Second) // 主进程做其他事 } I'm in a goroutine panic: come to catch me goroutine 6 [running]: main.","title":"野生Goroutine带来的问题及对应解决方案"},{"content":"1. 前后台切换  在Linux终端运行命令的时候，在命令末尾加上 \u0026amp; 符号，就可以让程序在后台运行  $ ./main \u0026amp;  如果程序正在前台运行，可以使用 Ctrl+z 选项把程序暂停，然后用 bg %[number] 命令把这个程序放到后台运行，摁Ctrl+z，然后在最后一行加上bg %number\n  对于所有运行的程序，我们可以用jobs –l 指令查看\n  $ jobs -l 也可以用 fg %[number] 指令把一个程序掉到前台  $ fg %1 也可以直接终止后台运行的程序，使用 kill 命令  $ kill %1 2. fg、bg、jobs、\u0026amp;、nohup、ctrl+z、ctrl+c 命令  \u0026amp; 加在一个命令的最后，可以把这个命令放到后台执行，如  watch -n 10 sh test.sh \u0026amp; #每10s在后台执行一次test.sh脚本  ctrl + z 可以将一个正在前台执行的命令放到后台，并且处于暂停状态。\n  jobs 查看当前有多少在后台运行的命令 jobs -l选项可显示所有任务的PID，jobs的状态可以是running, stopped, Terminated。但是如果任务被终止了（kill），shell 从当前的shell环境已知的列表中删除任务的进程标识。\n  fg 将后台中的命令调至前台继续运行。如果后台中有多个命令，可以用fg %jobnumber（是命令编号，不是进程号）将选中的命令调出。\n  bg 将一个在后台暂停的命令，变成在后台继续执行。如果后台中有多个命令，可以用bg %jobnumber将选中的命令调出。\n  kill\n   通过jobs命令查看job号（假设为num），然后执行kill %num 通过ps命令查看job的进程号（PID，假设为pid），然后执行kill pid 前台进程的终止：Ctrl+c  nohup 如果让程序始终在后台执行，即使关闭当前的终端也执行（之前的\u0026amp;做不到），这时候需要nohup。该命令可以在你退出帐户/关闭终端之后继续运行相应的进程。关闭中断后，在另一个终端jobs已经无法看到后台跑得程序了，此时利用ps（进程查看命令）  $ ps -aux | grep “test.sh” #a:显示所有程序 u:以用户为主的格式来显示 x:显示所有程序，不以终端机来区分 查看nohup.out的日志  $ tail -fn 50 nohup.out  转自：Linux程序前台后台切换\n ","permalink":"http://yangchnet.github.io/Dessert/posts/linux/linux%E7%A8%8B%E5%BA%8F%E5%89%8D%E5%8F%B0%E5%90%8E%E5%8F%B0%E5%88%87%E6%8D%A2/","summary":"1. 前后台切换  在Linux终端运行命令的时候，在命令末尾加上 \u0026amp; 符号，就可以让程序在后台运行  $ ./main \u0026amp;  如果程序正在前台运行，可以使用 Ctrl+z 选项把程序暂停，然后用 bg %[number] 命令把这个程序放到后台运行，摁Ctrl+z，然后在最后一行加上bg %number\n  对于所有运行的程序，我们可以用jobs –l 指令查看\n  $ jobs -l 也可以用 fg %[number] 指令把一个程序掉到前台  $ fg %1 也可以直接终止后台运行的程序，使用 kill 命令  $ kill %1 2. fg、bg、jobs、\u0026amp;、nohup、ctrl+z、ctrl+c 命令  \u0026amp; 加在一个命令的最后，可以把这个命令放到后台执行，如  watch -n 10 sh test.sh \u0026amp; #每10s在后台执行一次test.sh脚本  ctrl + z 可以将一个正在前台执行的命令放到后台，并且处于暂停状态。\n  jobs 查看当前有多少在后台运行的命令 jobs -l选项可显示所有任务的PID，jobs的状态可以是running, stopped, Terminated。但是如果任务被终止了（kill），shell 从当前的shell环境已知的列表中删除任务的进程标识。","title":"Linux程序前台后台切换"},{"content":"1. 线程池基础 1.1 野生线程 在我们平常的开发中，经常会有用到多线程的场景，合理利用多线程可有效利用CPU的多核结构，提高程序的执行效率。有这样一种线程：我们利用其完成一些工作，但只是将工作交给这个线程，该线程并不保证完成任务，也不保证正常退出，并且在线程开始运行后我们无法对其进行控制。这种状态可称为：野生线程，意为其已经不受控制，在内存中自由运行。\n这种线程可能带来一系列问题：\n 频繁申请/销毁线程，可能带来巨大的额外消耗 当内存中存在较多的野生线程，会导致过分调度，降低系统性能 不能正常退出的线程会导致内存泄露 系统无法合理管理内部的资源分布，会降低系统的稳定性 ……  鉴于以上野生线程带来的问题，我们需要一种方式将其管理起来，使其从野生的线程变成“家养”的线程。\n1.2 什么是线程池  池化：池化是一种将资源统一进行管理，从而最大化收益并最小化风险的思想。\n 线程池维护若干个线程，在总体上控制线程的数量，具体上控制线程的创建、销毁等生命周期，系统可通过申请线程池中的线程异步的完成某个任务。线程池通过对线程的管理实现对资源的有效利用，避免系统资源浪费或内存泄露等问题。\n1.3 使用线程池的好处  线程池中的线程可反复利用，减少了线程创建和销毁的开销 任务无需等待线程创建即可开始运行，提高了系统响应速度 通过设置合理的线程池线程数，可有效避免资源使用不当，资源浪费 对线程运行进行有效的监视与管理  通俗易懂的讲，如果将线程比作完成任务的人，那么线程池就像一个专门管理这些人的部门。当我有任务到来时，直接把任务交给该部门，而不用自己再去找人来完成任务。\n2. 线程池的工作机制 2.1 线程池模型 线程池的内部实际上可以看做是生产者消费者模型，二者并不直接关联，通过任务队列进行交互，从而可以有效的缓冲任务，复用线程。\n在线程池模型中，扮演生产者角色的是任务管理部分，其接受提交的任务，并判断任务应如何处理：\n 直接申请线程执行该任务 缓冲到队列中等待线程执行 直接拒绝该任务  线程管理部分是消费者，线程被统一维护在线程池中，当有任务请求到来时，某一线程被分配去执行这个任务，执行完成后继续或许新的任务来执行，最终当线程获取不到任务时，线程就被回收以节省系统资源。\n2.2 线程池的状态 线程池一方面维护自身的状态，另一方面管理线程和任务，使二者良好的结合从而执行并行任务。 线程池的状态有5种：\n   运行状态 状态描述     RUNNING 能接受新提交的任务，并且也能处理阻塞队列中的任务   SHUTDOWN 关闭状态，不再接受新提交的任务，但可以继续处理阻塞队列中已保存的任务   STOP 不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程   TIDYING 所有的任务都已终止，有效线程数为0   TERMINATED 在terminated()方法执行后进入该状态   其生命周期转换如下图所示：     sequenceDiagram RUNNING-\u0026gt;\u0026gt;SHUTDOWN:shutdown() RUNNING-\u0026gt;\u0026gt;STOP: shutdownNow() SHUTDOWN-\u0026gt;\u0026gt;TIDYING:所有任务都已完成，阻塞队列为空，工作线程数为0 STOP-\u0026gt;\u0026gt;TIDYING:线程池中工作线程数为0 TIDYING-\u0026gt;\u0026gt;TERMINATED: terminated() 2.3 任务执行机制 2.3.1 任务调度 任务调度是线程池的主要入口，用户提交任务后，这部分将决定任务如何执行。 任务调度的流程图如下：  提交任务后，首先检测运行池状态，若不是RUNNING，则直接拒绝，线程池要保证在RUNNING状态下执行任务。 如果线程数小于核心数，说明系统还没有被充分利用，则可添加线程并执行。若线程数大于核心数，此时再一味增加线程数只会带来调度开销，则将任务放入阻塞队列。 若阻塞队列未满，则将任务放入阻塞队列等待执行，否则进行下一步。 若线程数小于最大线程数，可添加工作线程执行，若线程数已大于等于最大线程数，此时直接拒绝任务，不予执行。  2.3.2 任务缓冲 线程池的本质是对任务和线程的管理，要让二者分别独立运行。如果不使用线程池，一个任务即一个线程，对任务与线程的管理都将陷入混乱。要分别对任务和线程进行管理，则需要将二者进行解耦，不让二者直接关联。线程池以消费者-生产者模型，通过一个阻塞队列实现二者的解耦。阻塞队列缓存任务，工作线程从阻塞队列中获取任务。\n阻塞队列(BlockingQueue)是一个支持两个附加操作的队列。这两个附加的操作是：\n 在队列为空时，获取元素的线程会等待队列变为非空。 当队列满时，存储元素的线程会等待队列可用。 阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。 其工作模式如下：   2.3.3 任务申请 从上文任务调度部分可知，任务的执行有两种可能：\n 任务直接由新创建的线程执行 线程从任务队列中获取任务然后执行，执行完任务的空闲进行再次去队列中申请任务执行 第一种情况仅在线程初始创建时出现，多数情况下是第二种情况  线程要从任务缓存模块中不断获取任务执行，定义getTask方法来帮助线程从阻塞队列中获取任务，实现线程管理模块和任务管理模块的通信。其执行流程如下： 这里进行了多次判断，目的在于控制线程的数量，使其符合线程池的状态。如果线程池现在不应该持有那么多线程，则会返回null值。工作线程Worker会不断接收新任务去执行，而当工作线程Worker接收不到任务的时候，就会开始被回收。\n2.3.4 任务拒绝 任务拒绝模块是线程池的保护部分。当线程池的任务缓存队列已满，并且线程数达到设定的最大值，就需要拒绝到来的任务，保护线程池。\n2.4 Worker线程管理 2.4.1 Worker线程 线程池为了掌握线程的状态并维护线程的生命周期，设计了线程池内的工作线程Worker。\nWorker持有一个线程thread和一个初始化的任务firstTask。thread是在Worker创建时创建的线程，可用来执行任务；firstTask保存传入的第一个任务，这个任务可以有也可以为空。如果此值非空，那么Worker会先执行这个任务，再去获取任务执行；如果此值为空，那么Worker直接去阻塞队列中获取任务执行。 线程池需要管理线程的生命周期，需要在线程长时间不运行的时候进行回收。线程池使用一张Hash表去持有线程的引用，这样可以通过添加引用、移除引用这样的操作来控制线程的生命周期。这个时候重要的就是如何判断线程是否在运行。\n​Worker是通过继承AQS，使用AQS来实现独占锁这个功能。没有使用可重入锁ReentrantLock，而是使用AQS，为的就是实现不可重入的特性去反应线程现在的执行状态。\n1.lock方法一旦获取了独占锁，表示当前线程正在执行任务中。 2.如果正在执行任务，则不应该中断线程。 3.如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断。 4.线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态；如果线程是空闲状态则可以安全回收。\n在线程回收过程中就使用到了这种特性，回收过程如下图所示：\n2.4.2 Worker线程增加 增加线程是通过线程池中的addWorker方法，该方法的功能就是增加一个线程，该方法不考虑线程池是在哪个阶段增加的该线程，这个分配线程的策略是在上个步骤完成的，该步骤仅仅完成增加线程，并使它运行，最后返回是否成功这个结果。addWorker方法有两个参数：firstTask、core。firstTask参数用于指定新增的线程执行的第一个任务，该参数可以为空；core参数为true表示在新增线程时会判断当前活动线程数是否少于corePoolSize，false表示新增线程前需要判断当前活动线程数是否少于maximumPoolSize，其执行流程如下图所示： 2.4.3 Worker线程回收 线程池中线程的销毁依赖JVM自动的回收，线程池做的工作是根据当前线程池的状态维护一定数量的线程引用，防止这部分线程被JVM回收，当线程池决定哪些线程需要回收时，只需要将其引用消除即可。Worker被创建出来后，就会不断地进行轮询，然后获取任务去执行，核心线程可以无限等待获取任务，非核心线程要限时获取任务。当Worker无法获取到任务，也就是获取的任务为空时，循环会结束，Worker会主动消除自身在线程池内的引用。\n事实上，将线程引用移出线程池就已经结束了线程销毁的部分。但由于引起线程销毁的可能性有很多，线程池还要判断是什么引发了这次销毁，是否要改变线程池的现阶段状态，是否要根据新状态，重新分配线程。\n2.4.4 Worker线程执行任务 在Worker类中的run方法调用了runWorker方法来执行任务，runWorker方法的执行过程如下：\n1.while循环不断地通过getTask()方法获取任务。 2.getTask()方法从阻塞队列中取任务。 3.如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态。 4.执行任务。 5.如果getTask结果为null则跳出循环，执行processWorkerExit()方法，销毁线程。 ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%9E%B6%E6%9E%84/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","summary":"1. 线程池基础 1.1 野生线程 在我们平常的开发中，经常会有用到多线程的场景，合理利用多线程可有效利用CPU的多核结构，提高程序的执行效率。有这样一种线程：我们利用其完成一些工作，但只是将工作交给这个线程，该线程并不保证完成任务，也不保证正常退出，并且在线程开始运行后我们无法对其进行控制。这种状态可称为：野生线程，意为其已经不受控制，在内存中自由运行。\n这种线程可能带来一系列问题：\n 频繁申请/销毁线程，可能带来巨大的额外消耗 当内存中存在较多的野生线程，会导致过分调度，降低系统性能 不能正常退出的线程会导致内存泄露 系统无法合理管理内部的资源分布，会降低系统的稳定性 ……  鉴于以上野生线程带来的问题，我们需要一种方式将其管理起来，使其从野生的线程变成“家养”的线程。\n1.2 什么是线程池  池化：池化是一种将资源统一进行管理，从而最大化收益并最小化风险的思想。\n 线程池维护若干个线程，在总体上控制线程的数量，具体上控制线程的创建、销毁等生命周期，系统可通过申请线程池中的线程异步的完成某个任务。线程池通过对线程的管理实现对资源的有效利用，避免系统资源浪费或内存泄露等问题。\n1.3 使用线程池的好处  线程池中的线程可反复利用，减少了线程创建和销毁的开销 任务无需等待线程创建即可开始运行，提高了系统响应速度 通过设置合理的线程池线程数，可有效避免资源使用不当，资源浪费 对线程运行进行有效的监视与管理  通俗易懂的讲，如果将线程比作完成任务的人，那么线程池就像一个专门管理这些人的部门。当我有任务到来时，直接把任务交给该部门，而不用自己再去找人来完成任务。\n2. 线程池的工作机制 2.1 线程池模型 线程池的内部实际上可以看做是生产者消费者模型，二者并不直接关联，通过任务队列进行交互，从而可以有效的缓冲任务，复用线程。\n在线程池模型中，扮演生产者角色的是任务管理部分，其接受提交的任务，并判断任务应如何处理：\n 直接申请线程执行该任务 缓冲到队列中等待线程执行 直接拒绝该任务  线程管理部分是消费者，线程被统一维护在线程池中，当有任务请求到来时，某一线程被分配去执行这个任务，执行完成后继续或许新的任务来执行，最终当线程获取不到任务时，线程就被回收以节省系统资源。\n2.2 线程池的状态 线程池一方面维护自身的状态，另一方面管理线程和任务，使二者良好的结合从而执行并行任务。 线程池的状态有5种：\n   运行状态 状态描述     RUNNING 能接受新提交的任务，并且也能处理阻塞队列中的任务   SHUTDOWN 关闭状态，不再接受新提交的任务，但可以继续处理阻塞队列中已保存的任务   STOP 不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程   TIDYING 所有的任务都已终止，有效线程数为0   TERMINATED 在terminated()方法执行后进入该状态   其生命周期转换如下图所示：     sequenceDiagram RUNNING-\u0026gt;\u0026gt;SHUTDOWN:shutdown() RUNNING-\u0026gt;\u0026gt;STOP: shutdownNow() SHUTDOWN-\u0026gt;\u0026gt;TIDYING:所有任务都已完成，阻塞队列为空，工作线程数为0 STOP-\u0026gt;\u0026gt;TIDYING:线程池中工作线程数为0 TIDYING-\u0026gt;\u0026gt;TERMINATED: terminated() 2.","title":"线程池"},{"content":"1. 安装高版本的Python  这里要说明，不能删除原来的python2以及python3.5，因为系统是依赖于这两个python版本的，当然你也可以试试，后果自负\u0026hellip;\n  去官网下载最新的Python 我这里下载的是源码，因为没有对应的安装包。（Python3.9） 下载完成后解压到本地 sudo tar -xvf Python-3.9.5.tar.xz -C /opt/python  编译安装 cd /opt/python mv Python-3.9.5 python3.9 sudo ./configure --enable-optimizations # 默认安装到/usr/local/bin, 可用--prefix指定安装目录 make -j8 \u0026amp;\u0026amp; sudo make altinstall sudo make clean  验证安装成功 /usr/local/bin/python3.9  Python 3.9.5 (default, May 13 2021, 09:51:10) [GCC 6.3.0 20170516] on linux Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; exit()   2. 设置默认Python版本 2.1 用户级修改 vim ~/.bashrc 增加一行：alias python='/usr/local/bin/python3.9\nsource ~/.bashrc 2.2 系统级修改 sudo rm /usr/bin/python # 删除原来默认的Python软链接 sudo ln -s /usr/local/bin/python3.9 /usr/bin/python # 设置新的软连接 从python3.9指向python 2.3 基于update-alternatives 列出所有可用的python版本替代信息\nupdate-alternatives --list python 若出现update-alternatives: 错误: 无 python 的候选项，则说明update-alternatives没有添加Python的替代版本，需要手动添加\nsudo update-alternatives --install /usr/bin/python python /usr/bin/python2.7 1 sudo update-alternatives --install /usr/bin/python python /usr/bin/python3.5 2 sudo update-alternatives --install /usr/bin/python python /usr/local/bin/python3.9 3 update-alternatives的--install参数后跟4个参数，分别是link name path priority， link is the generic name for the master link, name is the name of its symlink in the alternatives directory, and path is the alternative being introduced for the master link。最后一个是优先级，数字越高优先级越高 再次使用update-alternatives --list python查看可用的版本替代信息\n开始切换：\nupdate-alternatives --config python 有 3 个候选项可用于替换 python (提供 /usr/bin/python)。 选择 路径 优先级 状态 ------------------------------------------------------------ * 0 /usr/local/bin/python3.9 3 自动模式 1 /usr/bin/python2.7 1 手动模式 2 /usr/bin/python3.5 2 手动模式 3 /usr/local/bin/python3.9 3 手动模式 要维持当前值[*]请按\u0026lt;回车键\u0026gt;，或者键入选择的编号： 输入3，选择Python3.9为默认值\n3. pip错误 更换版本后，pip可能会出现错误。 在我的电脑上出现了subprocess.CalledProcessError: Command '('lsb_release', '-a')' returned non-zero exit status 1.错误， 解决方法为：删除/usr/bin/lsb_release\nsudo rm /usr/bin/lsb_release ","permalink":"http://yangchnet.github.io/Dessert/posts/python/deepin%E4%B8%8A%E5%8D%87%E7%BA%A7python/","summary":"1. 安装高版本的Python  这里要说明，不能删除原来的python2以及python3.5，因为系统是依赖于这两个python版本的，当然你也可以试试，后果自负\u0026hellip;\n  去官网下载最新的Python 我这里下载的是源码，因为没有对应的安装包。（Python3.9） 下载完成后解压到本地 sudo tar -xvf Python-3.9.5.tar.xz -C /opt/python  编译安装 cd /opt/python mv Python-3.9.5 python3.9 sudo ./configure --enable-optimizations # 默认安装到/usr/local/bin, 可用--prefix指定安装目录 make -j8 \u0026amp;\u0026amp; sudo make altinstall sudo make clean  验证安装成功 /usr/local/bin/python3.9  Python 3.9.5 (default, May 13 2021, 09:51:10) [GCC 6.3.0 20170516] on linux Type \u0026quot;help\u0026quot;, \u0026quot;copyright\u0026quot;, \u0026quot;credits\u0026quot; or \u0026quot;license\u0026quot; for more information. \u0026gt;\u0026gt;\u0026gt; exit()   2. 设置默认Python版本 2.1 用户级修改 vim ~/.","title":"deepin上升级Python"},{"content":"在使用git时，有时某分支已在远程服务器删除，但本地不会同步删除，这个分支依然存在。\n如下命令可以删除本地版本库上那些失效的远程追踪分支，具体用法是，假如你的远程版本库名是 origin,则使用如下命令先查看哪些分支需要清理：\n$ git remote prune origin --dry-run 修剪 origin URL：git@yuhu.github.com:yuhu-tech/grampus-contracts.git * [将删除] origin/cq-2021-0227_refactor * [将删除] origin/lichagn-feat-impl-grc20 * [将删除] origin/lichagn-feat-impl-grc20-em20-em721 * [将删除] origin/lichang-feat-add-some-support-for-ANT * [将删除] origin/lichang-feat-impl-20-and-720 * [将删除] origin/lichang-feat-mdy-20 * [将删除] origin/lichang-feat-mdy-20-and-721 * [将删除] origin/litao-dev * [将删除] origin/runjam-v0.0.2 可以看到， 以上分支已经失效，将被删除，执行\n$ git remote prune origin 修剪 origin URL：git@yuhu.github.com:yuhu-tech/grampus-contracts.git * [已删除] origin/cq-2021-0227_refactor * [已删除] origin/lichagn-feat-impl-grc20 * [已删除] origin/lichagn-feat-impl-grc20-em20-em721 * [已删除] origin/lichang-feat-add-some-support-for-ANT * [已删除] origin/lichang-feat-impl-20-and-720 * [已删除] origin/lichang-feat-mdy-20 * [已删除] origin/lichang-feat-mdy-20-and-721 * [已删除] origin/litao-dev * [已删除] origin/runjam-v0.0.2 ","permalink":"http://yangchnet.github.io/Dessert/posts/git/%E6%B8%85%E7%90%86%E6%9C%AC%E5%9C%B0%E5%88%86%E6%94%AF/","summary":"在使用git时，有时某分支已在远程服务器删除，但本地不会同步删除，这个分支依然存在。\n如下命令可以删除本地版本库上那些失效的远程追踪分支，具体用法是，假如你的远程版本库名是 origin,则使用如下命令先查看哪些分支需要清理：\n$ git remote prune origin --dry-run 修剪 origin URL：git@yuhu.github.com:yuhu-tech/grampus-contracts.git * [将删除] origin/cq-2021-0227_refactor * [将删除] origin/lichagn-feat-impl-grc20 * [将删除] origin/lichagn-feat-impl-grc20-em20-em721 * [将删除] origin/lichang-feat-add-some-support-for-ANT * [将删除] origin/lichang-feat-impl-20-and-720 * [将删除] origin/lichang-feat-mdy-20 * [将删除] origin/lichang-feat-mdy-20-and-721 * [将删除] origin/litao-dev * [将删除] origin/runjam-v0.0.2 可以看到， 以上分支已经失效，将被删除，执行\n$ git remote prune origin 修剪 origin URL：git@yuhu.github.com:yuhu-tech/grampus-contracts.git * [已删除] origin/cq-2021-0227_refactor * [已删除] origin/lichagn-feat-impl-grc20 * [已删除] origin/lichagn-feat-impl-grc20-em20-em721 * [已删除] origin/lichang-feat-add-some-support-for-ANT * [已删除] origin/lichang-feat-impl-20-and-720 * [已删除] origin/lichang-feat-mdy-20 * [已删除] origin/lichang-feat-mdy-20-and-721 * [已删除] origin/litao-dev * [已删除] origin/runjam-v0.","title":"清理本地分支"},{"content":"1. 什么是同质化代币（FT） 同质化代币是一种能够相互替换，具有统一性，可接近无穷拆分的代币。在同质化代币的交易中，只需要关注代币交接的数量即可，其价值可能会根据交换的时间间隔而改变，但其本质没有发生变化。 举例来说，美元，人民币都是同质化代币，虽然每一张美元或人民币的序号不同，但在面额相同的情况下，不同序号的币对持有者来说没有区别。\n2. 什么是非同质化代币(NFT) Non-Fungible Tokens\n非同质化代币包含了记录在其智能合约中的识别信息。这些信息使每种代币具有其独特性，因此不能被另一种代币直接取代。它们不能以一换一，因为没有两个 NFT 是相同的。 此外，非同质化代币也不可分割，就像不能送给别人演唱会门票的一部分一样，门票的一部分并不值钱也不能兑换。 非同质化的独特属性使得它通常与特定资产挂钩，可以用来证明数字物品（如游戏皮肤）的所有权，甚至实物资产的所有权，主要应用于游戏和加密收藏品领域。 FT 和 NFT 的一大区别在于使用了不同的合约接口，前者为 ERC-20，后者为 ERC-721。\n3. 什么是ERC-20? ERC-20 协议是以太坊区块链较早的、比较流行的代币规格协议。若以太坊平台上两种代币都以 ERC-20 发行，则两者之间可以进行自由置换。ERC20 是标准代币接口，规定了其基本功能 , 方便第三方使用。系统开源使得 ERC20 的标准已经简单到可以 5 分钟发行一个 ERC-20 代币。ERC-20 代币听命于同一组代币合约的命令，也就意味着所有 ERC-20 协议中的代币都可轻松实现转移、请求、批准等功能，但其功能因此也具有局限性。\n4. 什么是ERC-721？ 相比于 ERC-20，ERC-721 协议功能更多且技术更先进。该协议是以太坊的针对不可置换代币的 NFT 数字资产的第一个标准，应用于 CryptoKitties、Decentraland 等项目。ERC721 标准正是由 CryptoKitties 的 CTO Dieter Shirley 所创建和发布的，Dieter Shirley 是 NFT 的奠基人之一。\n虽然 ERC-721 较 ERC-20 用例较少，功能还处于探索之用，但 721 协议下的资产——画作、债券、房子或是汽车——的优势在于能保证所有权的安全性、所有权转移的便捷性以及所有权历史的不可更改性和透明性。另外，ERC721 还可以促进追踪、交易和管理真实资 产的交易和管理等等。随着游戏虚拟资产不断流行起来，5G 和 VR 不断普及，搭载区块链技术，721 协议前景一片光明。\n","permalink":"http://yangchnet.github.io/Dessert/posts/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%90%8C%E8%B4%A8%E5%8C%96%E4%BB%A3%E5%B8%81%E5%92%8C%E9%9D%9E%E5%90%8C%E8%B4%A8%E5%8C%96%E4%BB%A3%E5%B8%81/","summary":"1. 什么是同质化代币（FT） 同质化代币是一种能够相互替换，具有统一性，可接近无穷拆分的代币。在同质化代币的交易中，只需要关注代币交接的数量即可，其价值可能会根据交换的时间间隔而改变，但其本质没有发生变化。 举例来说，美元，人民币都是同质化代币，虽然每一张美元或人民币的序号不同，但在面额相同的情况下，不同序号的币对持有者来说没有区别。\n2. 什么是非同质化代币(NFT) Non-Fungible Tokens\n非同质化代币包含了记录在其智能合约中的识别信息。这些信息使每种代币具有其独特性，因此不能被另一种代币直接取代。它们不能以一换一，因为没有两个 NFT 是相同的。 此外，非同质化代币也不可分割，就像不能送给别人演唱会门票的一部分一样，门票的一部分并不值钱也不能兑换。 非同质化的独特属性使得它通常与特定资产挂钩，可以用来证明数字物品（如游戏皮肤）的所有权，甚至实物资产的所有权，主要应用于游戏和加密收藏品领域。 FT 和 NFT 的一大区别在于使用了不同的合约接口，前者为 ERC-20，后者为 ERC-721。\n3. 什么是ERC-20? ERC-20 协议是以太坊区块链较早的、比较流行的代币规格协议。若以太坊平台上两种代币都以 ERC-20 发行，则两者之间可以进行自由置换。ERC20 是标准代币接口，规定了其基本功能 , 方便第三方使用。系统开源使得 ERC20 的标准已经简单到可以 5 分钟发行一个 ERC-20 代币。ERC-20 代币听命于同一组代币合约的命令，也就意味着所有 ERC-20 协议中的代币都可轻松实现转移、请求、批准等功能，但其功能因此也具有局限性。\n4. 什么是ERC-721？ 相比于 ERC-20，ERC-721 协议功能更多且技术更先进。该协议是以太坊的针对不可置换代币的 NFT 数字资产的第一个标准，应用于 CryptoKitties、Decentraland 等项目。ERC721 标准正是由 CryptoKitties 的 CTO Dieter Shirley 所创建和发布的，Dieter Shirley 是 NFT 的奠基人之一。\n虽然 ERC-721 较 ERC-20 用例较少，功能还处于探索之用，但 721 协议下的资产——画作、债券、房子或是汽车——的优势在于能保证所有权的安全性、所有权转移的便捷性以及所有权历史的不可更改性和透明性。另外，ERC721 还可以促进追踪、交易和管理真实资 产的交易和管理等等。随着游戏虚拟资产不断流行起来，5G 和 VR 不断普及，搭载区块链技术，721 协议前景一片光明。","title":"同质化代币和非同质化代币"},{"content":" ubuntu环境\n 0. 拉取github仓库的两种方式 在拉取github仓库时，我们常用\ngit clone https://github.com/username/repoName.git 的方式，这种方式使用https协议 还可以使用ssh协议，以如下方式拉取仓库\ngit clone git@github.com:username/repoName.git 以下介绍的设置方法，基于ssh协议。\n1. 使用SSH连接到GitHub 使用 SSH 协议可以连接远程服务器和服务并向它们验证。 利用 SSH 密钥可以连接 GitHub，而无需在每次访问时都提供用户名和个人访问令牌。\n检查现有SSH秘钥 在生成 SSH 密钥之前，您可以检查是否有任何现有的 SSH 密钥。\n$ ls -al ~/.ssh # Lists the files in your .ssh directory, if they exist 如果你的主机上已有SSH公钥，则其可能是如下：\nid_rsa.pub id_ecdsa.pub id_ed25519.pub 如果你没有现有的公钥和私钥对，或者不想使用现有的秘钥连接到github，则可以生成新的SSH秘钥。\n生成新SSH秘钥 输入如下命令：\nssh-keygen -t rsa -C \u0026#34;your_email@example.com\u0026#34; 会有如下输出：\nGenerating public/private rsa key pair. Enter file in which to save the key (/home/lc/.ssh/id_rsa): # 可以直接回车使用默认位置 Enter passphrase (empty for no passphrase): # 也可直接回车 然后就可以在你的~/.ssh目录下生成新的秘钥\n添加秘钥到ssh-agent 启动ssh-agent\neval \u0026#34;$(ssh-agent -s)\u0026#34; # 输出： Agent pid 59566 添加\nssh-add ~/.ssh/id_rsa 新增 SSH 密钥到 GitHub 帐户 复制你的ssh秘钥（id_rsa.pub文件内容），打开github 点击new ssh key,将你的秘钥复制到对应的位置 测试你的秘钥是否生效 ssh -T git@github.com # Hi yenian! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. 2. 设置两个github账户 取消已有的全局配置 git config --global --unset user.name git config --global --unset user.email 生成两个新的ssh秘钥 输入如下命令：\nssh-keygen -t rsa -C \u0026#34;your_email@example.com\u0026#34; 会有如下输出：\nGenerating public/private rsa key pair. Enter file in which to save the key (/home/lc/.ssh/id_rsa): # 这里要为两个秘钥定义不同的文件名 Enter passphrase (empty for no passphrase): # 也可直接回车 这里要注意的是设置文件名时不能直接跳过，要为两个秘钥定义不同的文件名，比如所一个为id_rsa, 另一个为id_rsa_work ，其中work可以设置你的工作git用户名。分别用于你个人和工作用的github账号。\n将两个秘钥分别加入对应的github账号 \u0026hellip; 如上 \u0026hellip;\n配置 ~/.ssh/config 文件 打开~/.ssh/config 文件（没有则创建）\nvim ~/.ssh/config 文件内容如下：\n# default github account Host github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa_one Host work.github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa_two 测试是否设置成功 ssh -T git@work.github.com # Hi $yourWorkAccountName$! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. ssh -T git@github.com # Hi $yourPersonAccountName$! You\u0026#39;ve successfully authenticated, but GitHub does not provide shell access. 还需要做什么 如果你要以工作账户的身份去拉取某个库，那么你需要将原来用的\ngit clone git@github.com:username/repository-name.git 替换为\ngit clone git@work.github.com:username/repository-name.git 和我们的config相对应\n而如果直接使用原命令，即\ngit clone git@github.com:username/repository-name.git 那么默认使用的是你个人账户。\n如果你想要为你一个已有的仓库指定账户，可使用\ngit remote origin set-url git@work.github.com:username/repository-name.git # 指定工作账户 ","permalink":"http://yangchnet.github.io/Dessert/posts/git/%E4%B8%BB%E6%9C%BA%E4%B8%8A%E8%AE%BE%E7%BD%AE%E4%B8%A4%E4%B8%AAgit%E8%B4%A6%E5%8F%B7/","summary":"ubuntu环境\n 0. 拉取github仓库的两种方式 在拉取github仓库时，我们常用\ngit clone https://github.com/username/repoName.git 的方式，这种方式使用https协议 还可以使用ssh协议，以如下方式拉取仓库\ngit clone git@github.com:username/repoName.git 以下介绍的设置方法，基于ssh协议。\n1. 使用SSH连接到GitHub 使用 SSH 协议可以连接远程服务器和服务并向它们验证。 利用 SSH 密钥可以连接 GitHub，而无需在每次访问时都提供用户名和个人访问令牌。\n检查现有SSH秘钥 在生成 SSH 密钥之前，您可以检查是否有任何现有的 SSH 密钥。\n$ ls -al ~/.ssh # Lists the files in your .ssh directory, if they exist 如果你的主机上已有SSH公钥，则其可能是如下：\nid_rsa.pub id_ecdsa.pub id_ed25519.pub 如果你没有现有的公钥和私钥对，或者不想使用现有的秘钥连接到github，则可以生成新的SSH秘钥。\n生成新SSH秘钥 输入如下命令：\nssh-keygen -t rsa -C \u0026#34;your_email@example.com\u0026#34; 会有如下输出：\nGenerating public/private rsa key pair. Enter file in which to save the key (/home/lc/.","title":"主机上设置两个git账号"},{"content":"使用git log命令查看git日志文件，假设为如下内容\ncommit cc7b5fc7bd2ae6f8d88144cd61c8ffad15d44e41 Author: yangchnet \u0026lt;1048887414@qq.com\u0026gt; Date: Sun Apr 25 19:40:03 2021 +0800 4-25 commit fbd7265095b4c8989fba830393eb32ef29cd9ee1 Merge: 3ae3c19 6a25204 Author: yangchnet \u0026lt;1048887414@qq.com\u0026gt; Date: Sun Apr 25 15:04:38 2021 +0800 Merge branch 'master' of https://github.com/yangchnet/Tem commit 6a25204187602449bfe4ca8c862c9677e65fed04 Author: yangchnet \u0026lt;30308940+yangchnet@users.noreply.github.com\u0026gt; Date: Thu Apr 22 21:36:05 2021 +0800 Delete CNAME ... 现在想合并最后两个提交，则进行以下步骤：\n 复制倒数第三个提交的哈希值，即：6a25204187602449bfe4ca8c862c9677e65fed04 使用如下命令进行合并：  git rebase -i 6a25204187602449bfe4ca8c862c9677e65fed04 # 这个哈希值就是你刚才复制的 若有如下提示，请进行第4步，否则直接进行第5步   不能变基：您有未暂存的变更。 请提交或为它们保存进度。\n4. 使用`git stash`暂存修改 ```sh $ git stash 保存工作目录和索引状态 WIP on master: cc7b5fc 4-25 HEAD 现在位于 cc7b5fc 4-25 使用git rebase后，会出现如下内容  pick 3ae3c19 增加graphql介绍 pick cc7b5fc 4-25 # 变基 6a25204..cc7b5fc 到 6a25204（2 个提交） # # 命令: # p, pick = 使用提交 # r, reword = 使用提交，但修改提交说明 # e, edit = 使用提交，但停止以便进行提交修补 # s, squash = 使用提交，但和前一个版本融合 # f, fixup = 类似于 \u0026quot;squash\u0026quot;，但丢弃提交说明日志 # x, exec = 使用 shell 运行命令（此行剩余部分） # d, drop = 删除提交 # # 这些行可以被重新排序；它们会被从上至下地执行。 # # # 如果您在这里删除一行，对应的提交将会丢失。 # # 然而，如果您删除全部内容，变基操作将会终止。 # # 注意空提交已被注释掉 前两行为你想要合并的commit，按照注释内容，要保留的commit开头不变，要合并到另一个的开头设为s，意为：使用提交，但和前一个版本融合 （可以按照你的需求改变），更改完成后保存。 6. 保存完成后会出现如下内容\n# 这是一个 2 个提交的组合。 # 这是第一个提交说明： 增加graphql介绍 # 这是提交说明 #2： 4-25 # 请为您的变更输入提交说明。以 '#' 开始的行将被忽略，而一个空的提交 # 说明将会终止提交。 # ... 这是你的commit的说明，将你想保留的commit说明保留，不想要的直接删除。保存之。 7. 再次查看git log, 可以看到刚才的更改已经生效。\ncommit 2994a193577f4b4175b1fe7015db955df9143b89 Author: yangchnet \u0026lt;1048887414@qq.com\u0026gt; Date: Thu Apr 22 21:30:48 2021 +0800 增加graphql介绍 commit 6a25204187602449bfe4ca8c862c9677e65fed04 Author: yangchnet \u0026lt;30308940+yangchnet@users.noreply.github.com\u0026gt; Date: Thu Apr 22 21:36:05 2021 +0800 Delete CNAME 若进行了第4步，则需进行本步骤  git stash pop ","permalink":"http://yangchnet.github.io/Dessert/posts/git/%E5%B0%86%E4%B8%A4%E4%B8%AAcommit%E5%90%88%E5%B9%B6%E4%B8%BA%E4%B8%80%E4%B8%AA/","summary":"使用git log命令查看git日志文件，假设为如下内容\ncommit cc7b5fc7bd2ae6f8d88144cd61c8ffad15d44e41 Author: yangchnet \u0026lt;1048887414@qq.com\u0026gt; Date: Sun Apr 25 19:40:03 2021 +0800 4-25 commit fbd7265095b4c8989fba830393eb32ef29cd9ee1 Merge: 3ae3c19 6a25204 Author: yangchnet \u0026lt;1048887414@qq.com\u0026gt; Date: Sun Apr 25 15:04:38 2021 +0800 Merge branch 'master' of https://github.com/yangchnet/Tem commit 6a25204187602449bfe4ca8c862c9677e65fed04 Author: yangchnet \u0026lt;30308940+yangchnet@users.noreply.github.com\u0026gt; Date: Thu Apr 22 21:36:05 2021 +0800 Delete CNAME ... 现在想合并最后两个提交，则进行以下步骤：\n 复制倒数第三个提交的哈希值，即：6a25204187602449bfe4ca8c862c9677e65fed04 使用如下命令进行合并：  git rebase -i 6a25204187602449bfe4ca8c862c9677e65fed04 # 这个哈希值就是你刚才复制的 若有如下提示，请进行第4步，否则直接进行第5步   不能变基：您有未暂存的变更。 请提交或为它们保存进度。\n4. 使用`git stash`暂存修改 ```sh $ git stash 保存工作目录和索引状态 WIP on master: cc7b5fc 4-25 HEAD 现在位于 cc7b5fc 4-25 使用git rebase后，会出现如下内容  pick 3ae3c19 增加graphql介绍 pick cc7b5fc 4-25 # 变基 6a25204.","title":"将两个commit合并为一个"},{"content":"1. 什么是Graphql GraphQL 既是一种用于 API 的查询语言也是一个满足你数据查询的runtime。 GraphQL对你的API中的数据提供了一套易于理解的完整描述，使得客户端能够准确地获得它需要的数据，而且没有任何冗余，也让API更容易地随着时间推移而演进，还能用于构建强大的开发者工具。\n一个 GraphQL 服务是通过定义类型和类型上的字段来创建的，然后给每个类型上的每个字段提供解析函数。\n简单的说，GraphQL为我们定义数据库提供了更为便捷的方式，你不需要写任何SQL语句，即可完成数据库的创建及迁移等工作。\n2. 概览 例如，一个 GraphQL 服务告诉我们当前登录用户是 me，这个用户的名称可能像这样：\ntype Query { me: User } type User { id: ID name: String } 一并的还有每个类型上字段的解析函数：\nfunction Query_me(request) { return request.auth.user; } function User_name(user) { return user.getName(); } 一旦一个 GraphQL 服务运行起来（通常在 web 服务的一个 URL 上），它就能接收 GraphQL 查询，并验证和执行。接收到的查询首先会被检查确保它只引用了已定义的类型和字段，然后运行指定的解析函数来生成结果。\n例如这个查询：\n{ me { name } } 会产生这样的JSON结果：\n{ \u0026#34;me\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Luke Skywalker\u0026#34; } } 3. Schema 和类型 GraphQL 服务可以用任何语言编写，但并不依赖于任何特定语言的句法句式（譬如 JavaScript）来与 GraphQL schema 沟通，Graphql定义了自己的简单语言，称之为 “GraphQL schema language”。\n3.1 对象类型和字段 一个 GraphQL schema 中的最基本的组件是对象类型，它就表示你可以从服务上获取到什么类型的对象，以及这个对象有什么字段。使用 GraphQL schema language，我们可以这样表示它：\ntype Character { name: String! appearsIn: [Episode!]! }  说明\n  Character 是一个 GraphQL 对象类型，表示其是一个拥有一些字段的类型。你的 schema 中的大多数类型都会是对象类型。 name 和 appearsIn 是 Character 类型上的字段。这意味着在一个操作 Character 类型的 GraphQL 查询中的任何部分，都只能出现 name 和 appearsIn 字段。 String 是内置的标量类型之一 —— 标量类型是解析到单个标量对象的类型，无法在查询中对它进行次级选择。后面我们将细述标量类型。 String! 表示这个字段是非空的，GraphQL 服务保证当你查询这个字段后总会给你返回一个值。在类型语言里面，我们用一个感叹号来表示这个特性。 [Episode!]! 表示一个 Episode 数组。因为它也是非空的，所以当你查询 appearsIn 字段的时候，你也总能得到一个数组（零个或者多个元素）。且由于 Episode! 也是非空的，你总是可以预期到数组中的每个项目都是一个 Episode 对象  3.1.5 查询和变更类型（The Query and Mutation Types） 你的 schema 中大部分的类型都是普通对象类型，但是一个 schema 内有两个特殊类型：\nschema { query: Query mutation: Mutation } 每一个 GraphQL 服务都有一个 query 类型，可能有一个 mutation 类型。这两个类型和常规对象类型无差，但是它们之所以特殊，是因为它们定义了每一个 GraphQL 查询的入口。因此如果你看到一个像这样的查询：\n# Request query { hero { name } droid(id: \u0026#34;2000\u0026#34;) { name } } # Response { \u0026#34;data\u0026#34;: { \u0026#34;hero\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;R2-D2\u0026#34; }, \u0026#34;droid\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;C-3PO\u0026#34; } } } 那表示这个 GraphQL 服务需要一个 Query 类型，且其上有 hero 和 droid 字段：\ntype Query { hero(episode: Episode): Character droid(id: ID!): Droid } Mutation也是类似的工作方式 —— 你在 Mutation 类型上定义一些字段，然后这些字段将作为 mutation 根字段使用，接着你就能在你的查询中调用.\n有必要记住的是，除了作为 schema 的入口，Query 和 Mutation 类型与其它 GraphQL 对象类型别无二致，它们的字段也是一样的工作方式。\n3.2 参数 GraphQL 对象类型上的每一个字段都可能有零个或者多个参数，例如下面的 length 字段:\ntype Starship { id: ID! name: String! length(unit: LengthUnit = METER): Float } 所有参数都是具名的。在本例中，length字段定义了一个参数：unit。参数可能是必选或者可选的，当一个参数是可选的，我们可以定义一个默认值 —— 如果 unit 参数没有传递，那么它将会被默认设置为 METER。\n3.3 标量类型（Scalar Types） 一个对象类型有自己的名字和字段，而某些时候，这些字段必然会解析到具体数据。这就是标量类型的来源：它们表示对应 GraphQL 查询的叶子节点。\n下列查询中，name 和 appearsIn 字段将解析到标量类型：\n{ hero { name appearsIn } } { \u0026#34;data\u0026#34;: { \u0026#34;hero\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;R2-D2\u0026#34;, \u0026#34;appearsIn\u0026#34;: [ \u0026#34;NEWHOPE\u0026#34;, \u0026#34;EMPIRE\u0026#34;, \u0026#34;JEDI\u0026#34; ] } } } 标量类型没有任何次级字段，它们是一次查询的叶子节点。 Graphql中预定义的标量类型有：\n Int：有符号 32 位整数。 Float：有符号双精度浮点值。 String：UTF‐8 字符序列。 Boolean：true 或者 false。 ID：ID 标量类型表示一个唯一标识符，通常用以重新获取对象或者作为缓存中的键。ID 类型使用和 String 一样的方式序列化；然而将其定义为 ID 意味着并不需要人类可读型。  还可以自定义标量类型：\nscalar Date 在自己的实现中定义如何将其序列化、反序列化和验证。例如，你可以指定 Date 类型应该总是被序列化成整型时间戳，而客户端应该知道去要求任何 date 字段都是这个格式。\n3.4 枚举类型（Enumseration Types） 枚举类型是一种特殊的标量，它限制在一个特殊的可选值集合内。这让你能够：\n 验证这个类型的任何参数是可选值的的某一个 与类型系统沟通，一个字段总是一个有限值集合的其中一个值。  下面是一个用 GraphQL schema 语言表示的 enum 定义：\nenum Episode { NEWHOPE EMPIRE JEDI } 这表示无论我们在 schema 的哪处使用了 Episode，都可以肯定它返回的是 NEWHOPE、EMPIRE 和 JEDI 之一。\n3.5 列表和非空 对象类型、标量以及枚举是 GraphQL 中你唯一可以定义的类型种类。但是当你在 schema 的其他部分使用这些类型时，或者在你的查询变量声明处使用时，你可以给它们应用额外的类型修饰符来影响这些值的验证。我们先来看一个例子：\ntype Character { name: String! appearsIn: [Episode]! } String类型后的感叹号！表示此类型非空。服务器在返回这个字段时，总是会返回一个非空值，如果结果得到了一个空值，那么事实上将会触发一个 GraphQL 执行错误，以让客户端知道发生了错误。\n在 GraphQL schema 语言中，我们通过将类型包在方括号（[ 和 ]）中的方式来标记列表。列表对于参数也是一样的运作方式，验证的步骤会要求对应值为数组。\n非空和列表修饰符可以组合使用。\nmyField: [String!] # 这表示数组本身可以为空,但是其不能有任何空值成员. # myField: null // 有效 # myField: [] // 有效 # myField: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] // 有效 # myField: [\u0026#39;a\u0026#39;, null, \u0026#39;b\u0026#39;] // 错误 myField: [String]! # 数组本身不能为空，但是其可以包含空值成员 # myField: null // 错误 # myField: [] // 有效 # myField: [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;] // 有效 # myField: [\u0026#39;a\u0026#39;, null, \u0026#39;b\u0026#39;] // 有效 你可以根据需求嵌套任意层非空和列表修饰符。\n3.6 接口（interface） 跟许多类型系统一样，GraphQL 支持接口。一个接口是一个抽象类型，它包含某些字段，而对象类型必须包含这些字段，才能算实现了这个接口。\n例如，你可以用一个 Character 接口用以表示《星球大战》三部曲中的任何角色：\ninterface Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! } 这意味着任何实现 Character 的类型都要具有这些字段，并有对应参数和返回类型。\n例如，这里有一些可能实现了 Character 的类型：\ntype Human implements Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! starships: [Starship] totalCredits: Int } type Droid implements Character { id: ID! name: String! friends: [Character] appearsIn: [Episode]! primaryFunction: String } 可见这两个类型都具备 Character 接口的所有字段，但也引入了其他的字段 totalCredits、starships 和 primaryFunction，这都属于特定的类型的角色。\n3.7 联合类型 联合类型和接口十分相似，但是它并不指定类型之间的任何共同字段。\nunion SearchResult = Human | Droid | Starship 在我们的schema中，任何返回一个 SearchResult 类型的地方，都可能得到一个 Human、Droid 或者 Starship。注意，联合类型的成员需要是具体对象类型；你不能使用接口或者其他联合类型来创造一个联合类型。\n3.7 输入类型 目前为止，我们只讨论过将例如枚举和字符串等标量值作为参数传递给字段，但是你也能很容易地传递复杂对象。这在变更（mutation）中特别有用，因为有时候你需要传递一整个对象作为新建对象。在 GraphQL schema language 中，输入对象看上去和常规对象一模一样，除了关键字是 input 而不是 type：\ninput ReviewInput { stars: Int! commentary: String } ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/graphql/","summary":"1. 什么是Graphql GraphQL 既是一种用于 API 的查询语言也是一个满足你数据查询的runtime。 GraphQL对你的API中的数据提供了一套易于理解的完整描述，使得客户端能够准确地获得它需要的数据，而且没有任何冗余，也让API更容易地随着时间推移而演进，还能用于构建强大的开发者工具。\n一个 GraphQL 服务是通过定义类型和类型上的字段来创建的，然后给每个类型上的每个字段提供解析函数。\n简单的说，GraphQL为我们定义数据库提供了更为便捷的方式，你不需要写任何SQL语句，即可完成数据库的创建及迁移等工作。\n2. 概览 例如，一个 GraphQL 服务告诉我们当前登录用户是 me，这个用户的名称可能像这样：\ntype Query { me: User } type User { id: ID name: String } 一并的还有每个类型上字段的解析函数：\nfunction Query_me(request) { return request.auth.user; } function User_name(user) { return user.getName(); } 一旦一个 GraphQL 服务运行起来（通常在 web 服务的一个 URL 上），它就能接收 GraphQL 查询，并验证和执行。接收到的查询首先会被检查确保它只引用了已定义的类型和字段，然后运行指定的解析函数来生成结果。\n例如这个查询：\n{ me { name } } 会产生这样的JSON结果：\n{ \u0026#34;me\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Luke Skywalker\u0026#34; } } 3. Schema 和类型 GraphQL 服务可以用任何语言编写，但并不依赖于任何特定语言的句法句式（譬如 JavaScript）来与 GraphQL schema 沟通，Graphql定义了自己的简单语言，称之为 “GraphQL schema language”。","title":"Graphql基本概念"},{"content":"1. 区块链定义 区块链技术本质上是一个去中心化的数据库，它是比特币的核心技术与基础架构，是分布式数据存储、点对点传输、共识机制、加密算法等计算机技术的新型应用模式。狭义来讲，区块链是一种按照时间顺序将数据区块以顺序相连的方式组合成的一种链式数据结构，并以密码学方式保证的不可篡改、不可伪造的分布式账本。广义来讲，区块链技术是利用块链式数据结构来验证与存储数据、利用分布式节点共识算法来生成和更新数据、利用密码学方式保证数据传输和访问的安全、利用由自动化脚本代码组成的智能合约来编程和操作数据的一种全新的分布式基础架构与计算范式。\n1.1 区块链的技术特征 区块链上存储的数据需由全网节点共同维护，可以在缺乏信任的节点之间有效地传递价值。相比现有的数据库技术，区块链具有以下技术特征。\n 块链式数据结构\n区块链利用块链式数据结构来验证和存储数据，通过上文对区块链基本概念的介绍可以知道，每个区块打包记录了一段时间内发生的交易是对当前账本的一次共识，并且通过记录上一个区块的哈希值进行关联，从而形成块链式的数据结构。 分布式共识算法\n区块链系统利用分布式共识算法来生成和更新数据，从技术层面杜绝了非法篡改数据的可能性，从而取代了传统应用中保证信任和交易安全的第三方中介机构，降低了为维护信用而造成的时间成本、人力成本和资源耗用 密码学方式\n区块链系统利用密码学的方式保证数据传输和访问的安全。存储在区块链上的交易信息是公开的，但账户的身份信息是高度加密的。区块链系统集成了对称加密、非对称加密及哈希算法的优点，并使用数字签名技术来保证交易的安全。  1.2 区块链的功能特征 区块链系统的以上技术特征决定了其应用具有如下功能特征。\n  多中心 不同于传统应用的中心化数据管理，区块链网络中有多个机构进行相互监督并实时对账，从而避免了单一记账人造假的可能性，提高了数据的安全性。\n  自动化 区块链系统中的智能合约是可以自动化执行一些预先定义好的规则和条款的一段计算机程序代码，它大大提高了经济活动与契约的自动化程度。\n  可信任 存储在区块链上的交易记录和其他数据是不可篡改并且可溯源的，所以能够很好地解决各方不信任的问题，无需第三方可信中介。\n  2. 区块链的相关概念 区块链以密码学的方式维护一份不可篡改和不可伪造的分布式账本，并通过基于协商一致的规范和协议（共识机制）解决了去中心化的记账系统的一致性问题，其相关概念主要包括以下三个。\n 交易（Transaction）\n区块链上每一次导致区块状态变化的操作都称为交易，每一次交易对应唯一的交易哈希值，一段时间后便会对交易进行打包。 区块（Block）\n打包记录一段时间内发生的交易和状态结果，是对当前账本的一次共识。每个区块以一个相对平稳的时间间隔加入到链上，在企业级区块链平台中，共识时间可以动态设置。 链（Chain）\n区块按照时间顺序串联起来，通过每个区块记录上一个区块的哈希值关联，是整个状态改变的日志记录。   区块链的主要结构  如何解决交易中的信任和安全问题 区块链技术体系不是通过一个权威的中心化机构来保证交易的可信和安全，而是通过加密和分布式共识机制来解决信任和安全问题，其主要技术创新有以下4点。\n  分布式账本 交易是由分布式系统中的多个节点共同记录的。每一个节点都记录完整的交易记录，因此它们都可以参与监督交易合法性并验证交易的有效性。不同于传统的中心化技术方案，区块链中没有任何一个节点有权限单独记录交易，从而避免了因单一记账人或节点被控制而造假的可能性。另一方面，由于全网节点参与记录，理论上讲，除非所有的节点都被破坏，否则交易记录就不会丢失，从而保证了数据的安全性。\n  加密技术和授权技术 区块链技术很好地集成了当前对称加密、非对称加密和哈希算法的许多优点，并使用了数字签名技术来保证交易的安全性，其中最具代表性的是使用椭圆曲线加密算法生成用户的公私钥对和使用椭圆曲线数字签名算法来保证交易安全。打包在区块上的交易信息对于参与共识的所有节点是公开的，但是账户的身份信息是经过严格加密的。\n  共识机制 共识机制是区块链系统中各个节点达成一致的策略和方法。区块链的共识机制替代了传统应用中保证信任和交易安全的第三方中心机构，能够降低由于各方不信任而产生的第三方信用成本、时间成本和资本耗用。常用的共识机制主要有PoW、PoS、DPoS、Paxos、PBFT等，共识机制既是数据写入的方式，也是防止篡改的手段。\n  智能合约 智能合约是可以自动化执行预先定义规则的一段计算机程序代码，它自己就是一个系统参与者。它能够实现价值的存储、传递、控制和管理，为基于区块链的应用提供了创新性的解决方案。\n  3. 区块链分类 按照节点参与方式的不同，区块链技术可以分为：公有链（Public Blockchain）、联盟链（Consortium Blockchain）和私有链（Private Blockchain）。按照权限的不同，区块链技术可以分为：许可链（Permissioned Blockchain）和非许可链（Permissionless Blockchain）。前述的三大类区块链技术中，联盟链和私有链属于许可链，公有链属于非许可链。\n  公有链\n公有链，顾名思义，就是公开的区块链。公有链是全公开的，所有人都可以作为网络中的一个节点，而不需要任何人给予权限或授权。在公有链中，每个节点都可以自由加入或者退出网络，参与链上数据的读写、执行交易，还可以参与网络中共识达成的过程，即决定哪个区块可以添加到主链上并记录当前的网络状态。公有链是完全意义上的去中心化区块链，它借助密码学中的加密算法保证链上交易的安全。在采取共识算法达成共识时，公有链主要采取工作量证明（PoW，Proof of Work）机制或权益证明（PoS，Proof of Stake）机制等共识算法，将经济奖励和加密数字验证结合起来，来达到去中心化和全网达成共识的目的。在这些算法共识形成的过程中，每个节点都可以为共识过程做出贡献，也是我们俗称的“挖矿”，来获取与贡献成正比的经济奖励，也就是系统中发行的数字代币。\n公有链通常也被称为公共链，它属于一种非许可链，不需要许可就可以自由参加退出。当前最典型的代表应用有比特币、以太坊（Ethereum）等。因其完全去中心化和面向大众的特性，公有链通常适用于“虚拟加密货币”和面向大众的一些金融服务以及电子商务等。\n  联盟链 联盟链不是完全去中心化的，而是一种多中心化或者部分去中心化的区块链。在区块链系统运行时，它的共识过程可能会受某些指定节点的控制。例如，在一个有15个金融机构接入的区块链系统中，每个机构都作为链上的一个节点，每确认一笔交易，都需要至少对10个节点进行确认（2/3确认），这笔交易或者这个区块才能被认可。联盟链账本上的数据与公有链的完全公开是不同的，只有联盟成员节点才可以访问，并且链上的读写权限、参与记账规则等操作也需要由联盟成员节点共同决定。由于联盟链场景中的参与者组成一个联盟， 参与共识的节点相对公有链而言会少很多，并且一般是针对某个商业场景，所以共识协议一般不采用与工作量证明类似的挖矿机制，同时也不一定需要代币作为激励机制，而是采用PBFT、RAFT这类适用于多中心化且效率较高的共识算法。同时，联盟链对交易的时间、状态、每秒交易数等与公有链有很大区别，所以它比公有链有更高的安全和性能要求。\n联盟链属于一种许可链，意味着不是任何人都能自由加入网络中，而是需要一定的权限许可，才可以作为一个新的节点加入。当前联盟链典型的代表有Linux基金会支持的超级账本（Hyperledger）项目、R3区块链联盟开发的Corda，以及趣链科技推出的Hyperchain平台等。\n  私有链 私有链，是指整个区块链上的所有写入权限仅仅掌握在一个组织手里，而读取权限可以根据情况对外开放或者任意进行限制。所以，私有链的应用场景一般是单一的企业内部总公司对分公司的管理方面，如数据库管理和审计等。相比于公有链和联盟链，私有链的价值主要体现在它可以提供一个安全、可追溯、不可篡改的平台，并且可以同时防止来自内部和外部的安全攻击。目前对于私有链确实存在着一些争议，有人认为私有链的意义不大，因为它需要依赖于第三方的区块链平台机构，所有的权限都被控制在一个节点中，已经违背了区块链技术的初衷，不能算一种区块链技术，而是已经存在的分布式账本技术。但是也有人认为私有链拥有很大的潜在价值，因为它可以给当前存在的许多问题提供一个很好的解决方案，比如企业内部规章制度的遵守、金融机构的反洗钱行为以及政府部门的预算和执行，等等。\n与联盟链一样，私有链也属于一种许可链，不过它的许可权掌握在单一节点中，在有些场景中，私有链还被称为专有链。当下私有链的应用不是很多，开创者都在努力探索之中。当前已经存在的应用主要有英国币科学公司（Coin Sciences Ltd.）推出的多链（Multichain）平台，这个平台的宗旨是希望能帮助各企业快速地部署私链环境，提供良好的隐私保护和权限控制。\n  自诞生至今，区块链技术经历了三次大的技术演进，其典型代表平台为2009年的比特币、2013年的以太坊和2015年的Fabric和Hyperchain，其组织形态从资源消耗严重、交易性能低下、缺乏灵活控制机制的公有区块链，向高效共识、智能可编程、可保护隐私的联盟区块链转变。当前，Hyperchian平台的TPS（每秒事务处理量）已达到千甚至万量级，可以满足大部分商业场景的需要。将来，随着技术的进一步发展，基于联盟链的区块链商业应用将成为区块链应用的主要形态。\n4. 区块链关键技术 4.1 基础模型 区块链基本架构可以分为数据层、网络层、共识层、激励层、合约层和应用层：\n 数据层封装了区块链的链式结构、区块数据以及非对称加密等区块链核心技术； 网络层提供点对点的数据通信传播以及验证机制； 共识层主要是网络节点间达成共识的各种共识算法； 激励层将经济因素引入到区块链技术体系之中，主要包括经济因素的发行机制和分配机制； 合约层展示了区块链系统的可编程性，封装了各类脚本、智能合约和算法； 应用层则封装了区块链技术的应用场景和案例。  在该架构中，基于时间戳的链式结构、分布式节点间的共识机制和可编程的智能合约是区块链技术最具代表性的创新点。一般可以在合约层编写智能合约或者进行脚本编程，来构建基于区块链的去中心化应用。下面将对本架构中每一层所涉及的技术展开具体介绍。 4.2 数据层 数据层是区块链的核心部分，区块链本质上是一种数据库技术和分布式共享账本，是由包含交易信息的区块从后向前有序连接起来的一种数据结构。该层涉及的技术主要包括：区块结构、Merkle树、非对称加密、时间戳、数字签名和哈希函数。时间戳和哈希函数相对比较简单，这里重点介绍一下区块结构、Merkle树、非对称加密和数字签名。\n区块结构 每个区块一般都由区块头和区块体两部分组成。如图所示，区块头部分包含了父区块哈希值、时间戳、Merkle根等信息，而区块体部分则包含着此区块中所有的交易信息。除此之外，每一个区块还对应着两个值来识别区块：区块头哈希值和区块高度。 每一个区块都会有一个区块头哈希值，这是一个通过SHA256算法对区块头进行二次哈希计算而得到的32字节的数字指纹。例如，比特币的第一个区块的头哈希值为000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f。区块头哈希值可以唯一标识一个区块链上的区块，并且任何节点通过对区块头进行简单的哈希计算都可以得到该区块头的哈希值。区块头哈希也包含在区块的整体数据结构中，但是区块头的数据和区块体的数据并不一定一起存储，为了检索效率起见，在实现中可以将二者分开存储。\n除了通过头哈希值来识别区块，还可以通过区块高度来对区块进行识别。例如高度为0和前面000000000019d6689c085ae165831e934ff763ae46a2a6c172b3f1b60a8ce26f所索引的区块都是第一个区块。但是与头哈希值不同的是，区块高度并不能唯一地标识一个区块。由于区块链存在着分叉情况，所以可能存在2个或以上区块的区块高度是一样的\nMerkle树 前面介绍了区块头哈希值、区块高度和区块头的结构，接着来看看区块体。区块体存储着交易信息，在区块中它们是以一棵Merkle树的数据结构进行存储的，而Merkle树是一种用来有效地总结区块中所有交易的数据结构。Merkle树是一棵哈希二叉树，树的每个叶子节点都是一笔交易的哈希值。以比特币为例，在比特币网络中，Merkle树被用来归纳一个区块中的所有交易，同时生成整个交易集合的数字指纹即Merkle树根，且提供了一种校验区块是否存在某交易的高效途径。生成一棵Merkle树需要递归地对每两个哈希节点进行哈希得到一个新的哈希值，并将新的哈希值存入Merkle树中，直到两两结合最终只有一个哈希值时，这个哈希值就是这一区块所有交易的Merkle根，存储到上面介绍的区块头结构中。 非对称加密与数字签名 非对称加密是区块链技术中用于安全性需求和所有权认证时采用的加密技术，常见的非对称加密算法有RSA、Elgamal、背包算法、Rabin、D-H、ECC（椭圆曲线加密算法）和ECDSA（椭圆曲线数字签名算法），等等。与对称加密算法不同的是，非对称加密算法需要两个密钥：公开密钥（public key）和私有密钥（private key）。基于非对称加密算法可使通信双方在不安全的媒体上交换信息，安全地达成信息的一致。公开密钥是对外公开的，而私有密钥是保密的，其他人不能通过公钥推算出对应的私钥。每一个公开密钥都有其相对应的私有密钥，如果我们使用公开密钥对信息进行了加密，那么则必须有对应的私有密钥才能对加密后的信息进行解密；而如果是用私有密钥加密信息，则只有对应的公开密钥才可以进行解密。在区块链中，非对称加密主要用于信息加密、数字签名等场景。\n在信息加密场景中，如图所示，信息发送者A需要发送一个信息给信息接收者B，需要先使用B的公钥对信息进行加密，B收到后，使用自己的私钥就可以对这一信息进行解密，而其他人没有私钥，是没办法对这个加密信息进行解密的。 而在数字签名场景中，如图所示，发送者A先用哈希函数对原文生成一个摘要（Digest），然后使用私钥对摘要进行加密，生成数字签名（Signature），之后将数字签名与原文一起发送给接收者B；B收到信息后使用A的公钥对数字签名进行解密得到摘要，由此确保信息是A发出的，然后再对收到的原文使用哈希函数产生摘要，并与解密得到的摘要进行对比，如果相同，则说明收到的信息在传输过程中没有被修改过。 4.3 网络层 网络层是区块链平台信息传输的基础，通过P2P的组网方式、特定的信息传播协议和数据验证机制，使得区块链网络中的每个节点都可以平等地参与共识与记账。下面将详细介绍区块链平台网络层中的P2P网络架构、信息传输机制和数据验证机制。\nP2P网络架构\n区块链网络架构一般采用的是基于互联网的P2P（peer-to-peer）架构，在P2P网络中，每台计算机每个节点都是对等的，它们共同为全网提供服务。而且，没有任何中心化的服务端，每台主机都可以作为服务端响应请求，也可以作为客户端使用其他节点所提供的服务。P2P通信不需要从其他实体或CA获取地址验证，因此有效地消除了篡改的可能性和第三方欺骗。所以P2P网络是去中心化和开放的，这也正符合区块链技术的理念。\n在区块链网络中，所有的节点地位均等且以扁平式拓扑结构相互连通和交互，每个节点都需要承担网络路由、验证区块数据、传播区块数据等功能。在比特币网络中，存在着两类节点，一类是全节点，它保存着区块链上所有的完整数据信息，并需要实时地参与区块链数据的校验和记录来更新区块链主链。另一类是轻节点，它只保存着区块链中的部分信息，通过简易支付验证（SPV）方式向其他相邻的节点请求数据以便完成数据的验证。\n传输机制\n在新的区块数据生成后，生成该数据的节点会将其广播到全网的其他节点以供验证。目前的区块链底层平台一般都会根据自身的实际应用需求，在比特币传输机制的基础上重新设计或者改进出新的传输机制，如以太坊区块链集成了所谓的“幽灵协议”，以解决因区块数据确认速度快而导致的高区块作废率和随之而来的安全性风险。这里我们以中本聪设计的比特币系统为例，列出其传输协议的步骤如下：\n  比特币交易节点将新生成的交易数据向全网所有节点进行广播；\n  每个节点都将收集到的交易数据存储到一个区块中；\n  每个节点基于自身算力在区块中找到一个具有足够难度的工作量证明；\n  当节点找到区块的工作量证明后，就向全网所有节点广播此区块；\n  只有包含在区块中的所有交易都有效且之前未存在过，其他节点才认同该区块的有效性；\n  其他节点接收该数据区块，并在该区块的末尾制造新的区块以延长链，而将被接收的区块的随机哈希值视为新区块的前序区块哈希值。\n  如果交易的相关节点是一个未与其他节点相连接的新节点，比特币系统通常会将一组长期稳定运行的“种子节点”推荐给新节点以建立连接，或者推荐至少一个节点连接新节点。此外，进行广播的交易数据并不需要全部节点都接收到，只要有足够多的节点做出响应，交易数据便可整合到区块链账本中。而未接收到完整交易数据的节点可以向临近节点请求下载缺失的交易数据。\n验证机制 在区块链网络中，所有的节点都会时刻监听网络中广播的交易数据和新产生的区块。在接收到相邻节点发来的数据后，会首先验证该数据的有效性，若数据有效则按接收顺序为新数据建立存储池来暂存这些数据，并且继续向临近节点转发；若数据无效则立即废弃该数据，从而保证无效数据不会在区块链网络中继续传播。验证有效性的方法是根据预定义好的标准，从数据结构、语法规范性、输入输出和数字签名等各方面进行校验。对于新区块的校验同理，某节点产生出新区块后，其他节点按照预定义的标准对新区块的工作量证明、时间戳等方面进行校验，若确认有效，则将该区块链接到主区块链上，并开始争取下一个区块的记账权。\n4.4 共识层 Leslie Lamport于1982年提出著名的拜占庭将军问题，引发了无数研究者探索解决方案。如何在分布式系统中高效地达成共识是分布式计算领域的一个重要研究课题。区块链的共识层的作用就是在不同的应用场景下通过使用不同的共识算法，在决策权高度分散的去中心化系统中使得各个节点高效地达成共识。\n最初，比特币区块链选用了一种依赖节点算力的工作量证明共识（Proof of Work，PoW）机制来保证比特币网络分布式记账的一致性。之后随着区块链技术的不断演进和改进，研究者陆续提出了一些不过度依赖算力而能达到全网一致的算法，比如权益证明共识（Proof of Stake，PoS）机制、授权股份证明共识（Delegated Proof of Stake，DPoS）机制、实用拜占庭容错（Practical Byzantine Fault Tolerance，PBFT）算法，等等。下面我们对这几种共识算法进行简单介绍。\nPoW（工作量证明机制）\nPoW机制诞生于1997年 Adam Back 设计的Hashcash系统，它最初被创造出来用于预防邮件系统中漫天遍地的垃圾邮件。2009年，中本聪将PoW机制运用于比特币区块链网络中，作为达成全网一致性的共识机制。从严格意义上讲，比特币中所采用的是一种可重复使用的Hashcash工作证明，使得生成工作证明量可以是一个概率意义上的随机过程。在该机制中，网络上的每一个节点都在使用SHA256哈希算法运算一个不断变化的区块头的哈希值。共识要求算出的值必须等于或者小于某个给定的值。在分布式网络中，所有的参与者都需要使用不同的随机数来持续计算该哈希值，直到达到目标为止。当一个节点得出了确切的值，其他所有的节点必须相互确认该值的正确性。之后，新区块中的交易将被验证以防欺诈。然后，用于计算的交易信息的集合会被确认为认证结果，用区块链中的新区块表示。在比特币中，运算哈希值的节点被称作“矿工”，而PoW的过程被称为“挖矿”。由于认证的计算是一个耗时的过程，所以也提出了相应的激励机制（例如向矿工授予一小部分比特币）。总的来说，工作量证明就是对于工作量的证明，每个区块加入到链上，必须得到网络参与者的同意验证，矿工对它完成了相对应的工作量。PoW的优点是完全的去中心化和分布式账簿。缺点也很明显，即消耗资源：挖矿行为造成了大量的资源浪费，同时PoW达成共识的周期也比较长，比特币网络会自动调整目标值来确保区块生成过程大约需要10分钟，因此它不是很适合商业运用。\nPoS（股权证明机制）\nPoS的想法源于尼克·萨博（Nick Szabo），是PoW的一种节能替代选择，它不需要用户在不受限制的空间中找到一个随机数，而是要求人们证明货币数量的所有权，因为其相信拥有货币数量多的人攻击网络的可能性更低。由于基于账户余额的选择是非常不公平的，因为单一最富有的人势必在网络中占主导地位，所以提出了许多解决方案，结合股权来决定谁来创建下一个块。其中，Blackcoin使用随机选择来预测下一个创建者，而Peercoin则倾向于基于币龄来选择。Peercoin首次开创性地实现了真正的股权证明，它采用工作量证明机制发行新币，采用股权证明机制维护网络安全，这也是“虚拟货币”历史上的一次创举。同比特币网络要求证明人执行一定量的工作不同，该机制只需要证明人提供一定数量“数字货币”的所有权即可。在股权证明机制中，每当创建一个区块时，矿工需要创建一个称为“币权”的交易，这个交易会按照一定的比例预先将一些币发给矿工。然后股权证明机制根据每个节点持有代币的比例和时间，依据算法等比例地降低节点的挖矿难度，以加快节点寻找随机数的速度，缩短达成共识所需的时间。与PoW相比，PoS可以节省更多的能源，更有效率。但是，由于挖矿成本接近于零，因此可能会遭受攻击。且PoS在本质上仍然需要网络中的节点进行挖矿运算，所以它同样难以应用于商业领域。\nDPoS（股份授权证明机制）\nDPoS由比特股（Bitshares）项目组发明。股权拥有者选举他们的代表来进行区块的生成和验证。DPoS类似于现代企业董事会制度，比特股系统将代币持有者称为股东，由股东投票选出101名代表，然后由这些代表负责生成和验证区块。持币者若想成为一名代表，需先用自己的公钥去区块链注册，获得一个长度为32位的特有身份标识符，股东可以对这个标识符以交易的形式进行投票，得票数前101位被选为代表。代表们轮流产生区块，收益（交易手续费）平分。如果有的代表不老实生产区块，很容易被其他代表和股东发现，他将立即被踢出“董事会”，空缺位置由票数排名102的代表自动填补。DPoS的优点在于大幅减少了参与区块验证和记账的节点数量，从而缩短了共识验证所需要的时间，大幅提高了交易效率。从某种角度来说，DPoS可以理解为多中心系统，兼具去中心化和中心化优势\nPBFT（实用拜占庭容错算法）\n这个算法最初出现在MIT的Miguel和Barbara Liskov的学术论文中[33]，初衷是为一个低延迟存储系统所设计，降低算法的复杂度，该算法可以应用于吞吐量不大但需要处理大量事件的数字资产平台。它允许每个节点发布公钥，任何通过节点的消息都由节点签名，以验证其格式。验证过程分为三个阶段：预备、准备、落实。如果已经收到超过$\\frac{1}{3}$不同节点的批准，服务操作将是有效的。使用PBFT，区块链网络$N$个节点中可以包含$f$个拜占庭恶意节点，其中$f=\\frac{N-1}{3}$。 换句话说，PBFT确保至少$2f+1$个节点在将信息添加到分布式共享账簿之前达到共识。目前，HyperLedger联盟、中国ChinaLedger 联盟等诸多区块链联盟都在研究和验证这个算法的实际部署和应用。\n4.5 激励层 激励层作为将经济因素引入区块链技术的一个层次，其存在的必要性取决于建立在区块链技术上的具体应用需求。这里以比特币系统为例，对其激励层进行介绍。\n在比特币系统中，大量的节点算力资源通过共识过程得以汇聚，从而实现区块链账本的数据验证和记账工作，因而其本质上是一种共识节点间的任务众包过程。在去中心化系统中，共识节点本身是自利的，其参与数据验证和记账工作的根本目的是最大化自身收益。所以，必须设计合理的激励机制，使得共识节点最大化自身收益的个体行为与区块链系统的安全性和有效性相契合，从而使大规模的节点对区块链历史形成稳定的共识。\n比特币采用PoW共识机制，在该共识中其经济激励由两部分组成：一是新发行的比特币；二是交易流通过程中的手续费。两者组合在一起，奖励给PoW共识过程中成功计算出符合要求的随机数并生成新区块的节点。因此，只有当各节点达成共识，共同合作来构建和维护区块链历史记录及其系统的有效性，当作奖励的比特币才会有价值。\n 发行机制  在比特币系统中，新区块产生发行比特币的数量是随着时间阶梯型递减的。从创世区块起，每个新区块将发行50个比特币奖励给该区块的记账者，此后每隔约4年（21万个区块），每个新区块发行的比特币数量减少一半，以此类推，一直到比特币的数量稳定在上限2100万为止。前文提到过，给记账者的另一部分奖励是比特币交易过程中产生的手续费，目前默认的手续费是1/10000个比特币。两部分费用会被封装在新区块的第一个交易（称为Coinbase交易）中。虽然现在每个新区块的总手续费与新发行的比特币相比要少得多，但随着时间推移，未来比特币的发行数量会越来越少，甚至停止发行，到那时手续费便会成为共识节点记账的主要动力。此外，手续费还可以起到保障安全性的作用，防止大量微额交易对比特币系统发起“粉尘攻击”。\n分配机制  随着比特币挖矿生态圈的成熟，“矿池”出现在人们的视野中。大量的小算力节点通过加入矿池而联合起来，相互合作汇集算力来提高获得记账权的概率，并共享生成新区块得到的新发行比特币和交易手续费奖励。据Bitcoinminning.com统计，目前已经存在13种不同的分配机制。现今主流矿池通常采用PPLNS（Pay Per Last N Shares）、PPS（Pay Per Share）和PROP（PRO Portionately）等机制。在矿池中，根据各个节点贡献的算力，按比例划分为不同的股份。PPLNS机制在产生新的区块后，各合作节点根据其在最后N个股份内贡献的实际股份比例来分配奖励；PPS则直接根据股份比例为各节点估算和支付一个固定的理论收益，采用此方式的矿池将会适度收取手续费来弥补其为各个节点承担的收益不确定性风险；PROP机制则根据节点贡献的股份按比例地分配奖励。\n4.6 合约层 合约层封装了各类脚本、算法和智能合约，是区块链可编程性的体现。比特币本身就具有简单脚本的编写功能，而以太坊极大地强化了编程语言协议，理论上可以编写实现任何功能的应用。如果把比特币看成是全球账本的话，以太坊可以看作一台“全球计算机”，任何人都可以上传和执行任意的应用程序，并且程序的有效执行能得到保证。如果说数据、网络和共识三个层次作为区块链底层“虚拟机”，分别承担数据表示、数据传播和数据验证功能，合约层则是建立在区块链虚拟机之上的商业逻辑和算法，是实现区块链系统灵活编程和操作数据的基础。包括比特币在内的“数字加密货币”大多采用非图灵完备的简单脚本代码来编程控制交易过程，这也是智能合约的雏形。随着技术的发展，目前已经出现以太坊等图灵完备的可实现更为复杂和灵活的智能合约的脚本语言，使得区块链能够支持宏观金融和社会系统的诸多应用。\n智能合约的概念可以追溯到1995年，是由学者尼克·萨博提出并进行如下定义的：“一个智能合约是一套以数字形式定义的承诺，包括合约参与方可以在上面执行这些承诺的协议。”其设计初衷是希望通过将智能合约内置到物理实体来创造各种灵活可控的智能资产。但由于计算手段的落后和应用场景的缺失，智能合约在当时并未受到研究者的广泛关注。\n区块链技术的出现对智能合约进行了新的定义并使其成为了可能。智能合约作为区块链技术的关键特性之一，是运行在区块链上的模块化、可重用、自动执行的脚本，能够实现数据处理、价值转移、资产管理等一系列功能。合约部署的时候被虚拟机编译成操作码存储在区块链上，对应地会有一个存储地址。当预定的条件发生时，就会发送一笔交易（transaction）到该合约地址，全网节点都会执行合约脚本编译生成的操作码，最后将执行结果写入区块链[。作为一种嵌入式程序化合约，智能合约可以内置在任何区块链数据、交易或资产中，形成可由程序自行控制的系统、市场或资产。智能合约不仅为金融行业提供了创新性的解决方案，同时也能在社会系统中的信息、资产、合同、监管等事务管理中发挥重要作用。\n基于区块链技术的智能合约不仅可以发挥智能合约在成本效率方面的优势，还可以避免恶意行为对合约正常执行的干扰。智能合约可以应用到任何一种数据驱动的业务逻辑中，以太坊首先看到了区块链和智能合约的契合，发布了白皮书《以太坊：下一代智能合约和去中心化应用平台》，构建了内置有图灵完备编程语言的公有区块链，使得任何人都能够创建合约和去中心化应用。\n智能合约与区块链的结合，丰富了区块链本身的价值内涵，其特性有以下3点：\n 用程序逻辑中的丰富合约规则表达能力实现了不信任方之间的公平交换，避免了恶意方中断协议等可能性； 最小化交易方之间的交互，避免了计划外的监控和跟踪的可能性； 丰富了交易与外界状态的交互，比如可信数据源提供的股票信息、天气预报等。  ","permalink":"http://yangchnet.github.io/Dessert/posts/%E5%8C%BA%E5%9D%97%E9%93%BE/%E5%8C%BA%E5%9D%97%E9%93%BE%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8/","summary":"1. 区块链定义 区块链技术本质上是一个去中心化的数据库，它是比特币的核心技术与基础架构，是分布式数据存储、点对点传输、共识机制、加密算法等计算机技术的新型应用模式。狭义来讲，区块链是一种按照时间顺序将数据区块以顺序相连的方式组合成的一种链式数据结构，并以密码学方式保证的不可篡改、不可伪造的分布式账本。广义来讲，区块链技术是利用块链式数据结构来验证与存储数据、利用分布式节点共识算法来生成和更新数据、利用密码学方式保证数据传输和访问的安全、利用由自动化脚本代码组成的智能合约来编程和操作数据的一种全新的分布式基础架构与计算范式。\n1.1 区块链的技术特征 区块链上存储的数据需由全网节点共同维护，可以在缺乏信任的节点之间有效地传递价值。相比现有的数据库技术，区块链具有以下技术特征。\n 块链式数据结构\n区块链利用块链式数据结构来验证和存储数据，通过上文对区块链基本概念的介绍可以知道，每个区块打包记录了一段时间内发生的交易是对当前账本的一次共识，并且通过记录上一个区块的哈希值进行关联，从而形成块链式的数据结构。 分布式共识算法\n区块链系统利用分布式共识算法来生成和更新数据，从技术层面杜绝了非法篡改数据的可能性，从而取代了传统应用中保证信任和交易安全的第三方中介机构，降低了为维护信用而造成的时间成本、人力成本和资源耗用 密码学方式\n区块链系统利用密码学的方式保证数据传输和访问的安全。存储在区块链上的交易信息是公开的，但账户的身份信息是高度加密的。区块链系统集成了对称加密、非对称加密及哈希算法的优点，并使用数字签名技术来保证交易的安全。  1.2 区块链的功能特征 区块链系统的以上技术特征决定了其应用具有如下功能特征。\n  多中心 不同于传统应用的中心化数据管理，区块链网络中有多个机构进行相互监督并实时对账，从而避免了单一记账人造假的可能性，提高了数据的安全性。\n  自动化 区块链系统中的智能合约是可以自动化执行一些预先定义好的规则和条款的一段计算机程序代码，它大大提高了经济活动与契约的自动化程度。\n  可信任 存储在区块链上的交易记录和其他数据是不可篡改并且可溯源的，所以能够很好地解决各方不信任的问题，无需第三方可信中介。\n  2. 区块链的相关概念 区块链以密码学的方式维护一份不可篡改和不可伪造的分布式账本，并通过基于协商一致的规范和协议（共识机制）解决了去中心化的记账系统的一致性问题，其相关概念主要包括以下三个。\n 交易（Transaction）\n区块链上每一次导致区块状态变化的操作都称为交易，每一次交易对应唯一的交易哈希值，一段时间后便会对交易进行打包。 区块（Block）\n打包记录一段时间内发生的交易和状态结果，是对当前账本的一次共识。每个区块以一个相对平稳的时间间隔加入到链上，在企业级区块链平台中，共识时间可以动态设置。 链（Chain）\n区块按照时间顺序串联起来，通过每个区块记录上一个区块的哈希值关联，是整个状态改变的日志记录。   区块链的主要结构  如何解决交易中的信任和安全问题 区块链技术体系不是通过一个权威的中心化机构来保证交易的可信和安全，而是通过加密和分布式共识机制来解决信任和安全问题，其主要技术创新有以下4点。\n  分布式账本 交易是由分布式系统中的多个节点共同记录的。每一个节点都记录完整的交易记录，因此它们都可以参与监督交易合法性并验证交易的有效性。不同于传统的中心化技术方案，区块链中没有任何一个节点有权限单独记录交易，从而避免了因单一记账人或节点被控制而造假的可能性。另一方面，由于全网节点参与记录，理论上讲，除非所有的节点都被破坏，否则交易记录就不会丢失，从而保证了数据的安全性。\n  加密技术和授权技术 区块链技术很好地集成了当前对称加密、非对称加密和哈希算法的许多优点，并使用了数字签名技术来保证交易的安全性，其中最具代表性的是使用椭圆曲线加密算法生成用户的公私钥对和使用椭圆曲线数字签名算法来保证交易安全。打包在区块上的交易信息对于参与共识的所有节点是公开的，但是账户的身份信息是经过严格加密的。\n  共识机制 共识机制是区块链系统中各个节点达成一致的策略和方法。区块链的共识机制替代了传统应用中保证信任和交易安全的第三方中心机构，能够降低由于各方不信任而产生的第三方信用成本、时间成本和资本耗用。常用的共识机制主要有PoW、PoS、DPoS、Paxos、PBFT等，共识机制既是数据写入的方式，也是防止篡改的手段。\n  智能合约 智能合约是可以自动化执行预先定义规则的一段计算机程序代码，它自己就是一个系统参与者。它能够实现价值的存储、传递、控制和管理，为基于区块链的应用提供了创新性的解决方案。\n  3. 区块链分类 按照节点参与方式的不同，区块链技术可以分为：公有链（Public Blockchain）、联盟链（Consortium Blockchain）和私有链（Private Blockchain）。按照权限的不同，区块链技术可以分为：许可链（Permissioned Blockchain）和非许可链（Permissionless Blockchain）。前述的三大类区块链技术中，联盟链和私有链属于许可链，公有链属于非许可链。","title":"区块链基础入门"},{"content":"1. sync.Mutex互斥锁 不同goroutine之间对公共资源进行访问需要使用互斥锁。例如在对银行账户的操作中，如果我们有两种操作，一个是查询余额，一个是存款。其操作如下：\npackage bank // 存款余额 var balance int // 存款 func Deposit(amount int) { balance = balance + amount } // 查询 func Balance() int { return balance } // Alice: go func() { bank.Deposit(200) // A1  fmt.Println(\u0026#34;=\u0026#34;, bank.Balance()) // A2 }() // Bob: go bank.Deposit(100) // B 这其中，若把A1分为两个操作，A1r：把余额从内存中读出来；A2w：把修改后的余额写入内存。\n若执行顺序为A1r → B → A1w → A2， 正常情况下，Alice和Bob分别存入了$200，$100，因此最后的存款应该是300，但最后输出结果为200。因为A在计算时是按照A1r读出的数值进行计算，忽略了B的操作，A与B之间发生了数据竞争。\n 数据竞争：无论任何时候，只要有两个goroutine并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争。\n 解决此问题的办法之一是使用互斥锁。\nimport \u0026#34;sync\u0026#34; var ( mu sync.Mutex // guards balance  balance int ) func Deposit(amount int) { mu.Lock() defer mu.Unlock() balance = balance + amount } func Balance() int { mu.Lock() defer mu.Unlock() return balance } 每次一个goroutine访问bank变量时(这里只有balance余额变量)，它都会调用mutex的Lock方法来获取一个互斥锁。如果其它的goroutine已经获得了这个锁的话，这个操作会被阻塞直到其它goroutine调用了Unlock使该锁变回可用状态.\n2. sync.RWMutex读写锁 由于Balance函数只需要读取变量的状态，所以我们同时让多个Balance调用并发运行事实上 是安全的，只要在运行的时候没有存款或者取款操作就行。在这种场景下我们需要一种特殊 类型的锁，其允许多个只读操作并行执行，但写操作会完全互斥。这种锁叫作“多读单写”锁 (multiple readers, single writer lock)，Go语言提供的这样的锁是sync.RWMutex：\nvar mu sync.RWMutex var balance int func Balance() int { mu.RLock() // readers lock  defer mu.RUnlock() return balance } 读写锁的规则是\n 读锁不能阻塞读锁 读锁需要阻塞写锁，直到所有读锁都释放 写锁需要阻塞读锁，直到所有写锁都释放 写锁需要阻塞写锁  ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/go%E4%B8%AD%E7%9A%84%E9%94%81/","summary":"1. sync.Mutex互斥锁 不同goroutine之间对公共资源进行访问需要使用互斥锁。例如在对银行账户的操作中，如果我们有两种操作，一个是查询余额，一个是存款。其操作如下：\npackage bank // 存款余额 var balance int // 存款 func Deposit(amount int) { balance = balance + amount } // 查询 func Balance() int { return balance } // Alice: go func() { bank.Deposit(200) // A1  fmt.Println(\u0026#34;=\u0026#34;, bank.Balance()) // A2 }() // Bob: go bank.Deposit(100) // B 这其中，若把A1分为两个操作，A1r：把余额从内存中读出来；A2w：把修改后的余额写入内存。\n若执行顺序为A1r → B → A1w → A2， 正常情况下，Alice和Bob分别存入了$200，$100，因此最后的存款应该是300，但最后输出结果为200。因为A在计算时是按照A1r读出的数值进行计算，忽略了B的操作，A与B之间发生了数据竞争。\n 数据竞争：无论任何时候，只要有两个goroutine并发访问同一变量，且至少其中的一个是写操作的时候就会发生数据竞争。\n 解决此问题的办法之一是使用互斥锁。\nimport \u0026#34;sync\u0026#34; var ( mu sync.Mutex // guards balance  balance int ) func Deposit(amount int) { mu.","title":"Go中的锁"},{"content":"三个goroutine分别输出张三、李四、王五，使其按上述顺序输出5遍。 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var w sync.WaitGroup func main() { w.Add(15) chan1 := make(chan struct{}, 0) chan2 := make(chan struct{}, 0) for i := 0; i \u0026lt; 5; i++ { go func() { defer w.Done() fmt.Println(\u0026#34;张三\u0026#34;) chan1 \u0026lt;- struct{}{} }() go func() { defer w.Done() \u0026lt;- chan1 fmt.Println(\u0026#34;李四\u0026#34;) chan2 \u0026lt;- struct{}{} }() go func() { defer w.Done() \u0026lt;- chan2 fmt.Println(\u0026#34;王五\u0026#34;) }() } w.Wait() } 编写程序输出某目录下的所有文件（包括子目录） package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) func main() { dir := os.Args[1] listAll(dir, 0) } func listAll(path string, curHier int) { fileInfos, err := ioutil.ReadDir(path) if err != nil { fmt.Println(err) return } for _, info := range fileInfos { if info.IsDir(){ for tmpHier := curHier; tmpHier \u0026gt; 0; tmpHier-- { fmt.Printf(\u0026#34;|\\t\u0026#34;) } fmt.Println(info.Name(), \u0026#34;\\\\\u0026#34;) listAll(path + \u0026#34;/\u0026#34; + info.Name(), curHier + 1) } else { for tmpHier := curHier; tmpHier \u0026gt; 0; tmpHier-- { fmt.Printf(\u0026#34;|\\t\u0026#34;) } fmt.Println(info.Name()) } } } ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/%E9%9D%A2%E8%AF%95%E9%A2%98/","summary":"三个goroutine分别输出张三、李四、王五，使其按上述顺序输出5遍。 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) var w sync.WaitGroup func main() { w.Add(15) chan1 := make(chan struct{}, 0) chan2 := make(chan struct{}, 0) for i := 0; i \u0026lt; 5; i++ { go func() { defer w.Done() fmt.Println(\u0026#34;张三\u0026#34;) chan1 \u0026lt;- struct{}{} }() go func() { defer w.Done() \u0026lt;- chan1 fmt.Println(\u0026#34;李四\u0026#34;) chan2 \u0026lt;- struct{}{} }() go func() { defer w.Done() \u0026lt;- chan2 fmt.Println(\u0026#34;王五\u0026#34;) }() } w.Wait() } 编写程序输出某目录下的所有文件（包括子目录） package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;os\u0026#34; ) func main() { dir := os.","title":"面试题golang"},{"content":" 转载自：https://segmentfault.com/a/1190000011365430\n 1. WSGI介绍 1.1 什么是WSGI 首先介绍几个关于WSGI相关的概念 WSGI：全称是Web Server Gateway Interface，WSGI不是服务器，python 模块，框架，API或者任何软件，只是一种规范，描述web server如何与web application通信的规范。server和application的规范在PEP 3333中有具体描述。要实现WSGI协议，必须同时实现web server和web application，当前运行在WSGI协议之上的web框架有Torando,Flask,Django\nuwsgi:与WSGI一样是一种通信协议，是uWSGI服务器的独占协议，用于定义传输信息的类型(type of information)，每一个uwsgi packet前4byte为传输信息类型的描述，与WSGI协议是两种东西，据说该协议是fcgi协议的10倍快。\nuWSGI：是一个web服务器，实现了WSGI协议、uwsgi协议、http协议等。\nWSGI协议主要包括server和application两部分：\n WSGI server负责从客户端接收请求，将request转发给application，将application返回的response返回给客户端； WSGI application接收由server转发的request，处理请求，并将处理结果返回给server。application中可以包括多个栈式的中间件(middlewares)，这些中间件需要同时实现server与application，因此可以在WSGI服务器与WSGI应用之间起调节作用：对服务器来说，中间件扮演应用程序，对应用程序来说，中间件扮演服务器。\n WSGI协议其实是定义了一种server与application解耦的规范，即可以有多个实现WSGI server的服务器，也可以有多个实现WSGI application的框架，那么就可以选择任意的server和applicatiodn组合实现自己的web应用。例如uWSGI和Gunicorn都是实现了WSGI server协议的服务器，Django，Flask是实现了WSGI application协议的web框架，可以根据项目实际情况搭配使用。\n以上介绍了相关的常识，接下来我们来看看如何简单实现WSGI协议。\n1.2 怎么实现WSGI 上文说过，实现WSGI协议必须要有wsgi server和application，因此，我们就来实现这两个东西。\n我们来看看官方WSGI使用WSGI的wsgiref模块实现的小demo\ndef demo_app(environ,start_response): from StringIO import StringIO stdout = StringIO() print \u0026gt;\u0026gt;stdout, \u0026#34;Hello world!\u0026#34; print \u0026gt;\u0026gt;stdout h = environ.items(); h.sort() for k,v in h: print \u0026gt;\u0026gt;stdout, k,\u0026#39;=\u0026#39;, repr(v) start_response(\u0026#34;200 OK\u0026#34;, [(\u0026#39;Content-Type\u0026#39;,\u0026#39;text/plain\u0026#39;)]) return [stdout.getvalue()] httpd = make_server(\u0026#39;localhost\u0026#39;, 8002, demo_app) httpd.serve_forever() # 使用select  实现了一个application，来获取客户端的环境和回调函数两个参数，以及httpd服务端的实现，我们来看看make_server的源代码\ndef make_server( host, port, app, server_class=WSGIServer, handler_class=WSGIRequestHandler): \u0026#34;\u0026#34;\u0026#34;Create a new WSGI server listening on `host` and `port` for `app`\u0026#34;\u0026#34;\u0026#34; server = server_class((host, port), handler_class) server.set_app(app) return server 下面我们自己来实现一遍： WSGI 规定每个 python 程序（Application）必须是一个可调用的对象（实现了__call__ 函数的方法或者类），接受两个参数 environ（WSGI 的环境信息） 和 start_response（开始响应请求的函数），并且返回 iterable。几点说明：\nenviron 和 start_response 由 http server 提供并实现 environ 变量是包含了环境信息的字典 Application 内部在返回前调用 start_response start_response也是一个 callable，接受两个必须的参数，status（HTTP状态）和 response_headers（响应消息的头） 可调用对象要返回一个值，这个值是可迭代的。  application\n # 1. 可调用对象是一个函数 def application(environ, start_response): response_body = \u0026#39;The request method was %s\u0026#39; % environ[\u0026#39;REQUEST_METHOD\u0026#39;] # HTTP response code and message status = \u0026#39;200 OK\u0026#39; # 应答的头部是一个列表，每对键值都必须是一个 tuple。 response_headers = [(\u0026#39;Content-Type\u0026#39;, \u0026#39;text/plain\u0026#39;), (\u0026#39;Content-Length\u0026#39;, str(len(response_body)))] # 调用服务器程序提供的 start_response，填入两个参数 start_response(status, response_headers) # 返回必须是 iterable return [response_body] # 2. 可调用对象是一个类 class AppClass: \u0026#34;\u0026#34;\u0026#34;这里的可调用对象就是 AppClass 这个类，调用它就能生成可以迭代的结果。 使用方法类似于： for result in AppClass(env, start_response): do_somthing(result) \u0026#34;\u0026#34;\u0026#34; def __init__(self, environ, start_response): self.environ = environ self.start = start_response def __iter__(self): status = \u0026#39;200 OK\u0026#39; response_headers = [(\u0026#39;Content-type\u0026#39;, \u0026#39;text/plain\u0026#39;)] self.start(status, response_headers) yield \u0026#34;Hello world!\\n\u0026#34; # 3. 可调用对象是一个实例  class AppClass: \u0026#34;\u0026#34;\u0026#34;这里的可调用对象就是 AppClass 的实例，使用方法类似于： app = AppClass() for result in app(environ, start_response): do_somthing(result) \u0026#34;\u0026#34;\u0026#34; def __init__(self): pass def __call__(self, environ, start_response): status = \u0026#39;200 OK\u0026#39; response_headers = [(\u0026#39;Content-type\u0026#39;, \u0026#39;text/plain\u0026#39;)] self.start(status, response_headers) yield \u0026#34;Hello world!\\n\u0026#34;  server\n 上面已经说过，标准要能够确切地实行，必须要求程序端和服务器端共同遵守。上面提到， envrion 和 start_response 都是服务器端提供的。下面就看看，服务器端要履行的义务。\n准备 environ 参数 定义 start_response 函数 调用程序端的可调用对象 import os, sys def run_with_cgi(application): # application 是程序端的可调用对象 # 准备 environ 参数，这是一个字典，里面的内容是一次 HTTP 请求的环境变量 environ = dict(os.environ.items()) environ[\u0026#39;wsgi.input\u0026#39;] = sys.stdin environ[\u0026#39;wsgi.errors\u0026#39;] = sys.stderr environ[\u0026#39;wsgi.version\u0026#39;] = (1, 0) environ[\u0026#39;wsgi.multithread\u0026#39;] = False environ[\u0026#39;wsgi.multiprocess\u0026#39;] = True environ[\u0026#39;wsgi.run_once\u0026#39;] = True environ[\u0026#39;wsgi.url_scheme\u0026#39;] = \u0026#39;http\u0026#39; headers_set = [] headers_sent = [] # 把应答的结果输出到终端 def write(data): sys.stdout.write(data) sys.stdout.flush() # 实现 start_response 函数，根据程序端传过来的 status 和 response_headers 参数， # 设置状态和头部 def start_response(status, response_headers, exc_info=None): headers_set[:] = [status, response_headers] return write # 调用客户端的可调用对象，把准备好的参数传递过去 result = application(environ, start_response) # 处理得到的结果，这里简单地把结果输出到标准输出。 try: for data in result: if data: # don\u0026#39;t send headers until body appears write(data) finally: if hasattr(result, \u0026#39;close\u0026#39;): result.close() 2. 由Django框架分析WSGI 下面我们以django为例，分析一下wsgi的整个流程\n2.1 django WSGI application WSGI application应该实现为一个可调用iter对象，例如函数、方法、类(包含call方法)。需要接收两个参数：一个字典，该字典可以包含了客户端请求的信息以及其他信息，可以认为是请求上下文，一般叫做environment（编码中多简写为environ、env），一个用于发送HTTP响应状态（HTTP status）、响应头（HTTP headers）的回调函数,也就是start_response()。通过回调函数将响应状态和响应头返回给server，同时返回响应正文(response body)，响应正文是可迭代的、并包含了多个字符串。 下面是Django中application的具体实现部分：\n# 继承, 但只实现了 __call__ 方法, 方便使用 class WSGIHandler(base.BaseHandler): initLock = Lock() # 可以将其视为一个代表 http 请求的类 request_class = WSGIRequest # WSGIHandler 也可以作为函数来调用 def __call__(self, environ, start_response): # Set up middleware if needed. We couldn\u0026#39;t do this earlier, because # settings weren\u0026#39;t available. # 这里的检测: 因为 self._request_middleware 是最后才设定的, 所以如果为空, # 很可能是因为 self.load_middleware() 没有调用成功. if self._request_middleware is None: with self.initLock: try: # Check that middleware is still uninitialised. if self._request_middleware is None: 因为 load_middleware() 可能没有调用, 调用一次. self.load_middleware() except: # Unload whatever middleware we got self._request_middleware = None raise set_script_prefix(base.get_script_name(environ)) signls.request_started.send(sender=self.__class__) # __class__ 代表自己的类 try: # 实例化 request_class = WSGIRequest, 将在日后文章中展开, 可以将其视为一个代表 http 请求的类 request = self.request_class(environ) except UnicodeDecodeError: logger.warning(\u0026#39;Bad Request (UnicodeDecodeError)\u0026#39;, exc_info=sys.exc_info(), extra={ \u0026#39;status_code\u0026#39;: 400, } ) response = http.HttpResponseBadRequest() else: # 调用 self.get_response(), 将会返回一个相应对象 response\u0026lt;br\u0026gt; ############# 关键的操作, self.response() 可以获取响应数据.  response = self.get_response(request) # 将 self 挂钩到 response 对象 response._handler_class = self.__class__ try: status_text = STATUS_CODE_TEXT[response.status_code] except KeyError: status_text = \u0026#39;UNKNOWN STATUS CODE\u0026#39; # 状态码 status = \u0026#39;%s%s\u0026#39; % (response.status_code, status_text) response_headers = [(str(k), str(v)) for k, v in response.items()] # 对于每个一个 cookie, 都在 header 中设置: Set-cookie xxx=yyy for c in response.cookies.values(): response_headers.append((str(\u0026#39;Set-Cookie\u0026#39;), str(c.output(header=\u0026#39;\u0026#39;)))) # start_response() 操作已经在上节中介绍了 start_response(force_str(status), response_headers) # 成功返回相应对象 return response 可以看出application的流程包括:加载所有中间件，以及执行框架相关的操作，设置当前线程脚本前缀，发送请求开始信号；处理请求，调用get_response()方法处理当前请求，该方法的的主要逻辑是通过urlconf找到对应的view和callback，按顺序执行各种middleware和callback。调用由server传入的start_response()方法将响应header与status返回给server。返回响应正文\n2.2 django WSGI Server 负责获取http请求，将请求传递给WSGI application，由application处理请求后返回response。以Django内建server为例看一下具体实现。通过runserver运行django 项目，在启动时都会调用下面的run方法，创建一个WSGIServer的实例，之后再调用其serve_forever()方法启动服务。\ndef run(addr, port, wsgi_handler, ipv6=False, threading=False): server_address = (addr, port) if threading: httpd_cls = type(str(\u0026#39;WSGIServer\u0026#39;), (socketserver.ThreadingMixIn, WSGIServer), {}) else: httpd_cls = WSGIServer # 这里的wsgi_handler就是WSGIApplication  httpd = httpd_cls(server_address, WSGIRequestHandler, ipv6=ipv6) if threading: httpd.daemon_threads = True httpd.set_app(wsgi_handler) httpd.serve_forever() 下面表示WSGI server服务器处理流程中关键的类和方法。\n**WSGIServerrun()**方法会创建WSGIServer实例，主要作用是接收客户端请求，将请求传递给application，然后将application返回的response返回给客户端。 创建实例时会指定HTTP请求的handler：WSGIRequestHandler类 通过set_app和get_app方法设置和获取WSGIApplication实例wsgi_handler 处理http请求时，调用handler_request方法，会创建WSGIRequestHandler 实例处理http请求。 WSGIServer中get_request方法通过socket接受请求数据\nWSGIRequestHandler 由WSGIServer在调用handle_request时创建实例，传入request、cient_address、WSGIServer三个参数，__init__方法在实例化同时还会调用自身的handle方法handle方法会创建ServerHandler实例，然后调用其run方法处理请求\nServerHandler WSGIRequestHandler在其handle方法中调用run方法，传入self.server.get_app()参数，获取WSGIApplication，然后调用实例(call)，获取response，其中会传入start_response回调，用来处理返回的header和status。通过application获取response以后，通过finish_response返回response\nWSGIHandler WSGI协议中的application，接收两个参数，environ字典包含了客户端请求的信息以及其他信息，可以认为是请求上下文，start_response用于发送返回status和header的回调函数\n虽然上面一个WSGI server涉及到多个类实现以及相互引用，但其实原理还是调用WSGIHandler，传入请求参数以及回调方法start_response()，并将响应返回给客户端\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/wsgi/","summary":"转载自：https://segmentfault.com/a/1190000011365430\n 1. WSGI介绍 1.1 什么是WSGI 首先介绍几个关于WSGI相关的概念 WSGI：全称是Web Server Gateway Interface，WSGI不是服务器，python 模块，框架，API或者任何软件，只是一种规范，描述web server如何与web application通信的规范。server和application的规范在PEP 3333中有具体描述。要实现WSGI协议，必须同时实现web server和web application，当前运行在WSGI协议之上的web框架有Torando,Flask,Django\nuwsgi:与WSGI一样是一种通信协议，是uWSGI服务器的独占协议，用于定义传输信息的类型(type of information)，每一个uwsgi packet前4byte为传输信息类型的描述，与WSGI协议是两种东西，据说该协议是fcgi协议的10倍快。\nuWSGI：是一个web服务器，实现了WSGI协议、uwsgi协议、http协议等。\nWSGI协议主要包括server和application两部分：\n WSGI server负责从客户端接收请求，将request转发给application，将application返回的response返回给客户端； WSGI application接收由server转发的request，处理请求，并将处理结果返回给server。application中可以包括多个栈式的中间件(middlewares)，这些中间件需要同时实现server与application，因此可以在WSGI服务器与WSGI应用之间起调节作用：对服务器来说，中间件扮演应用程序，对应用程序来说，中间件扮演服务器。\n WSGI协议其实是定义了一种server与application解耦的规范，即可以有多个实现WSGI server的服务器，也可以有多个实现WSGI application的框架，那么就可以选择任意的server和applicatiodn组合实现自己的web应用。例如uWSGI和Gunicorn都是实现了WSGI server协议的服务器，Django，Flask是实现了WSGI application协议的web框架，可以根据项目实际情况搭配使用。\n以上介绍了相关的常识，接下来我们来看看如何简单实现WSGI协议。\n1.2 怎么实现WSGI 上文说过，实现WSGI协议必须要有wsgi server和application，因此，我们就来实现这两个东西。\n我们来看看官方WSGI使用WSGI的wsgiref模块实现的小demo\ndef demo_app(environ,start_response): from StringIO import StringIO stdout = StringIO() print \u0026gt;\u0026gt;stdout, \u0026#34;Hello world!\u0026#34; print \u0026gt;\u0026gt;stdout h = environ.items(); h.sort() for k,v in h: print \u0026gt;\u0026gt;stdout, k,\u0026#39;=\u0026#39;, repr(v) start_response(\u0026#34;200 OK\u0026#34;, [(\u0026#39;Content-Type\u0026#39;,\u0026#39;text/plain\u0026#39;)]) return [stdout.","title":"wsgi"},{"content":"1. ORM是什么 面向对象编程把所有实体看成对象（object），关系型数据库则是采用实体之间的关系（relation）连接数据。很早就有人提出，关系也可以用对象表达，这样的话，就能使用面向对象编程，来操作关系型数据库。 简单的说，ORM 就是通过实例对象的语法，完成关系型数据库的操作的技术，是\u0026quot;对象-关系映射\u0026quot;（Object/Relational Mapping） 的缩写。\nORM把数据库映射为对象\n 数据库的表（table） \u0026ndash;\u0026gt; 类（class） 记录（record，行数据）\u0026ndash;\u0026gt; 对象（object） 字段（field）\u0026ndash;\u0026gt; 对象的属性（attribute）\n 举例来说，下面是一行SQL语句\nSELECT id, first_name, last_name, phone, birth_date, sex FROM persons WHERE id = 10 程序直接运行SQL，操作数据库的写法如下：\nres = db.execSql(sql) name = res[0][\u0026#34;FIRST_NAME\u0026#34;] 改成ORM的写法如下：\np = Person.get(10) name = p.first_name 一比较就可以发现，ORM 使用对象，封装了数据库操作，因此可以不碰 SQL 语言。开发者只使用面向对象编程，与数据对象直接交互，不用关心底层数据库。\n总结起来，ORM有如下优点：\n 数据模型都在一个地方定义，更容易更新和维护，也利于重用代码。 ORM 有现成的工具，很多功能都可以自动完成，比如数据消毒、预处理、事务等等。 它迫使你使用 MVC 架构，ORM 就是天然的 Model，最终使代码更清晰。 基于 ORM 的业务代码比较简单，代码量少，语义性好，容易理解。 你不必编写性能不佳的 SQL。 但是ORM也有很突出的缺点： ORM 库不是轻量级工具，需要花很多精力学习和设置。 对于复杂的查询，ORM 要么是无法表达，要么是性能不如原生的 SQL。 ORM 抽象掉了数据库层，开发者无法了解底层的数据库操作，也无法定制一些特殊的 SQL。  2. 实例 Django是一个非常著名的python web框架，其提供了简单易用的ORM。\n安装django\npip install django 完成安装后，使用如下命令创建一个新的django项目\ndjango-admin startproject newSite 尝试运行\ncd newSite python manage.py runserver 访问https://127.0.0.1:8000查看是否运行成功。\n2.1 Model 完成了项目的创建后，下一步是要定义一个Model，一般来说，每个Model都映射一张数据库表。\n 每个模型都是一个 Python 的类，这些类继承 django.db.models.Model 模型类的每个属性都相当于一个数据库的字段。 利用这些，Django 提供了一个自动生成访问数据库的 API。  为django项目添加一个新的app\npython manage.py startapp ormTest 切换到ormTest目录下，添加如下代码\n# models.py  from django.db import models class Person(models.Model): first_name = models.CharField(max_length=30) last_name = models.CharField(max_length=30) 以上代码定义了一个 Person 模型，拥有 first_name 和 last_name:first_name 和 last_name 是模型的字段。每个字段都被指定为一个类属性，并且每个属性映射为一个数据库列。 在/newSite/newSite/setting.py中的INSTALLED_APPS添加如下代码，来告诉django你准备使用这个模型。\nINSTALLED_APPS = [ #... \u0026#39;ormTest.apps.OrmtestConfig\u0026#39;, #... ] 使用如下命令生成对应的数据库表\npython manage.py makemigrations ormTest python manage.py migrate 上面的Person模型会创建一个如下的数据库表：\nCREATE TABLE ormTest_person ( \u0026#34;id\u0026#34; serial NOT NULL PRIMARY KEY, \u0026#34;first_name\u0026#34; varchar(30) NOT NULL, \u0026#34;last_name\u0026#34; varchar(30) NOT NULL ); 2.2 CRUD 进入python命令行\npython manage.py shell In [1]: from ormTest.models import Person # Create  In [4]: Person.objects.create(first_name=\u0026#39;li\u0026#39;, last_name=\u0026#39;chang\u0026#39;) Out[4]: \u0026lt;Person: Person object (1)\u0026gt; # Read In [5]: Person.objects.all() Out[5]: \u0026lt;QuerySet [\u0026lt;Person: Person object (1)\u0026gt;]\u0026gt; # Update In [6]: person1 = Person.objects.get(id=1) In [8]: person1.first_name Out[8]: \u0026#39;li\u0026#39; In [9]: person1.last_name Out[9]: \u0026#39;chang\u0026#39; In [10]: person1.last_name = \u0026#39;YANG\u0026#39; In [11]: person1.save() In [14]: person2 = Person.objects.get(id=1) In [15]: person2.last_name Out[15]: \u0026#39;YANG\u0026#39; # Delete In [16]: person2.delete() Out[16]: (1, {\u0026#39;ormTest.Person\u0026#39;: 1}) In [17]: Person.objects.all() Out[17]: \u0026lt;QuerySet []\u0026gt; ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/orm%E7%AE%80%E4%BB%8B/","summary":"1. ORM是什么 面向对象编程把所有实体看成对象（object），关系型数据库则是采用实体之间的关系（relation）连接数据。很早就有人提出，关系也可以用对象表达，这样的话，就能使用面向对象编程，来操作关系型数据库。 简单的说，ORM 就是通过实例对象的语法，完成关系型数据库的操作的技术，是\u0026quot;对象-关系映射\u0026quot;（Object/Relational Mapping） 的缩写。\nORM把数据库映射为对象\n 数据库的表（table） \u0026ndash;\u0026gt; 类（class） 记录（record，行数据）\u0026ndash;\u0026gt; 对象（object） 字段（field）\u0026ndash;\u0026gt; 对象的属性（attribute）\n 举例来说，下面是一行SQL语句\nSELECT id, first_name, last_name, phone, birth_date, sex FROM persons WHERE id = 10 程序直接运行SQL，操作数据库的写法如下：\nres = db.execSql(sql) name = res[0][\u0026#34;FIRST_NAME\u0026#34;] 改成ORM的写法如下：\np = Person.get(10) name = p.first_name 一比较就可以发现，ORM 使用对象，封装了数据库操作，因此可以不碰 SQL 语言。开发者只使用面向对象编程，与数据对象直接交互，不用关心底层数据库。\n总结起来，ORM有如下优点：\n 数据模型都在一个地方定义，更容易更新和维护，也利于重用代码。 ORM 有现成的工具，很多功能都可以自动完成，比如数据消毒、预处理、事务等等。 它迫使你使用 MVC 架构，ORM 就是天然的 Model，最终使代码更清晰。 基于 ORM 的业务代码比较简单，代码量少，语义性好，容易理解。 你不必编写性能不佳的 SQL。 但是ORM也有很突出的缺点： ORM 库不是轻量级工具，需要花很多精力学习和设置。 对于复杂的查询，ORM 要么是无法表达，要么是性能不如原生的 SQL。 ORM 抽象掉了数据库层，开发者无法了解底层的数据库操作，也无法定制一些特殊的 SQL。  2.","title":"ORM简介"},{"content":"1. 安装并对redis进行配置 更新源并安装redis\nsudo apt-get update sudo apt-get install redis-server 将redis设置为systemctl\nsudo vim /etc/redis/redis.conf 找到supervised选项，设置为systemd\n# If you run Redis from upstart or systemd, Redis can interact with your # supervision tree. Options: # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # Note: these supervision methods only signal \u0026#34;process is ready.\u0026#34; # They do not enable continuous liveness pings back to your supervisor. supervised systemd 开启redis服务\nsudo service redis-server start 2. 测试redis 查看redis运行状态\nsudo service redis-server status 打开redis命令行\nredis-cli 127.0.0.1:6379\u0026gt; ping PONG 127.0.0.1:6379\u0026gt; set test \u0026#34;It\u0026#39;s a working\u0026#34; OK 127.0.0.1:6379\u0026gt; get test \u0026#34;It\u0026#39;s a working\u0026#34; 127.0.0.1:6379\u0026gt;exit 退出后重新连接redis，再次访问test键\n127.0.0.1:6379\u0026gt; get test \u0026#34;It\u0026#39;s a working\u0026#34; 127.0.0.1:6379\u0026gt; 3. 绑定到本地 一般来说，不推荐配置redis远程可访问，因此，这里只将其配置为本地可访问。\n打开Redis configuration file\nsudo vim /etc/redis/redis.conf 定位到bind,并将其配置如下\n# By default, if no \u0026#34;bind\u0026#34; configuration directive is specified, Redis listens # for connections from all the network interfaces available on the server. # It is possible to listen to just one or multiple selected interfaces using # the \u0026#34;bind\u0026#34; configuration directive, followed by one or more IP addresses. # # Examples: # # bind 192.168.1.100 10.0.0.1 bind 127.0.0.1 ::1 # 这里本来被注释掉，去掉注释即可 保存退出，重启redis\nsudo service redis-server restart 查看此项配置是否生效\n$ sudo netstat -lnp | grep redis tcp 0 0 127.0.0.1:6379 0.0.0.0:* LISTEN 2086/redis-server 1 tcp6 0 0 ::1:6379 :::* LISTEN 2086/redis-server 1 4. 为redis配置密码 打开redis配置文件，定位到# requirepass foobared\nsudo vim /etc/redis/redis.conf 将# requirepass foobared注释去掉，把foobared改成你想要的密码。\n重启redis服务\nsudo service redis-server restart 再次进入redis，尝试get\n$ redis-cli 127.0.0.1:6379\u0026gt; get test (error) NOAUTH Authentication required. 127.0.0.1:6379\u0026gt; get失败，因为没有进行认证.\n127.0.0.1:6379\u0026gt; auth your_redis_password OK 127.0.0.1:6379\u0026gt; get test \u0026#34;It\u0026#39;s a working\u0026#34; 127.0.0.1:6379\u0026gt;  参考：How To Install and Secure Redis on Ubuntu 18.04\n ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/ubuntu18%E5%AE%89%E8%A3%85redis/","summary":"1. 安装并对redis进行配置 更新源并安装redis\nsudo apt-get update sudo apt-get install redis-server 将redis设置为systemctl\nsudo vim /etc/redis/redis.conf 找到supervised选项，设置为systemd\n# If you run Redis from upstart or systemd, Redis can interact with your # supervision tree. Options: # supervised no - no supervision interaction # supervised upstart - signal upstart by putting Redis into SIGSTOP mode # supervised systemd - signal systemd by writing READY=1 to $NOTIFY_SOCKET # supervised auto - detect upstart or systemd method based on # UPSTART_JOB or NOTIFY_SOCKET environment variables # Note: these supervision methods only signal \u0026#34;process is ready.","title":"Ubuntu18（WSL2）安装redis"},{"content":"1. 问题现象 莫名其妙，多出来几个显示器。 从设备管理器中看，也是存在多个通用非即插即用显示器2. 解决办法 重新安装Intel显卡驱动，可以从电脑厂家官网下载。但需要注意的一点是：在重新安装显卡驱动后，需要禁用显卡驱动程序的自动更新，否则还有可能出现这个问题。 打开组策略gpedit.msc，选择计算机配置”-\u0026gt;“管理模板”-\u0026gt;“系统”-\u0026gt;“设备安装”-\u0026gt;“设备安装限制”，找到Intel显卡的类Guid添加到阻止使用与下列设备安装程序类相匹配的驱动程序安装设备中\n","permalink":"http://yangchnet.github.io/Dessert/posts/windows/%E5%A4%9A%E5%87%BA%E5%87%A0%E4%B8%AA%E9%80%9A%E7%94%A8%E9%9D%9E%E5%8D%B3%E6%8F%92%E5%8D%B3%E7%94%A8%E6%98%BE%E7%A4%BA%E5%99%A8/","summary":"1. 问题现象 莫名其妙，多出来几个显示器。 从设备管理器中看，也是存在多个通用非即插即用显示器2. 解决办法 重新安装Intel显卡驱动，可以从电脑厂家官网下载。但需要注意的一点是：在重新安装显卡驱动后，需要禁用显卡驱动程序的自动更新，否则还有可能出现这个问题。 打开组策略gpedit.msc，选择计算机配置”-\u0026gt;“管理模板”-\u0026gt;“系统”-\u0026gt;“设备安装”-\u0026gt;“设备安装限制”，找到Intel显卡的类Guid添加到阻止使用与下列设备安装程序类相匹配的驱动程序安装设备中","title":"多出几个通用非即插即用显示器"},{"content":"1. 长度  数组\n 对于数组来说，它的长度是固定的，并且数组的长度是其类型的一部分，即对于以下两个数组来说，他们是不同的类型。\nvar a [5]int var b [6]int fmt.Printf(\u0026#34;%v\u0026#34;, reflect.TypeOf(a) == reflect.TypeOf(b)) // 输出： false 数组的长度必须是常量表达式，因为数组的长度需要在编译阶段确定。\n对于数组来说，由于其长度是固定的，因此不能添加或删除元素。\n 切片\n 而对于切片，其长度是不固定的，不同长度的切片，只要其元素类型相同，则它们就是相同的切片类型。\na := make([]int, 5) b := make([]int, 6) fmt.Printf(\u0026#34;%v\\n\u0026#34;, reflect.TypeOf(a) == reflect.TypeOf(b)) // 输出： true 如果切片操作超出cap(s)的上限将导致一个panic异常，但是超出len(s)则是意味着扩展了 slice，因为新slice的长度会变大：\nmonths := [...]string{1: \u0026#34;January\u0026#34;, /* ... */, 12: \u0026#34;December\u0026#34;} summer := months[6:9] fmt.Println(summer[:20]) // panic: out of range endlessSummer := summer[:5] // extend a slice (within capacity) fmt.Println(endlessSummer) // \u0026#34;[June July August September October]\u0026#34; 2. 比较  数组\n 如果一个数组的元素类型是可以相互比较的，那么数组类型也是可以相互比较的，这时候我们可以直接通过==比较运算符来比较两个数组。只有当两个数组的所有元素都是相等的时候数组才是相等的。不想等比较运算符!=遵循同样的规则.\na := [2]int{1, 2} b := [...]int{1, 2} c := [2]int{1, 3} fmt.Println(a==b, a==c, b==c) // \u0026#34;true, false, false\u0026#34; d := [3]int{1, 2} fmt.Println(a==d) // compile error: cannot compare [2]int == [3]int  切片\n 切片之间不能比较，因此我们不能使用==操作符来判断两个slice是否含有全部相等元素。一般来说，要想判断两个slice是否相等，我们必须自己展开每个元素进行比较。\n为什么slice不直接支持比较运算符呢？1. 一个slice的元素是间接引用的，一个slice甚至可以包含自身。虽然有很多办法可以处理这种情形，但没有一个是简单有效的。2. 因为slice是间接引用的，一个固定值的slice在不同的时间可能包含不同的元素，因为底层数组的元素可能会被修改.\nslice唯一合法的比较操作是和nil进行比较，例如：\nif summer == nil { /* ... */ } 3. 作为函数参数  数组\n 当数组作为函数的参数传递时，实际上传递的是一个数组的复制。因此，任何在函数内部对于数组的修改都是在数组的复制上修改的，并不能直接修改调用时原始的数组变量。\n//先定义一个数组 var a = [5]int{1, 2, 3, 4, 5} //定义一个函数，将数组中的第一个值设为0 func change(a [5]int){ a[0] = 0 fmt.Println(a) } change(a) fmt.Println(a) /* 输出： [0 2 3 4 5] [1 2 3 4 5] */ // 只修改了复制的数组，原始数组没有得到修改。 可以显式的传入一个数组指针，这样的话函数通过指针对数组的任何修改都可以直接反馈到调用者。\nfunc main() { var a = [5]int{1, 2, 3, 4, 5} fmt.Println(a) change(\u0026amp;a) fmt.Println(a) } func change(ptr *[5]int) { ptr[0] = 0 fmt.Println(*ptr) } /* 输出: [1 2 3 4 5] [0 2 3 4 5] [0 2 3 4 5] */  slice\n slice是一个引用类型，slice值包含指向第一个slice元素的指针，因此向函数传递slice将允许在函数内部修改底 层数组的元素。换句话说，复制一个slice只是对底层的数组创建了一个新的slice别名。\nfunc reverse(s []int) { for i, j := 0, len(s)-1; i \u0026lt; j; i, j = i+1, j-1 { s[i], s[j] = s[j], s[i] } } a := [...]int{0, 1, 2, 3, 4, 5} reverse(a[:]) fmt.Println(a) // \u0026#34;[5 4 3 2 1 0]\u0026#34; ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/slice%E5%92%8C%E6%95%B0%E7%BB%84%E7%9A%84%E5%8C%BA%E5%88%AB/","summary":"1. 长度  数组\n 对于数组来说，它的长度是固定的，并且数组的长度是其类型的一部分，即对于以下两个数组来说，他们是不同的类型。\nvar a [5]int var b [6]int fmt.Printf(\u0026#34;%v\u0026#34;, reflect.TypeOf(a) == reflect.TypeOf(b)) // 输出： false 数组的长度必须是常量表达式，因为数组的长度需要在编译阶段确定。\n对于数组来说，由于其长度是固定的，因此不能添加或删除元素。\n 切片\n 而对于切片，其长度是不固定的，不同长度的切片，只要其元素类型相同，则它们就是相同的切片类型。\na := make([]int, 5) b := make([]int, 6) fmt.Printf(\u0026#34;%v\\n\u0026#34;, reflect.TypeOf(a) == reflect.TypeOf(b)) // 输出： true 如果切片操作超出cap(s)的上限将导致一个panic异常，但是超出len(s)则是意味着扩展了 slice，因为新slice的长度会变大：\nmonths := [...]string{1: \u0026#34;January\u0026#34;, /* ... */, 12: \u0026#34;December\u0026#34;} summer := months[6:9] fmt.Println(summer[:20]) // panic: out of range endlessSummer := summer[:5] // extend a slice (within capacity) fmt.Println(endlessSummer) // \u0026#34;[June July August September October]\u0026#34; 2.","title":"slice和数组的区别"},{"content":"1. Reader接口 type Reader interface { Read(p []byte) (n int, err error) }  接口说明\n Read 将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 \u0026lt;= n \u0026lt;= len(p)） 以及任何遇到的错误。即使 Read 返回的 n \u0026lt; len(p)，它也会在调用过程中占用 len(p) 个字节作为暂存空间。若可读取的数据不到 len(p) 个字节，Read 会返回可用数据，而不是等待更多数据。\n当 Read 在成功读取 n \u0026gt; 0 个字节后遇到一个错误或 EOF (end-of-file)，它会返回读取的字节数。它可能会同时在本次的调用中返回一个non-nil错误,或在下一次的调用中返回这个错误（且 n 为 0）。 一般情况下, Reader会返回一个非0字节数n, 若 n = len(p) 个字节从输入源的结尾处由 Read 返回，Read可能返回 err == EOF 或者 err == nil。并且之后的 Read() 都应该返回 (n:0, err:EOF)。\n调用者在考虑错误之前应当首先处理返回的数据。这样做可以正确地处理在读取一些字节后产生的 I/O 错误，同时允许EOF的出现\n 例子\n func ReadFrom(reader io.Reader, num int) ([]byte, error) { p := make([]byte, num) n, err := reader.Read(p) if n \u0026gt; 0 { return p[:n], nil } return p, err } ReadFrom函数将io.Reader作为参数，也就是说，ReadFrom可以从任何实现了io.Reader接口的地方读取数据。\n// 从标准输入读取数据 data, err := ReadFrom(os.Stdin, 11) // 从普通文件中读取， file = new(os.File) data, err := Read From(file, 9) // 从字符串读取 data, err := ReadFrom(strings.NewReader(\u0026#34;from string\u0026#34;), 12) io.Reader将当前io.Reader实例中的值读取到参数p中 $$io.Reader \\stackrel{data}{\\rightarrow} [\\ ]byte$$\n2. Writer接口 type Writer interface { Write(p []byte) (n int, err error) }  功能说明\n Write 将 len(p) 个字节从 p 中写入到基本数据流中。它返回从 p 中被写入的字节数 n（0 \u0026lt;= n \u0026lt;= len(p)）以及任何遇到的引起写入提前停止的错误。若 Write 返回的 n \u0026lt; len(p)，它就必须返回一个 非nil 的错误。\n 例子\n 在fmt标准库中，有一组函数:Fprint/Fprintf/Fprintln,它们接收一个io.Wirter类型参数，也就是说它们将数据格式化输出到io.Writer中。那么，调用这组函数时，该如何实现这个参数呢？\n以fmt.Fprintln()为例：\nfunc Println(a ...interface{}) (n int, err error) { return Fprintln(os.Stdout, a...) } io.Writer将p中的数据写入到io.Wirter实例中 $$[\\ ]byte \\stackrel{data}{\\rightarrow} io.Writer$$\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/reader%E5%92%8Cwriter%E6%8E%A5%E5%8F%A3/","summary":"1. Reader接口 type Reader interface { Read(p []byte) (n int, err error) }  接口说明\n Read 将 len(p) 个字节读取到 p 中。它返回读取的字节数 n（0 \u0026lt;= n \u0026lt;= len(p)） 以及任何遇到的错误。即使 Read 返回的 n \u0026lt; len(p)，它也会在调用过程中占用 len(p) 个字节作为暂存空间。若可读取的数据不到 len(p) 个字节，Read 会返回可用数据，而不是等待更多数据。\n当 Read 在成功读取 n \u0026gt; 0 个字节后遇到一个错误或 EOF (end-of-file)，它会返回读取的字节数。它可能会同时在本次的调用中返回一个non-nil错误,或在下一次的调用中返回这个错误（且 n 为 0）。 一般情况下, Reader会返回一个非0字节数n, 若 n = len(p) 个字节从输入源的结尾处由 Read 返回，Read可能返回 err == EOF 或者 err == nil。并且之后的 Read() 都应该返回 (n:0, err:EOF)。","title":"Reader和Writer接口"},{"content":"1. 线程 在操作系统中，进程是分配资源的基本单位，但当进程作为调度的基本单位时，会造成较大的开销，频繁的进程调度将消耗大量时间。因此引出了线程：线程是处理器调度的基本单位，线程只拥有很小的运行时必要的资源。一个进程可拥有多个线程，同一个进程中的所有线程共享进程获得的主存空间和资源。 线程的实现\n有些系统同时支持用户线程和内核线程，由此产生了不同的多线程模型，即实现用户级线程 和内核级线程的连接方式：多对一模型、一对一模型、多对多模型。\n2. goroutine 在Go语言中，每一个并发的执行单元叫作一个goroutine，是一种轻量级的线程。\n3. 线程与goroutine的区别   运行时栈的大小\n 每个系统级线程都会有一个固定大小的栈（一般为2MB），主要用于保存函数递归调用时参数和局部变量。这造成了两个问题：  对于某些需要很小的栈空间的线程来说是一个巨大的浪费 对于少数需要巨大栈空间的线程来说又面临栈溢出的风险   goroutine会以一个很小的栈启动（2KB或4KB），当遇到深度递归时导致当前栈空间不足，会根据需要动态的伸缩栈的大小。    调度\n go的运行时还包括了其自己的调度器，可以在n个操作系统线程上多工调度m个goroutine（类似于多线程模型中的多对多模型）。 go调度器的工作和内核的调度时相似的，但是这个调度器只关注单独的go程序中的goroutine。 goroutinie采用的是半抢占式的协作调度，只有当当前goroutine发生阻塞时才会导致调度。 这种调度发生在用户态，调度器会根据具体函数只保存必要的寄存器，切换的代价比系统线程要低得多。    ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/goroutine%E5%92%8C%E7%BA%BF%E7%A8%8B/","summary":"1. 线程 在操作系统中，进程是分配资源的基本单位，但当进程作为调度的基本单位时，会造成较大的开销，频繁的进程调度将消耗大量时间。因此引出了线程：线程是处理器调度的基本单位，线程只拥有很小的运行时必要的资源。一个进程可拥有多个线程，同一个进程中的所有线程共享进程获得的主存空间和资源。 线程的实现\n有些系统同时支持用户线程和内核线程，由此产生了不同的多线程模型，即实现用户级线程 和内核级线程的连接方式：多对一模型、一对一模型、多对多模型。\n2. goroutine 在Go语言中，每一个并发的执行单元叫作一个goroutine，是一种轻量级的线程。\n3. 线程与goroutine的区别   运行时栈的大小\n 每个系统级线程都会有一个固定大小的栈（一般为2MB），主要用于保存函数递归调用时参数和局部变量。这造成了两个问题：  对于某些需要很小的栈空间的线程来说是一个巨大的浪费 对于少数需要巨大栈空间的线程来说又面临栈溢出的风险   goroutine会以一个很小的栈启动（2KB或4KB），当遇到深度递归时导致当前栈空间不足，会根据需要动态的伸缩栈的大小。    调度\n go的运行时还包括了其自己的调度器，可以在n个操作系统线程上多工调度m个goroutine（类似于多线程模型中的多对多模型）。 go调度器的工作和内核的调度时相似的，但是这个调度器只关注单独的go程序中的goroutine。 goroutinie采用的是半抢占式的协作调度，只有当当前goroutine发生阻塞时才会导致调度。 这种调度发生在用户态，调度器会根据具体函数只保存必要的寄存器，切换的代价比系统线程要低得多。    ","title":"goroutine和线程"},{"content":"1. Panic异常 func panic(v interface{}) 在通常情况下，函数向其调用方报告错误都是返回一个error类型，但有时会遇到致命（即会让程序崩溃）的错误时，显然无法通过返回error进行处理。这时我们使用panic函数来报告致命错误。\n当panic异常发生时，程序会中断运行，并立即执行在该goroutine中被defer的函数。随后，程序崩溃并输出日志信息（panic value和函数调用的堆栈信息）。在Go的panic机制中，延迟函数的调用在释放堆栈信息之前.\npanic的来源： 1. 运行时panic异常 2. 直接调用内置的panic函数\n例子：\nfunc main(){ fmt.Println(\u0026#34;main start\u0026#34;) outerFunc() fmt.Println(\u0026#34;main end\u0026#34;) } func outerFunc(){ fmt.Println(\u0026#34;out start\u0026#34;) innerFunc() fmt.Println(\u0026#34;out end\u0026#34;) } func innerFunc(){ panic(errors.New(\u0026#34;an intended fatal error\u0026#34;)) }  输出\n // 只有start，而没有end，因为程序崩溃了 main start out start panic: an intended fatal error 在这个程序中，当调用innerFunc中的panic时，innerFunc会立即停止执行，紧接着，outerFunc也会被停止，运行时panic沿着调用栈一直反方向进行传播，直至到达当前goroutine的调用栈最顶层。\n2. recover func recover() interface{} 通常来说，不应该对panic异常做任何处理，但有时我们可能需要在程序崩溃前做一些操作。这时，我们可以“从异常中恢复”。\n如果在defer函数中调用了内置函数recover，并且定义该defer语句的函数发生了panic异常，recover会使程序从panic中恢复，并返回panic value。导致panic异常的函数不会继续运行，但能正常返回。在未发生panic时调用recover，recover会返回nil。\n// ...  // 将innerFunc修改为如下 func innerFunc(){ defer func(){ if p := recover(); p != nil { fmt.Printf(\u0026#34;internal error:%v \\n\u0026#34;,p) } }() panic(errors.New(\u0026#34;an intended fatal error\u0026#34;)) }  输出\n // 程序正常结束 main start out start internal error:an intended fatal error out end main end ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/panic%E5%92%8Crecover/","summary":"1. Panic异常 func panic(v interface{}) 在通常情况下，函数向其调用方报告错误都是返回一个error类型，但有时会遇到致命（即会让程序崩溃）的错误时，显然无法通过返回error进行处理。这时我们使用panic函数来报告致命错误。\n当panic异常发生时，程序会中断运行，并立即执行在该goroutine中被defer的函数。随后，程序崩溃并输出日志信息（panic value和函数调用的堆栈信息）。在Go的panic机制中，延迟函数的调用在释放堆栈信息之前.\npanic的来源： 1. 运行时panic异常 2. 直接调用内置的panic函数\n例子：\nfunc main(){ fmt.Println(\u0026#34;main start\u0026#34;) outerFunc() fmt.Println(\u0026#34;main end\u0026#34;) } func outerFunc(){ fmt.Println(\u0026#34;out start\u0026#34;) innerFunc() fmt.Println(\u0026#34;out end\u0026#34;) } func innerFunc(){ panic(errors.New(\u0026#34;an intended fatal error\u0026#34;)) }  输出\n // 只有start，而没有end，因为程序崩溃了 main start out start panic: an intended fatal error 在这个程序中，当调用innerFunc中的panic时，innerFunc会立即停止执行，紧接着，outerFunc也会被停止，运行时panic沿着调用栈一直反方向进行传播，直至到达当前goroutine的调用栈最顶层。\n2. recover func recover() interface{} 通常来说，不应该对panic异常做任何处理，但有时我们可能需要在程序崩溃前做一些操作。这时，我们可以“从异常中恢复”。\n如果在defer函数中调用了内置函数recover，并且定义该defer语句的函数发生了panic异常，recover会使程序从panic中恢复，并返回panic value。导致panic异常的函数不会继续运行，但能正常返回。在未发生panic时调用recover，recover会返回nil。\n// ...  // 将innerFunc修改为如下 func innerFunc(){ defer func(){ if p := recover(); p !","title":"panic和recover"},{"content":"hugo默认不支持latex公式，为了在我们的博客上显示数学公式，我们需要使用katex.\n使用方法 对于hugo来说，我们只需要为每个页面加上\n\u0026lt;!-- KaTeX --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/contrib/auto-render.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.addEventListener(\u0026#34;DOMContentLoaded\u0026#34;, function() { renderMathInElement(document.body, { delimiters: [ {left: \u0026#34;$$\u0026#34;, right: \u0026#34;$$\u0026#34;, display: true}, {left: \u0026#34;$\u0026#34;, right: \u0026#34;$\u0026#34;, display: false} ] }); }); \u0026lt;/script\u0026gt; 就行了。\n可以通过在themes/{themeName}/layouts/partials/footer.html中添加来使katex包含到每个页面中。\n书写公式 行内公式可以使用$f(x)= \\cos x$来编辑,效果为$f(x)= \\cos x$ 行间公式可使用如下格式：\n$$\\frac{ x^{2} }{ k+1 }\\qquad$$ 效果为： $$\\frac{ x^{2} }{ k+1 }\\qquad$$\n","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%9D%82%E8%AE%B0/hugo%E4%B8%AD%E7%9A%84%E5%85%AC%E5%BC%8F%E9%97%AE%E9%A2%98/","summary":"hugo默认不支持latex公式，为了在我们的博客上显示数学公式，我们需要使用katex.\n使用方法 对于hugo来说，我们只需要为每个页面加上\n\u0026lt;!-- KaTeX --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.css\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/katex.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.10.0-rc.1/contrib/auto-render.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; document.addEventListener(\u0026#34;DOMContentLoaded\u0026#34;, function() { renderMathInElement(document.body, { delimiters: [ {left: \u0026#34;$$\u0026#34;, right: \u0026#34;$$\u0026#34;, display: true}, {left: \u0026#34;$\u0026#34;, right: \u0026#34;$\u0026#34;, display: false} ] }); }); \u0026lt;/script\u0026gt; 就行了。\n可以通过在themes/{themeName}/layouts/partials/footer.html中添加来使katex包含到每个页面中。\n书写公式 行内公式可以使用$f(x)= \\cos x$来编辑,效果为$f(x)= \\cos x$ 行间公式可使用如下格式：\n$$\\frac{ x^{2} }{ k+1 }\\qquad$$ 效果为： $$\\frac{ x^{2} }{ k+1 }\\qquad$$","title":"hugo中的公式问题"},{"content":"1. 数据库系统的结构抽象 1.1 三级模式(三级视图)  External Schema \u0026mdash;-（External）View 某一用户能看到与处理的数据的结构描述 (Conceptual) Schema \u0026mdash;- Conceptual View 从全局角度理解/管理的数据的结构描述, 含相应的关联约束。体现在数据之间的内在本质联系 Internal Schema \u0026mdash;- Internal View 存储在介质上的数据的结构描述，含存储路径、存储方式 、索引方式等  1.2 两层映像  E-C Mapping：External Schema-Conceptual Schema Mapping 将外模式映射为概念模式，从而支持实现数据概念视图向外部视图的转换，便于用户观察和使用 C-I Mapping：Conceptual Schema-Internal Schema Mapping 将概念模式映射为内模式，从而支持实现数据概念视图向内部视图的转换，便于计算机进行存储和处理  1.3 两个独立性  逻辑数据独立性 当概念模式变化时，可以不改变外部模式(只需改变E-C Mapping)，从而无需 改变应用程序 物理数据独立性 当内部模式变化时，可以不改变概念模式(只需改变C-I Mapping) ，从而不改 变外部模式  1.4 数据模型  数据模型  规定模式统一描述方式的模型，包括：数据结构、操作和约束 数据模型是对模式本身结构的抽象，模式是对数据本身结构形式的抽象   三大经典数据模型  关系模型：表的形式组织数据 层次模型：树的形式组织数据 网状模型：图的形式组织数据    2. 关系模型的基本概念 2.1 关系模型的三个要素  基本结构  形象地说，一个关系(relation)就是一个Table Relation/Table\n  基本操作  基本的\n  并$\\cup$ 差：$-$ 广义积：$\\times$ 选择: $\\delta$ 投影：$\\pi$   扩展的\n  交: $\\cap$ 连接: $\\Join$ 除：$\\div$   完整性约束 实体完整性、参照完整性和用户自定义的完整性  2.2 什么是关系 关系 笛卡尔积中具有某一方面意义的那些元组被称作一个关系\n 笛卡尔积的数学描述： $$一组域D_1, D_2, \u0026hellip; , D_n的笛卡尔积为： D_1 \\times D_2 \\times \\cdots \\times D_n = \\lbrace (d_1, d_2, \\cdots, d_n)| d_i\\in D_i,\\ i=1, \\cdots , n \\rbrace$$\n 2.3 关系模式与关系  同一关系模式下，可有很多的关系 关系模式是关系的结构, 关系是关系模式在某一时刻的数据 关系模式是稳定的；而关系是某一时刻的值，是随时间可能变化的  2.4 关系与表的异同 大部分方面都是相同的，但关系中任意两个元组不能完全相同，而表可能并不完全遵守此特性\n2.5 关系的特性  关系的任意两个元组不能完全相同 属性不可再分特性:又被称为关系第一范式  2.6 关系上的一些重要概念 候选码/候选键 关系中的一个属性组，其值能唯一标识一个元组，若从该属性组中去掉任何一个属性，它就不具有这一性质了，这样的属性组称作候选码。\n主码/主键 当有多个候选码时，可以选定一个作为主码。\n主属性和非主属性 包含在任何一个候选码中的属性被称作主属性，而其他属性被称作非主属性\n 最简单的，候选码只包含一个属性 最极端的，所有属性构成这个关系的候选码，称为全码(All-Key)\n 外码/外键 关系R中的一个属性组，它不是R的候选码，但它与另一个关系S的候选 码相对应，则称这个属性组为R的外码或外键。\n 两个关系通常是靠外码连接起来的。\n 2.3 关系模型的完整性   实体完整性\n关系的主码中的属性值不能为空值； 空值：不知道或无意义的值\n意义：关系中的元组对应到现实世界相互之间可区分的一个个个 体，这些个体是通过主码来唯一标识的；若主码为空，则出现不可标识 的个体，这是不容许的\n  参照完整性（对外码而言） 如果关系R1的外码Fk与关系R2的主 码Pk相对应，则R1中的每一个元组的 Fk值或者等于R2 中某个元组的Pk 值， 或者为空值\n  用户自定义完整性\n用户针对具体的应用环境定义的完整性约束条件\n   实体完整性和参照完整性由DBMS系统自动支持 DBMS系统通常提供了如下机制：  (1)它使用户可以自行定义有关的完整性约束条件 (2)当有更新操作发生时，DBMS将自动按照完整性约束条件检验更新操作的正确性，即是否符合用户自定义的完整性    3. 关系代数 3.1 关系代数操作 集合操作和纯关系操作\n3.2 关系代数基本操作 3.2.1 关系代数运算的约束  并相容性\n关系R与关系S存在相容性，当且仅当：\n(1) 关系R和关系S的属性数目必须相同；\n(2) 对于任意i，关系R的第i个属性的域必须和关系S的第i个属性的域相同  3.2.2 关系代数的操作  并$\\vee$(要满足并相容性)\n数学描述： $$R\\vee S= \\lbrace t|t\\in R \\vee t \\in S \\rbrace$$ 差$-$(要满足并相容性)\n数学描述： $$R-S=\\lbrace t| t \\in R \\land t \\notin S \\rbrace$$ 广义笛卡尔积操作\n数学描述： $$关系R\u0026lt; a_1, a_2, \\cdots , a_n\u0026gt;, 关系S\u0026lt;b_1, b_2, \\cdots , b_n\u0026gt;, 则 \\ R \\times S = \\lbrace \u0026lt;a_1, a_2, \\cdots , a_n, b_1, b_2, \\cdots , b_n\u0026gt; | \u0026lt;a_1, a_2, \\cdots , a_n\u0026gt; \\in R \\land \u0026lt;b_1, b_2, \\cdots , b_n\u0026gt; \\in S \\rbrace$$ 选择操作\n数学描述： $$\\delta _{con}(R)=\\lbrace t | t \\in R \\land con(t) = true \\rbrace$$ 投影\n数学描述： $$\\Pi_{a_{i1}, a_{i2}, \\cdots, a_{ik}}(R) = \\lbrace \u0026lt;t[A_{i1}],t[A_{i2}], \\cdots , t[A_{ik}]\u0026gt; | t \\in R \\rbrace$$ **示例**\n  3.3 关系代数扩展操作   交\n数学描述：\n$$R \\cap S= \\lbrace t|t\\in R \\land t \\in S \\rbrace$$\n  $\\theta$-连接\n第一步：对两个表进行广义笛卡尔积\n第二步：从广义笛卡尔积中选取出符合条件的元组\n数学描述： $$R \\underset{A \\theta B} \\Join S = \\delta_{t[A] \\theta s[B]}(R\\times B)$$\n其中$\\theta$是比较运算符\n 例子\n 查询至少98030101号同学和98040202号同学学过的所有课程号\n数学描述： $$\\pi_{SC.C}(\\delta_{SC.S=\u0026ldquo;98030101\u0026rdquo;\\land SC1.S=\u0026ldquo;98040202\u0026rdquo;}(SC \\underset{SC.C=SC1.C} \\Join \\rho_{SC1} (SC)) $$\n其中$\\rho$代表更名操作\n  等值连接\n给定关系R和关系S, R与S的等值连接运算结果也是一个关系， 记作$R \\underset{A=B} \\Join S$，它由关系R和关系S的笛卡尔积中选取R中属性A与S中属性 B上值相等的元组所构成。 数学描述：\n$$R \\underset{A=B}\\Join S = \\delta_{t[A]=s[B]}(R\\times S)$$ 当$\\theta$-连接中运算符为“＝”时，就是等值连接，等值连接是$\\theta$-连接的一个特例；   自然连接\n给定关系R和关系S, R与S的自然连接运算结果也是一个关系，记作$R \\Join S$ ，它由关系R和关系S的笛卡尔积中选取相同属性组B上值相等的元 组所构成。\n数学描述： $$R \\Join S = \\delta_{t[B]=s[B]}(R\\times S)$$\n是一种特殊的等值连接\n要求关系R和S必须有相同的属性组B\n  3.4 关系代数的复杂操作   除操作$\\div$\n前提条件\n若$R(A_1, A_2, \\cdots,A_n)$为n度关系，关系$S(B_1, B_2, \\cdots, B_n)$为m度关系，只有当$\\lbrace B_1, B_2, \\cdots, B_n\\rbrace \\subseteq \\lbrace A_1, A_2, \\cdots,A_n \\rbrace $即B是A的真子集，$m\u0026lt;n$时才可进行$R\\div S$运算\n定义\n设关系$R\u0026lt;a_1, \\cdots, a_n\u0026gt;$和关系$S\u0026lt;b_1, \\cdots, b_m\u0026gt;$,那么$R\\div S$结果为关系为元组$\u0026lt;c_1, \\cdots, c_k\u0026gt;$的集合，元组$\u0026lt;c_1, \\cdots, c_k\u0026gt;$满足下述条件:它与S中每一个元组$\u0026lt;b_1, \\cdots, b_m\u0026gt;$组合形成的一个新元组都是R中的某一个元组$\u0026lt;a_1, \\cdots, a_n\u0026gt;$\n示例 外连接（Outer-Join） 定义\n两个关系R与S进行连接时，如果关系R(或S)中的元组在S(或R)中找不到相匹配的元组，则为了避免该元组信息丢失，从而将该元组与S(或R)中 假定存在的全为空值的元组形成连接，放置在结果关系中，这种连接称之为外连接(Outer Join)。\n外连接 = 自然连接 (或$\\theta$连接) + 失配的元组(与全空元组形成的连接)\n外连接的形式   左外连接 = 自然连接(或$\\theta$连接) + 左侧表中失配的元组。 记作$⟕$  右外连接 = 自然连接(或$\\theta$连接) + 右侧表中失配的元组。 记作 $⟖$\n 全外连接 = 自然连接(或$\\theta$连接) + 两侧表中失配的元组。 记作$⟗$\n    4. 关系演算  关系元组演算  以元组变量作为谓词变量的基本对象\n  关系域演算  以域变量作为谓词变量的基本对象\n   4.1 关系元组演算 基本形式\n$$\\lbrace t | P(t)\\rbrace$$\n其中，$P(t)$可以是如下三种形式之一的原子公式：\n $t\\in R$ $s[A] \\theta c$\n其中$\\theta$为比较运算符$\u0026lt;, \\le, \\ge, \u0026gt;, \\ne$\n例如$\\lbrace t| t\\in R \\land t[Sage]\\le 19 \\land t[Sname] = \u0026lsquo;Bob\u0026rsquo;\\rbrace$ $s[A] \\theta u[B]$\ns[A]与u[B]为元组分量，A和B分别是某些关系的属性，他们之间满足比较关系$\\theta$\n例如：检索除年龄不是最小的所有同学\n$\\lbrace t|t\\in Student \\land \\exist (u \\in Student)(t[Sage]\u0026gt;u[Sage])\\rbrace$\n  4.2 关系域演算 \u0026hellip;\n关系数据库中的范式  第一范式（1NF）\n关系的每一个分量都是不可分的数据项 第二范式（2NF）\n若$R\\in 1NF$,且每一个非主属性完全函数依赖于任何一个候选码，则$R\\in 2NF$ 第三范式（3NF）\n设关系模式$R\u0026lt;U,F\u0026gt;\\in 1NF$, 若R中不存在这样的码X，属性组Y及非主属性$Z(Z\\nsubseteq Y)$，使得$X\\rightarrow Y, Y \\rightarrow Z$成立，$Y\\nrightarrow X$, 则称$R\u0026lt;U,F\u0026gt;\\in 3NF$。用人话说就是，若$R\\in 3NF$,则每一个非主属性既不传递依赖于码，也不部分依赖于码。 BC范式 关系模式$R\u0026lt;U,F\u0026gt;\\in1NF$,若$X\\rightarrow Y$且$Y\\nsubseteq X$时必含有码，则$R\u0026lt;U,F\u0026gt;\\in BCNF$。也就是说，关系模式$R\u0026lt;U,F\u0026gt;$中，若每一个决定因素都包含码，则$R\u0026lt;U,F\u0026gt;\\in BCNF$\n一个满足BCNF的关系模式有：  所有非主属性对每一个码都是完全函数依赖 所有主属性对每一个不包含它的码也是完全函数依赖 没有任何属性完全函数依赖于非码的任何一组属性    ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%9D%82%E8%AE%B0/%E6%95%B0%E6%8D%AE%E5%BA%93%E5%8E%9F%E7%90%86/","summary":"1. 数据库系统的结构抽象 1.1 三级模式(三级视图)  External Schema \u0026mdash;-（External）View 某一用户能看到与处理的数据的结构描述 (Conceptual) Schema \u0026mdash;- Conceptual View 从全局角度理解/管理的数据的结构描述, 含相应的关联约束。体现在数据之间的内在本质联系 Internal Schema \u0026mdash;- Internal View 存储在介质上的数据的结构描述，含存储路径、存储方式 、索引方式等  1.2 两层映像  E-C Mapping：External Schema-Conceptual Schema Mapping 将外模式映射为概念模式，从而支持实现数据概念视图向外部视图的转换，便于用户观察和使用 C-I Mapping：Conceptual Schema-Internal Schema Mapping 将概念模式映射为内模式，从而支持实现数据概念视图向内部视图的转换，便于计算机进行存储和处理  1.3 两个独立性  逻辑数据独立性 当概念模式变化时，可以不改变外部模式(只需改变E-C Mapping)，从而无需 改变应用程序 物理数据独立性 当内部模式变化时，可以不改变概念模式(只需改变C-I Mapping) ，从而不改 变外部模式  1.4 数据模型  数据模型  规定模式统一描述方式的模型，包括：数据结构、操作和约束 数据模型是对模式本身结构的抽象，模式是对数据本身结构形式的抽象   三大经典数据模型  关系模型：表的形式组织数据 层次模型：树的形式组织数据 网状模型：图的形式组织数据    2.","title":"数据库原理"},{"content":"0. 复试英语考试形式  自我介绍+老师提问（popular） 听一段文章内容，听完后回答（少） 小组讨论（少）  1. 自我介绍 一定不要说：我的英语很糟糕, My English is very poor!\n 目的是： 表达我配上研究生\n  先说姓名（微笑脸），年龄，学校 大学取得的成绩（没有成绩可以编\u0026hellip; 编点无从考证的，比如家教啥的） 再说性格爱好(稍微两句话提提)，尽量和专业联系到一起。 That\u0026rsquo;s all, thanks you very much. If I were admitted, I will go all out to learn my professional knowledge.除了学习①专业知识，我一定会加强我的②实践能力，我还要学会③更好的和导师和同学之间进行合作。Please trusted me.(不要超过三分钟)  2. 老师常问的9个问题  你为什么考研，为什么选择这个专业？  一定不要说本科学校坏话， 不要说我要挣钱.. 也不要说为了中华之崛起.. 我真心喜欢我的专业😊(举个例子怎么感兴趣的) 我遗憾自己以前没有好好学习，在别人选择工作的时候我决定考研提升自己 终极答案是喜欢   你对未来有什么规划？  3年研究生的规划和研究生刚毕业的规划，太远不要说 研究生入校后，一定跟老师好好学习专业知识，协助导师，争取自己早日发表论文，有机会考博，培养自己的实践能力，合作能力，与人相处能力。毕业后找一份自己喜欢的工作，在自己的岗位上做出贡献。（一定要配合导师）   介绍你的家乡  首先要说我爱的家乡（怀有一颗感恩的心） 说点名人和特产（有很多可以such as，然后重点说一个） 最后再说，欢迎老师到我的家乡去旅游   介绍你的家庭  先说几口人 对我的人生产生最大的影响是谁（举个栗子(〃￣︶￣)人）   介绍你的本科学校  一个字，好 学校有历史、就业率好、有名气（老师你可能从来没听过这个名字，但是我非常热爱它） 虽然我的学校不是那么有名气，但是我依然结到了很多朋友，给我了很多温暖   对英语的态度，关于英语你怎么看  喜欢，感兴趣 以前对英语没那么感兴趣，只是一门课 后来发现英语真他娘重要，意识到学英语的重要性 在研究生期间更加专注对英语的学习 我的口语没有那么好，但是我希望在研究生期间可以有长足的进步   你对我们学校和专业了解多少  首先，学校名气大（毋庸置疑） 其次，对我们学院相当有了解，对教授了解（提一下教授的名字） 师资力量，著作   你的优点和缺点  优点可以和专业相关，但是缺点不行 我喜欢交朋友\u0026hellip; 编\u0026hellip;（给爷爬）≡(▔﹏▔)≡   为什么换专业（给跨考）  \u0026hellip;    3. 注意事项  听不懂怎么办  提前准备可以听懂 pardon一下。。   提前找师兄师姐  贫僧自东土大唐而来，往西天取经而去。。 带点特产，送送礼   穿什么  不用穿西装打领带 牛仔裤，T恤衫就行，里面的衣服不要大于外面的衣服 女生不要染头发、涂太艳的指甲油、不要用香水 不能穿太休闲 走路不要发出声音，不要驼背   微笑，不要怕眼神接触 专业问题回答不上来怎么办  非常遗憾我还回答不上来，但是如果我读研究生，我会好好学习的，请给我这个机会   不要打断老师说话 不要用一句话来回答老师的问题 不要晃腿  ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%9D%82%E8%AE%B0/%E5%A4%8D%E8%AF%95%E8%8B%B1%E8%AF%AD/","summary":"0. 复试英语考试形式  自我介绍+老师提问（popular） 听一段文章内容，听完后回答（少） 小组讨论（少）  1. 自我介绍 一定不要说：我的英语很糟糕, My English is very poor!\n 目的是： 表达我配上研究生\n  先说姓名（微笑脸），年龄，学校 大学取得的成绩（没有成绩可以编\u0026hellip; 编点无从考证的，比如家教啥的） 再说性格爱好(稍微两句话提提)，尽量和专业联系到一起。 That\u0026rsquo;s all, thanks you very much. If I were admitted, I will go all out to learn my professional knowledge.除了学习①专业知识，我一定会加强我的②实践能力，我还要学会③更好的和导师和同学之间进行合作。Please trusted me.(不要超过三分钟)  2. 老师常问的9个问题  你为什么考研，为什么选择这个专业？  一定不要说本科学校坏话， 不要说我要挣钱.. 也不要说为了中华之崛起.. 我真心喜欢我的专业😊(举个例子怎么感兴趣的) 我遗憾自己以前没有好好学习，在别人选择工作的时候我决定考研提升自己 终极答案是喜欢   你对未来有什么规划？  3年研究生的规划和研究生刚毕业的规划，太远不要说 研究生入校后，一定跟老师好好学习专业知识，协助导师，争取自己早日发表论文，有机会考博，培养自己的实践能力，合作能力，与人相处能力。毕业后找一份自己喜欢的工作，在自己的岗位上做出贡献。（一定要配合导师）   介绍你的家乡  首先要说我爱的家乡（怀有一颗感恩的心） 说点名人和特产（有很多可以such as，然后重点说一个） 最后再说，欢迎老师到我的家乡去旅游   介绍你的家庭  先说几口人 对我的人生产生最大的影响是谁（举个栗子(〃￣︶￣)人）   介绍你的本科学校  一个字，好 学校有历史、就业率好、有名气（老师你可能从来没听过这个名字，但是我非常热爱它） 虽然我的学校不是那么有名气，但是我依然结到了很多朋友，给我了很多温暖   对英语的态度，关于英语你怎么看  喜欢，感兴趣 以前对英语没那么感兴趣，只是一门课 后来发现英语真他娘重要，意识到学英语的重要性 在研究生期间更加专注对英语的学习 我的口语没有那么好，但是我希望在研究生期间可以有长足的进步   你对我们学校和专业了解多少  首先，学校名气大（毋庸置疑） 其次，对我们学院相当有了解，对教授了解（提一下教授的名字） 师资力量，著作   你的优点和缺点  优点可以和专业相关，但是缺点不行 我喜欢交朋友\u0026hellip; 编\u0026hellip;（给爷爬）≡(▔﹏▔)≡   为什么换专业（给跨考）  \u0026hellip;    3.","title":"复试英语"},{"content":"Github 出现 Failed to connect to github.com port 443: Timed out 1. 问题来由 可能是由于使用了全局代理的原因\n2. 解决 取消全局代理： git config --global --unset http.proxy git config --global --unset https.proxy  设置全局代理\n git config --global http.proxy http://127.0.0.1:1080 git config --global https.proxy http://127.0.0.1:1080 ","permalink":"http://yangchnet.github.io/Dessert/posts/git/failed-to-connect-to-github.com-port-443/","summary":"Github 出现 Failed to connect to github.com port 443: Timed out 1. 问题来由 可能是由于使用了全局代理的原因\n2. 解决 取消全局代理： git config --global --unset http.proxy git config --global --unset https.proxy  设置全局代理\n git config --global http.proxy http://127.0.0.1:1080 git config --global https.proxy http://127.0.0.1:1080 ","title":"Failed to connect to github.com port 443"},{"content":"VsCode Snippets的Snippets功能  snippets是代码片段, 在这里的意思是代码模板. 在使用vscode写代码时，有时需要使用代码模板，一个典型的例子是在写文件头注释时，需要一个固定格式的注释，来表明当前的时间、作者等。\n 1. 使用内置的snippets vscode中已经为我们内置了许多语言的代码模板，在安装了对应的语言插件后,可直接使用这些snippets. 2. 安装来自marketplace的snippets 按Ctrl+Shift+X打开marketplace, 输入@category:\u0026quot;snippets\u0026quot;,即可下载来自marketplace的snippets 3. 自定义snippets 如果你对内置的或来自marketplace的snippets均不满意,那么你可以自定义你的snippets.\n在File \u0026gt; Preferences \u0026gt; User Snippets选项下,选择你要定义snippets的文件类型\n在选择了文件类型之后,你就可以根据vscode提供的Example自定义snippets了.\nExample: \u0026quot;Print to console\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;log\u0026quot;, \u0026quot;body\u0026quot;: [ \u0026quot;console.log('$1');\u0026quot;, \u0026quot;$2\u0026quot; ], \u0026quot;description\u0026quot;: \u0026quot;Log output to console\u0026quot; \u0026quot;Print to console\u0026quot;是你自定义的snippets的名字,prefix为前缀,在输入了你定义的prefix后,body中的内容就会输出到当前光标的位置.\n在body中,你可以使用\u0026quot;variables\u0026ldquo;来描述你的snippets, 其格式为:\n  ${1:label}: 其中的1表示在body输出后光标会第一个停放在这个位置,而label是对当前variables的描述.\n  ${1|one, two, three|}: 这个语法格式将提醒你选择one, two, three中的一个值.\n  $name或${name:default}: 其中的name为预定义的变量名,可使用default指定其默认值.预定义的变量名有如下:\n 有关文件与目录的\n TM_SELECTED_TEXT当前选定的文本或空字符串 TM_CURRENT_LIN当前行的内容 TM_CURRENT_WORD光标下或空字符串下的单词内容 TM_LINE_INDEX基于零指数的行数 TM_LINE_NUMBER基于一个索引的行数 TM_FILENAME当前文档的文件名 TM_FILENAME_BASE没有扩展的当前文档的文件名 TM_DIRECTORY当前文档的目录 TM_FILEPATH当前文档的完整文件路径 CLIPBOARD剪贴板的内容 WORKSPACE_NAME打开的工作区或文件夹的名称 WORKSPACE_FOLDER打开的工作区或文件夹的路径    有关时间的\n CURRENT_YEAR本年度 CURRENT_YEAR_SHORT今年最后两位数 CURRENT_MONTH以两位数表示的月份（例如\u0026quot;02\u0026rdquo;） CURRENT_MONTH_NAME本月全名（例如\u0026quot;七月\u0026quot;） CURRENT_MONTH_NAME_SHORT本月的简称（例如\u0026quot;七月\u0026quot;） CURRENT_DATE每月的一天 CURRENT_DAY_NAME日名称（例如\u0026quot;星期一\u0026quot;） CURRENT_DAY_NAME_SHORT当天的简称（例如\u0026quot;星期一\u0026quot;） CURRENT_HOUR24 小时时钟格式的当前小时 CURRENT_MINUTE当前分钟 CURRENT_SECOND当前秒 CURRENT_SECONDS_UNIX自Unix epoch以来的秒数    有关注释的\n BLOCK_COMMENT_START Example output: in PHP or in HTML /*\u0026lt;!-- BLOCK_COMMENT_END Example output: in PHP or in HTML */--\u0026gt; LINE_COMMENT Example output: in PHP //     ","permalink":"http://yangchnet.github.io/Dessert/posts/tool/vscode-snippets%E5%8A%9F%E8%83%BD%E7%9A%84%E4%BD%BF%E7%94%A8/","summary":"VsCode Snippets的Snippets功能  snippets是代码片段, 在这里的意思是代码模板. 在使用vscode写代码时，有时需要使用代码模板，一个典型的例子是在写文件头注释时，需要一个固定格式的注释，来表明当前的时间、作者等。\n 1. 使用内置的snippets vscode中已经为我们内置了许多语言的代码模板，在安装了对应的语言插件后,可直接使用这些snippets. 2. 安装来自marketplace的snippets 按Ctrl+Shift+X打开marketplace, 输入@category:\u0026quot;snippets\u0026quot;,即可下载来自marketplace的snippets 3. 自定义snippets 如果你对内置的或来自marketplace的snippets均不满意,那么你可以自定义你的snippets.\n在File \u0026gt; Preferences \u0026gt; User Snippets选项下,选择你要定义snippets的文件类型\n在选择了文件类型之后,你就可以根据vscode提供的Example自定义snippets了.\nExample: \u0026quot;Print to console\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;log\u0026quot;, \u0026quot;body\u0026quot;: [ \u0026quot;console.log('$1');\u0026quot;, \u0026quot;$2\u0026quot; ], \u0026quot;description\u0026quot;: \u0026quot;Log output to console\u0026quot; \u0026quot;Print to console\u0026quot;是你自定义的snippets的名字,prefix为前缀,在输入了你定义的prefix后,body中的内容就会输出到当前光标的位置.\n在body中,你可以使用\u0026quot;variables\u0026ldquo;来描述你的snippets, 其格式为:\n  ${1:label}: 其中的1表示在body输出后光标会第一个停放在这个位置,而label是对当前variables的描述.\n  ${1|one, two, three|}: 这个语法格式将提醒你选择one, two, three中的一个值.\n  $name或${name:default}: 其中的name为预定义的变量名,可使用default指定其默认值.预定义的变量名有如下:\n 有关文件与目录的\n TM_SELECTED_TEXT当前选定的文本或空字符串 TM_CURRENT_LIN当前行的内容 TM_CURRENT_WORD光标下或空字符串下的单词内容 TM_LINE_INDEX基于零指数的行数 TM_LINE_NUMBER基于一个索引的行数 TM_FILENAME当前文档的文件名 TM_FILENAME_BASE没有扩展的当前文档的文件名 TM_DIRECTORY当前文档的目录 TM_FILEPATH当前文档的完整文件路径 CLIPBOARD剪贴板的内容 WORKSPACE_NAME打开的工作区或文件夹的名称 WORKSPACE_FOLDER打开的工作区或文件夹的路径    有关时间的","title":"VsCode Snippets功能的使用"},{"content":"VsCode Snippets的Snippets功能  snippets是代码片段, 在这里的意思是代码模板. 在使用vscode写代码时，有时需要使用代码模板，一个典型的例子是在写文件头注释时，需要一个固定格式的注释，来表明当前的时间、作者等。\n 1. 使用内置的snippets vscode中已经为我们内置了许多语言的代码模板，在安装了对应的语言插件后,可直接使用这些snippets. 2. 安装来自marketplace的snippets 按Ctrl+Shift+X打开marketplace, 输入@category:\u0026quot;snippets\u0026quot;,即可下载来自marketplace的snippets 3. 自定义snippets 如果你对内置的或来自marketplace的snippets均不满意,那么你可以自定义你的snippets.\n在File \u0026gt; Preferences \u0026gt; User Snippets选项下,选择你要定义snippets的文件类型\n在选择了文件类型之后,你就可以根据vscode提供的Example自定义snippets了.\nExample: \u0026quot;Print to console\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;log\u0026quot;, \u0026quot;body\u0026quot;: [ \u0026quot;console.log('$1');\u0026quot;, \u0026quot;$2\u0026quot; ], \u0026quot;description\u0026quot;: \u0026quot;Log output to console\u0026quot; \u0026quot;Print to console\u0026quot;是你自定义的snippets的名字,prefix为前缀,在输入了你定义的prefix后,body中的内容就会输出到当前光标的位置.\n在body中,你可以使用\u0026quot;variables\u0026ldquo;来描述你的snippets, 其格式为:\n  ${1:label}: 其中的1表示在body输出后光标会第一个停放在这个位置,而label是对当前variables的描述.\n  ${1|one, two, three|}: 这个语法格式将提醒你选择one, two, three中的一个值.\n  $name或${name:default}: 其中的name为预定义的变量名,可使用default指定其默认值.预定义的变量名有如下:\n 有关文件与目录的\n TM_SELECTED_TEXT当前选定的文本或空字符串 TM_CURRENT_LIN当前行的内容 TM_CURRENT_WORD光标下或空字符串下的单词内容 TM_LINE_INDEX基于零指数的行数 TM_LINE_NUMBER基于一个索引的行数 TM_FILENAME当前文档的文件名 TM_FILENAME_BASE没有扩展的当前文档的文件名 TM_DIRECTORY当前文档的目录 TM_FILEPATH当前文档的完整文件路径 CLIPBOARD剪贴板的内容 WORKSPACE_NAME打开的工作区或文件夹的名称 WORKSPACE_FOLDER打开的工作区或文件夹的路径    有关时间的\n CURRENT_YEAR本年度 CURRENT_YEAR_SHORT今年最后两位数 CURRENT_MONTH以两位数表示的月份（例如\u0026quot;02\u0026rdquo;） CURRENT_MONTH_NAME本月全名（例如\u0026quot;七月\u0026quot;） CURRENT_MONTH_NAME_SHORT本月的简称（例如\u0026quot;七月\u0026quot;） CURRENT_DATE每月的一天 CURRENT_DAY_NAME日名称（例如\u0026quot;星期一\u0026quot;） CURRENT_DAY_NAME_SHORT当天的简称（例如\u0026quot;星期一\u0026quot;） CURRENT_HOUR24 小时时钟格式的当前小时 CURRENT_MINUTE当前分钟 CURRENT_SECOND当前秒 CURRENT_SECONDS_UNIX自Unix epoch以来的秒数    有关注释的\n BLOCK_COMMENT_START Example output: in PHP or in HTML /*\u0026lt;!-- BLOCK_COMMENT_END Example output: in PHP or in HTML */--\u0026gt; LINE_COMMENT Example output: in PHP //     ","permalink":"http://yangchnet.github.io/Dessert/posts/windows/vscode-snippets%E5%8A%9F%E8%83%BD%E7%9A%84%E4%BD%BF%E7%94%A8/","summary":"VsCode Snippets的Snippets功能  snippets是代码片段, 在这里的意思是代码模板. 在使用vscode写代码时，有时需要使用代码模板，一个典型的例子是在写文件头注释时，需要一个固定格式的注释，来表明当前的时间、作者等。\n 1. 使用内置的snippets vscode中已经为我们内置了许多语言的代码模板，在安装了对应的语言插件后,可直接使用这些snippets. 2. 安装来自marketplace的snippets 按Ctrl+Shift+X打开marketplace, 输入@category:\u0026quot;snippets\u0026quot;,即可下载来自marketplace的snippets 3. 自定义snippets 如果你对内置的或来自marketplace的snippets均不满意,那么你可以自定义你的snippets.\n在File \u0026gt; Preferences \u0026gt; User Snippets选项下,选择你要定义snippets的文件类型\n在选择了文件类型之后,你就可以根据vscode提供的Example自定义snippets了.\nExample: \u0026quot;Print to console\u0026quot;: { \u0026quot;prefix\u0026quot;: \u0026quot;log\u0026quot;, \u0026quot;body\u0026quot;: [ \u0026quot;console.log('$1');\u0026quot;, \u0026quot;$2\u0026quot; ], \u0026quot;description\u0026quot;: \u0026quot;Log output to console\u0026quot; \u0026quot;Print to console\u0026quot;是你自定义的snippets的名字,prefix为前缀,在输入了你定义的prefix后,body中的内容就会输出到当前光标的位置.\n在body中,你可以使用\u0026quot;variables\u0026ldquo;来描述你的snippets, 其格式为:\n  ${1:label}: 其中的1表示在body输出后光标会第一个停放在这个位置,而label是对当前variables的描述.\n  ${1|one, two, three|}: 这个语法格式将提醒你选择one, two, three中的一个值.\n  $name或${name:default}: 其中的name为预定义的变量名,可使用default指定其默认值.预定义的变量名有如下:\n 有关文件与目录的\n TM_SELECTED_TEXT当前选定的文本或空字符串 TM_CURRENT_LIN当前行的内容 TM_CURRENT_WORD光标下或空字符串下的单词内容 TM_LINE_INDEX基于零指数的行数 TM_LINE_NUMBER基于一个索引的行数 TM_FILENAME当前文档的文件名 TM_FILENAME_BASE没有扩展的当前文档的文件名 TM_DIRECTORY当前文档的目录 TM_FILEPATH当前文档的完整文件路径 CLIPBOARD剪贴板的内容 WORKSPACE_NAME打开的工作区或文件夹的名称 WORKSPACE_FOLDER打开的工作区或文件夹的路径    有关时间的","title":"VsCode Snippets功能的使用"},{"content":"GitHub图床+vscode+Picgo 0. 来由 用markdown写博客的时候，图片往哪里存地干活？图床里存···\n1. GitHub配置   创建图床仓库 为了不污染我原来的git账号，我决定新建一个git账号，专门用作图床账号。 新建账号之后，new一个repo，啥都不用点，直接create。\n  生成token 点击你GitHub页面右上角的头像，点击settings 在页面左侧找到Developer settings，选择之，再找到Personal access tokens，再选择之，然后generate new tokens 在新弹出的页面中填写note，并选择repo， 然后直接到最下面，Generate token 这样GitHub会为你生成一个token（只会出现这一次），复制它留用。   2. 配置VScode中的Picgo插件 在vscode的插件商店中直接搜索Picgo，然后点击安装 安装完成后，再来配置你的Picgo File\u0026gt;Preferences\u0026gt;settings\u0026gt;Entensions\u0026gt;Picgo找到配置picgo的位置，填写必要的信息 \u0026#34;picgo.picBed.current\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;picgo.picBed.github.branch\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;picgo.picBed.github.path\u0026#34;: \u0026#34;\u0026#34;, # 你想要图片存储的路径 \u0026#34;picgo.picBed.github.repo\u0026#34;: \u0026#34;\u0026#34;, # 你的用户名以及repo名，user/REPO_name \u0026#34;picgo.picBed.github.token\u0026#34;: \u0026#34;\u0026#34; # 刚才复制的token，粘贴到这里 3. 使用picgo上传图片 截个图并复制到剪贴板，在vscode里按下\u0026quot;CTRL+ALT+u\u0026quot;，图片就可以十分迅速的上传到你配置的GitHub仓库并为你返回图片链接 （￣︶￣）↗。\nEND\n","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%9D%82%E8%AE%B0/github%E5%9B%BE%E5%BA%8A+vscode+picgo-/","summary":"GitHub图床+vscode+Picgo 0. 来由 用markdown写博客的时候，图片往哪里存地干活？图床里存···\n1. GitHub配置   创建图床仓库 为了不污染我原来的git账号，我决定新建一个git账号，专门用作图床账号。 新建账号之后，new一个repo，啥都不用点，直接create。\n  生成token 点击你GitHub页面右上角的头像，点击settings 在页面左侧找到Developer settings，选择之，再找到Personal access tokens，再选择之，然后generate new tokens 在新弹出的页面中填写note，并选择repo， 然后直接到最下面，Generate token 这样GitHub会为你生成一个token（只会出现这一次），复制它留用。   2. 配置VScode中的Picgo插件 在vscode的插件商店中直接搜索Picgo，然后点击安装 安装完成后，再来配置你的Picgo File\u0026gt;Preferences\u0026gt;settings\u0026gt;Entensions\u0026gt;Picgo找到配置picgo的位置，填写必要的信息 \u0026#34;picgo.picBed.current\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;picgo.picBed.github.branch\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;picgo.picBed.github.path\u0026#34;: \u0026#34;\u0026#34;, # 你想要图片存储的路径 \u0026#34;picgo.picBed.github.repo\u0026#34;: \u0026#34;\u0026#34;, # 你的用户名以及repo名，user/REPO_name \u0026#34;picgo.picBed.github.token\u0026#34;: \u0026#34;\u0026#34; # 刚才复制的token，粘贴到这里 3. 使用picgo上传图片 截个图并复制到剪贴板，在vscode里按下\u0026quot;CTRL+ALT+u\u0026quot;，图片就可以十分迅速的上传到你配置的GitHub仓库并为你返回图片链接 （￣︶￣）↗。\nEND","title":"GitHub图床+vscode+Picgo "},{"content":"安装与配置clash  参考了这位老哥的博客\n 0. 来由 阿里云与腾讯云git太慢了。。想快点\n1. 下载安装clash 地址在这里，找到对应自己系统的版本，可以先下载到自己本地主机后再用FileZilla上传到云服务器（虽然蛮麻烦，但是它快呀）\n2. 安装clash 将下载的clash上传到自己的服务器之后，解压之：\ngunzip clash-linux-amd64-v1.4.1.gz 解压结果就是一个可执行文件 重命名：\nmv clash-linux-amd64 clash 赋予运行权限：\nchmod +x clash 移动到bin目录下：\nmv clash /usr/bin 3. 编辑config.yaml文件 config.yaml文件的内容来自你购买的vpn提供商\nmkdir /etc/clash touch /etc/clash/config.yaml ··· # 编辑你的config.yaml 4. 将clash添加为系统服务 cd /etc/systemd/system/ vim clash.service clash.service的内容为：\n[Unit] Description=clash proxy After=network.target [Service] Type=simple ExecStart=/usr/bin/clash -d /etc/clash [Install] WantedBy=multi-user.target  要想深入了解systemctl服务，可前往阮一峰大佬的教程\n 编辑完成后，重载systemctl\nsystemctl daemon-reload 开启clash服务\nsystemctl start clash 5. 开启http代理和socks5代理  手动开启代理 export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7891  保持启动，修改~/.bashrc echo \u0026#34;export https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7891\u0026#34; \u0026gt;\u0026gt; ~/.bashrc   6. 测试是否成功 curl -I https://www.google.com/ 返回：\nHTTP/1.1 200 Connection established HTTP/2 200 content-type: text/html; charset=ISO-8859-1 p3p: CP=\u0026quot;This is not a P3P policy! See g.co/p3phelp for more info.\u0026quot; date: Thu, 04 Mar 2021 09:08:48 GMT server: gws x-xss-protection: 0 x-frame-options: SAMEORIGIN expires: Thu, 04 Mar 2021 09:08:48 GMT cache-control: private set-cookie: 1P_JAR=2021-03-04-09; expires=Sat, 03-Apr-2021 09:08:48 GMT; path=/; domain=.google.com; Secure set-cookie: NID=210=wzyYoXKPgWcDE4ptLfGQOeOE1w5kehSHm4-gycNKB2bUaeueNyGXgDUm-p5KR6X0aTtmcXjxsamD0xM3YJVRqJnw74uXjiOwcJpRiwsQ-jdUc4y4JG8ObdBOGQJQcddFf_d8fyJ1nVEeEWWZanQUDJToFA6b0T05oCegNpeM70Q; expires=Fri, 03-Sep-2021 09:08:48 GMT; path=/; domain=.google.com; HttpOnly alt-svc: h3-29=\u0026quot;:443\u0026quot;; ma=2592000,h3-T051=\u0026quot;:443\u0026quot;; ma=2592000,h3-Q050=\u0026quot;:443\u0026quot;; ma=2592000,h3-Q046=\u0026quot;:443\u0026quot;; ma=2592000,h3-Q043=\u0026quot;:443\u0026quot;; ma=2592000,quic=\u0026quot;:443\u0026quot;; ma=2592000; v=\u0026quot;46,43\u0026quot; ","permalink":"http://yangchnet.github.io/Dessert/posts/linux/%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AEclash/","summary":"安装与配置clash  参考了这位老哥的博客\n 0. 来由 阿里云与腾讯云git太慢了。。想快点\n1. 下载安装clash 地址在这里，找到对应自己系统的版本，可以先下载到自己本地主机后再用FileZilla上传到云服务器（虽然蛮麻烦，但是它快呀）\n2. 安装clash 将下载的clash上传到自己的服务器之后，解压之：\ngunzip clash-linux-amd64-v1.4.1.gz 解压结果就是一个可执行文件 重命名：\nmv clash-linux-amd64 clash 赋予运行权限：\nchmod +x clash 移动到bin目录下：\nmv clash /usr/bin 3. 编辑config.yaml文件 config.yaml文件的内容来自你购买的vpn提供商\nmkdir /etc/clash touch /etc/clash/config.yaml ··· # 编辑你的config.yaml 4. 将clash添加为系统服务 cd /etc/systemd/system/ vim clash.service clash.service的内容为：\n[Unit] Description=clash proxy After=network.target [Service] Type=simple ExecStart=/usr/bin/clash -d /etc/clash [Install] WantedBy=multi-user.target  要想深入了解systemctl服务，可前往阮一峰大佬的教程\n 编辑完成后，重载systemctl\nsystemctl daemon-reload 开启clash服务\nsystemctl start clash 5. 开启http代理和socks5代理  手动开启代理 export https_proxy=http://127.","title":"安装与配置clash"},{"content":"博客建设记 0. 前记 一直想要建设一个属于自己的博客，一开始用python写过一个简单的，可以做到富文本编辑、发布、更新、评论等功能，但那个不是一个单纯的博客，并且界面也不是太友好，因此后来废弃了。后来又用了一段时间的jupyter notebook，很强大，尤其让我喜欢的是可以直接运行代码，曾经有一段时间想过可否把jupyter notebook直接作为我的博客页面，或者是嵌入我的页面内，于是看了看其源代码。。。遂放弃。后来又用了为知笔记，印象笔记，Notion等，但感觉都没jupyter notebook好用。 在用jupyter notebook记了有了一定的数目之后，就想将其发布出来，考虑过CSDN，但感觉上面广告好多，不太喜欢，因此没有使用。后来买了域名和服务器，用wordpress搞了一个，但是不是太满意，也没发布。后来用go语言写了一个，因为某些原因，中间的一些数据通路没有搞通（主要是从jupyter到md再到网站的自动发布），再加上后来考研，所以这个项目也没活到\u0026quot;成站\u0026quot;。 终于，用hugo搞了一个。之所以用hugo，一是因为最近研究go语言，对go语言的项目具有一定的好感，第二是因为看了网上的一些介绍并且发现了一些使用hugo的个人博客。 2021/2/28，记之。\n1. 使用hugo开始自己的网站 1.1 开始 hugo的使用炒鸡简单，你只需要使用\nhugo new site MySite 即可新建一个名为MySite的网站\n1.2 为你的网站选择一个theme 进入到我们刚才建立的网站目录\ncd Mysite/ 从GitHub导入你想应用的主题\ngit init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 待下载完成后，还需要修改你的配置文件\necho \u0026#39;theme = \u0026#34;ananke\u0026#34; \u0026#39; \u0026gt;\u0026gt; config.toml 1.3 为你的网站添加一些内容 hugo使用我们上传的md文件来自动生成静态网页，而我们上传的md文件的位置在MySite/content/posts/*, 我们可以直接复制已经编辑好的md文件到这个目录，或者使用如下命令：\nhugo new posts/my-first-post.md 需要注意的一点：为了让hugo知道更多的信息，我们上传的md文件一般会有一个\u0026quot;standand header\u0026quot;, 如下：\n--- title: \u0026quot;My First Post\u0026quot; date: 2019-03-26T08:47:11+01:00 draft: true --- 这里的头部并不是一成不变的，你可以根据需要自行配置。\n1.4 开始让你的网站服务 使用如下命令让你的网站开始服务吧！\nhugo server -D 注意，这个命令只会让你的hugo服务器监听本地访问，也就是127.0.0.1 如果你想要你的hugo服务器为整个网络服务，可以这样：\nhugo server --bind=\u0026#39;0.0.0.0\u0026#39; 这样，你的网站就可以全网访问了。\n2. 使用webhook 简单的说，webhook是一个触发器，当我们做出某个特定的的动作后，webhook可以自动完成特定任务。\n2.1 服务端配置 首先，我们使用https://github.com/adnanh/webhook.git来配置我们的服务器端，使其可监听webhook请求。\n 安装adnanh/webhook go build github.com/adnanh/webhook  编辑hooks.json [ { \u0026#34;id\u0026#34;: \u0026#34;redeploy-webhook\u0026#34;, \u0026#34;execute-command\u0026#34;: \u0026#34;/var/scripts/redeploy.sh\u0026#34;, //脚本的位置 \u0026#34;command-working-directory\u0026#34;: \u0026#34;/var/webhook\u0026#34; // 脚本的工作目录 } ] 如果你想要你的脚本返回一些值作为提醒，可以这样设置：\n\u0026#34;response-message\u0026#34;:\u0026#34;hooks,hooks\u0026#34;  编辑你要运行的自动部署脚本 # 你的脚本，根据你所要执行的任务自行编写   ✦✦你需要注意你的脚本权限，确保其可以运行\n2.2 GitHub的webhook 在服务端配置完成后，开始配置GitHub。 Github为我们提供了webhook功能，可以方便的应用在我们的代码仓库中。 在github上配置你的webhook，content type选择application/json,Payload URL为你想要webhook监听的端口与路径，其中路径中的最后一部分与hooks.json中的id是对应的。 2.3 测试通路 测试你的webhook是否设置成功。\n 开启服务端监听  /path/to/webhook -hooks hooks.json -verbose # 默认端口9000 # 你可以使用-port参数指定监听端口 在GitHub上发送请求 GitHub webhook配置完成后会自动发送请求查看是否有回应，若Recent Deliveries中是红色的感叹号，代表测试失败。你可以点击Redeliver按钮重新测试。若出现绿色的对号，则代表测试成功。 ![redeliver]{}  2.4 将webhook设置为systemctl 为了让webhook能一直监听请求，我们需要使webhook保持运行。 新建/etc/systemed/system/webhook.service 其内容如下：\n[Unit] Description=Webhooks [Service] ExecStart=/usr/bin/webhook -port 12345 -hooks /path/to/hooks.json -hotreload [Install] WantedBy=multi-user.target 保存并关闭。 运行以下命令\nsudo systemctl daemon-reload # 重载配置文件 sudo systemctl start webhook.service # 启动webhook.service sudo systemctl status webhook.service # 查看webhook的状态 3. 使用nginx作为服务器 安装nginx：\nsudo apt-get install nginx 使用hugo生成静态文件\n# cd Mysite hugo hugo生成的静态文件存储在public文件夹中。 将public文件夹中的所有文件复制到nginx指定的root文件夹中。 访问你的服务器ip地址或域名。 页面正常！ ✦✦如果你的nginx显示404，那么请检查你的nginx的root文件夹配置以及你的文件位置；如果显示403，可能是你服务端权限配置错误。\n4. 数据通路 本地编辑md文件 → 上传GitHub → webhook发送请求 → 服务器接收请求，拉取GitHub文件，重新生成静态文件 → 复制静态文件到nginx指定的root目录。更新完成\n","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%9D%82%E8%AE%B0/%E5%8D%9A%E5%AE%A2%E5%BB%BA%E8%AE%BE/","summary":"博客建设记 0. 前记 一直想要建设一个属于自己的博客，一开始用python写过一个简单的，可以做到富文本编辑、发布、更新、评论等功能，但那个不是一个单纯的博客，并且界面也不是太友好，因此后来废弃了。后来又用了一段时间的jupyter notebook，很强大，尤其让我喜欢的是可以直接运行代码，曾经有一段时间想过可否把jupyter notebook直接作为我的博客页面，或者是嵌入我的页面内，于是看了看其源代码。。。遂放弃。后来又用了为知笔记，印象笔记，Notion等，但感觉都没jupyter notebook好用。 在用jupyter notebook记了有了一定的数目之后，就想将其发布出来，考虑过CSDN，但感觉上面广告好多，不太喜欢，因此没有使用。后来买了域名和服务器，用wordpress搞了一个，但是不是太满意，也没发布。后来用go语言写了一个，因为某些原因，中间的一些数据通路没有搞通（主要是从jupyter到md再到网站的自动发布），再加上后来考研，所以这个项目也没活到\u0026quot;成站\u0026quot;。 终于，用hugo搞了一个。之所以用hugo，一是因为最近研究go语言，对go语言的项目具有一定的好感，第二是因为看了网上的一些介绍并且发现了一些使用hugo的个人博客。 2021/2/28，记之。\n1. 使用hugo开始自己的网站 1.1 开始 hugo的使用炒鸡简单，你只需要使用\nhugo new site MySite 即可新建一个名为MySite的网站\n1.2 为你的网站选择一个theme 进入到我们刚才建立的网站目录\ncd Mysite/ 从GitHub导入你想应用的主题\ngit init git submodule add https://github.com/budparr/gohugo-theme-ananke.git themes/ananke 待下载完成后，还需要修改你的配置文件\necho \u0026#39;theme = \u0026#34;ananke\u0026#34; \u0026#39; \u0026gt;\u0026gt; config.toml 1.3 为你的网站添加一些内容 hugo使用我们上传的md文件来自动生成静态网页，而我们上传的md文件的位置在MySite/content/posts/*, 我们可以直接复制已经编辑好的md文件到这个目录，或者使用如下命令：\nhugo new posts/my-first-post.md 需要注意的一点：为了让hugo知道更多的信息，我们上传的md文件一般会有一个\u0026quot;standand header\u0026quot;, 如下：\n--- title: \u0026quot;My First Post\u0026quot; date: 2019-03-26T08:47:11+01:00 draft: true --- 这里的头部并不是一成不变的，你可以根据需要自行配置。\n1.4 开始让你的网站服务 使用如下命令让你的网站开始服务吧！\nhugo server -D 注意，这个命令只会让你的hugo服务器监听本地访问，也就是127.0.0.1 如果你想要你的hugo服务器为整个网络服务，可以这样：","title":"博客建设"},{"content":"/usr/bin/env: ‘node’: No such file or directory 解决方法 sudo apt-get install nodejs-legacy ","permalink":"http://yangchnet.github.io/Dessert/posts/linux/nodejs/","summary":"/usr/bin/env: ‘node’: No such file or directory 解决方法 sudo apt-get install nodejs-legacy ","title":"/usr/bin/env:‘node’:Nosuchfileordirectory"},{"content":"1、python与其他语言的对比（hello world）  C语言\n include\u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello world\u0026#34;); return 0; }  Java语言\n public class HelloWorld{ public static void main(String[] args) { System.out.println(\u0026#34;Hello World!\u0026#34;); } }  Python\n print(\u0026#39;hello world\u0026#39;) 2、python中的常用数据类型  Number String List Tuple Dictionary  # Number a = 1 b = True c = 3.15 d = 1.1+2.2j # 字符串 str1 = \u0026#39;hello\u0026#39; str1_1 = \u0026#34;hello\u0026#34; str2 = \u0026#34;world\u0026#34; print(str1==str1_1) # 字符串连接 str3 = str1 + str2 print(str3) # 转义字符 str4 = \u0026#39;hello \\nworld\u0026#39; print(str4) str5 = \u0026#39;hello \\\\n world\u0026#39; print(str5) # 格式化输出 print(\u0026#39;str1:%s.\u0026#39;%str1) # 切片 print(str1[1:4]) True helloworld hello world hello \\n world str1:hello. ell  # 列表 list1 = [\u0026#39;google\u0026#39;, \u0026#39;alibaba\u0026#39;, 2001, 3.14] # 通过下标访问 print(list1[0]) # 更新列表 list1[2] = \u0026#39;baidu\u0026#39; print(list1) # 删除元素 del list1[3] print(list1) # 拼接列表 list2 = [\u0026#39;microsoft\u0026#39;, \u0026#39;amazon\u0026#39;] list3 = list1 + list2 print(list3) # 增添列表项 list1.append(\u0026#39;jingdong\u0026#39;) print(list1) google ['google', 'alibaba', 'baidu', 3.14] ['google', 'alibaba', 'baidu'] ['google', 'alibaba', 'baidu', 'microsoft', 'amazon'] ['google', 'alibaba', 'baidu', 'jingdong']  # 元组：类似列表,是一系列元素的有序集合,但元组中的元素无法修改 tuple1 = (\u0026#39;google\u0026#39;, \u0026#39;alibaba\u0026#39;, \u0026#39;baidu\u0026#39;) tuple1[0] = \u0026#39;amazon\u0026#39; # 不能被改变 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) \u0026lt;ipython-input-23-4ed3e334c834\u0026gt; in \u0026lt;module\u0026gt; 1 # 元组：类似列表,是一系列元素的有序集合,但元组中的元素无法修改 2 tuple1 = ('google', 'alibaba', 'baidu') ----\u0026gt; 3 tuple1[0] = 'amazon' TypeError: 'tuple' object does not support item assignment  # 字典 dict1 = { \u0026#39;color\u0026#39;: \u0026#39;green\u0026#39;, \u0026#39;points\u0026#39;: 5 } # 访问列表中的值 print(dict1[\u0026#39;color\u0026#39;]) # 增加字典中键值对 dict1[\u0026#39;x_pos\u0026#39;] = 0 dict1[\u0026#39;y_pos\u0026#39;] =4 print(dict1) green {'color': 'green', 'points': 5, 'x_pos': 0, 'y_pos': 4}  3、python中的结构语句 3.1、if条件语句 car = \u0026#39;bmw\u0026#39; if car == \u0026#39;bmw\u0026#39;: print(car.upper()) # 输出car的大写版本 else: print(car.title()) # 输出car的标题版本 Bmw  现实世界中,很多情况下需要考虑的情形都超过两个。例如,来看一个根据年龄段收费的 游乐场:\n 4岁以下免费; 4~18岁收费5美元; 18岁(含)以上收费10美元。   如果只使用一条 if 语句,如何确定门票价格呢?下面的代码确定一个人所属的年龄段,并打印一条包含门票价格的消息:\n age = 12 if age \u0026lt; 4: print(\u0026#34;Your admission cost is $0.\u0026#34;) elif age \u0026lt; 18: print(\u0026#34;Your admission cost is $5.\u0026#34;) else: print(\u0026#34;Your admission cost is $10.\u0026#34;) Your admission cost is $5.  3.2、for循环语句 fruits = [\u0026#39;banana\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;mango\u0026#39;] for fruit in fruits: print(\u0026#39;当前水果：%s\u0026#39;%fruit) 当前水果：banana 当前水果：apple 当前水果：mango  # range 步长为1 for i in range(0, 6): print(i) 1 2 3 4 5  # range 步长为2 for i in range(0, 6, 2): print(i) 0 2 4  # break 和 continue for i in range(0, 6): if i == 3: break print(i) for i in range(0, 6): if i == 3: continue print(i, end=\u0026#39;\u0026#39;) 0 1 2 01245  3.3、while循环语句 # while循环 current_number = 1 while current_number \u0026lt;= 5: print(current_number) current_number += 1 1 2 3 4 5  3.4、函数 def greet_user(username): \u0026#34;\u0026#34;\u0026#34; 显示简单的问候语 \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Hello, \u0026#34; + username.title() + \u0026#34;!\u0026#34;) greet_user(\u0026#39;jesse\u0026#39;) greet_user(\u0026#39;jack\u0026#39;) Hello, Jesse! Hello, Jack!  # 有返回值的函数 def add(a, b): return a+b print(\u0026#39;第一个函数：%d\u0026#39;%add(2, 3)) # 列表作为参数的函数 def add_l(mylist): result = 0 for l in mylist: result += l return result print(\u0026#39;第二个函数：%d\u0026#39;%add_l([1, 2, 3, 4])) # 有多个返回值的函数 def muti_re(mylist): a = max(mylist) b = min(mylist) return a, b a, b = muti_re([1, 2, 3, 4]) print(\u0026#39;第三个函数, 最大值：%d, 最小值：%d\u0026#39;%(a,b)) 第一个函数：5 第二个函数：10 第三个函数, 最大值：4, 最小值：1  有时候,你预先不知道函数需要接受多少个实参, 但是Python允许函数从调用语句中收集任意数量的实参。\n 例如,来看一个制作比萨的函数,它需要接受很多配料,但你无法预先确定顾客要多少种配 料。下面的函数只有一个形参 *toppings ,但不管调用语句提供了多少实参,这个形参都将它们 统统收入囊中:\n def make_pizza(*toppings): print(toppings) make_pizza(\u0026#39;pepperoni\u0026#39;) make_pizza(\u0026#39;mushrooms\u0026#39;, \u0026#39;green peppers\u0026#39;, \u0026#39;extra cheese\u0026#39;) ('pepperoni',) ('mushrooms', 'green peppers', 'extra cheese')  3.5、类 面向对象编程是最有效的软件编写方法之一。在面向对象编程中, 你编写表示现实世界中的事物和情景的类,并基于这些类来创建对象。 编写类时,你定义一大类对象都有的通用行为。基于类创建对象时, 每个对象都自动具备这种通用行为,然后可根据需要赋予每个对象独 特的个性。使用面向对象编程可模拟现实情景,其逼真程度达到了令 你惊讶的地步。 根据类来创建对象被称为实例化,这让你能够使用类的实例。在 本章中,你将编写一些类并创建其实例。你将指定可在实例中存储什 么信息,定义可对这些实例执行哪些操作。你还将编写一些类来扩展 既有类的功能,让相似的类能够高效地共享代码。你将把自己编写的类存储在模块中,并在 自己的程序文件中导入其他程序员编写的类\n使用类几乎可以模拟任何东西。下面来编写一个表示小狗的简单类 Dog ——它表示的不是特 定的小狗,而是任何小狗。对于大多数宠物狗,我们都知道些什么呢?它们都有名字和年龄;我 们还知道,大多数小狗还会蹲下和打滚。由于大多数小狗都具备上述两项信息(名字和年龄)和 两种行为(蹲下和打滚),我们的 Dog 类将包含它们。这个类让Python知道如何创建表示小狗的对 象。编写这个类后,我们将使用它来创建表示特定小狗的实例。\n# 创建类 class Dog(): def __init__(self, name, age): self.name = name self.age = age def sit(self): print(self.name.title() + \u0026#34; is now sitting.\u0026#34;) def roll_over(self): print(self.name.title() + \u0026#34; rolled over!\u0026#34;)对字符串的大小写进行更改 类中的函数称为方法;你前面学到的有关函数的一切都适用于方法,就目前而言,唯一重要 的差别是调用方法的方式。方法 init() 是一个特殊的方法,每当你根据 Dog 类创建新实 例时,Python都会自动运行它。在这个方法的名称中,开头和末尾各有两个下划线,这是一种约 定,旨在避免Python默认方法与普通方法发生名称冲突。\n# 根据类创建实例 my_dog = Dog(\u0026#39;willie\u0026#39;, 6) print(\u0026#34;My dog\u0026#39;s name is \u0026#34; + my_dog.name.title() + \u0026#34;.\u0026#34;) print(\u0026#34;My dog is \u0026#34; + str(my_dog.age) + \u0026#34; years old.\u0026#34;) My dog's name is Willie. My dog is 6 years old.  # 访问类的属性 my_dog.name 'willie'  # 调用类的方法 my_dog.sit() my_dog.roll_over() Willie is now sitting. Willie rolled over!  4、对字符串的一些操作 4.1、对字符串的大小写进行更改 # 对字符串的大小写进行更改 name = \u0026#34;ada lovelace\u0026#34; print(name.title()) name = \u0026#34;Ada Lovelace\u0026#34; print(name.upper()) print(name.lower()) Ada Lovelace ADA LOVELACE ada lovelace  4.2、合并/拼接字符串 first_name = \u0026#34;ada\u0026#34; last_name = \u0026#34;lovelace\u0026#34; full_name = first_name + \u0026#34; \u0026#34; + last_name print(full_name) ada lovelace  4.3、使用制表符或换行符来添加空白 print(\u0026#34;\\tPython\u0026#34;) print(\u0026#34;Languages:\\nPython\\nC\\nJavaScript\u0026#34;)  Python Languages: Python C JavaScript  4.4、删除空白 favorite_language = \u0026#39; python \u0026#39; # 删除末尾的空白 favorite_language.rstrip() # 删除开头的空白 favorite_language.lstrip() 'python '  4.5、字符串分割 my_languages = \u0026#39;python,C,JAVA,PHP,MATLAB\u0026#39; languages_list = my_languages.split(\u0026#39;,\u0026#39;) print(languages_list) print(languages_list[0]) print(languages_list[0][3]) ['python', 'C', 'JAVA', 'PHP', 'MATLAB'] python h  习题 1、打印出99乘法表 2、判断是否是闰年 3、编写Python程序计算斐波那契数列，要求：输入序号n，输出数列的第n项，数列的计算用函数实现 4、使用面向对象的思想， 创建一个名为 User 的类,其中包含属性 first_name 和 last_name ,还有用户简介通常会存储的其他几个属性。在类 User 中定义一个名为 describe_user() 的方法,它打印用户信息摘要;再定义一个名为 greet_user() 的方法,它向用户发出个性化的问候。 创建多个表示不同用户的实例,并对每个实例都调用上述两个方法。 ","permalink":"http://yangchnet.github.io/Dessert/posts/python/python%E5%9F%BA%E7%A1%80/","summary":"1、python与其他语言的对比（hello world）  C语言\n include\u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello world\u0026#34;); return 0; }  Java语言\n public class HelloWorld{ public static void main(String[] args) { System.out.println(\u0026#34;Hello World!\u0026#34;); } }  Python\n print(\u0026#39;hello world\u0026#39;) 2、python中的常用数据类型  Number String List Tuple Dictionary  # Number a = 1 b = True c = 3.15 d = 1.1+2.2j # 字符串 str1 = \u0026#39;hello\u0026#39; str1_1 = \u0026#34;hello\u0026#34; str2 = \u0026#34;world\u0026#34; print(str1==str1_1) # 字符串连接 str3 = str1 + str2 print(str3) # 转义字符 str4 = \u0026#39;hello \\nworld\u0026#39; print(str4) str5 = \u0026#39;hello \\\\n world\u0026#39; print(str5) # 格式化输出 print(\u0026#39;str1:%s.","title":"1、python与其他语言的对比（helloworld）"},{"content":"2016统计学专业数据挖掘实验课程考核  此考核预计用时120m, 满分100分\n  姓名： 学号：  1. Wordcount（30分） 计算出下文中每个英文字母出现的次数（不区分大小写, 去除空格与标点符号），并进行输出。\nOur entire class is quaking in its boots. The reason, of course, is the upcoming meeting in which the teachers decide who\u0026rsquo;ll be promoted to the next grade and who\u0026rsquo;ll be kept back. Half the class is making bets. G.Z. and I laugh ourselves sick at the two boys behind us, C.N. and Jacques Kocernoot, who have staked their entire vacation savings on their bet. From morning to night, it\u0026rsquo;s \u0026ldquo;You\u0026rsquo;re going to pass, No, I\u0026rsquo;m not,\u0026rdquo; \u0026ldquo;Yes, you are,\u0026rdquo; \u0026ldquo;No, I\u0026rsquo;m not.\u0026rdquo; Even G.\u0026rsquo;s pleading glances and my angry outbursts can\u0026rsquo;t calm them down. If you ask me, there are so many dummies that about a quarter of the class should be kept back, but teachers are the most unpredictable creatures on earth. Maybe this time they\u0026rsquo;ll be unpredictable in the right direction for a change. I\u0026rsquo;m not so worried about my girlfriends and myself.\n（节选自《安妮日记》）\nTips: 使用字典存储每个字母出现次数，例如：\nmy_str = \u0026#39;our\u0026#39; result = {} for s in my_str: result.setdefault(s, 0) result[s] += 1 print(result) {'o': 1, 'u': 1, 'r': 1}  你的答案：  2. 分词处理（30分） 使用jieba分词工具对下文进行分词，要求去除标点符号，并输出最后分词结果。\n我晓得他们的方法，直捷杀了，是不肯的，而且也不敢，怕有祸祟。所以他们大家连络，布满了罗网，逼我自戕。试看前几天街上男女的样子，和这几天我大哥的作为，便足可悟出八九分了。最好是解下腰带，挂在梁上，自己紧紧勒死；他们没有杀人的罪名，又偿了心愿，自然都欢天喜地的发出一种呜呜咽咽的笑声。否则惊吓忧愁死了，虽则略瘦，也还可以首肯几下。\n他们是只会吃死肉的！记得什么书上说，有一种东西，叫“海乙那”的，眼光和样子都很难看；时常吃死肉，连极大的骨头，都细细嚼烂，咽下肚子去，想起来也教人害怕。“海乙那”是狼的亲眷，狼是狗的本家。前天赵家的狗，看我几眼，可见他也同谋，早已接洽。老头子眼看着地，岂能瞒得我过。\n最可怜的是我的大哥，他也是人，何以毫不害怕；而且合伙吃我呢？还是历来惯了，不以为非呢？还是丧了良心，明知故犯呢？\n我诅咒吃人的人，先从他起头；要劝转吃人的人，也先从他下手。\n（节选自鲁迅《狂人日记》）\n 你的答案：  3. 朴素贝叶斯分类（40分） 鸢尾花数据集简介:\nIris数据集是常用的分类实验数据集，由Fisher, 1936收集整理。Iris也称鸢尾花卉数据集，是一类多重变量分析的数据集。数据集包含150个数据集，分为3类，每类50个数据，每个数据包含4个属性。iris以鸢尾花的特征作为数据来源，常用在分类操作中。该数据集由3种不同类型的鸢尾花的50个样本数据构成。其中的一个种类与另外两个种类是线性可分离的，后两个种类是非线性可分离的。数据集包括4个属性，分别为花萼的长、花萼的宽、花瓣的长和花瓣的宽。\n#加载数据集, 每一列代表一种属性，具体数据可查看iris.txt from sklearn import datasets iris = datasets.load_iris() X = iris.data Y = iris.target print(X[1:3]) print(Y[1:3]) [[4.9 3. 1.4 0.2] [4.7 3.2 1.3 0.2]] [0 0]   （1） 分别求出三种类型鸢尾花的花萼长度的平均值 你的答案： （2） 画出花萼长和花萼宽两种属性的散点分布图，使用“red”, \u0026ldquo;blue\u0026rdquo;, \u0026ldquo;green\u0026rdquo; 三种颜色代表三种类型的花。 你的答案： （3） 使用MultinomialNB分类器，对数据集进行训练，并计算最终分类准确率 你的答案：  恭喜你完成了本学期的所有数据挖掘实验课程！ 你对本课程的建议与看法： 得分： ","permalink":"http://yangchnet.github.io/Dessert/posts/python/2016%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B8%93%E4%B8%9A%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E5%AE%9E%E9%AA%8C%E8%AF%BE%E7%A8%8B%E8%80%83%E6%A0%B8/","summary":"2016统计学专业数据挖掘实验课程考核  此考核预计用时120m, 满分100分\n  姓名： 学号：  1. Wordcount（30分） 计算出下文中每个英文字母出现的次数（不区分大小写, 去除空格与标点符号），并进行输出。\nOur entire class is quaking in its boots. The reason, of course, is the upcoming meeting in which the teachers decide who\u0026rsquo;ll be promoted to the next grade and who\u0026rsquo;ll be kept back. Half the class is making bets. G.Z. and I laugh ourselves sick at the two boys behind us, C.N. and Jacques Kocernoot, who have staked their entire vacation savings on their bet.","title":"2016统计学专业数据挖掘实验课程考核"},{"content":"AutoReserve | 使用说明 1. 简介 AutoReserve是一个帮助同学们自动预约图书馆座位的系统，提供每晚代约座位服务，由一位热心同学开发和维护。\n2.访问站点 我们的网站是：http://59.110.140.133/reserve/ ，欢迎访问注册\n3.如何使用 访问网站-\u0026gt;注册账号-\u0026gt;填写表格-\u0026gt;审核通过-\u0026gt;成功加入预约名单\n3.1 访问并注册 访问http://59.110.140.133/reserve/主页\n点击免费注册或上方导航栏里的注册按钮进行注册，跳转到注册页面\n填写表单进行注册\n两次密码不一致会有检查提示\n注册完成后自动重定向到我的预约页面\n页面下方会显示系统数据库中已经被“预约”的位置\n按照提示填写表单后，页面上方会刷新出你的预约信息\n4. Q\u0026amp;A Q： 本系统的用户名必须和预约系统的账号一样吗？\nA： 不一定，你可以选择自己喜欢的用户名，比如：悲伤的雪，等等。在你填写自己的预约信息时要求的账号才是你图书馆预约系统的账号。\n Q： 可以100%保证我每天都可以约到想要的位置吗？\nA： 不一定，由于本系统也是模拟登录等行为来进行预约，因此也受到比如网络拥塞，系统卡顿等问题，因此不一定每天都可以约到想要的位置，当用户指定的位置未完成预约时，系统将自动预约与其相邻的下一个座位，保证用户有位置可坐。\n Q： 有时注册提交表单时会出现Internal Error 500,这代表什么意思，是注册失败了吗？\nA： Internal Error 500代表服务器内部错误，由于某些未知的原因，此类错误尚无法预知并排除，出现此类错误时，通常预约已经完成，用户可再次访问网页直接登录。推荐用户在浏览器内打开网址，不建议在QQ，微信环境下直接进入网页。\n Q： 我填写完表单后，当天就可以约到位置吗？\nA： 系统在每天晚上12点为用户预约“明天”的座位，也就是说，如果用户在1月1日中午填写表单，那么系统将在1月2日的凌晨00:00为其预约1月3日的座位，此后每天晚上都会再次预约。\n Q： 我今天不想去了，怎么才能取消今天的座位？\nA： 本系统不提供取消座位服务，用户可直接登录官方预约系统微信端（ http://libzwxt.ahnu.edu.cn/SeatWx/login.aspx ） 或网页端（ http://libzwxt.ahnu.edu.cn/SeatManage/ ） 进行取消。\n Q： 我想换个位置做，可以修改预约信息吗？\nA： 用户可直接登录系统，点击上方我的预约导航按钮，进入我的预约页面修改信息。\n Q： 一个账号可以提交多个预约信息吗？\nA： 不可以，每个账号只能为一个人预约。\n Q： 为什么我的座位没有预约成功？\nA： 系统可能存在未知的BUG， 反复出现此问题请联系管理员。\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/autoreserve%E4%BD%BF%E7%94%A8%E8%AF%B4%E6%98%8E/","summary":"AutoReserve | 使用说明 1. 简介 AutoReserve是一个帮助同学们自动预约图书馆座位的系统，提供每晚代约座位服务，由一位热心同学开发和维护。\n2.访问站点 我们的网站是：http://59.110.140.133/reserve/ ，欢迎访问注册\n3.如何使用 访问网站-\u0026gt;注册账号-\u0026gt;填写表格-\u0026gt;审核通过-\u0026gt;成功加入预约名单\n3.1 访问并注册 访问http://59.110.140.133/reserve/主页\n点击免费注册或上方导航栏里的注册按钮进行注册，跳转到注册页面\n填写表单进行注册\n两次密码不一致会有检查提示\n注册完成后自动重定向到我的预约页面\n页面下方会显示系统数据库中已经被“预约”的位置\n按照提示填写表单后，页面上方会刷新出你的预约信息\n4. Q\u0026amp;A Q： 本系统的用户名必须和预约系统的账号一样吗？\nA： 不一定，你可以选择自己喜欢的用户名，比如：悲伤的雪，等等。在你填写自己的预约信息时要求的账号才是你图书馆预约系统的账号。\n Q： 可以100%保证我每天都可以约到想要的位置吗？\nA： 不一定，由于本系统也是模拟登录等行为来进行预约，因此也受到比如网络拥塞，系统卡顿等问题，因此不一定每天都可以约到想要的位置，当用户指定的位置未完成预约时，系统将自动预约与其相邻的下一个座位，保证用户有位置可坐。\n Q： 有时注册提交表单时会出现Internal Error 500,这代表什么意思，是注册失败了吗？\nA： Internal Error 500代表服务器内部错误，由于某些未知的原因，此类错误尚无法预知并排除，出现此类错误时，通常预约已经完成，用户可再次访问网页直接登录。推荐用户在浏览器内打开网址，不建议在QQ，微信环境下直接进入网页。\n Q： 我填写完表单后，当天就可以约到位置吗？\nA： 系统在每天晚上12点为用户预约“明天”的座位，也就是说，如果用户在1月1日中午填写表单，那么系统将在1月2日的凌晨00:00为其预约1月3日的座位，此后每天晚上都会再次预约。\n Q： 我今天不想去了，怎么才能取消今天的座位？\nA： 本系统不提供取消座位服务，用户可直接登录官方预约系统微信端（ http://libzwxt.ahnu.edu.cn/SeatWx/login.aspx ） 或网页端（ http://libzwxt.ahnu.edu.cn/SeatManage/ ） 进行取消。\n Q： 我想换个位置做，可以修改预约信息吗？\nA： 用户可直接登录系统，点击上方我的预约导航按钮，进入我的预约页面修改信息。\n Q： 一个账号可以提交多个预约信息吗？\nA： 不可以，每个账号只能为一个人预约。\n Q： 为什么我的座位没有预约成功？\nA： 系统可能存在未知的BUG， 反复出现此问题请联系管理员。","title":"AutoReserve|使用说明"},{"content":"CentOS安装Python环境 吐槽：网上一堆从官网获取安装包然后自己编译的，慢不说，还容易出错\n可使用以下命令安装Python3环境：\n   yum install rh-python36 使用这条命令，安装Python3.6，但是安装后找不到，输入Python3后还是找不到命令\n scl enable rh-python36 bash\n上面的命令是调用/opt/rh/rh-python36/enable更改shell环境变量的脚本。\n如果再次检查Python版本，你会发现Python 3.6现在是当前shell中的默认版本。 需要指出的是，Python 3.6仅在此shell会话中设置为默认的Python版本。如果退出会话或从另一个终端打开一个新会话，Python 2.7将是默认的Python版本。\n  可使用当前shell窗口建立一个Python3虚拟环境，这样就可以使用Python3\n  #首先，创建项目目录并切换到它： mkdir ~/my_new_project cd ~/my_new_project #使用该scl工具激活Python 3.6 ： sl enable rh-python36 bash # 从项目根目录内部运行以下命令以创建名为的虚拟环境my_project_venv： python -m venv my_project_venv #要首先使用虚拟环境，我们需要输入以下命令来激活它： source my_project_venv/bin/activate #激活环境后，shell提示符将以环境名称作为前缀： (my_project_venv) user@host:~/my_new_project$ ","permalink":"http://yangchnet.github.io/Dessert/posts/linux/centos%E5%AE%89%E8%A3%85python%E7%8E%AF%E5%A2%83/","summary":"CentOS安装Python环境 吐槽：网上一堆从官网获取安装包然后自己编译的，慢不说，还容易出错\n可使用以下命令安装Python3环境：\n   yum install rh-python36 使用这条命令，安装Python3.6，但是安装后找不到，输入Python3后还是找不到命令\n scl enable rh-python36 bash\n上面的命令是调用/opt/rh/rh-python36/enable更改shell环境变量的脚本。\n如果再次检查Python版本，你会发现Python 3.6现在是当前shell中的默认版本。 需要指出的是，Python 3.6仅在此shell会话中设置为默认的Python版本。如果退出会话或从另一个终端打开一个新会话，Python 2.7将是默认的Python版本。\n  可使用当前shell窗口建立一个Python3虚拟环境，这样就可以使用Python3\n  #首先，创建项目目录并切换到它： mkdir ~/my_new_project cd ~/my_new_project #使用该scl工具激活Python 3.6 ： sl enable rh-python36 bash # 从项目根目录内部运行以下命令以创建名为的虚拟环境my_project_venv： python -m venv my_project_venv #要首先使用虚拟环境，我们需要输入以下命令来激活它： source my_project_venv/bin/activate #激活环境后，shell提示符将以环境名称作为前缀： (my_project_venv) user@host:~/my_new_project$ ","title":"CentOS安装Python环境"},{"content":"defer用法 defer用来延迟对某个语句的调用，常用于处理成对的操作，如打开、关闭、连接、断开连接，加锁、释放锁。通过defer语句，无论函数逻辑多复杂，都能保证在任何代码执行路径下，资源被释放。defer应该直接跟在请求资源的语句后。\ndefer语句将函数的调用push到一个列表中，当外层函数返回时，会执行保存的函数列表\n举个例子，这个程序打开两个文件并将一个文件的内容复制到另一个文件的函数\nfunc CopyFile(dstName, srcName string) (written int64, err error) { src, err := os.Open(srcName) if err != nil { return } dst, err := os.Create(dstName) if err != nil { return } written, err = io.Copy(dst, src) dst.Close() src.Close() return } 这个函数似乎可以正常工作，但其实存在一个bug，如果对os.Create的调用失败，该函数将返回但却不关闭源文件，通过在第二个return语句中调用src.Close可以解决这个问题。但是如果函数更加复杂，问题可能不会那么容易被发现和解决。通过使用defer语句，可以确保始终关闭文件。\nfunc CopyFile(dstName, srcName string) (written int64, err error) { src, err := os.Open(srcName) if err != nil { return } defer src.Close() dst, err := os.Create(dstName) if err != nil { return } defer dst.Close() return io.Copy(dst, src) } Defer语句使我们可以考虑在打开每个文件后立即将其关闭，从而确保无论函数中有return语句多少，文件都将被关闭。\n defer语句的行为直接且可预测，有三个简单的规则：\n1. defer函数的参数是在defer函数声明时的参数 import \u0026#34;fmt\u0026#34; func a() { i := 0 defer fmt.Println(i) i++ return } a() 0  2. defer函数的执行顺序与声明顺序相反，类似于栈 func b() { for i := 0; i \u0026lt; 4; i++ { defer fmt.Println(i) } } b() 3 2 1 0  3. defer函数可以读取函数的返回值 func c() (i int) { defer func() { i++ }() return 1 } c() 2  defer语句中的函数会在return语句更新返回值变量后再执行，又因为在函数中定义的匿名函数可以访问该函数包括返回值变量在内的所有变量，所以，对匿名函数采用defer机制，可以使其访问函数的返回值。\n被延迟执行的匿名函数甚至可以修改函数返回给调用者的返回值\nfunc triple(x int) ( result int){ defer func() {result += x}() return x*2 } fmt.Println(triple(4)) 12 3 \u0026lt;nil\u0026gt;  func triple(x int) ( result int){ defer func() {result += x}() return x*2 } fmt.Println(triple(4)) 12 3 \u0026lt;nil\u0026gt;  defer函数  可以用这种方法记录一个函数的运行时间\n func test(){ defer a()() // 这里后一个括号必须要加，否则a()返回的函数将不被执行  fmt.Println() } func a() func(){ fmt.Println(\u0026#34;h1\u0026#34;) return func(){fmt.Println(\u0026#34;h2\u0026#34;)} } test() h1 h2  循环体中的defer语句 在循环语句中的defer语句要特别注意，因为只有在函数执行完毕后，这些被延迟的函数才会执行。\n下面的代码将会导致系统的文件描述符耗尽，因为在所有文件都被处理之前， 没有文件会被关闭。\nfo _,filename := range filenames{ f, err := os.Open(filename) if err != nil { return err } defer f.close() descriptors //... } 一种解决办法是将循环体中的defer语句移至另外一个函数，在每次循环时，调用这个函数。\nfor _, filename := { if err := doFile(filename); err != nil { return err } } func doFile(filename string) error{ f, err := os.Open(filename) if err != nil { return err } defer f.Close() //...process } ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/defer%E7%94%A8%E6%B3%95/","summary":"defer用法 defer用来延迟对某个语句的调用，常用于处理成对的操作，如打开、关闭、连接、断开连接，加锁、释放锁。通过defer语句，无论函数逻辑多复杂，都能保证在任何代码执行路径下，资源被释放。defer应该直接跟在请求资源的语句后。\ndefer语句将函数的调用push到一个列表中，当外层函数返回时，会执行保存的函数列表\n举个例子，这个程序打开两个文件并将一个文件的内容复制到另一个文件的函数\nfunc CopyFile(dstName, srcName string) (written int64, err error) { src, err := os.Open(srcName) if err != nil { return } dst, err := os.Create(dstName) if err != nil { return } written, err = io.Copy(dst, src) dst.Close() src.Close() return } 这个函数似乎可以正常工作，但其实存在一个bug，如果对os.Create的调用失败，该函数将返回但却不关闭源文件，通过在第二个return语句中调用src.Close可以解决这个问题。但是如果函数更加复杂，问题可能不会那么容易被发现和解决。通过使用defer语句，可以确保始终关闭文件。\nfunc CopyFile(dstName, srcName string) (written int64, err error) { src, err := os.Open(srcName) if err != nil { return } defer src.Close() dst, err := os.","title":"defer用法"},{"content":"Did you install mysqlclient? 在进行新的django项目时出现了这个错误\n解决方法  确保pymysql和mysqlcient都安装 在和setting.py同级的init.py中加入  import pymysql pymysql.install_as_MySQLdb() ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/did-you-install-mysqlclient/","summary":"Did you install mysqlclient? 在进行新的django项目时出现了这个错误\n解决方法  确保pymysql和mysqlcient都安装 在和setting.py同级的init.py中加入  import pymysql pymysql.install_as_MySQLdb() ","title":"Did you install mysqlclient?"},{"content":"Django, Forms 使用forms完成了用户登录 1、创建model class User(User): pass  这里使用了django提供的User类，直接继承\n2、创建UserForm类 class SigninFrom(forms.Form): user_name = forms.CharField() user_email = forms.EmailField() user_password = forms.CharField() 3、完成模板 \u0026lt;form action=\u0026#34;{% url \u0026#39;permission:signin\u0026#39; %}\u0026#34; accept-charset=\u0026#34;UTF-8\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input name=\u0026#34;utf8\u0026#34; type=\u0026#34;hidden\u0026#34; value=\u0026#34;\u0026amp;#x2713;\u0026#34;/\u0026gt; {% csrf_token %} \u0026lt;dl class=\u0026#34;form-group mt-0\u0026#34;\u0026gt; \u0026lt;dt class=\u0026#34;input-label\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;form-label f5\u0026#34; for=\u0026#34;user[login]\u0026#34;\u0026gt;用户名\u0026lt;/label\u0026gt; \u0026lt;/dt\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;user_name\u0026#34; id=\u0026#34;user_name\u0026#34; class=\u0026#34;form-control form-control-lg input-block\u0026#34; placeholder=\u0026#34;{{ default_name }}\u0026#34; autofocus\u0026gt; \u0026lt;/dl\u0026gt; \u0026lt;dl class=\u0026#34;form-group\u0026#34;\u0026gt; \u0026lt;dt class=\u0026#34;input-label\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;form-label f5\u0026#34; for=\u0026#34;user[email]\u0026#34;\u0026gt;Email\u0026lt;/label\u0026gt; \u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;user_email\u0026#34; id=\u0026#34;user_email\u0026#34; class=\u0026#34;form-control form-control-lg input-block js-email-notice-trigger\u0026#34; placeholder=\u0026#34;you@example.com\u0026#34;\u0026gt; \u0026lt;/dd\u0026gt; \u0026lt;/dl\u0026gt; \u0026lt;dl class=\u0026#34;form-group\u0026#34;\u0026gt; \u0026lt;dt class=\u0026#34;input-label\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;form-label f5\u0026#34; for=\u0026#34;user[password]\u0026#34;\u0026gt;密码\u0026lt;/label\u0026gt; \u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt; \u0026lt;input type=\u0026#34;password\u0026#34; name=\u0026#34;user_password\u0026#34; id=\u0026#34;user_password\u0026#34; class=\u0026#34;form-control form-control-lg input-block\u0026#34; placeholder=\u0026#34;Create a password\u0026#34;\u0026gt; \u0026lt;/dd\u0026gt; \u0026lt;/dl\u0026gt; \u0026lt;button class=\u0026#34;btn-mktg btn-primary-mktg btn-large-mktg f4 btn-block\u0026#34; type=\u0026#34;submit\u0026#34; data-ga-click=\u0026#34;Signup, Attempt, location:teams;\u0026#34;\u0026gt;在Bodydetect上注册 \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt;  注意，这里三者要统一用一样的name，否则会接收不到数据  views.py如何编写 def fun(request): if request.method == \u0026#39;GET\u0026#39;: ... return ... if request.method == \u0026#39;POST\u0026#39;: ... return  使用forms.cleaned_data访问数据，返回字典类型  你还可以  从view中返回form，django会自动为你渲染，当然，十分丑陋  例如：\n\u0026lt;form action = \u0026#34;{% url \u0026#39;permission:signin\u0026#39; %}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; {% csrf_token %} \u0026lt;table\u0026gt; {{ form }} \u0026lt;/table\u0026gt; \u0026lt;button class=\u0026#34;btn-mktg btn-primary-mktg btn-large-mktg f4 btn-block\u0026#34; type=\u0026#34;submit\u0026#34; data-ga-click=\u0026#34;Signup, Attempt, location:teams;\u0026#34;\u0026gt;在Bodydetect上注册 \u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 只需要为form保留位置\n渲染结果：\n不使用自动渲染\n使用ModelForm类  views.py\n from django.db import models class Article(models.Model): author = models.CharField(max_length = 150) title = models.CharField(max_lengeth = 100) content = models.CharField(max_lengeth = 10000) time = models.TimeField( )  model.py\n from django.forms import ModelForm class Article(ModelForm): class Meta: model = Article fields = [\u0026#39;author\u0026#39;, \u0026#39;title\u0026#39;, \u0026#39;content\u0026#39;, \u0026#39;time\u0026#39;] save方法  每个ModelForm还有一个save()方法，此方法根据绑定到表单的数据创建并保存数据库对象。   # Create a form instance with POST data. \u0026gt;\u0026gt;\u0026gt; f = AuthorForm(request.POST) # Create, but don't save the new author instance. \u0026gt;\u0026gt;\u0026gt; new_author = f.save(commit=False) # Modify the author in some way. \u0026gt;\u0026gt;\u0026gt; new_author.some_field = 'some_value' # Save the new instance. \u0026gt;\u0026gt;\u0026gt; new_author.save() # Now, save the many-to-many data for the form. \u0026gt;\u0026gt;\u0026gt; f.save_m2m() Reference Django 教程 9: 使用表单\n从模型创建表单 | Django documentation | Django\nThe Forms API | Django documentation | Django\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/django-form/","summary":"Django, Forms 使用forms完成了用户登录 1、创建model class User(User): pass  这里使用了django提供的User类，直接继承\n2、创建UserForm类 class SigninFrom(forms.Form): user_name = forms.CharField() user_email = forms.EmailField() user_password = forms.CharField() 3、完成模板 \u0026lt;form action=\u0026#34;{% url \u0026#39;permission:signin\u0026#39; %}\u0026#34; accept-charset=\u0026#34;UTF-8\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026lt;input name=\u0026#34;utf8\u0026#34; type=\u0026#34;hidden\u0026#34; value=\u0026#34;\u0026amp;#x2713;\u0026#34;/\u0026gt; {% csrf_token %} \u0026lt;dl class=\u0026#34;form-group mt-0\u0026#34;\u0026gt; \u0026lt;dt class=\u0026#34;input-label\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;form-label f5\u0026#34; for=\u0026#34;user[login]\u0026#34;\u0026gt;用户名\u0026lt;/label\u0026gt; \u0026lt;/dt\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;user_name\u0026#34; id=\u0026#34;user_name\u0026#34; class=\u0026#34;form-control form-control-lg input-block\u0026#34; placeholder=\u0026#34;{{ default_name }}\u0026#34; autofocus\u0026gt; \u0026lt;/dl\u0026gt; \u0026lt;dl class=\u0026#34;form-group\u0026#34;\u0026gt; \u0026lt;dt class=\u0026#34;input-label\u0026#34;\u0026gt; \u0026lt;label class=\u0026#34;form-label f5\u0026#34; for=\u0026#34;user[email]\u0026#34;\u0026gt;Email\u0026lt;/label\u0026gt; \u0026lt;/dt\u0026gt; \u0026lt;dd\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; name=\u0026#34;user_email\u0026#34; id=\u0026#34;user_email\u0026#34; class=\u0026#34;form-control form-control-lg input-block js-email-notice-trigger\u0026#34; placeholder=\u0026#34;you@example.","title":"Django,Forms"},{"content":"django中forms的定义 直接定义 class ContactForm(forms.Form): date = DateField(widget=CalendarWidget) name = CharField(max_length=40, widget=OtherWidget) widget参数定义了要使用的小部件，小部件选项可见这里\n通过模型定义 必须继承ModelForm类\nfrom django.forms import ModelForm class BlogForm(ModelForm): class Meta: model = Blog fields = [\u0026#39;author\u0026#39;, \u0026#39;essay\u0026#39;, \u0026#39;title\u0026#39;, \u0026#39;label\u0026#39;, \u0026#39;cover\u0026#39;] widgets = { \u0026#39;essay\u0026#39;: CKEditorWidget, \u0026#39;cover\u0026#39;: } 通过定义内部类来生命form的属性\n 常用内部类参数说明：\nmodel: 说明要继承的模型\nfield：说明要在表单中显示的字段，__all__表示所有\nexclude: 要从表单中排除的字段\nwidgets: 设置字段的小部件\n（详细文档）\n ","permalink":"http://yangchnet.github.io/Dessert/posts/django/django%E4%B8%ADform%E7%9A%84%E5%AE%9A%E4%B9%89/","summary":"django中forms的定义 直接定义 class ContactForm(forms.Form): date = DateField(widget=CalendarWidget) name = CharField(max_length=40, widget=OtherWidget) widget参数定义了要使用的小部件，小部件选项可见这里\n通过模型定义 必须继承ModelForm类\nfrom django.forms import ModelForm class BlogForm(ModelForm): class Meta: model = Blog fields = [\u0026#39;author\u0026#39;, \u0026#39;essay\u0026#39;, \u0026#39;title\u0026#39;, \u0026#39;label\u0026#39;, \u0026#39;cover\u0026#39;] widgets = { \u0026#39;essay\u0026#39;: CKEditorWidget, \u0026#39;cover\u0026#39;: } 通过定义内部类来生命form的属性\n 常用内部类参数说明：\nmodel: 说明要继承的模型\nfield：说明要在表单中显示的字段，__all__表示所有\nexclude: 要从表单中排除的字段\nwidgets: 设置字段的小部件\n（详细文档）\n ","title":"django中forms的定义"},{"content":"django中使用highchart 引入js文件  顺序不能错\n \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.1.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://code.highcharts.com/highcharts.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 一点小插曲 在刚开始使用highchart时，由于使用的是继承模板，导致js文件引入的顺序没有把握好，导致不能显示图像，因此将上面两句提到base.html的前面，然后可以显示图像。\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/django%E4%B8%AD%E4%BD%BF%E7%94%A8highchart/","summary":"django中使用highchart 引入js文件  顺序不能错\n \u0026lt;script src=\u0026#34;https://code.jquery.com/jquery-3.1.1.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;https://code.highcharts.com/highcharts.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; 一点小插曲 在刚开始使用highchart时，由于使用的是继承模板，导致js文件引入的顺序没有把握好，导致不能显示图像，因此将上面两句提到base.html的前面，然后可以显示图像。","title":"django中使用highchart"},{"content":"Django 中图像的处理方法 图像的上传保存  前端图片的上传：  \u0026lt;form action=\u0026#34;/updateinfo\u0026#34; method=\u0026#34;POST\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;updateImg\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;{{ account.photo.url }}\u0026#34; alt=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;input name=\u0026#34;photo\u0026#34; type=\u0026#34;file\u0026#34; id=\u0026#34;exampleInputFile\u0026#34;\u0026gt; \u0026lt;button id=\u0026#34;photo\u0026#34; class=\u0026#34;btn btn-danger\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt;上传头像\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 其中input标签的type为file， 2. 图片模型\nmodels.ImageField(upload_to=\u0026lsquo;path\u0026rsquo;) upload_to的储存路径是相对于MEDIA_ROOT而来的，若MEDIA_ROOT为/media/，upload_to路径为image，则图片上传后的储存路径为/media/image\n在前端显示上传的图片 {% load static %} \u0026lt;body data-media-url=\u0026#34;{% get_media_prefix %}\u0026#34;\u0026gt; 使用get_media_prefxi模板tag，代表MEDIA_URL变量\n\u0026lt;img src=\u0026#34;{% get_media_prefix %}/{{ page.cover }}\u0026#34; alt = \u0026#34;{{ page.cover }}\u0026#34;\u0026gt;  存在的问题  每个用户上传的图片集中在一个文件夹下，容易造成命名冲突，\n可参考这里\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/%E5%9B%BE%E5%83%8F%E7%9A%84%E4%B8%8A%E4%BC%A0%E4%BF%9D%E5%AD%98%E6%98%BE%E7%A4%BA/","summary":"Django 中图像的处理方法 图像的上传保存  前端图片的上传：  \u0026lt;form action=\u0026#34;/updateinfo\u0026#34; method=\u0026#34;POST\u0026#34; enctype=\u0026#34;multipart/form-data\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;updateImg\u0026#34;\u0026gt; \u0026lt;img src=\u0026#34;{{ account.photo.url }}\u0026#34; alt=\u0026#34;\u0026#34;/\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;input name=\u0026#34;photo\u0026#34; type=\u0026#34;file\u0026#34; id=\u0026#34;exampleInputFile\u0026#34;\u0026gt; \u0026lt;button id=\u0026#34;photo\u0026#34; class=\u0026#34;btn btn-danger\u0026#34; type=\u0026#34;submit\u0026#34;\u0026gt;上传头像\u0026lt;/button\u0026gt; \u0026lt;/form\u0026gt; 其中input标签的type为file， 2. 图片模型\nmodels.ImageField(upload_to=\u0026lsquo;path\u0026rsquo;) upload_to的储存路径是相对于MEDIA_ROOT而来的，若MEDIA_ROOT为/media/，upload_to路径为image，则图片上传后的储存路径为/media/image\n在前端显示上传的图片 {% load static %} \u0026lt;body data-media-url=\u0026#34;{% get_media_prefix %}\u0026#34;\u0026gt; 使用get_media_prefxi模板tag，代表MEDIA_URL变量\n\u0026lt;img src=\u0026#34;{% get_media_prefix %}/{{ page.cover }}\u0026#34; alt = \u0026#34;{{ page.cover }}\u0026#34;\u0026gt;  存在的问题  每个用户上传的图片集中在一个文件夹下，容易造成命名冲突，\n可参考这里","title":"Django中图像的处理方法"},{"content":"Docker 搭建Java环境 1. 拉取Ubuntu镜像 docker pull ubuntu 2. 运行docker镜像，并进入 docker run -it -v /home/hadoop/build:/root/build --name ubuntu ubuntu  -i 表示Interaction，交互，开启交互模式\n-t 表示分配一个tty，即控制台\n-v 分配一个共享目录，\n\u0026ndash;name 为镜像命名\n 3. 基本操作  首先更新源，并安装vim  apt-get update apt-get install vim  为保证后面的软件安装速度，进行换源\n打开/etc/apt/sources.list，将其中的内容替换为：  deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiverse 然后进行源更新\napt-get update apt-get upgrade 4. 安装jdk apt-get install openjdk-8-jdk 设置环境变量vim ~/.bashrc\nexport JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64/ export PATH=$PATH:$JAVA_HOME/bin source ~/.bashrc 5. 安装mysql apt-get update apt-get install mysql-server 安装完成后并不知道MySQL的初始密码，可在/etc/mysql/debian.cnf寻找\nuser = debian-sys-maint password = xXI6LBYyXzeWAwYj 这就是mysql初始的用户与密码\n使用\nmysql -u debian-sys-maint -p 登录，其密码为xXI6LBYyXzeWAwYj\n若出现ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2)，则可能是mysql服务尚未打开，可使用/etc/init.d/mysql start打开，同时可将/etc/init.d/mysql start添加到~/.bashrc，以开机启动。\n为mysql添加root用户\nmysql\u0026gt;set password for \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; = password(\u0026#39;123456\u0026#39;); Query OK, 0 rows affected (0.00 sec) 更改root用户的访问位置\nuse mysql; update user set host = '%' where user = 'root'; 改为%代表可在任何位置，原来是localhost，也就是只能本机访问\n6. 安装tomcat 将下载好的tomcat安装包通过共享文件夹保存到docker容器的/root/build\n解压到/usr/local\ntar -zxvf apache-tomcat-7.0.77.tar.gz -C /usr/local cd /usr/local mv apache-tomcat-7.0.77.tar.gz tomcat7 设置环境变量\nCATALINA_HOME=/usr/local/tomcat7 export CATALINA_HOME 设置tomcat\nvim /usr/local/tomcat7/bin/catalina.sh 在其中增加\nCATALINA_HOME=/usr/local/tomcat7 JAVA_HOME=/usr/local/java/jdk1.8.0_121 # 这个要根据自己的来 启动tomcat\nsudo ./bin/startup.sh 可将其写入~/.bashrc开机启动\n","permalink":"http://yangchnet.github.io/Dessert/posts/%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%AE%B9%E5%99%A8/%E5%AE%89%E8%A3%85java%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","summary":"Docker 搭建Java环境 1. 拉取Ubuntu镜像 docker pull ubuntu 2. 运行docker镜像，并进入 docker run -it -v /home/hadoop/build:/root/build --name ubuntu ubuntu  -i 表示Interaction，交互，开启交互模式\n-t 表示分配一个tty，即控制台\n-v 分配一个共享目录，\n\u0026ndash;name 为镜像命名\n 3. 基本操作  首先更新源，并安装vim  apt-get update apt-get install vim  为保证后面的软件安装速度，进行换源\n打开/etc/apt/sources.list，将其中的内容替换为：  deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiverse deb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse deb http://mirrors.","title":"Docker 搭建Java环境"},{"content":"docker常用操作  启动docker服务 sudo systemctl start docker 查看本地镜像 sudo docker images 查看正在运行的镜像 sudo docker ps 查看所有镜像 sudo docker ps -a 停止正在运行的镜像 sudo docker stop container_name 开始运行某个镜像 sudo docker start container_name 删除某个镜像 sudo docker rmi container_name 进入某个正在运行的镜像 sudo docker attach container_name 导出容器 sudo docker export container_id \u0026gt; name.tar 导入容器 cat name.tar | sudo docker import -test/buntu:v1.0 从网络导入 sudo docker import http://example.com/exampleimage.tgz example/imagerepo  ","permalink":"http://yangchnet.github.io/Dessert/posts/%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%AE%B9%E5%99%A8/docker/","summary":"docker常用操作  启动docker服务 sudo systemctl start docker 查看本地镜像 sudo docker images 查看正在运行的镜像 sudo docker ps 查看所有镜像 sudo docker ps -a 停止正在运行的镜像 sudo docker stop container_name 开始运行某个镜像 sudo docker start container_name 删除某个镜像 sudo docker rmi container_name 进入某个正在运行的镜像 sudo docker attach container_name 导出容器 sudo docker export container_id \u0026gt; name.tar 导入容器 cat name.tar | sudo docker import -test/buntu:v1.0 从网络导入 sudo docker import http://example.com/exampleimage.tgz example/imagerepo  ","title":"docker常用操作"},{"content":"1、docker的安装（Ubuntu) 1.1、 设置存储库  若是已安装旧版本的docker，\n请卸载：sudo apt-get remove docker docker-engine docker.io containerd runc\n 1.1.1、更新apt索引 sudo apt-get update 1.1.2、安装依赖 sudo apt-get install \\  apt-transport-https \\  ca-certificates \\  curl \\  gnupg-agent \\  software-properties-common 1.1.3、添加docker官方的GPG秘钥 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -  在进行此步时，出现了sudo: unable to resolve host iZ2ze4512bfzoapfvch6btZ，这是因为机器不能反向解析\n打开主机上的 /etc/hosts\n添加： 127.0.0.1 【hostname】# 【hostname】用主机名替代\n可在/etc/hostname中修改主机名，sudo shutdown -r now重启过后完成主机名修改\n 验证添加成功：\nsudo apt-key fingerprint 0EBFCD88 1.1.4、 设置存储库 sudo add-apt-repository \u0026quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) \\stable\u0026quot; 1.2、安装dockerCE 1.2.1 更新apt索引 sudo apt-get update 1.2.2、安装最新版本的dockerCE和containerd sudo apt-get install docker-ce docker-ce-cli containerd.io 1.2.3、通过运行hello-world验证是否正确安装了dockerCE sudo docker run hello-world 1.2.4、卸载dockerCE 1、卸载dockerCE软件包\nsudo apt-get purge docker-ce 2、主机上的图像，容器，卷或自定义配置文件不会自动删除。要删除所有图像，容器和卷：\nsudo rm -rf /var/lib/docker 1.3、在docker中运行应用 1.3.1、创建工作目录 mkdir dockerwork 进入：\ncd dockerwork 1.3.2、 创建DockerFile 内容如下：\nUse an official Python runtime as a parent image FROM python:2.7-slim # Set the working directory to /app  WORKDIR /app # Copy the current directory contents into the container at /app  COPY . /app # Install any needed packages specified in requirements.txt  RUN pip install --trusted-host pypi.python.org -r requirements.txt # Make port 80 available to the world outside this container  EXPOSE 80 # Define environment variable  ENV NAME World # Run app.py when the container launches  CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] 有关DockerFile的解释可见这里\n 其中 WORKDIR表示工作目录， COPY是把当前目录下（.）的内容复制到 /app\n 其中包含两个未建立的文件：requirements.txt \u0026amp; app.py 其内容如下：\n requirements.txt\n Flask Redis  app.py\n from flask import Flask from redis import Redis, RedisError import os import socket # Connect to Redis redis = Redis(host=\u0026#34;redis\u0026#34;, db=0, socket_connect_timeout=2, socket_timeout=2) app = Flask(__name__) @app.route(\u0026#34;/\u0026#34;) def hello(): try: visits = redis.incr(\u0026#34;counter\u0026#34;) except RedisError: visits = \u0026#34;\u0026lt;i\u0026gt;cannot connect to Redis, counter disabled\u0026lt;/i\u0026gt;\u0026#34; html = \u0026#34;\u0026lt;h3\u0026gt;Hello {name}!\u0026lt;/h3\u0026gt;\u0026#34; \\ \u0026#34;\u0026lt;b\u0026gt;Hostname:\u0026lt;/b\u0026gt; {hostname}\u0026lt;br/\u0026gt;\u0026#34; \\ \u0026#34;\u0026lt;b\u0026gt;Visits:\u0026lt;/b\u0026gt; {visits}\u0026#34; return html.format(name=os.getenv(\u0026#34;NAME\u0026#34;, \u0026#34;world\u0026#34;), hostname=socket.gethostname(), visits=visits) if __name__ == \u0026#34;__main__\u0026#34;: app.run(host=\u0026#39;0.0.0.0\u0026#39;, port=80) 1.3.3、构建应用程序 docker build --tag=friendlyhello . 1.3.4、运行应用程序 docker run -p 4000:80 friendlyhello  这是运行一般程序的步骤，要构建django项目，请到这里\n ","permalink":"http://yangchnet.github.io/Dessert/posts/%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%AE%B9%E5%99%A8/docker-%E7%AC%AC%E4%B8%80%E7%AF%87/","summary":"1、docker的安装（Ubuntu) 1.1、 设置存储库  若是已安装旧版本的docker，\n请卸载：sudo apt-get remove docker docker-engine docker.io containerd runc\n 1.1.1、更新apt索引 sudo apt-get update 1.1.2、安装依赖 sudo apt-get install \\  apt-transport-https \\  ca-certificates \\  curl \\  gnupg-agent \\  software-properties-common 1.1.3、添加docker官方的GPG秘钥 curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -  在进行此步时，出现了sudo: unable to resolve host iZ2ze4512bfzoapfvch6btZ，这是因为机器不能反向解析\n打开主机上的 /etc/hosts\n添加： 127.0.0.1 【hostname】# 【hostname】用主机名替代\n可在/etc/hostname中修改主机名，sudo shutdown -r now重启过后完成主机名修改\n 验证添加成功：\nsudo apt-key fingerprint 0EBFCD88 1.1.4、 设置存储库 sudo add-apt-repository \u0026quot;deb [arch=amd64] https://download.","title":"docker的安装（Ubuntu)"},{"content":"Flag包的基本用法  flag包用于处理golang命令行程序中的参数\n 1. 使用flag包的基本流程 使用flag包涉及三个步骤：\n 定义变量以捕获标志值 定义Go应用程序将使用的标志 在执行时解析提供给应用程序的标志。  flag软件包中的大多数功能都与定义标志并将其绑定到定义的变量有关。解析阶段由Parse()函数处理。\n一个例子 创建一个程序，该程序定义一个布尔标志，该标志会更改将打印到标准输出的消息。如果-color提供了一个标志，程序将以蓝色打印一条消息。如果未提供标志，则消息将被打印为没有任何颜色。\n// boolean.go import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; ) type Color string // 定义变量以捕获标志值  const ( ColorBlack Color = \u0026#34;\\u001b[30m\u0026#34; ColorRed = \u0026#34;\\u001b[31m\u0026#34; ColorGreen = \u0026#34;\\u001b[32m\u0026#34; ColorYellow = \u0026#34;\\u001b[33m\u0026#34; ColorBlue = \u0026#34;\\u001b[34m\u0026#34; ColorReset = \u0026#34;\\u001b[0m\u0026#34; ) func colorize(color Color, message string) { fmt.Println(string(color), message, string(ColorReset)) } func main() { useColor := flag.Bool(\u0026#34;color\u0026#34;, false, \u0026#34;display colorized output\u0026#34;) // 定义Go应用程序将使用的标志  flag.Parse() // 解析标志  if *useColor { colorize(ColorBlue, \u0026#34;Hello, DigitalOcean!\u0026#34;) return } fmt.Println(\u0026#34;Hello, DigitalOcean!\u0026#34;) } 在main函数中，使用flag.Bool定义了一个布尔型的标志color，其默认值为第二个参数false，在未提供color参数时将默认使用此值。最后一个参数是关于此标志用法的说明文档。\nflag.Bool返回值是一个bool指针类型，flag.Parse使用此bool指针根据用户传递的标志来设置变量。然后我们就可以通过引用这个指针来检查这个变量，通过变量的值控制程序的行为。\n2. 处理位置参数 通常，命令带有一定的参数，并且这些参数是命令工作的焦点所在，例如：python main.py,这里的main.py就是一个位置参数，是python这个命令的第一个参数。\n假如我们有个命令head，它打印一个文件的开始几行，用法为：head {inputfile}。\n通常，Parse()函数解析一个命令直到其检查到没有标志参数的存在。flag包通过Args和Arg函数来解决位置参数的问题。\n// head.go import ( \u0026#34;bufio\u0026#34; \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; ) func main() { var count int flag.IntVar(\u0026amp;count, \u0026#34;n\u0026#34;, 5, \u0026#34;number of lines to read from the file\u0026#34;) flag.Parse() var in io.Reader if filename := flag.Arg(0); filename != \u0026#34;\u0026#34; { f, err := os.Open(filename) if err != nil { fmt.Println(\u0026#34;error opening file: err:\u0026#34;, err) os.Exit(1) } defer f.Close() in = f } else { in = os.Stdin } buf := bufio.NewScanner(in) for i := 0; i \u0026lt; count; i++ { if !buf.Scan() { break } fmt.Println(buf.Text()) } if err := buf.Err(); err != nil { fmt.Fprintln(os.Stderr, \u0026#34;error reading: err:\u0026#34;, err) } } 首先，我们定义了一个count变量来标记程序需要读取文件的前几行。通过flag.IntVar定义了-n参数。这个函数允许我们传递一个指针作为标记而不是像没有Var后缀的函数那样返回一个指针。flag.IntVar和flag.Int之间除了这一点不同外，其余参数的意义都相同。在使用flag.Parse解析后，接下来是根据参数来控制程序逻辑。\n在if部分，使用flag.Arg来访问在所有标志参数之后的第一个位置参数。\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/flag%E5%8C%85%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%94%A8%E6%B3%95/","summary":"Flag包的基本用法  flag包用于处理golang命令行程序中的参数\n 1. 使用flag包的基本流程 使用flag包涉及三个步骤：\n 定义变量以捕获标志值 定义Go应用程序将使用的标志 在执行时解析提供给应用程序的标志。  flag软件包中的大多数功能都与定义标志并将其绑定到定义的变量有关。解析阶段由Parse()函数处理。\n一个例子 创建一个程序，该程序定义一个布尔标志，该标志会更改将打印到标准输出的消息。如果-color提供了一个标志，程序将以蓝色打印一条消息。如果未提供标志，则消息将被打印为没有任何颜色。\n// boolean.go import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; ) type Color string // 定义变量以捕获标志值  const ( ColorBlack Color = \u0026#34;\\u001b[30m\u0026#34; ColorRed = \u0026#34;\\u001b[31m\u0026#34; ColorGreen = \u0026#34;\\u001b[32m\u0026#34; ColorYellow = \u0026#34;\\u001b[33m\u0026#34; ColorBlue = \u0026#34;\\u001b[34m\u0026#34; ColorReset = \u0026#34;\\u001b[0m\u0026#34; ) func colorize(color Color, message string) { fmt.Println(string(color), message, string(ColorReset)) } func main() { useColor := flag.Bool(\u0026#34;color\u0026#34;, false, \u0026#34;display colorized output\u0026#34;) // 定义Go应用程序将使用的标志  flag.","title":"Flag包的基本用法"},{"content":"Github API问题 使用github的RESTful API 访问https://developer.github.com/v3/来查看帮助文档\nAPI访问限制 在云服务器上使用git的API时，发现出现message\u0026quot;:\u0026quot;API rate limit exceeded for 59.110.140.133. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\u0026quot;,\u0026quot;documentation_url\u0026quot;:\u0026quot;https://developer.github.com/v3/#rate-limiting提示信息，显然，这是存在着访问限制。\n查看访问限制 使用curl -i https://api.github.com/rate_limit查看自己的限制信息\nHTTP/1.1 200 OK Content-Type: application/json X-Ratelimit-Limit: 60 X-Ratelimit-Remaining: 59 X-Ratelimit-Reset: 1585470905 Date: Sun, 29 Mar 2020 07:49:35 GMT Content-Length: 482 Accept-Ranges: bytes X-GitHub-Request-Id: BB32:30AB:3EF690:50F336:5E80530E { \u0026#34;resources\u0026#34;: { \u0026#34;core\u0026#34;: { \u0026#34;limit\u0026#34;: 60, \u0026#34;remaining\u0026#34;: 59, \u0026#34;reset\u0026#34;: 1585470905 }, \u0026#34;graphql\u0026#34;: { \u0026#34;limit\u0026#34;: 0, \u0026#34;remaining\u0026#34;: 0, \u0026#34;reset\u0026#34;: 1585471775 }, \u0026#34;integration_manifest\u0026#34;: { \u0026#34;limit\u0026#34;: 5000, \u0026#34;remaining\u0026#34;: 5000, \u0026#34;reset\u0026#34;: 1585471775 }, \u0026#34;search\u0026#34;: { \u0026#34;limit\u0026#34;: 10, \u0026#34;remaining\u0026#34;: 10, \u0026#34;reset\u0026#34;: 1585468235 } }, \u0026#34;rate\u0026#34;: { \u0026#34;limit\u0026#34;: 60, \u0026#34;remaining\u0026#34;: 59, \u0026#34;reset\u0026#34;: 1585470905 } } rate.limit 为60次，访问60次后就被限制，很显然不太够用\n提高访问限制 通过在github注册应用程序，可提高到每小时5000次访问，一般应用程序足够了 在https://github.com/settings/applications/new注册应用程序\n就可以得到client_id和client_secret\n使用curl -u my_client_id:my_client_secret 'https://api.github.com/user/repos'进行身份验证，然后即可\n","permalink":"http://yangchnet.github.io/Dessert/posts/git/api%E9%99%90%E5%88%B6%E9%97%AE%E9%A2%98/","summary":"Github API问题 使用github的RESTful API 访问https://developer.github.com/v3/来查看帮助文档\nAPI访问限制 在云服务器上使用git的API时，发现出现message\u0026quot;:\u0026quot;API rate limit exceeded for 59.110.140.133. (But here's the good news: Authenticated requests get a higher rate limit. Check out the documentation for more details.)\u0026quot;,\u0026quot;documentation_url\u0026quot;:\u0026quot;https://developer.github.com/v3/#rate-limiting提示信息，显然，这是存在着访问限制。\n查看访问限制 使用curl -i https://api.github.com/rate_limit查看自己的限制信息\nHTTP/1.1 200 OK Content-Type: application/json X-Ratelimit-Limit: 60 X-Ratelimit-Remaining: 59 X-Ratelimit-Reset: 1585470905 Date: Sun, 29 Mar 2020 07:49:35 GMT Content-Length: 482 Accept-Ranges: bytes X-GitHub-Request-Id: BB32:30AB:3EF690:50F336:5E80530E { \u0026#34;resources\u0026#34;: { \u0026#34;core\u0026#34;: { \u0026#34;limit\u0026#34;: 60, \u0026#34;remaining\u0026#34;: 59, \u0026#34;reset\u0026#34;: 1585470905 }, \u0026#34;graphql\u0026#34;: { \u0026#34;limit\u0026#34;: 0, \u0026#34;remaining\u0026#34;: 0, \u0026#34;reset\u0026#34;: 1585471775 }, \u0026#34;integration_manifest\u0026#34;: { \u0026#34;limit\u0026#34;: 5000, \u0026#34;remaining\u0026#34;: 5000, \u0026#34;reset\u0026#34;: 1585471775 }, \u0026#34;search\u0026#34;: { \u0026#34;limit\u0026#34;: 10, \u0026#34;remaining\u0026#34;: 10, \u0026#34;reset\u0026#34;: 1585468235 } }, \u0026#34;rate\u0026#34;: { \u0026#34;limit\u0026#34;: 60, \u0026#34;remaining\u0026#34;: 59, \u0026#34;reset\u0026#34;: 1585470905 } } rate.","title":"GithubAPI问题"},{"content":"go get 没反应 修改hosts，然后reboot 添加\n192.30.253.112 github.com 151.101.185.194 github.global.ssl.fastly.net 到/etc/hosts 然后reboot\ngo get golang.org 在使用go get golang.org/...时，总是time out（就算fp也一样，fp之后可以访问golang.org），不知道为啥。\n幸好github上存在golang.org的镜像\n例如\ngo get -u golang.org/x/net 那么这个包的位置在github上就是github.com/golang/net, 所以，我们可以手动建立golang.org/x/目录，并切换到该目录下，然后使用\ngit clone https://github.com/golang/net.git **注意：**要使用git clone命令，直接下载下来复制到目录下会提示找不到版本号。\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/go-get-%E6%B2%A1%E5%8F%8D%E5%BA%94/","summary":"go get 没反应 修改hosts，然后reboot 添加\n192.30.253.112 github.com 151.101.185.194 github.global.ssl.fastly.net 到/etc/hosts 然后reboot\ngo get golang.org 在使用go get golang.org/...时，总是time out（就算fp也一样，fp之后可以访问golang.org），不知道为啥。\n幸好github上存在golang.org的镜像\n例如\ngo get -u golang.org/x/net 那么这个包的位置在github上就是github.com/golang/net, 所以，我们可以手动建立golang.org/x/目录，并切换到该目录下，然后使用\ngit clone https://github.com/golang/net.git **注意：**要使用git clone命令，直接下载下来复制到目录下会提示找不到版本号。","title":"goget没反应"},{"content":"golang中的print系函数详解 pirnt系函数来自fmt包，主要用于做各种格式的输出 这些函数主要有\n golang中的print系函数详解  fmt.Fprintf fmt.Printf fmt.Sprintf fmt.Fprint fmt.Print fmt.Sprint fmt.Fprintln fmt.Println fmt.Sprintln 总结    下面来逐个分析\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;io\u0026#34; ) fmt.Fprintf  函数原型：  Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error)   官方注释 Fprintf formats according to a format specifier and writes to w.It returns the number of bytes written and any write error encountered.\n  Arguement\nfmt.Fprintf() 依据指定的格式向第一个参数内写入字符串，第一参数必须实现了 io.Writer 接口。Fprintf() 能够写入任何类型，只要其实现了 Write 方法，包括 os.Stdout,文件（例如 os.File），管道，网络连接，通道等等，同样的也可以使用 bufio 包中缓冲写入。bufio 包中定义了 type Writer struct{...}。Fprintf：来格式化并输出到 io.Writers 而不是 os.Stdout。\n  // example func ExampleFprintf() { const name, age = \u0026#34;Kim\u0026#34;, 22 n, err := fmt.Fprintf(os.Stdout, \u0026#34;%s is %d years old.\\n\u0026#34;, name, age) // The n and err return values from Fprintf are \t// those returned by the underlying io.Writer. \tif err != nil { fmt.Fprintf(os.Stderr, \u0026#34;Fprintf: %v\\n\u0026#34;, err) } fmt.Printf(\u0026#34;%d bytes written.\\n\u0026#34;, n) // Output: \t// Kim is 22 years old. \t// 21 bytes written. } ExampleFprintf() Kim is 22 years old. 21 bytes written.  fmt.Printf  函数原型  Printf(format string, a ...interface{}) (n int, err error)   官方注释\nPrintf formats according to a format specifier and writes to standard output.It returns the number of bytes written and any write error encountered.\n  Arguement\n只可以打印出格式化的字符串。只可以直接输出字符串类型的变量（不可以输出整形变量和整形 等），其实这个函数是fmt.Fprintf的调用，其调用语句return Fprintf(os.Stdout, format, a...)，输出对象为标准输出。\n  optional\n     optional description     %d 十进制整数   %x, %o, %b 十六进制，八进制，二进制整数   %f, %g, %e 浮点数，3.141593 3.141592653589793 3.141593e+00   %t 布尔 ture或false   %c 字符（rune）（Uniode码点）   %s 字符串   %q 带双引号的字符串\u0026quot;abc\u0026quot;或带单引号的字符\u0026rsquo;c'   %v 变量的自然形式   %T 变量的类型   %% 字面上的百分号标志（无操作数）    fmt.Printf(\u0026#34;整数：%d\\t浮点数：%v\\t字符串：%s\\n\u0026#34;, 1, 3.14, \u0026#34;hello world\u0026#34;) func ExamplePrintf() { const name, age = \u0026#34;Kim\u0026#34;, 22 fmt.Printf(\u0026#34;%s is %d years old.\\n\u0026#34;, name, age) // It is conventional not to worry about any \t// error returned by Printf.  // Output: \t// Kim is 22 years old. } ExamplePrintf() 整数：1\t浮点数：3.14\t字符串：hello world Kim is 22 years old.  fmt.Sprintf  函数原型  func Sprintf(format string, a ...interface{}) string   官方注释\nSprintf formats according to a format specifier and returns the resulting string.\n  Argument\n格式化并返回一个字符串而不带任何输出。可用于给其他函数传递格式化参数。\n  func ExampleSprintf() { const name, age = \u0026#34;Kim\u0026#34;, 22 s := fmt.Sprintf(\u0026#34;%s is %d years old.\\n\u0026#34;, name, age) io.WriteString(os.Stdout, s) // Ignoring error for simplicity.  // Output: \t// Kim is 22 years old. } ExampleSprintf() Kim is 22 years old.  fmt.Fprint  函数原型  Fprint(w io.Writer, a ...interface{}) (n int, err error)   官方注释\nFprint formats using the default formats for its operands and writes to w.Spaces are added between operands when neither is a string.It returns the number of bytes written and any write error encountered.\n  Argument\n向io.Writer对象中输入字符，第一个参数为输入对象，后面的参数为字符串，直接输出\n  func ExampleFprint() { const name, age = \u0026#34;Kim\u0026#34;, 22 n, err := fmt.Fprint(os.Stdout, name, \u0026#34; is \u0026#34;, age, \u0026#34; years old.\\n\u0026#34;) // The n and err return values from Fprint are \t// those returned by the underlying io.Writer. \tif err != nil { fmt.Fprintf(os.Stderr, \u0026#34;Fprint: %v\\n\u0026#34;, err) } fmt.Print(n, \u0026#34; bytes written.\\n\u0026#34;) // Output: \t// Kim is 22 years old. \t// 21 bytes written. } ExampleFprint() Kim is 22 years old. 21 bytes written.  fmt.Print  函数原型  func Print(a ...interface{}) (n int, err error) { return Fprint(os.Stdout, a...) }   官方注释\nPrint formats using the default formats for its operands and writes to standard output.Spaces are added between operands when neither is a string.It returns the number of bytes written and any write error encountered.\n  Arguement\n显然，这个函数是对fmt.Fprint的调用，只是把输入对象默认为标准输出。\n  func ExamplePrint() { const name, age = \u0026#34;Kim\u0026#34;, 22 fmt.Print(name, \u0026#34; is \u0026#34;, age, \u0026#34; years old.\\n\u0026#34;) // It is conventional not to worry about any \t// error returned by Print.  // Output: \t// Kim is 22 years old. } ExamplePrint() Kim is 22 years old.  fmt.Sprint  函数原型  Sprint(a ...interface{}) string   官方注释\nSprint formats using the default formats for its operands and returns the resulting string.Spaces are added between operands when neither is a string.\n  Arguement\n格式化并返回一个字符串而不带任何输出\n  func ExampleSprint() { const name, age = \u0026#34;Kim\u0026#34;, 22 s := fmt.Sprint(name, \u0026#34; is \u0026#34;, age, \u0026#34; years old.\\n\u0026#34;) io.WriteString(os.Stdout, s) // Ignoring error for simplicity.  // Output: \t// Kim is 22 years old. } ExampleSprint() Kim is 22 years old.  fmt.Fprintln  函数原型  Fprintln(w io.Writer, a ...interface{}) (n int, err error)   官方注释\nFprintln formats using the default formats for its operands and writes to w.Spaces are always added between operands and a newline is appended.It returns the number of bytes written and any write error encountered.\n  Arguement\n输入字符串到io.Writer,并且带有换行\n  func ExampleFprintln() { const name, age = \u0026#34;Kim\u0026#34;, 22 n, err := fmt.Fprintln(os.Stdout, name, \u0026#34;is\u0026#34;, age, \u0026#34;years old.\u0026#34;) // The n and err return values from Fprintln are \t// those returned by the underlying io.Writer. \tif err != nil { fmt.Fprintf(os.Stderr, \u0026#34;Fprintln: %v\\n\u0026#34;, err) } fmt.Println(n, \u0026#34;bytes written.\u0026#34;) // Output: \t// Kim is 22 years old. \t// 21 bytes written. } ExampleFprintln() Kim is 22 years old. 21 bytes written.  fmt.Println  函数原型  func Println(a ...interface{}) (n int, err error) { return Fprintln(os.Stdout, a...) }   官方注释\nPrintln formats using the default formats for its operands and writes to standard output.Spaces are always added between operands and a newline is appended.It returns the number of bytes written and any write error encountered.\n  Arguement\n显然这个函数是对fmt.Fprintln的调用，输入到os.Stdout\n  func ExamplePrintln() { const name, age = \u0026#34;Kim\u0026#34;, 22 fmt.Println(name, \u0026#34;is\u0026#34;, age, \u0026#34;years old.\u0026#34;) // It is conventional not to worry about any \t// error returned by Println.  // Output: \t// Kim is 22 years old. } ExamplePrintln() Kim is 22 years old.  fmt.Sprintln  函数原型  Sprintln(a ...interface{}) string   官方注释 Sprintln formats using the default formats for its operands and returns the resulting string.Spaces are always added between operands and a newline is appended.\n  Arguement\n返回一个字符串，不做任何输出\n  func ExampleSprintln() { const name, age = \u0026#34;Kim\u0026#34;, 22 s := fmt.Sprintln(name, \u0026#34;is\u0026#34;, age, \u0026#34;years old.\u0026#34;) io.WriteString(os.Stdout, s) // Ignoring error for simplicity.  // Output: \t// Kim is 22 years old. } ExampleSprintln() Kim is 22 years old.  总结 所有的函数名都是_print_格式的，其中_代表某个标志，标志及其含义如下：\n   标志 含义     _f 格式化   _ln 换行   F_ 输入到某个对象   S_ 只返回而不做输出    且，\nfmt.Fprintf和fmt.Printf是一对 fmt.Fprint和fmt.Print是一对\nfmt.Fprintln和fmt.Println是一对 不带F前缀的函数均是对带F前缀函数的调用，其输入对象均设置为标准输出\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/golang%E4%B9%8Bprint/","summary":"golang中的print系函数详解 pirnt系函数来自fmt包，主要用于做各种格式的输出 这些函数主要有\n golang中的print系函数详解  fmt.Fprintf fmt.Printf fmt.Sprintf fmt.Fprint fmt.Print fmt.Sprint fmt.Fprintln fmt.Println fmt.Sprintln 总结    下面来逐个分析\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;io\u0026#34; ) fmt.Fprintf  函数原型：  Fprintf(w io.Writer, format string, a ...interface{}) (n int, err error)   官方注释 Fprintf formats according to a format specifier and writes to w.It returns the number of bytes written and any write error encountered.\n  Arguement\nfmt.Fprintf() 依据指定的格式向第一个参数内写入字符串，第一参数必须实现了 io.","title":"golang中的print系函数详解"},{"content":"GOPATH的正确打开方式  GOPATH环境变量用于指定$GOROOT以外的目录，其中包含Go项目及其二进制文件的源。\n GOPATH指定了go项目的位置及其编译得到的二进制文件的位置。GOPAHT可以是一个列表，也就是说可以设置多个GOPATH。\n1.如何查看GOPATH 使用\ngo env 命令查看go相关的环境变量\n2. GOPATH的目录结构 GOPATH的目录结构如下：\n. ├── bin ├── pkg └── src └── main └── main.go $GOPATH/bin\n这个目录下存储编译的二进制文件，Linux操作系统使用\\$PATH环境变量来查找无需完整路径即可执行的二进制应用程序，我们可以将这个目录添加到$PATH中，这样就可以方便的执行我们的二进制文件。\n$GOPATH/pkg\nGo在该目录中存储了预编译的目标文件，以加快程序的后续编译速度。通常，我们不需要访问该目录。但是如果在编译时遇到问题，可以安全地删除该目录，然后Go会重建它。\n$GOPATH/src\n这里是我们的代码所在位置。\n3. 我应该如何设置GOPATH   设置一个GOPATH\n当设置一个GOPAHT时，我们自行安装的一些包以及我们所有的项目文件，都会在\\$GOPATH/src目录下，未免显得太过拥挤。不推荐。\n  设置两个GOPATH\n可以设置两个GOPATH，其中第一个作为从网络获取的包所在位置，第二个存放我们自己的项目，在从网络获取包时，将自动安装在第一个GOPATH下，这样就避免了我们自己的代码和网络上获取的代码挤在一起\n  每个项目设置一个GOPATH\n每个项目设置一个GOPATH，可以在建立项目的目录结构后使用\n  export GOPATH=`pwd` 来添加当前目录到GOPATH，但是下一次在运行这个命令时会将上一次的覆盖掉。这个方法的优点在于每个项目的目录结构变得清晰了，不再是所有项目存在于一个src文件夹下，可以建立在任意位置。但缺点在于每次切换项目都要重新export，同时还需要重新安装一些必要的包。类似于Python中的virtualenv.\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/gopath%E7%9A%84%E6%AD%A3%E7%A1%AE%E6%89%93%E5%BC%80%E6%96%B9%E5%BC%8F/","summary":"GOPATH的正确打开方式  GOPATH环境变量用于指定$GOROOT以外的目录，其中包含Go项目及其二进制文件的源。\n GOPATH指定了go项目的位置及其编译得到的二进制文件的位置。GOPAHT可以是一个列表，也就是说可以设置多个GOPATH。\n1.如何查看GOPATH 使用\ngo env 命令查看go相关的环境变量\n2. GOPATH的目录结构 GOPATH的目录结构如下：\n. ├── bin ├── pkg └── src └── main └── main.go $GOPATH/bin\n这个目录下存储编译的二进制文件，Linux操作系统使用\\$PATH环境变量来查找无需完整路径即可执行的二进制应用程序，我们可以将这个目录添加到$PATH中，这样就可以方便的执行我们的二进制文件。\n$GOPATH/pkg\nGo在该目录中存储了预编译的目标文件，以加快程序的后续编译速度。通常，我们不需要访问该目录。但是如果在编译时遇到问题，可以安全地删除该目录，然后Go会重建它。\n$GOPATH/src\n这里是我们的代码所在位置。\n3. 我应该如何设置GOPATH   设置一个GOPATH\n当设置一个GOPAHT时，我们自行安装的一些包以及我们所有的项目文件，都会在\\$GOPATH/src目录下，未免显得太过拥挤。不推荐。\n  设置两个GOPATH\n可以设置两个GOPATH，其中第一个作为从网络获取的包所在位置，第二个存放我们自己的项目，在从网络获取包时，将自动安装在第一个GOPATH下，这样就避免了我们自己的代码和网络上获取的代码挤在一起\n  每个项目设置一个GOPATH\n每个项目设置一个GOPATH，可以在建立项目的目录结构后使用\n  export GOPATH=`pwd` 来添加当前目录到GOPATH，但是下一次在运行这个命令时会将上一次的覆盖掉。这个方法的优点在于每个项目的目录结构变得清晰了，不再是所有项目存在于一个src文件夹下，可以建立在任意位置。但缺点在于每次切换项目都要重新export，同时还需要重新安装一些必要的包。类似于Python中的virtualenv.","title":"GOPATH的正确打开方式"},{"content":"Go中的标准库 在Go语言的安装文件里包含了一些可以直接使用的包，即标准库。Go语言的标准库（通常被称为语言自带的电池），提供了清晰的构建模块和公共接口，包含 I/O 操作、文本处理、图像、密码学、网络和分布式应用程序等，并支持许多标准化的文件格式和编解码协议。\n在 Windows 下，标准库的位置在Go语言根目录下的子目录 pkg\\windows_amd64 中；在 Linux 下，标准库在Go语言根目录下的子目录 pkg\\linux_amd64 中（如果是安装的是 32 位，则在 linux_386 目录中）。一般情况下，标准包会存放在 $GOROOT/pkg/$GOOS_$GOARCH/ 目录下。\nGo语言的编译器也是标准库的一部分，通过词法器扫描源码，使用语法树获得源码逻辑分支等。Go语言的周边工具也是建立在这些标准库上。在标准库上可以完成几乎大部分的需求。\nGo语言的标准库以包的方式提供支持，下表列出了Go语言标准库中常见的包及其功能。\n bufio\t带缓冲的 I/O 操作 bytes\t实现字节操作 container\t封装堆、列表和环形列表等容器 crypto\t加密算法 database\t数据库驱动和接口 debug\t各种调试文件格式访问及调试功能 encoding\t常见算法如 JSON、XML、Base64 等 flag\t命令行解析 fmt\t格式化操作 go\tGo语言的词法、语法树、类型等。可通过这个包进行代码信息提取和修改 html\tHTML 转义及模板系统 image\t常见图形格式的访问及生成 io\t实现 I/O 原始访问接口及访问封装 math\t数学库 net\t网络库，支持 Socket、HTTP、邮件、RPC、SMTP 等 os\t操作系统平台不依赖平台操作封装 path\t兼容各操作系统的路径操作实用函数 plugin\tGo 1.7 加入的插件系统。支持将代码编译为插件，按需加载 reflect\t语言反射支持。可以动态获得代码中的类型信息，获取和修改变量的值 regexp\t正则表达式封装 runtime\t运行时接口 sort\t排序接口 strings\t字符串转换、解析及实用函数 time\t时间接口 text\t文本模板及 Token 词法器  ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/%E6%A0%87%E5%87%86%E5%BA%93/","summary":"Go中的标准库 在Go语言的安装文件里包含了一些可以直接使用的包，即标准库。Go语言的标准库（通常被称为语言自带的电池），提供了清晰的构建模块和公共接口，包含 I/O 操作、文本处理、图像、密码学、网络和分布式应用程序等，并支持许多标准化的文件格式和编解码协议。\n在 Windows 下，标准库的位置在Go语言根目录下的子目录 pkg\\windows_amd64 中；在 Linux 下，标准库在Go语言根目录下的子目录 pkg\\linux_amd64 中（如果是安装的是 32 位，则在 linux_386 目录中）。一般情况下，标准包会存放在 $GOROOT/pkg/$GOOS_$GOARCH/ 目录下。\nGo语言的编译器也是标准库的一部分，通过词法器扫描源码，使用语法树获得源码逻辑分支等。Go语言的周边工具也是建立在这些标准库上。在标准库上可以完成几乎大部分的需求。\nGo语言的标准库以包的方式提供支持，下表列出了Go语言标准库中常见的包及其功能。\n bufio\t带缓冲的 I/O 操作 bytes\t实现字节操作 container\t封装堆、列表和环形列表等容器 crypto\t加密算法 database\t数据库驱动和接口 debug\t各种调试文件格式访问及调试功能 encoding\t常见算法如 JSON、XML、Base64 等 flag\t命令行解析 fmt\t格式化操作 go\tGo语言的词法、语法树、类型等。可通过这个包进行代码信息提取和修改 html\tHTML 转义及模板系统 image\t常见图形格式的访问及生成 io\t实现 I/O 原始访问接口及访问封装 math\t数学库 net\t网络库，支持 Socket、HTTP、邮件、RPC、SMTP 等 os\t操作系统平台不依赖平台操作封装 path\t兼容各操作系统的路径操作实用函数 plugin\tGo 1.7 加入的插件系统。支持将代码编译为插件，按需加载 reflect\t语言反射支持。可以动态获得代码中的类型信息，获取和修改变量的值 regexp\t正则表达式封装 runtime\t运行时接口 sort\t排序接口 strings\t字符串转换、解析及实用函数 time\t时间接口 text\t文本模板及 Token 词法器  ","title":"Go中的标准库"},{"content":"Go的http包详解 详细地解剖一下 http 包，看它到底是怎样实现整个过程的。\nGo 的 http 有两个核心功能：Conn、ServeMux\nConn的goroputine 为了实现高并发和高性能，go使用了goroutine来处理Conn的读写事件，这样每个请求都能保持独立，相互不会阻塞，可以高效的相应网络事件。\ngo在等待客户端请求中是这样的：\nc, err := srv.newConn(rw) if err != nil { continue } go c.serve() 可以看到，客户端的每次请求都会创建一个Conn，这个Conn里面保存了该次请求的信息，然后再传递到相应的handler，该handler中便可以读取到相应的header信息，这样保证了每个请求的独立性。\nServeMux的自定义 conn.server内部调用了http包默认的路由器，通过路由器把本次请求的信息传递到了后端的处理函数，那么这个路由器是怎么实现的呢？\n它的结构如下：\ntype ServeMux struct{ mu sync.RWMutext // 锁，请求涉及到并发处理，因此需要一个锁机制  m map[string]muxEntry // 路由规则，一个String对应一个mux实体，这里的String就是注册的一个路由表达式  hosts bool // 是否在任意的规则中带有host信息 } 下面看一下muxEntry\ntype muxEntry struct { explicit bool // 是否精确匹配  h Handler // 这个路由表达式对应哪个handler  pattern string // 匹配字符串 } 在看一下Handler的定义\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) // 路由实现器 } Handler是一个接口，但是附中的sayhelloName函数中并没有实现ServeHTTP这个接口，为什么能添加呢？这是因为http包里面还定义了一个类型HandlerFunc，定义的函数sayhelloName就是这个HandlerFunc调用之后的结果，这个类型默认就实现了ServeHTTP这个方法，即我们调用了HandlerFunc(f)，强制类型转换f成为HandlerFunc类型，这样f就拥有了ServeHTTP方法。\ntype HandlerFunc func(ResponseWriter, *Request) // ServeHTTP calls f(w, r) func (f HandlerFunc) ServeHTTP(w ResponseWriter, r *Request){ f (w, r) }  路由器里面存储好了对应的路由规则之后，那么具体的请求又是怎么分发的呢？下面的代码，默认的路由器实现了ServeHTTP\nfunc (mux *ServeMux) ServeHTTP(w ResponseWriter, r *Request) { if r.RequestURL == \u0026#34;*\u0026#34;{ w.Header().Set(\u0026#34;connection\u0026#34;, \u0026#34;clost\u0026#34;) w.WriteHeader(StatusBadReqest) return } h, _ := mux.Handler(r) h.ServeHTTP(w, r) } 路由器接收到请求后，如果是*那么关闭链接，否则调用mux.Handler(r)返回对应设置路由的处理Handler，然后执行h.ServeHTTP(w, r)，也就是调用对应路由的handler的ServeHTTP接口，那么mux.Handler(r)怎么处理的呢？\nfunc (mux *ServeMux) Handler(r *Request)(h Handler, pattern string){ if r.Method != \u0026#34;CONNECT\u0026#34; { if p := cleanPath(r.URL.Path); p != r.URL.Path{ _, pattern = mux.handler(r.Host, p) return RedirectHandler(p, StatusMovedPermanently), pattern } } return mux.handler(r.Host, r.URL.Path) } func (mux *ServeMux) handler(host, path string) (h Handler, pattern string) { mux.mu.RLock() defer mux.mu.RUnlock() // Host-specific pattern takes precedence over generic ones  if mux.hosts { h, pattern = mux.match(host + path) } if h == nil { h, pattern = mux.match(path) } if h == nil { h, pattern = NotFoundHandler(), \u0026#34;\u0026#34; } return } 根据用户请求的URL和路由器里面存储的map来匹配，当匹配到之后返回存储的handler，调用这个handler的ServeHTTP接口就可以执行到相应的函数。\nGo 其实支持外部实现的路由器 ListenAndServe 的第二个参数就是用以配置外部路由器的，它是一个 Handler 接口，即外部路由器只要实现了 Handler 接口就可以，我们可以在自己实现的路由器的 ServeHTTP 里面实现自定义路由功能。 如下代码所示，我们自己实现了一个简易的路由器\nimport ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) type MyMux struct { } func (p *MyMux) ServeHTTP(w http.ResponseWriter, r *http.Request) { if r.URL.Path == \u0026#34;/\u0026#34; { sayhelloName(w, r) return } http.NotFound(w, r) return } func sayhelloName(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, \u0026#34;Hello myroute!\u0026#34;) } func main() { mux := \u0026amp;MyMux{} http.ListenAndServe(\u0026#34;:9090\u0026#34;, mux) } GO代码的执行流程 通过对http包的分析之后，现在让我们来梳理一下整个的代码执行过程。\n 首先调用Http.HandleFunc 按顺序做了几件事  调用了DefaultServeMux 的 HandleFunc 调用了 DefaultServeMux 的 Handle 往 DefaultServeMux 的 map [string] muxEntry 中增加对应的 handler 和路由规则   其次调用 http.ListenAndServe (\u0026quot;:9090\u0026quot;, nil)\n按顺序做了几件事  实例化 Server 调用 Server 的 ListenAndServe () 调用 net.Listen (\u0026ldquo;tcp\u0026rdquo;, addr) 监听端口 启动一个 for 循环，在循环体中 Accept 请求 对每个请求实例化一个 Conn，并且开启一个 goroutine 为这个请求进行服务 go c.serve () 读取每个请求的内容 w, err := c.readRequest () 判断 handler 是否为空，如果没有设置 handler（这个例子就没有设置 handler），handler 就设置为 DefaultServeMux 调用 handler 的 ServeHttp 在这个例子中，下面就进入到 DefaultServeMux.ServeHttp 根据 request 选择 handler，并且进入到这个 handler 的 ServeHTTP  mux.handler(r).ServeHTTP(w, r) 选择 handler：  判断是否有路由能满足这个 request（循环遍历 ServeMux 的 muxEntry） B 如果有路由满足，调用这个路由 handler 的 ServeHTTP 如果没有路由满足，调用 NotFoundHandler 的 ServeHTTP       附：\nfunc sayHelloName(w http.ResponseWriter, r *http.Request){ r.ParseForm() fmt.Println(r.Form) fmt.Println(\u0026#34;path\u0026#34;, r.URL.Path) fmt.Println(\u0026#34;scheme\u0026#34;, r.URL.Scheme) fmt.Println(r.Form[\u0026#34;url_long\u0026#34;]) for k, v := range r.Form{ fmt.Println(\u0026#34;key: \u0026#34;, k) fmt.Println(\u0026#34;val: \u0026#34;, strings.Join(v, \u0026#34; \u0026#34;)) } fmt.Println(w, \u0026#34;hello world\u0026#34;) } func main() { http.HandleFunc(\u0026#34;/\u0026#34;, sayHelloName) err := http.ListenAndServe(\u0026#34;:9090\u0026#34;, nil) if err != nil { log.Fatal(\u0026#34;listenandserver: \u0026#34;, err) } } ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/go%E7%9A%84http%E5%8C%85%E8%AF%A6%E8%A7%A3/","summary":"Go的http包详解 详细地解剖一下 http 包，看它到底是怎样实现整个过程的。\nGo 的 http 有两个核心功能：Conn、ServeMux\nConn的goroputine 为了实现高并发和高性能，go使用了goroutine来处理Conn的读写事件，这样每个请求都能保持独立，相互不会阻塞，可以高效的相应网络事件。\ngo在等待客户端请求中是这样的：\nc, err := srv.newConn(rw) if err != nil { continue } go c.serve() 可以看到，客户端的每次请求都会创建一个Conn，这个Conn里面保存了该次请求的信息，然后再传递到相应的handler，该handler中便可以读取到相应的header信息，这样保证了每个请求的独立性。\nServeMux的自定义 conn.server内部调用了http包默认的路由器，通过路由器把本次请求的信息传递到了后端的处理函数，那么这个路由器是怎么实现的呢？\n它的结构如下：\ntype ServeMux struct{ mu sync.RWMutext // 锁，请求涉及到并发处理，因此需要一个锁机制  m map[string]muxEntry // 路由规则，一个String对应一个mux实体，这里的String就是注册的一个路由表达式  hosts bool // 是否在任意的规则中带有host信息 } 下面看一下muxEntry\ntype muxEntry struct { explicit bool // 是否精确匹配  h Handler // 这个路由表达式对应哪个handler  pattern string // 匹配字符串 } 在看一下Handler的定义\ntype Handler interface { ServeHTTP(ResponseWriter, *Request) // 路由实现器 } Handler是一个接口，但是附中的sayhelloName函数中并没有实现ServeHTTP这个接口，为什么能添加呢？这是因为http包里面还定义了一个类型HandlerFunc，定义的函数sayhelloName就是这个HandlerFunc调用之后的结果，这个类型默认就实现了ServeHTTP这个方法，即我们调用了HandlerFunc(f)，强制类型转换f成为HandlerFunc类型，这样f就拥有了ServeHTTP方法。","title":"Go的http包详解"},{"content":"1.值类型与引用类型 值类型：int、float、bool和string这些类型都属于值类型，使用这些类型的变量直接指向存在内存中的值，值类型的变量的值存储在栈中。当使用等号=将一个变量的值赋给另一个变量时，如 j = i ,实际上是在内存中将 i 的值进行了拷贝。可以通过 \u0026amp;i 获取变量 i 的内存地址\n引用类型：特指slice、map、channel这三种预定义类型。引用类型拥有更复杂的存储结构:(1)分配内存 (2)初始化一系列属性等。一个引用类型的变量r1存储的是r1的值所在的内存地址（数字），或内存地址中第一个字所在的位置，这个内存地址被称之为指针，这个指针实际上也被存在另外的某一个字中\n2.值类型与引用类型的区别 值类型在传参时是做拷贝操作，即将原来的数据复制一份，而引用类型是直接传递指针，当参数在函数中被改变时，原数据也将改变。\n2.1.值类型 //先定义一个数组 var a = [5]int{1, 2, 3, 4, 5} //定义一个函数，将数组中的第一个值设为0 func change(a [5]int){ a[0] = 0 fmt.Println(a) } change(a) fmt.Println(a)  输出：\n [0 2 3 4 5] [1 2 3 4 5] 可以看到，数组在函数内部被变成{0,1,2,3,4}，但当函数结束，还是原来的值没有变。\n2.2 引用类型 // 定义一个map var dit = make(map[string]int) dit[\u0026#34;one\u0026#34;] = 1 fmt.Println(dit) // 传参并做改变 func change(dit map[string]int){ dit[\u0026#34;two\u0026#34;] = 2 fmt.Println(dit) } change(dit) //输出原来的map fmt.Println(dit)  输出\n map[one:1] map[one:1 two:2] map[one:1 two:2] 将map作为参数传入函数，当在函数内部对参数进行修改时，原数据也随之变化。 引用类型包括slice,map,channel.\n内置函数new计算类型大小,为其分配零值内存,返回指针.而make会被编译器翻译成具体的创建函数,由其分配内存和初始化成员结构,返回对象而非指针.\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/%E5%80%BC%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/","summary":"1.值类型与引用类型 值类型：int、float、bool和string这些类型都属于值类型，使用这些类型的变量直接指向存在内存中的值，值类型的变量的值存储在栈中。当使用等号=将一个变量的值赋给另一个变量时，如 j = i ,实际上是在内存中将 i 的值进行了拷贝。可以通过 \u0026amp;i 获取变量 i 的内存地址\n引用类型：特指slice、map、channel这三种预定义类型。引用类型拥有更复杂的存储结构:(1)分配内存 (2)初始化一系列属性等。一个引用类型的变量r1存储的是r1的值所在的内存地址（数字），或内存地址中第一个字所在的位置，这个内存地址被称之为指针，这个指针实际上也被存在另外的某一个字中\n2.值类型与引用类型的区别 值类型在传参时是做拷贝操作，即将原来的数据复制一份，而引用类型是直接传递指针，当参数在函数中被改变时，原数据也将改变。\n2.1.值类型 //先定义一个数组 var a = [5]int{1, 2, 3, 4, 5} //定义一个函数，将数组中的第一个值设为0 func change(a [5]int){ a[0] = 0 fmt.Println(a) } change(a) fmt.Println(a)  输出：\n [0 2 3 4 5] [1 2 3 4 5] 可以看到，数组在函数内部被变成{0,1,2,3,4}，但当函数结束，还是原来的值没有变。\n2.2 引用类型 // 定义一个map var dit = make(map[string]int) dit[\u0026#34;one\u0026#34;] = 1 fmt.Println(dit) // 传参并做改变 func change(dit map[string]int){ dit[\u0026#34;two\u0026#34;] = 2 fmt.","title":"Go语言中值类型与引用类型"},{"content":"Go语言中的字面量  什么是字面量 整型和浮点型的字面值 字符串的字面值 常量的字面值 数组的字面值 Slice的字面值 Map的字面值 结构体的字面值  什么是字面量 在计算机科学中，字面量（literal）是用于表达源代码中一个固定值的表示法（notation）。\n简单的说，字面量或者说字面值就是一个变量的值。\n整型和浮点型的字面值 var i int = 1 var f float64 = 3.14159 字符串的字面值 字符串值也可以用字符串面值方式编写，只要将一系列字节序列包含在双引号即可：\n\u0026#34;Hello 世界\u0026#34; `世界` 世界  一个原生的字符串面值形式是\n`...` 使用反引号代替双引号。在原生的字符串面值中，没有转义操作；全部的内容都是字面的意思，包含退格和换行，因此一个程序中的原生字符串面值可能跨越多行（译注：在原生字符串面值内部是无法直接写```````字符的，可以用八进制或十六进制转义或+\u0026quot;`\u0026quot;链接字符串常量完成）。唯一的特殊处理是会删除回车以保证在所有平台上的值都是一样的，包括那些把回车也放入文本文件的系统（译注：Windows系统会把回车和换行一起放入文本文件中）。\n原生字符串面值用于编写正则表达式会很方便，因为正则表达式往往会包含很多反斜杠。原生字符串面值同时被广泛应用于HTML模板、JSON面值、命令行提示信息以及那些需要扩展到多行的场景。\nconst GoUsage = `Go is a tool for managing Go source code. Usage: go command [arguments] ...` GoUsage Go is a tool for managing Go source code. Usage: go command [arguments] ...  常量的字面值 对于常量面值，不同的写法可能会对应不同的类型。例如0、0.0、0i和\\u0000虽然有着相同的常量值，但是它们分别对应无类型的整数、无类型的浮点数、无类型的复数和无类型的字符等不同的常量类型。同样，true和false也是无类型的布尔类型，字符串面值常量是无类型的字符串类型。\n数组的字面值 使用数组字面值语法用一组值来初始化数组：\nvar q [3]int = [3]int{1, 2, 3} var r [3]int = [3]int{1, 2} r[2] 0  在数组字面值中，如果在数组的长度位置出现的是“\u0026hellip;”省略号，则表示数组的长度是根据初始化值的个数来计算。因此，上面q数组的定义可以简化为\nimport \u0026#34;fmt\u0026#34; q := [...]int{1, 2, 3} fmt.Printf(\u0026#34;%T\\n\u0026#34;, q) // \u0026#34;[3]int\u0026#34; [3]int 7 \u0026lt;nil\u0026gt;  数组、slice、map和结构体字面值的写法都很相似。上面的形式是直接提供顺序初始化值序列，但是也可以指定一个索引和对应值列表的方式初始化，就像下面这样：\ntype Currency int const ( USD Currency = iota // 美元  EUR // 欧元  GBP // 英镑  RMB // 人民币 ) //这个看起来和字典很相似，但其实USD等标识是index下标 symbol := [...]string{USD: \u0026#34;$\u0026#34;, EUR: \u0026#34;€\u0026#34;, GBP: \u0026#34;￡\u0026#34;, RMB: \u0026#34;￥\u0026#34;} fmt.Println(RMB, symbol[RMB]) // \u0026#34;3 ￥\u0026#34; symbol[EUR] == symbol[1] 3 ￥ true  Slice的字面值 slice和数组的字面值语法很类似，它们都是用花括弧包含一系列的初始化元素，但是对于slice并没有指明序列的长度。这会隐式地创建一个合适大小的数组，然后slice的指针指向底层的数组。就像数组字面值一样，slice的字面值也可以按顺序指定初始化值序列，或者是通过索引和元素值指定，或者两种风格的混合语法初始化。\ns := []int{0, 1, 2, 3, 4, 5} s [0 1 2 3 4 5]  a := []string{\u0026#34;one\u0026#34;, \u0026#34;two\u0026#34;, 4:\u0026#34;three\u0026#34;} a[4] three  Map的字面值 用map字面值的语法创建map，同时还可以指定一些最初的key/value：\nages := map[string]int{ \u0026#34;alice\u0026#34;: 31, \u0026#34;charlie\u0026#34;: 34, } 这相当于\nages := make(map[string]int) ages[\u0026#34;alice\u0026#34;] = 31 ages[\u0026#34;charlie\u0026#34;] = 34 结构体的字面值 第一种写法\ntype Point struct{ X, Y int } p := Point{1, 2} 更常用的是第二种写法，以成员名字和相应的值来初始化，可以包含部分或全部的成员\nanim := gif.GIF{LoopCount: nframes} repl.go:1:9: undefined \u0026quot;gif\u0026quot; in gif.GIF \u0026lt;*ast.SelectorExpr\u0026gt;  两种写法不能混用\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E5%AD%97%E9%9D%A2%E9%87%8F/","summary":"Go语言中的字面量  什么是字面量 整型和浮点型的字面值 字符串的字面值 常量的字面值 数组的字面值 Slice的字面值 Map的字面值 结构体的字面值  什么是字面量 在计算机科学中，字面量（literal）是用于表达源代码中一个固定值的表示法（notation）。\n简单的说，字面量或者说字面值就是一个变量的值。\n整型和浮点型的字面值 var i int = 1 var f float64 = 3.14159 字符串的字面值 字符串值也可以用字符串面值方式编写，只要将一系列字节序列包含在双引号即可：\n\u0026#34;Hello 世界\u0026#34; `世界` 世界  一个原生的字符串面值形式是\n`...` 使用反引号代替双引号。在原生的字符串面值中，没有转义操作；全部的内容都是字面的意思，包含退格和换行，因此一个程序中的原生字符串面值可能跨越多行（译注：在原生字符串面值内部是无法直接写```````字符的，可以用八进制或十六进制转义或+\u0026quot;`\u0026quot;链接字符串常量完成）。唯一的特殊处理是会删除回车以保证在所有平台上的值都是一样的，包括那些把回车也放入文本文件的系统（译注：Windows系统会把回车和换行一起放入文本文件中）。\n原生字符串面值用于编写正则表达式会很方便，因为正则表达式往往会包含很多反斜杠。原生字符串面值同时被广泛应用于HTML模板、JSON面值、命令行提示信息以及那些需要扩展到多行的场景。\nconst GoUsage = `Go is a tool for managing Go source code. Usage: go command [arguments] ...` GoUsage Go is a tool for managing Go source code. Usage: go command [arguments] ...  常量的字面值 对于常量面值，不同的写法可能会对应不同的类型。例如0、0.","title":"Go语言中的字面量"},{"content":"Go语言中的错误处理策略 0. 错误处理的编码风格 检查某个子函数是否失败后，我们通常将处理失败的逻辑代码放在处理成功的代码之前。如果某个错误会导致函数返回，那么成功的逻辑代码不应该放在else中，而应直接放在函数体中。\n1. 错误传播 函数某个子程序的失败，会变成该函数的失败\nresp, err := http.Get(url) if err != nil{ return nill, err } 或是构造新的错误信息返回给调用者\ndoc, err := html.Parse(resp.Body) resp.Body.Close() if err != nil { return nil, fmt.Errorf(\u0026#34;parsing %s as HTML: %v\u0026#34;, url,err) } 一般而言，被调函数f(x)会将调用信息和参数信息作为发生错误时的上下文放在错误信息中并返回给调用者，调用者需要添加一些错误信息中不包含的信息。\n2. 重试失败的操作 如果错误的发生是偶然的，或由不可预知的问题导致的。此时可重新尝试失败的操作，但是在重试时，要限制重试的时间间隔或重试的时间次数，防止无限制的重试。\nfunc WaitForServer(url string) error { const timeout = 1 * time.Minute deadline := time.Now().Add(timeout) for tries := 0; time.Now().Before(deadline); tries++ { _, err := http.Head(url) if err == nil { return nil // success  } log.Printf(\u0026#34;server not responding (%s);retrying…\u0026#34;, err) time.Sleep(time.Second \u0026lt;\u0026lt; uint(tries)) // exponential back-off  } return fmt.Errorf(\u0026#34;server %s failed to respond after %s\u0026#34;, url, timeout) } 3. 输出错误信息并结束程序 这种策略应只在main中使用，对于库函数而言，应仅向上传播错误，除非该错误意味着程序内部包含不一致性，即遇到了bug，才能在库函数中结束程序\n// (In function main.) if err := WaitForServer(url); err != nil { fmt.Fprintf(os.Stderr, \u0026#34;Site is down: %v\\n\u0026#34;, err) os.Exit(1) } 4. 只输出错误信息 只输出错误信息，不需要中断函数的执行\nif err := Ping(); err != nil { log.Printf(\u0026#34;ping failed: %v; networking disabled\u0026#34;,err) } 5. 直接忽略错误 dir, err := ioutil.TempDir(\u0026#34;\u0026#34;, \u0026#34;scratch\u0026#34;) if err != nil { return fmt.Errorf(\u0026#34;failed to create temp dir: %v\u0026#34;,err) } // ...use temp dir… os.RemoveAll(dir) // ignore errors; $TMPDIR is cleaned periodically ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E7%AD%96%E7%95%A5/","summary":"Go语言中的错误处理策略 0. 错误处理的编码风格 检查某个子函数是否失败后，我们通常将处理失败的逻辑代码放在处理成功的代码之前。如果某个错误会导致函数返回，那么成功的逻辑代码不应该放在else中，而应直接放在函数体中。\n1. 错误传播 函数某个子程序的失败，会变成该函数的失败\nresp, err := http.Get(url) if err != nil{ return nill, err } 或是构造新的错误信息返回给调用者\ndoc, err := html.Parse(resp.Body) resp.Body.Close() if err != nil { return nil, fmt.Errorf(\u0026#34;parsing %s as HTML: %v\u0026#34;, url,err) } 一般而言，被调函数f(x)会将调用信息和参数信息作为发生错误时的上下文放在错误信息中并返回给调用者，调用者需要添加一些错误信息中不包含的信息。\n2. 重试失败的操作 如果错误的发生是偶然的，或由不可预知的问题导致的。此时可重新尝试失败的操作，但是在重试时，要限制重试的时间间隔或重试的时间次数，防止无限制的重试。\nfunc WaitForServer(url string) error { const timeout = 1 * time.Minute deadline := time.Now().Add(timeout) for tries := 0; time.Now().Before(deadline); tries++ { _, err := http.Head(url) if err == nil { return nil // success  } log.","title":"Go语言中的错误处理策略"},{"content":"HINT: Add or change a related_name 解决方案：\n需要在setting中重载AUTH_USER_MODEL\nAUTH_USER_MODEL = \u0026lsquo;users.UserProfile\u0026rsquo;\nusers：你的app\nUserProfile：model\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/hint-add-or-change-a-relatedname/","summary":"HINT: Add or change a related_name 解决方案：\n需要在setting中重载AUTH_USER_MODEL\nAUTH_USER_MODEL = \u0026lsquo;users.UserProfile\u0026rsquo;\nusers：你的app\nUserProfile：model","title":"HINT : Add or change are lated_name"},{"content":"http/template 什么是模板 模板是一种常见的视图，通过它我们可以传递数据以使该视图有意义。可以以任何方式对其进行自定义以获取任何可能的输出。\n模板包 Go中的模板附带两个包text/template和html/template。文本包允许我们使用模板插入文本，而HTML模板通过提供安全的HTML代码来帮助我们。\nPart of template 1. 模板动作 模板动作是主要的控制流程，数据评估功能。这些动作控制最终输出将如何显示\n{{ /* a comment isside template */ }} 2. 控制结构 控制结构确定模板的控制流程，有助于产生结构化的输出，以下是模板中的一些控制结构\nif语句\n{{ if .condition }} {{ else }} {{ end }} 循环块\n{{ range .Items }} {{ end }} 3. 功能 函数也可以在模板内部使用，可以使用管道符|来使用预定义的函数\n 如何预定义函数\n 下面的代码创建并分析上面定义的模板templ。注意方法调用链的顺序:template.New先创建并返回一个模板;Funcs方法将daysAgo等自定义函数注册到模板中,并返回模板;最后调用Parse函数分析模板。\nreport, err := template.New(\u0026#34;report\u0026#34;).Funcs(template.FuncMap{\u0026#34;daysAgo\u0026#34;: daysAgo}).Parse(templ) if err != nil { log.Fatal(err) } 在Go中解析模板 现在，我们来解析一些文本和HTML模板\n1. 访问数据 要访问传递的数据，使用点.，如下所示：\n{{ .data }} 2. 解析文本模板 现在，来解析一个文本模板\npackage main import ( \u0026#34;os\u0026#34; \u0026#34;text/template\u0026#34; ) type User struct { Name string Bio string } func main() { u := User{\u0026#34;John\u0026#34;, \u0026#34;a regular user\u0026#34;} ut, err := template.New(\u0026#34;users\u0026#34;).Parse(\u0026#34;The user is {{ .Name }} and he is {{ .Bio }}.\u0026#34;) if err != nil { panic(err) } err = ut.Execute(os.Stdout, u) if err != nil { panic(err) } } 其输出如图所示：\n3. 解析HTML模板  hello.html\n \u0026lt;h1\u0026gt;Go templates\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;The user is {{ .Name }}\u0026lt;/p\u0026gt; \u0026lt;h2\u0026gt;Skills:\u0026lt;/h2\u0026gt; {{ range .Skills }} \u0026lt;p\u0026gt;{{ . }}\u0026lt;/p\u0026gt; {{ end }}  main.go\n package main import ( \u0026#34;os\u0026#34; \u0026#34;html/template\u0026#34; ) func main() { t, err := template.ParseFiles(\u0026#34;templates/hello.gohtml\u0026#34;) if err != nil { panic(err) } data := struct { Name string Skills []string }{ Name: \u0026#34;John Doe\u0026#34;, Skills: []string{ \u0026#34;C++\u0026#34;, \u0026#34;Java\u0026#34;, \u0026#34;Python\u0026#34;, }, } err = t.Execute(os.Stdout, data) if err != nil { panic(err) } } 则结果：\nGo中的模板验证 为了验证模板是否有效，我们使用template.Must()函数。它有助于在解析过程中验证模板。因为模板通常在编译时就测试好了,如果模板解析失败将是一个致命的错误template.Must 辅助函数可以简化这个致命错误的处理:它接受一个模板和一个error类型的参数,检测error是否为nil(如果不是nil则发出panic异常),然后返回传入的模板\nvar report = template.Must(template.New(\u0026#34;issuelist\u0026#34;). Funcs(template.FuncMap{\u0026#34;daysAgo\u0026#34;: daysAgo}). Parse(templ)) func main() { result, err := github.SearchIssues(os.Args[1:]) if err != nil { log.Fatal(err) } if err := report.Execute(os.Stdout, result); err != nil { log.Fatal(err) } } ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/template/","summary":"http/template 什么是模板 模板是一种常见的视图，通过它我们可以传递数据以使该视图有意义。可以以任何方式对其进行自定义以获取任何可能的输出。\n模板包 Go中的模板附带两个包text/template和html/template。文本包允许我们使用模板插入文本，而HTML模板通过提供安全的HTML代码来帮助我们。\nPart of template 1. 模板动作 模板动作是主要的控制流程，数据评估功能。这些动作控制最终输出将如何显示\n{{ /* a comment isside template */ }} 2. 控制结构 控制结构确定模板的控制流程，有助于产生结构化的输出，以下是模板中的一些控制结构\nif语句\n{{ if .condition }} {{ else }} {{ end }} 循环块\n{{ range .Items }} {{ end }} 3. 功能 函数也可以在模板内部使用，可以使用管道符|来使用预定义的函数\n 如何预定义函数\n 下面的代码创建并分析上面定义的模板templ。注意方法调用链的顺序:template.New先创建并返回一个模板;Funcs方法将daysAgo等自定义函数注册到模板中,并返回模板;最后调用Parse函数分析模板。\nreport, err := template.New(\u0026#34;report\u0026#34;).Funcs(template.FuncMap{\u0026#34;daysAgo\u0026#34;: daysAgo}).Parse(templ) if err != nil { log.Fatal(err) } 在Go中解析模板 现在，我们来解析一些文本和HTML模板\n1. 访问数据 要访问传递的数据，使用点.，如下所示：\n{{ .data }} 2. 解析文本模板 现在，来解析一个文本模板","title":"http/template"},{"content":"%matplotlib inline ======================================= Receiver Operating Characteristic (ROC) Example of Receiver Operating Characteristic (ROC) metric to evaluate classifier output quality.\nROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the \u0026ldquo;ideal\u0026rdquo; point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.\nThe \u0026ldquo;steepness\u0026rdquo; of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.\nMulticlass settings ROC curves are typically used in binary classification to study the output of a classifier. In order to extend ROC curve and ROC area to multi-class or multi-label classification, it is necessary to binarize the output. One ROC curve can be drawn per label, but one can also draw a ROC curve by considering each element of the label indicator matrix as a binary prediction (micro-averaging).\nAnother evaluation measure for multi-class classification is macro-averaging, which gives equal weight to the classification of each label.\nprint(__doc__) import numpy as np import matplotlib.pyplot as plt from itertools import cycle from sklearn import svm, datasets from sklearn.metrics import roc_curve, auc from sklearn.model_selection import train_test_split from sklearn.preprocessing import label_binarize from sklearn.multiclass import OneVsRestClassifier from scipy import interp # Import some data to play with iris = datasets.load_iris() X = iris.data y = iris.target # Binarize the output y = label_binarize(y, classes=[0, 1, 2]) n_classes = y.shape[1] # Add noisy features to make the problem harder random_state = np.random.RandomState(0) n_samples, n_features = X.shape X = np.c_[X, random_state.randn(n_samples, 200 * n_features)] # shuffle and split training and test sets X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5, random_state=0) # Learn to predict each class against the other classifier = OneVsRestClassifier(svm.SVC(kernel=\u0026#39;linear\u0026#39;, probability=True, random_state=random_state)) y_score = classifier.fit(X_train, y_train).decision_function(X_test) # print(\u0026#39;y_score\u0026#39;) # print(y_score) # Compute ROC curve and ROC area for each class fpr = dict() tpr = dict() roc_auc = dict() for i in range(n_classes): fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i]) # print(fpr[i]) # print(tpr[i]) roc_auc[i] = auc(fpr[i], tpr[i]) # # Compute micro-average ROC curve and ROC area # fpr[\u0026#34;micro\u0026#34;], tpr[\u0026#34;micro\u0026#34;], _ = roc_curve(y_test.ravel(), y_score.ravel()) # roc_auc[\u0026#34;micro\u0026#34;] = auc(fpr[\u0026#34;micro\u0026#34;], tpr[\u0026#34;micro\u0026#34;]) # # print(roc_auc) Automatically created module for IPython interactive environment [0. 0. 0. 0.01851852 0.01851852 0.03703704 0.03703704 0.05555556 0.05555556 0.07407407 0.07407407 0.09259259 0.09259259 0.12962963 0.12962963 0.14814815 0.14814815 0.2037037 0.2037037 0.27777778 0.27777778 1. ] [0. 0.04761905 0.14285714 0.14285714 0.19047619 0.19047619 0.33333333 0.33333333 0.38095238 0.38095238 0.61904762 0.61904762 0.66666667 0.66666667 0.76190476 0.76190476 0.9047619 0.9047619 0.95238095 0.95238095 1. 1. ] [0. 0. 0. 0.02222222 0.02222222 0.11111111 0.11111111 0.17777778 0.17777778 0.2 0.2 0.24444444 0.24444444 0.26666667 0.26666667 0.37777778 0.37777778 0.42222222 0.42222222 0.48888889 0.48888889 0.55555556 0.55555556 0.62222222 0.62222222 0.64444444 0.64444444 0.66666667 0.66666667 0.73333333 0.73333333 0.75555556 0.75555556 0.88888889 0.88888889 1. ] [0. 0.03333333 0.13333333 0.13333333 0.16666667 0.16666667 0.2 0.2 0.26666667 0.26666667 0.33333333 0.33333333 0.4 0.4 0.43333333 0.43333333 0.5 0.5 0.56666667 0.56666667 0.6 0.6 0.63333333 0.63333333 0.7 0.7 0.73333333 0.73333333 0.9 0.9 0.93333333 0.93333333 0.96666667 0.96666667 1. 1. ] [0. 0. 0. 0.01960784 0.01960784 0.07843137 0.07843137 0.09803922 0.09803922 0.11764706 0.11764706 0.1372549 0.1372549 0.15686275 0.15686275 0.17647059 0.17647059 0.31372549 0.31372549 0.33333333 0.33333333 0.35294118 0.35294118 0.41176471 0.41176471 0.45098039 0.45098039 0.47058824 0.47058824 0.50980392 0.50980392 0.56862745 0.56862745 1. ] [0. 0.04166667 0.125 0.125 0.25 0.25 0.29166667 0.29166667 0.33333333 0.33333333 0.41666667 0.41666667 0.5 0.5 0.54166667 0.54166667 0.58333333 0.58333333 0.70833333 0.70833333 0.75 0.75 0.79166667 0.79166667 0.83333333 0.83333333 0.875 0.875 0.91666667 0.91666667 0.95833333 0.95833333 1. 1. ]  Plot of a ROC curve for a specific class\nplt.figure() lw = 2 plt.plot(fpr[2], tpr[2], color=\u0026#39;darkorange\u0026#39;, lw=lw, label=\u0026#39;ROC curve (area = %0.2f)\u0026#39; % roc_auc[2]) plt.plot([0, 1], [0, 1], color=\u0026#39;navy\u0026#39;, lw=lw, linestyle=\u0026#39;--\u0026#39;) plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) plt.title(\u0026#39;Receiver operating characteristic example\u0026#39;) plt.legend(loc=\u0026#34;lower right\u0026#34;) plt.show() Plot ROC curves for the multiclass problem\n# Compute macro-average ROC curve and ROC area # First aggregate all false positive rates all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)])) # Then interpolate all ROC curves at this points mean_tpr = np.zeros_like(all_fpr) for i in range(n_classes): mean_tpr += interp(all_fpr, fpr[i], tpr[i]) # Finally average it and compute AUC mean_tpr /= n_classes fpr[\u0026#34;macro\u0026#34;] = all_fpr tpr[\u0026#34;macro\u0026#34;] = mean_tpr roc_auc[\u0026#34;macro\u0026#34;] = auc(fpr[\u0026#34;macro\u0026#34;], tpr[\u0026#34;macro\u0026#34;]) # Plot all ROC curves plt.figure() plt.plot(fpr[\u0026#34;micro\u0026#34;], tpr[\u0026#34;micro\u0026#34;], label=\u0026#39;micro-average ROC curve (area = {0:0.2f})\u0026#39; \u0026#39;\u0026#39;.format(roc_auc[\u0026#34;micro\u0026#34;]), color=\u0026#39;deeppink\u0026#39;, linestyle=\u0026#39;:\u0026#39;, linewidth=4) plt.plot(fpr[\u0026#34;macro\u0026#34;], tpr[\u0026#34;macro\u0026#34;], label=\u0026#39;macro-average ROC curve (area = {0:0.2f})\u0026#39; \u0026#39;\u0026#39;.format(roc_auc[\u0026#34;macro\u0026#34;]), color=\u0026#39;navy\u0026#39;, linestyle=\u0026#39;:\u0026#39;, linewidth=4) colors = cycle([\u0026#39;aqua\u0026#39;, \u0026#39;darkorange\u0026#39;, \u0026#39;cornflowerblue\u0026#39;]) for i, color in zip(range(n_classes), colors): plt.plot(fpr[i], tpr[i], color=color, lw=lw, label=\u0026#39;ROC curve of class {0} (area = {1:0.2f})\u0026#39; \u0026#39;\u0026#39;.format(i, roc_auc[i])) plt.plot([0, 1], [0, 1], \u0026#39;k--\u0026#39;, lw=lw) plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) plt.title(\u0026#39;Some extension of Receiver operating characteristic to multi-class\u0026#39;) plt.legend(loc=\u0026#34;lower right\u0026#34;) plt.show() ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/plot_roc/","summary":"%matplotlib inline ======================================= Receiver Operating Characteristic (ROC) Example of Receiver Operating Characteristic (ROC) metric to evaluate classifier output quality.\nROC curves typically feature true positive rate on the Y axis, and false positive rate on the X axis. This means that the top left corner of the plot is the \u0026ldquo;ideal\u0026rdquo; point - a false positive rate of zero, and a true positive rate of one. This is not very realistic, but it does mean that a larger area under the curve (AUC) is usually better.","title":"Importsomedatatoplaywith"},{"content":"Keras函数式API 使用函数式API，你可以直接操作张量，也可以把层当做函数来使用，接收张量并返回张量。\n# 简单的实例 import os # **** change the warning level **** os.environ[\u0026#39;TF_CPP_MIN_LOG_LEVEL\u0026#39;] = \u0026#39;3\u0026#39; from keras.models import Sequential, Model from keras import layers from keras import Input # 使用Sequential模型 seq_model = Sequential() seq_model.add(layers.Dense(32, activation=\u0026#39;relu\u0026#39;, input_shape=(64,))) seq_model.add(layers.Dense(32, activation=\u0026#39;relu\u0026#39;)) seq_model.add(layers.Dense(10, activation=\u0026#39;softmax\u0026#39;)) # 对应的函数式API实现 input_tensor = Input(shape=(64,)) x = layers.Dense(32, activation=\u0026#39;relu\u0026#39;)(input_tensor) x = layers.Dense(32, activation=\u0026#39;softmax\u0026#39;)(x) output_tensor = layers.Dense(10, activation=\u0026#39;softmax\u0026#39;)(x) model = Model(input_tensor, output_tensor) model.summary() Model: \u0026quot;model_2\u0026quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) (None, 64) 0 _________________________________________________________________ dense_10 (Dense) (None, 32) 2080 _________________________________________________________________ dense_11 (Dense) (None, 32) 1056 _________________________________________________________________ dense_12 (Dense) (None, 10) 330 ================================================================= Total params: 3,466 Trainable params: 3,466 Non-trainable params: 0 _________________________________________________________________  Keras会在后台检索从input_tensor到output_tensor所包含的每一层，并将这些层组合成一个类图的数据结构，即一个Model。这种方法有效的原因在于，output_tensor是通过对input_tensor进行多次变换得到的。如果你试图利用不相关的输入和输出来构建一个模型，那么会得到RuntimeError\nunrelated_input = Input(shape=(32,)) bad_model = model = Model(unrelated_input, output_tensor) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) \u0026lt;ipython-input-3-54197a8d0ec3\u0026gt; in \u0026lt;module\u0026gt; 1 unrelated_input = Input(shape=(32,)) ----\u0026gt; 2 bad_model = model = Model(unrelated_input, output_tensor) /usr/lib/python3.7/site-packages/keras/legacy/interfaces.py in wrapper(*args, **kwargs) 89 warnings.warn('Update your `' + object_name + '` call to the ' + 90 'Keras 2 API: ' + signature, stacklevel=2) ---\u0026gt; 91 return func(*args, **kwargs) 92 wrapper._original_function = func 93 return wrapper /usr/lib/python3.7/site-packages/keras/engine/network.py in __init__(self, *args, **kwargs) 92 'inputs' in kwargs and 'outputs' in kwargs): 93 # Graph network ---\u0026gt; 94 self._init_graph_network(*args, **kwargs) 95 else: 96 # Subclassed network /usr/lib/python3.7/site-packages/keras/engine/network.py in _init_graph_network(self, inputs, outputs, name, **kwargs) 239 # Keep track of the network's nodes and layers. 240 nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network( --\u0026gt; 241 self.inputs, self.outputs) 242 self._network_nodes = nodes 243 self._nodes_by_depth = nodes_by_depth /usr/lib/python3.7/site-packages/keras/engine/network.py in _map_graph_network(inputs, outputs) 1509 'The following previous layers ' 1510 'were accessed without issue: ' + -\u0026gt; 1511 str(layers_with_complete_input)) 1512 for x in node.output_tensors: 1513 computable_tensors.append(x) ValueError: Graph disconnected: cannot obtain value for tensor Tensor(\u0026quot;input_2:0\u0026quot;, shape=(None, 64), dtype=float32) at layer \u0026quot;input_2\u0026quot;. The following previous layers were accessed without issue: []  对这种Model实例进行编译、训练或评估时，其API与Sequential模型相同\nmodel.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;) import numpy as np x_train = np.random.random((1000, 64)) y_train = np.random.random((1000, 10)) model.fit(x_train, y_train, epochs=10, batch_size=128) score = model.evaluate(x_train, y_train) Epoch 1/10 1000/1000 [==============================] - 0s 83us/step - loss: 11.6211 Epoch 2/10 1000/1000 [==============================] - 0s 33us/step - loss: 11.6215 Epoch 3/10 1000/1000 [==============================] - 0s 32us/step - loss: 11.6216 Epoch 4/10 1000/1000 [==============================] - 0s 27us/step - loss: 11.6216 Epoch 5/10 1000/1000 [==============================] - 0s 36us/step - loss: 11.6216 Epoch 6/10 1000/1000 [==============================] - 0s 37us/step - loss: 11.6217 Epoch 7/10 1000/1000 [==============================] - 0s 37us/step - loss: 11.6217 Epoch 8/10 1000/1000 [==============================] - 0s 25us/step - loss: 11.6217 Epoch 9/10 1000/1000 [==============================] - 0s 40us/step - loss: 11.6217 Epoch 10/10 1000/1000 [==============================] - 0s 34us/step - loss: 11.6216 1000/1000 [==============================] - 0s 69us/step  ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/keras%E5%87%BD%E6%95%B0%E5%BC%8Fapi/","summary":"Keras函数式API 使用函数式API，你可以直接操作张量，也可以把层当做函数来使用，接收张量并返回张量。\n# 简单的实例 import os # **** change the warning level **** os.environ[\u0026#39;TF_CPP_MIN_LOG_LEVEL\u0026#39;] = \u0026#39;3\u0026#39; from keras.models import Sequential, Model from keras import layers from keras import Input # 使用Sequential模型 seq_model = Sequential() seq_model.add(layers.Dense(32, activation=\u0026#39;relu\u0026#39;, input_shape=(64,))) seq_model.add(layers.Dense(32, activation=\u0026#39;relu\u0026#39;)) seq_model.add(layers.Dense(10, activation=\u0026#39;softmax\u0026#39;)) # 对应的函数式API实现 input_tensor = Input(shape=(64,)) x = layers.Dense(32, activation=\u0026#39;relu\u0026#39;)(input_tensor) x = layers.Dense(32, activation=\u0026#39;softmax\u0026#39;)(x) output_tensor = layers.Dense(10, activation=\u0026#39;softmax\u0026#39;)(x) model = Model(input_tensor, output_tensor) model.summary() Model: \u0026quot;model_2\u0026quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= input_2 (InputLayer) (None, 64) 0 _________________________________________________________________ dense_10 (Dense) (None, 32) 2080 _________________________________________________________________ dense_11 (Dense) (None, 32) 1056 _________________________________________________________________ dense_12 (Dense) (None, 10) 330 ================================================================= Total params: 3,466 Trainable params: 3,466 Non-trainable params: 0 _________________________________________________________________  Keras会在后台检索从input_tensor到output_tensor所包含的每一层，并将这些层组合成一个类图的数据结构，即一个Model。这种方法有效的原因在于，output_tensor是通过对input_tensor进行多次变换得到的。如果你试图利用不相关的输入和输出来构建一个模型，那么会得到RuntimeError","title":"Keras函数式API"},{"content":"Linux下的权限管理 Linux 系统中为什么需要设定不同的权限，所有用户都直接使用管理员（root）身份不好吗？\n 由于绝大多数用户使用的是个人计算机，使用者一般都是被信任的人（如家人、朋友等）。在这种情况下，大家都可以使用管理员身份直接登录。但在服务器上就不是这种情况了，往往运行的数据越重要（如游戏数据），价值越高（如电子商城数据、银行数据），则服务器中对权限的设定就要越详细，用户的分级也要越明确。\n和 Windows 系统不同，Linux 系统为每个文件都添加了很多的属性，最大的作用就是维护数据的安全。举个简单的例子，在你的 Linux 系统中，和系统服务相关的文件通常只有 root 用户才能读或写，就拿 /etc/shadow 这个文件来说，此文件记录了系统中所有用户的密码数据，非常重要，因此绝不能让任何人读取（否则密码数据会被窃取），只有 root 才可以有读取权限。 此外，如果你有一个软件开发团队，你希望团队中的每个人都可以使用某一些目录下的文件，而非团队的其他人则不予以开放。通过前面章节的学习我们知道，只需要将团队中的所有人加入新的群组，并赋予此群组读写目录的权限，即可实现要求。反之，如果你的目录权限没有做好，就很难防止其他人在你的系统中乱搞。 比如说，本来 root 用户才能做的开关机、ADSL 拨接程序，新增或删除用户等命令，一旦允许任何人拥有这些权限，系统很可能会经常莫名其妙的挂掉。而且，万一 root 用户的密码被其他人获取，他们就可以登录你的系统，从事一些只有 root 用户才能执行的操作，这是绝对不允许发生的。 因此，在服务器上，绝对不是所有的用户都使用 root 身份登录，而要根据不同的工作需要和职位需要，合理分配用户等级和权限等级。\n Linux 系统中，文件或目录的权限信息，可以使用 ls 命令查看，例如：\n[root@localhost ~]# ls -al total 156 drwxr-x---. 4 root root 4096 Sep 8 14:06 . drwxr-xr-x. 23 root root 4096 Sep 8 14:21 .. -rw-------. 1 root root 1474 Sep 4 18:27 anaconda-ks.cfg -rw-------. 1 root root 199 Sep 8 17:14 .bash_history -rw-r--r--. 1 root root 24 Jan 6 2007 .bash_logout 1. Linux chgrp命令：修改文件和目录的所属组 chgrp 命令用于修改文件（或目录）的所属组。 为了方便初学者记忆，可以将 chgrp 理解为是 \u0026ldquo;change group\u0026rdquo; 的缩写。\nchgrp 命令的用法很简单，其基本格式为：\n[root@localhost ~]# chgrp [-R] 所属组 文件名（目录名） -R（注意是大写）选项长作用于更改目录的所属组，表示更改连同子目录中所有文件的所属组信息。\n使用此命令需要注意的一点是，要被改变的群组名必须是真实存在的，否则命令无法正确执行，会提示 \u0026ldquo;invaild group name\u0026rdquo;。\n举个例子，当以 root 身份登录 Linux 系统时，主目录中会存在一个名为 install.log 的文件，我们可以使用如下方法修改此文件的所属组：\n[root@localhost ~]# groupadd group1 #新建用于测试的群组 group1 [root@localhost ~]# chgrp group1 install.log #修改install.log文件的所属组为group1 [root@localhost ~]# ll install.log -rw-r--r--. 1 root group1 78495 Nov 17 05:54 install.log #修改生效 [root@localhost ~]# chgrp testgroup install.log chgrp: invaild group name \u0026#39;testgroup\u0026#39; 可以看到，在具有 group1 群组的前提下，我们成功修改了 install.log 文件的所属组，但我们再次试图将所属组修改为 testgroup 时，命令执行失败，就是因为系统的 /etc/group 文件中，没有 testgroup 群组。\n2. Linux chown命令：修改文件和目录的所有者和所属组 chown 命令，可以认为是 \u0026ldquo;change owner\u0026rdquo; 的缩写，主要用于修改文件（或目录）的所有者，除此之外，这个命令也可以修改文件（或目录）的所属组。\n当只需要修改所有者时，可使用如下 chown 命令的基本格式：\n[root@localhost ~]# chown [-R] 所有者 文件或目录 -R（注意大写）选项表示连同子目录中的所有文件，都更改所有者。\n如果需要同时更改所有者和所属组，chown 命令的基本格式为：\n[root@localhost ~]# chown [-R] 所有者:所属组 文件或目录 注意，在 chown 命令中，所有者和所属组中间也可以使用点（.），但会产生一个问题，如果用户在设定账号时加入了小数点（例如 zhangsan.temp），就会造成系统误判。因此，建议大家使用冒号连接所有者和所属组。\n当然，chown 命令也支持单纯的修改文件或目录的所属组，例如 chown :group install.log 就表示修改 install.log 文件的所属组，但修改所属组通常使用 chgrp 命令，因此并不推荐大家使用 chown 命令。\n另外需要注意的一点是，使用 chown 命令修改文件或目录的所有者（或所属者）时，要保证使用者用户（或用户组）存在，否则该命令无法正确执行，会提示 \u0026ldquo;invalid user\u0026rdquo; 或者 \u0026ldquo;invaild group\u0026rdquo;。\n【例 1】\n其实，修改文件的所有者，更多时候是为了得到更高的权限，举一个实例：\n[root@localhost ~]# touch file #由root用户创建file文件 [root@localhost ~]# ll file -rw-r--r--. 1 root root 0 Apr 17 05:12 file #文件的所有者是root，普通用户user对这个文件拥有只读权限 [root@localhost ~]# chown user file #修改文件的所有者 [root@localhost ~]# ll file -rw-r--r--. 1 user root 0 Apr 17 05:12 file #所有者变成了user用户，这时user用户对这个文件就拥有了读、写权限 可以看到，通过修改 file 文件的所有者，user 用户从其他人身份（只对此文件有读取权限）转变成了所有者身份，对此文件拥有读和写权限。\n【例 2】\nLinux 系统中，用户等级权限的划分是非常清楚的，root 用户拥有最高权限，可以修改任何文件的权限，而普通用户只能修改自己文件的权限（所有者是自己的文件），例如：\n[root@localhost ~]# cd /home/user #进入user用户的家目录 [root@localhost user]# touch test #由root用户新建文件test [root@localhost user]# ll test -rw-r--r--. 1 root root 0 Apr 17 05:37 test #文件所有者和所属组都是root用户 [root@localhost user]# su - user #切换为user用户 [user@localhost ~]$ chmod 755 test chmod:更改\u0026#34;test\u0026#34;的权限：不允许的操作 #user用户不能修改test文件的权限 [user@localhost ~]$ exit #退回到root身份 [root@localhost user]# chown user test #由root用户把test文件的所有者改为user用户 [root@localhost user]# su - user #切换为user用户 [user@localhost ~]$ chmod 755 test #user用户由于是test文件的所有者，所以可以修改文件的权限 [user@localhost ~]$ ll test -rwxr-xr-x. 1 user root 0 Apr 17 05:37 test #查看权限 可以看到，user 用户无权更改所有者为 root 用户文件的权限，只有普通用户是这个文件的所有者，才可以修改文件的权限。\n【例 3】\n[root@localhost ~]# chown user:group file [root@localhost ~]# ll file -rw-r--r--. 1 user group 0 Apr 17 05:12 file 3. Linux权限位 Linux 系统，最常见的文件权限有 3 种，即对文件的读（用 r 表示）、写（用 w 表示）和执行（用 x 表示，针对可执行文件或目录）权限。在 Linux 系统中，每个文件都明确规定了不同身份用户的访问权限，通过 ls 命令即可看到。 除此之外，我们有时会看到 s（针对可执行文件或目录，使文件在执行阶段，临时拥有文件所有者的权限）和 t（针对目录，任何用户都可以在此目录中创建文件，但只能删除自己的文件），文件设置 s 和 t 权限，会占用 x 权限的位置。\n例如，我们以 root 的身份登陆 Linux，并执行如下指令：\n[root@localhost ~]# ls -al total 156 drwxr-x---. 4 root root 4096 Sep 8 14:06 . drwxr-xr-x. 23 root root 4096 Sep 8 14:21 .. -rw-------. 1 root root 1474 Sep 4 18:27 anaconda-ks.cfg -rw-------. 1 root root 199 Sep 8 17:14 .bash_history -rw-r--r--. 1 root root 24 Jan 6 2007 .bash_logout ... 可以看到，每行的第一列表示的就是各文件针对不同用户设定的权限，一共 11 位，但第 1 位用于表示文件的具体类型，最后一位此文件受 SELinux 的安全规则管理，不是本节关心的内容，放到后续章节做详细介绍。\n因此，为文件设定不同用户的读、写和执行权限，仅涉及到 9 位字符，以 ls 命令输出信息中的 .bash_logout 文件为例，设定不同用户的访问权限是 rw-r\u0026ndash;r\u0026ndash;，Linux 将访问文件的用户分为 3 类，分别是文件的所有者，所属组（也就是文件所属的群组）以及其他人。除了所有者，以及所属群组中的用户可以访问文件外，其他用户（其他群组中的用户）也可以访问文件，这部分用户都归为其他人范畴.很显然，Linux 系统为 3 种不同的用户身份，分别规定了是否对文件有读、写和执行权限。拿图 1 来说，文件所有者拥有对文件的读和写权限，但是没有执行权限；所属群组中的用户只拥有读权限，也就是说，这部分用户只能访问文件，无法修改文件；其他人也是只能访问文件。\nLinux 系统中，多数文件的文件所有者和所属群组都是 root（都是 root 账户创建的），这也就是为什么，root 用户是超级管理员，权限足够大的原因。\n4. Linux读写执行权限（-r、-w、-x）的真正含义 rwx 权限对文件的作用\n文件，是系统中用来存储数据的，包括普通的文本文件、数据库文件、二进制可执行文件，等等。不同的权限对文件的含义如表 1 所示。\n   rwx权限 对文件的作用     读权限（r） 表示可读取此文件中的实际内容，例如，可以对文件执行 cat、more、less、head、tail 等文件查看命令。   写权限（w） 表示可以编辑、新增或者修改文件中的内容，例如，可以对文件执行 vim、echo 等修改文件数据的命令。注意，无权限不赋予用户删除文件的权利，除非用户对文件的上级目录拥有写权限才可以。   执行权限（x） 表示该文件具有被系统执行的权限。Window系统中查看一个文件是否为可执行文件，是通过扩展名（.exe、.bat 等），但在 Linux 系统中，文件是否能被执行，是通过看此文件是否具有 x 权限来决定的。也就是说，只要文件拥有 x 权限，则此文件就是可执行文件。但是，文件到底能够正确运行，还要看文件中的代码是否正确。    rwx 权限对目录的作用 目录，主要用来记录文件名列表，不同的权限对目录的作用如表 2 所示。\n   rwx权限 对目录的作用     读权限（r） 表示具有读取目录结构列表的权限，也就是说，可以看到目录中有哪些文件和子目录。一旦对目录拥有 r 权限，就可以在此目录下执行 ls 命令，查看目录中的内容。   写权限（w） 对于目录来说，w 权限是最高权限。对目录拥有 w 权限，表示可以对目录做以下操作：     在此目录中建立新的文件或子目录； 删除已存在的文件和目录（无论子文件或子目录的权限是怎样的）； 对已存在的文件或目录做更名操作； 移动此目录下的文件和目录的位置. 一旦对目录拥有 w 权限，就可以在目录下执行 touch、rm、cp、mv 等命令。|\n|执行权限（x）|目录是不能直接运行的，对目录赋予 x 权限，代表用户可以进入目录，也就是说，赋予 x 权限的用户或群组可以使用 cd 命令。|  对目录来说，如果只赋予 r 权限，则此目录是无法使用的。很简单，只有 r 权限的目录，用户只能查看目录结构，根本无法进入目录（需要用 x 权限），更不用说使用了。\n因此，对于目录来说，常用来设定目录的权限其实只有 0（\u0026mdash;）、5（r-x）、7（rwx）这 3 种。\n【例 1】 某目录的权限如下所示：\ndrwxr--r--. 3 root root 4096 Jun 25 08:35 .ssh 系统有个账号名称为 vbird，此账户并不包含在 root 群组中，请问 vbird 对这个目录有何权限？是否可切换到此目录中？\n 答案：vbird 对此目录仅具有 r 的权限，因此 vbird 可以查询此目录下的文件名列表。因为 vbird 不具有 x 的权限，因此 vbird 并不能切换到此目录内。\n 【例 2】 假设有个账号名称为dmtsai，他的家目录在/home/dmtsai/，dmtsai对此目录具有[rwx]的权限。若在此目录下有个名为 the_root.data 的文件，该文件的权限如下：\n-rwx------. 1 root root 4365 Sep 19 23:20 the_root.data 请问 dmtsai 对此文件的权限为何？可否删除此文件？\n 答案：由于 dmtsai 对此文件来说是其他人的身份，因此这个文件他无法读、无法编辑也无法执行，也就是说，他无法变动这个文件的内容就是了。但是由于这个文件在他的家目录下，他在此目录下具有 rwx 的完整权限，因此对于 the_root.data 这个文件来说，是能够删除的。\n 5. Linux chmod命令：修改文件或目录的权限 既然我们已经知道文件权限对于一个系统的重要性，也知道每个文件都设定了针对不同用户的访问权限，那么，是否可以手动修改文件的访问权限呢？\n可以，通过 chmod 命令即可。chmod 命令设定文件权限的方式有 2 种，分别可以使用数字或者符号来进行权限的变更。 chmod命令使用数字修改文件权限 Linux 系统中，文件的基本权限由 9 个字符组成，以 rwxrw-r-x 为例，我们可以使用数字来代表各个权限，各个权限与数字的对应关系如下：\n r \u0026ndash;\u0026gt; 4 w \u0026ndash;\u0026gt; 2 x \u0026ndash;\u0026gt; 1  由于这 9 个字符分属 3 类用户，因此每种用户身份包含 3 个权限（r、w、x），通过将 3 个权限对应的数字累加，最终得到的值即可作为每种用户所具有的权限。\n拿 rwxrw-r-x 来说，所有者、所属组和其他人分别对应的权限值为：\n 所有者 = rwx = 4+2+1 = 7 所属组 = rw- = 4+2 = 6 其他人 = r-x = 4+1 = 5  所以，此权限对应的权限值就是 765。\n使用数字修改文件权限的 chmod 命令基本格式为：\n[root@localhost ~]# chmod [-R] 权限值 文件名 -R（注意是大写）选项表示连同子目录中的所有文件，也都修改设定的权限。\n例如，使用如下命令，即可完成对 .bashrc 目录文件的权限修改：\n[root@localhost ~]# ls -al .bashrc -rw-r--r--. 1 root root 176 Sep 22 2004 .bashrc [root@localhost ~]# chmod 777 .bashrc [root@localhost ~]# ls -al .bashrc -rwxrwxrwx. 1 root root 176 Sep 22 2004 .bashrc 再举个例子，通常我们以 Vim 编辑 Shell 文件批处理文件后，文件权限通常是 rw-rw-r\u0026ndash;（644），那么，如果要将该文件变成可执行文件，并且不让其他人修改此文件，则只需将此文件的权限该为 rwxr-xr-x（755）即可。 chmod命令使用字母修改文件权限 既然文件的基本权限就是 3 种用户身份（所有者、所属组和其他人）搭配 3 种权限（rwx），chmod 命令中用 u、g、o 分别代表 3 种身份，还用 a 表示全部的身份（all 的缩写）。另外，chmod 命令仍使用 r、w、x 分别表示读、写、执行权限。\n使用字母修改文件权限的 chmod 命令，其基本格式如图 1 所示。chmod 命令基本格式 图 1 chmod 命令基本格式\n例如，如果我们要设定 .bashrc 文件的权限为 rwxr-xr-x，则可执行如下命令：\n[root@localhost ~]# chmod u=rwx,go=rx .bashrc [root@localhost ~]# ls -al .bashrc -rwxr-xr-x. 1 root root 176 Sep 22 2004 .bashrc 再举个例子，如果想要增加 .bashrc 文件的每种用户都可做写操作的权限，可以使用如下命令：\n[root@localhost ~]# ls -al .bashrc -rwxr-xr-x. 1 root root 176 Sep 22 2004 .bashrc [root@localhost ~]# chmod a+w .bashrc [root@localhost ~]# ls -al .bashrc -rwxrwxrwx. 1 root root 176 Sep 22 2004 .bashrc 6. Linux umask详解：令新建文件和目录拥有默认权限 Linux 是注重安全性的操作系统，而安全的基础在于对权限的设定，不仅所有已存在的文件和目录要设定必要的访问权限，创建新的文件和目录时，也要设定必要的初始权限。\nWindows 系统中，新建的文件和目录时通过继承上级目录的权限获得的初始权限，而 Linux 不同，它是通过使用 umask 默认权限来给所有新建的文件和目录赋予初始权限的。\n那么，我们如何得知 umask 默认权限的值呢？直接通过 umask 命令即可：\n[root@localhost ~]# umask 0022 #root用户默认是0022，普通用户默认是 0002 大家可能会问，不应该只有 3 个数字（分别对应 3 种用户身份）吗，为什么有 4 个？ umask 默认权限确实由 4 个八进制数组成，但第 1 个数代表的是文件所具有的特殊权限（SetUID、SetGID、Sticky BIT），此部分内容放到后续章节中讲解，现在先不讨论。也就是说，后 3 位数字 \u0026ldquo;022\u0026rdquo; 才是本节真正要用到的 umask 权限值，将其转变为字母形式为 \u0026mdash;-w\u0026ndash;w-。\n注意，虽然 umask 默认权限是用来设定文件或目录的初始权限，但并不是直接将 umask 默认权限作为文件或目录的初始权限，还要对其进行 \u0026ldquo;再加工\u0026rdquo;。\n文件和目录的真正初始权限，可通过以下的计算得到： 文件（或目录）的初始权限 = 文件（或目录）的最大默认权限 - umask权限\n如果按照官方的标准算法，需要将 umask 默认权限使用二进制并经过逻辑与和逻辑非运算后，才能得到最终文件或目录的初始权限，计算过程比较复杂，且容易出错，因此本节给大家介绍了更简单的计算方式。\n显然，如果想最终得到文件或目录的初始权限值，我们还需要了解文件和目录的最大默认权限值。在 Linux 系统中，文件和目录的最大默认权限是不一样的： 对文件来讲，其可拥有的最大默认权限是 666，即 rw-rw-rw-。也就是说，使用文件的任何用户都没有执行（x）权限。原因很简单，执行权限是文件的最高权限，赋予时绝对要慎重，因此绝不能在新建文件的时候就默认赋予，只能通过用户手工赋予。 对目录来讲，其可拥有的最大默认权限是 777，即 rwxrwxrwx。\n接下来，我们利用字母权限的方式计算文件或目录的初始权限。以 umask 值为 022 为例，分别计算新建文件和目录的初始权限： 文件的最大默认权限是 666，换算成字母就是 \u0026ldquo;-rw-rw-rw-\u0026quot;，umask 的值是 022，换算成字母为 \u0026ldquo;\u0026mdash;\u0026ndash;w\u0026ndash;w-\u0026quot;。把两个字母权限相减，得到 (-rw-rw-rw-) - (\u0026mdash;\u0026ndash;w\u0026ndash;w-) = (-rw-r\u0026ndash;r\u0026ndash;)，这就是新建文件的初始权限。我们测试一下：\n[root@localhost ~]# umask 0022 #默认umask的值是0022 [root@localhost ~]# touch file \u0026lt;--新建file空文件 [root@localhost ~]# ll -d file -rw-r--r--. 1 root root 0 Apr 18 02:36 file 目录的默认权限最大可以是 777，换算成字母就是 \u0026ldquo;drwxrwxrwx\u0026rdquo;，umask 的值是 022，也就是 \u0026ldquo;\u0026mdash;\u0026ndash;w\u0026ndash;w-\u0026quot;。把两个字母权限相减，得到的就是新建目录的默认权限，即 (drwxrwxrwx) - (\u0026mdash;\u0026ndash;w\u0026ndash;w-) = (drwxr-xr-x)。我们再来测试一下：\n[root@localhost ~]# umask 0022 [root@localhost ~]# mkdir catalog \u0026lt;--新建catalog目录 [root@localhost ~]# ll -d catalog drwxr-xr-x. 2 root root 4096 Apr 18 02:36 catalog 注意，在计算文件或目录的初始权限时，不能直接使用最大默认权限和 umask 权限的数字形式做减法，这是不对的。例如，若 umask 默认权限的值为 033，按照数字形式计算文件的初始权限，666-033=633，但我们按照字母的形式计算会得到 （rw-rw-rw-) - (\u0026mdash;-wx-wx) = (rw-r\u0026ndash;r\u0026ndash;)，换算成数字形式是 644。 这里的减法，其实是“遮盖”的意思，也就是说，最大默认权限中和 umask 权限公共的部分，通过减法运算会被遮盖掉，最终剩下的“最大默认权限”，才是最终赋予文件或目录的初始权限。\numask默认权限的修改方法 umask 权限值可以通过如下命令直接修改：\n[root@localhost ~]# umask 002 [root@localhost ~]# umask 0002 [root@localhost ~]# umask 033 [root@localhost ~]# umask 0033 不过，这种方式修改的 umask 只是临时有效，一旦重启或重新登陆系统，就会失效。如果想让修改永久生效，则需要修改对应的环境变量配置文件 /etc/profile。例如：\n[root@localhost ~]# vim /etc/profile ...省略部分内容... if [ $UID -gt 199]\u0026amp;\u0026amp;[ \u0026#34;\u0026#39;id -gn\u0026#39;\u0026#34; = \u0026#34;\u0026#39;id -un\u0026#39;\u0026#34; ]; then umask 002 #如果UID大于199（普通用户），则使用此umask值 else umask 022 #如果UID小于199（超级用户），则使用此umask值 fi ...省略部分内容... 这是一段 Shell 脚本程序，不懂也没关系，大家只需要知道，普通用户的 umask 由 if 语句的第一段定义，而超级用户 root 的 umask 值由 else 语句定义即可。 修改此文件，则 umask 值就会永久生效。\n7. ACL权限是什么，Linux ACL访问控制权限（包含开启方式） Linux 系统传统的权限控制方式，无非是利用 3 种身份（文件所有者，所属群组，其他用户），并分别搭配 3 种权限（读 r，写 w，访问 x）。比如，我们可以通过 ls -l 命令查看当前目录中所有文件的详细信息，其中就包含对各文件的权限设置：\n[root@localhost ~]# ls -l total 36 drwxr-xr-x. 2 root root 4096 Apr 15 16:33 Desktop drwxr-xr-x. 2 root root 4096 Apr 15 16:33 Documents ... -rwxr-xr-x. 2 root root 4096 Apr 15 16:33 post-install ... 以上输出信息中，“rwxr-xr-x”就指明了不同用户访问文件的权限，即文件所有者拥有对文件的读、写、访问权限（rwx），文件所属群组拥有对文件的读、访问权限（r-x），其他用户拥有对文件的读、访问权限（r-x）。 权限前的字符，表示文件的具体类型，比如 d 表示目录，- 表示普通文件，l 表示连接文件，b 表示设备文件，等等。\n但在实际应用中，以上这 3 种身份根本不够用，给大家举个例子。 ACL控制权限 图 1 ACL 访问控制权限\n图 1 的根目录中有一个 /project 目录，这是班级的项目目录。班级中的每个学员都可以访问和修改这个目录，老师需要拥有对该目录的最高权限，其他班级的学员当然不能访问这个目录。\n需要怎么规划这个目录的权限呢？应该这样，老师使用 root 用户，作为这个目录的属主，权限为 rwx；班级所有的学员都加入 tgroup 组，使 tgroup 组作为 /project 目录的属组，权限是 rwx；其他人的权限设定为 0（也就是 \u0026mdash;）。这样一来，访问此目录的权限就符合我们的要求了。\n有一天，班里来了一位试听的学员 st，她必须能够访问 /project 目录，所以必须对这个目录拥有 r 和 x 权限；但是她又没有学习过以前的课程，所以不能赋予她 w 权限，怕她改错了目录中的内容，所以学员 st 的权限就是 r-x。可是如何分配她的身份呢？变为属主？当然不行，要不 root 该放哪里？加入 tgroup 组？也不行，因为 tgroup 组的权限是 rwx，而我们要求学员 st 的权限是 r-x。如果把其他人的权限改为 r-x 呢？这样一来，其他班级的所有学员都可以访问 /project 目录了。\n显然，普通权限的三种身份不够用了，无法实现对某个单独的用户设定访问权限，这种情况下，就需要使用 ACL 访问控制权限。\nACL，是 Access Control List（访问控制列表）的缩写，在 Linux 系统中， ACL 可实现对单一用户设定访问文件的权限。也可以这么说，设定文件的访问权限，除了用传统方式（3 种身份搭配 3 种权限），还可以使用 ACL 进行设定。拿本例中的 st 学员来说，既然赋予它传统的 3 种身份，无法解决问题，就可以考虑使用 ACL 权限控制的方式，直接对 st 用户设定访问文件的 r-x 权限。 开启 ACL 权限 CentOS 6.x 系统中，ACL 权限默认处于开启状态，无需手工开启。但如果你的操作系统不是 CentOS 6.x，可以通过如下方式查看ACL权限是否开启：\n[root@localhost ~]# mount /dev/sda1 on /boot type ext4 (rw) /dev/sda3 on I type ext4 (rw) …省略部分输出… #使用mount命令可以看到系统中已经挂载的分区，但是并没有看到ACL权限的设置 [root@localhost ~]# dumpe2fs -h /dev/sda3 #dumpe2fs是查询指定分区文件系统详细信息的命令 …省略部分输出… Default mount options: user_xattr acl …省略部分输出… `` 其中，dumpe2fs 命令的 -h 选项表示仅显示超级块中的信息，而不显示磁盘块组的详细信息； 使用 mount 命令可以查看到系统中已经挂载的分区，而使用 dumpe2fs 命令可以查看到这个分区文件系统的详细信息。大家可以看到，我们的 ACL 权限是 /dev/sda3 分区的默认挂载选项，所以不需要手工挂载。 如果 Linux 系统如果没有默认挂载，可以执行如下命令实现手动挂载： ```bash [root@localhost ~]# mount -o remount,acl /  #重新挂载根分区，并加入ACL权限  使用 mount 命令重新挂载，并加入 ACL 权限。但使用此命令只是临时生效，要想永久生效，需要修改 /etc/fstab 文件，修改方法如下：\n[root@localhost ~]#vi /etc/fstab UUID=c2ca6f57-b15c-43ea-bca0-f239083d8bd2 /ext4 defaults,acl 1 1 #加入ACL权限 [root@localhost ~]# mount -o remount / #重新挂载文件系统或重启系统，使修改生效 在你需要开启 ACL 权限的分区行上（也就是说 ACL 权限针对的是分区），手工在 defaults 后面加入 \u0026ldquo;，acl\u0026rdquo; 即可永久在此分区中开启 ACL 权限。\n8. Linux ACL权限设置（setfacl和getfacl） 通过上一节的学习，我们知道了什么是 ACL 权限，也了解了如何配置 Linux 系统使其开启 ACL 权限，本节来学习 ACL 设定文件访问权限的具体方法。\n设定 ACl 权限，常用命令有 2 个，分别是 setfacl 和 getfacl 命令，前者用于给指定文件或目录设定 ACL 权限，后者用于查看是否配置成功。\ngetfacl 命令用于查看文件或目录当前设定的 ACL 权限信息。该命令的基本格式为：\n[root@localhost ~]# getfacl 文件名 getfacl 命令的使用非常简单，且常和 setfacl 命令一起搭配使用。\nsetfacl 命令可直接设定用户或群组对指定文件的访问权限。此命令的基本格式为：\n[root@localhost ~]# setfacl 选项 文件名 表 1 罗列出了该命令可以使用的所用选项及功能。\n表 1 setfacl 命令选项及用法\n   选项 功能     -m 参数 设定 ACL 权限。如果是给予用户 ACL 权限，参数则使用 \u0026ldquo;u:用户名:权限\u0026rdquo; 的格式，例如 setfacl -m u:st:rx /project 表示设定 st 用户对 project 目录具有 rx 权限；如果是给予组 ACL 权限，参数则使用 \u0026ldquo;g:组名:权限\u0026rdquo; 格式，例如 setfacl -m g:tgroup:rx /project 表示设定群组 tgroup 对 project 目录具有 rx 权限。   -x 参数 删除指定用户（参数使用 u:用户名）或群组（参数使用 g:群组名）的 ACL 权限，例如 setfacl -x u:st /project 表示删除 st 用户对 project 目录的 ACL 权限。   -b 删除所有的 ACL 权限，例如 setfacl -b /project 表示删除有关 project 目录的所有 ACL 权限。   -d 设定默认 ACL 权限，命令格式为 \u0026ldquo;setfacl -m d:u:用户名:权限 文件名\u0026rdquo;（如果是群组，则使用 d:g:群组名:权限），只对目录生效，指目录中新建立的文件拥有此默认权限，例如 setfacl -m d:u:st:rx /project 表示 st 用户对 project 目录中新建立的文件拥有 rx 权限。   -R 递归设定 ACL 权限，指设定的 ACL 权限会对目录下的所有子文件生效，命令格式为 \u0026ldquo;setfacl -m u:用户名:权限 -R 文件名\u0026rdquo;（群组使用 g:群组名:权限），例如 setfacl -m u:st:rx -R /project 表示 st 用户对已存在于 project 目录中的子文件和子目录拥有 rx 权限。   -k 删除默认 ACL 权限。    setfacl -m：给用户或群组添加 ACL 权限 回归上一节案例，解决方案如下：\n 老师使用 root 用户，并作为 /project 的所有者，对 project 目录拥有 rwx 权限； 新建 tgroup 群组，并作为 project 目录的所属组，包含本班所有的班级学员（假定只有 zhangsan 和 lisi），拥有对 project 的 rwx 权限； 将其他用户访问 project 目录的权限设定为 0（也就是 \u0026mdash;）。 对于试听学员 st 来说，我们对其设定 ACL 权限，令该用户对 project 拥有 rx 权限。  具体的设置命令如下：\n[root@localhost ~]# useradd zhangsan [root@localhost ~]# useradd lisi [root@localhost ~]# useradd st [root@localhost ~]# groupadd tgroup \u0026lt;-- 添加需要试验的用户和用户组，省略设定密码的过程 [root@localhost ~]# mkdir /project \u0026lt;-- 建立需要分配权限的目录 [root@localhost ~]# chown root:tgroup /project \u0026lt;-- 改变/project目录的所有者和所属组 [root@localhost ~]# chmod 770 /project \u0026lt;-- 指定/project目录的权限 [root@localhost ~]# ll -d /project drwxrwx---. 2 root tgroup 4096 Apr 16 12:55 /project #这时st学员来试听了，如何给她分配权限 [root@localhost ~]# setfacl -m u:st:rx /project #给用户st赋予r-x权限，使用\u0026#34;u:用户名：权限\u0026#34; 格式 [root@localhost /]# cd / [root@localhost /]# ll -d /project drwxrwx---+ 2 root tgroup 4096 Apr 16 12:55 /project #如果查询时会发现，在权限位后面多了一个\u0026#34;+\u0026#34;，表示此目录拥有ACL权限 [root@localhost /]# getfacl project #查看/prpject目录的ACL权限 #file:project \u0026lt;--文件名 #owner:root \u0026lt;--文件的所有者 #group:tgroup \u0026lt;--文件的所属组 user::rwx \u0026lt;--用户名栏是空的，说明是所有者的权限 user:st:r-x \u0026lt;--用户st的权限 group::rwx \u0026lt;--组名栏是空的，说明是所属组的权限 mask::rwx \u0026lt;--mask权限 other::--- \u0026lt;--其他人的权限 可以看到，通过设定 ACL 权限，我们可以单独给 st 用户分配 r-x 权限，而无需给 st 用户设定任何身份。\n同样的道理，也可以给用户组设定 ACL 权限，例如：\n[root@localhost /]# groupadd tgroup2 #添加新群组 [root@localhost /]# setfacl -m g:tgroup2:rwx project #为组tgroup2纷配ACL权限 [root@localhost /]# ll -d project drwxrwx---+ 2 root tgroup 4096 1月19 04:21 project #属组并没有更改 [root@localhost /]# getfacl project #file: project #owner: root #group: tgroup user::rwx user:st:r-x group::rwx group:tgroup2:rwx \u0026lt;-用户组tgroup2拥有了rwx权限 mask::rwx other::--- setfacl -d：设定默认 ACL 权限 既然已经对 project 目录设定了 ACL 权限，那么，如果在这个目录中新建一些子文件和子目录，这些文件是否会继承父目录的 ACL 权限呢？执行以下命令进行验证：\n[root@localhost /]# cd project [root@localhost project]# touch abc [root@localhost project]# mkdir d1 #在/project目录中新建了abc文件和d1目录 [root@localhost project]#ll 总用量4 -rw-r--r-- 1 root root 01月19 05:20 abc drwxr-xr-x 2 root root 4096 1月19 05:20 d1 可以看到，这两个新建立的文件权限位后面并没有 \u0026ldquo;+\u0026quot;，表示它们没有继承 ACL 权限。这说明，后建立的子文件或子目录，并不会继承父目录的 ACL 权限。\n当然，我们可以手工给这两个文件分配 ACL 权限，但是如果在目录中再新建文件，都要手工指定，则显得过于麻烦。这时就需要用到默认 ACL 权限。\n默认 ACL 权限的作用是，如果给父目录设定了默认 ACL 权限，那么父目录中所有新建的子文件都会继承父目录的 ACL 权限。需要注意的是，默认 ACL 权限只对目录生效。\n例如，给 project 文件设定 st 用户访问 rx 的默认 ACL 权限，可执行如下指令：\n[root@localhost /]# setfacl -m d:u:st:rx project [root@localhost project]# getfacl project # file: project # owner: root # group: tgroup user:: rwx user:st:r-x group::rwx group:tgroup2:rwx mask::rwx other::--- default:user::rwx \u0026lt;--多出了default字段 default:user:st:r-x default:group::rwx default:mask::rwx default:other::--- [root@localhost /]# cd project [root@localhost project]# touch bcd [root@localhost project]# mkdir d2 #新建子文件和子目录 [root@localhost project]# ll 总用量8 -rw-r--r-- 1 root root 01月19 05:20 abc -rw-rw----+ 1 root root 01月19 05:33 bcd drwxr-xr-x 2 root root 4096 1月19 05:20 d1 drwxrwx---+ 2 root root 4096 1月19 05:33 d2 #新建的bcd和d2已经继承了父目录的ACL权限 大家发现了吗？原先的 abc 和 d1 还是没有 ACL 权限，因为默认 ACL 权限是针对新建立的文件生效的。\n对目录设定的默认 ACL 权限，可直接使用 setfacl -k 命令删除。例如：\n[root@localhost /]# setfacl -k project 通过此命令，即可删除 project 目录的默认 ACL 权限，读者可自行通过 getfacl 命令查看。 setfacl -R：设定递归 ACL 权限 递归 ACL 权限指的是父目录在设定 ACL 权限时，所有的子文件和子目录也会拥有相同的 ACL 权限。\n例如，给 project 目录设定 st 用户访问权限为 rx 的递归 ACL 权限，执行命令如下：\n[root@localhost project]# setfacl -m u:st:rx -R project [root@localhost project]# ll 总用量 8 -rw-r-xr--+ 1 root root 01月19 05:20 abc -rw-rwx--+ 1 root root 01月19 05:33 bcd drwxr-xr-x+ 2 root root 4096 1月19 05:20 d1 drwxrwx---+ 2 root root 4096 1月19 05:33 d2 #abc和d1也拥有了ACL权限 注意，默认 ACL 权限指的是针对父目录中后续建立的文件和目录会继承父目录的 ACL 权限；递归 ACL 权限指的是针对父目录中已经存在的所有子文件和子目录会继承父目录的 ACL 权限。 setfacl -x：删除指定的 ACL 权限 使用 setfacl -x 命令，可以删除指定的 ACL 权限，例如，删除前面建立的 st 用户对 project 目录的 ACL 权限，执行命令如下：\n[root@localhost /]# setfacl -x u:st project #删除指定用户和用户组的ACL权限 [root@localhost /]# getfacl project # file:project # owner: root # group: tgroup user::rwx group::rwx group:tgroup2:rwx mask::rwx other::--- #st用户的权限已被删除 setfacl -b：删除指定文件的所有 ACL 权限 此命令可删除所有与指定文件或目录相关的 ACL 权限。例如，现在我们删除一切与 project 目录相关的 ACL 权限，执行命令如下：\n[root@localhost /]# setfacl -b project #会删除文件的所有ACL权限 [root@localhost /]# getfacl project #file: project #owner: root # group: tgroup user::rwx group::rwx other::--- #所有ACL权限已被删除 9. Linux mask有效权限详解 前面，我们已经学习如何使用 setfacl 和 getfacl 为用户或群组添加针对某目录或文件的 ACL 权限。例如：\n[root@localhost /]# getfacl project #file: project \u0026lt;-文件名 #owner: root \u0026lt;-文件的属主 #group: tgroup \u0026lt;-文件的属组 user::rwx \u0026lt;-用户名栏是空的，说明是所有者的权限 group::rwx \u0026lt;-组名栏是空的，说明是所属组的权限 other::--- \u0026lt;-其他人的权限 [root@localhost ~]# setfacl -m u:st:rx /project #给用户st设定针对project目录的rx权限 [root@localhost /]# getfacl project #file: project  #owner: root #group: tgroup  user::rwx user:st:r-x \u0026lt;-用户 st 的权限 group::rwx mask::rwx \u0026lt;-mask 权限 other::--- 对比添加 ACL 权限前后 getfacl 命令的输出信息，后者多了 2 行信息，一行是我们对 st 用户设定的 r-x 权限，另一行就是 mask 权限。\nmask 权限，指的是用户或群组能拥有的最大 ACL 权限，也就是说，给用户或群组设定的 ACL 权限不能超过 mask 规定的权限范围，超出部分做无效处理。\n举个例子，如果像上面命令那样，给 st 用户赋予访问 project 目录的 r-x 权限，此时并不能说明 st 用户就拥有了对该目录的读和访问权限，还需要和 mask 权限对比，r-x 确实是在 rwx 范围内，这时才能说 st 用户拥有 r-x 权限。 需要注意的是，这里将权限进行对比的过程，实则是将两权限做“按位相与”运算，最终得出的值，即为 st 用户有效的 ACL 权限。这里以读（r）权限为例，做相与操作的结果如表 1 所示：\n表 1 读权限做相与操作\n   A B and     r r r   r - -   - r -   - - -    但是，如果把 mask 权限改为 r\u0026ndash;，再和 st 用户的权限 r-x 比对（r\u0026ndash; 和 r-w 做与运算），由于 r-w 超出 r\u0026ndash; 的权限范围，因此 st 用户最终只有 r 权限，手动赋予的 w 权限无效。这就是在设定 ACL 权限时 mask 权限的作用。\n大家可以这样理解 mask 权限的功能，它将用户或群组所设定的 ACL 权限限制在 mask 规定的范围内，超出部分直接失效。\nmask 权限可以使用 setfacl 命令手动更改，比如，更改 project 目录 mask 权限值为 r-x，可执行如下命令：\n[root@localhost ~]# setfacl -m m:rx /project #设定mask权限为r-x，使用\u0026#34;m:权限\u0026#34;格式 [root@localhost ~]# getfacl /project #file：project #owner：root #group：tgroup user::rwx group::rwx mask::r-x \u0026lt;--mask权限变为r-x other::--- 不过，我们一般不更改 mask 权限，只要赋予 mask 最大权限（也就是 rwx），则给用户或群组设定的 ACL 权限本身就是有效的。\n10. Linux SetUID（SUID）文件特殊权限用法详解 在讲解《权限位》一节时提到过，其实除了 rwx 权限，还会用到 s 权限，例如：\n[root@localhost ~]# ls -l /usr/bin/passwd -rwsr-xr-x. 1 root root 22984 Jan 7 2007 /usr/bin/passwd 可以看到，原本表示文件所有者权限中的 x 权限位，却出现了 s 权限，此种权限通常称为 SetUID，简称 SUID 特殊权限。\nSUID 特殊权限仅适用于可执行文件，所具有的功能是，只要用户对设有 SUID 的文件有执行权限，那么当用户执行此文件时，会以文件所有者的身份去执行此文件，一旦文件执行结束，身份的切换也随之消失。\n举一个例子，我们都知道，Linux 系统中所有用户的密码数据都记录在 /etc/shadow 这个文件中，通过 ll /etc/shadow 命令可以看到，此文件的权限是 0（\u0026mdash;\u0026mdash;\u0026mdash;），也就是说，普通用户对此文件没有任何操作权限。\n这就会产生一个问题，为什么普通用户可以使用 passwd 命令修改自己的密码呢？\n本节开头已经显示了 passwd 命令的权限配置，可以看到，此命令拥有 SUID 特殊权限，而且其他人对此文件也有执行权限，这就意味着，任何一个用户都可以用文件所有者，也就是 root 的身份去执行 passwd 命令。 Linux 系统中，绝对多数命令的文件所有者默认都是 root。\n换句话说，当普通用户使用 passwd 命令尝试更改自己的密码时，实际上是在以 root 的身份执行passwd命令，正因为 root 可以将密码写入 /etc/shadow 文件，所以普通用户也能做到。只不过，一旦命令执行完成，普通用户所具有的 root身份也随之消失。\n如果我们手动将 /usr/bin/passwd 文件的 SUID 权限取消，会发生什么呢？观察如下命令的执行过程：\n[root@localhost ~]# chmod u-s /usr/bin/passwd #属主取消SetUID权限 [root@localhost ~]# ll /usr/bin/passwd -rwxr-xr-x. 1 root root 30768 Feb 22 2012 /usr/bin/passwd [root@localhost ~]# su - lamp [lamp@localhost ~]$ passwd Changing password for user lamp. Changing password for user. (current) UNIX password: #看起来没有什么问题 New passwor: Retype new password: password:Authentication token manipulation error \u0026lt;--鉴定令牌操作错误 #最后密码没有生效 显然，虽然用户有执行 passwd 命令的权限，但无修改 /etc/shadow 文件的权限，因此最终密码修改失败。 注意，实验完成后，一定要再把 /usr/bin/passwd 文件的 SetUID 权限加上。\n那么，普通用户可以使用 cat 命令查看 /etc/shadow 文件吗？答案的否定的，因为 cat 不具有 SUID 权限，因此普通用户在执行 cat /etc/shadow 命令时，无法以 root 的身份，只能以普通用户的身份，因此无法成功读取。\n我们可以使用下面这张图来描述上述过程： SUID示意图 图 1 SUID示意图\n由此，我们可以总结出，SUID 特殊权限具有如下特点： 只有可执行文件才能设定 SetUID 权限，对目录设定 SUID，是无效的。 用户要对该文件拥有 x（执行）权限。 用户在执行该文件时，会以文件所有者的身份执行。 SetUID 权限只在文件执行过程中有效，一旦执行完毕，身份的切换也随之消失。\n11. SetUID（SUID）千万不要胡乱使用！ SetUID权限设置不当，会给 Linux 系统造成重大安全隐患。\n前面的例子中，我们试验了将 passwd 命令取消 SUID 权限，这会导致 passwd 命令的功能失效。那么，如果我们手动给默认无 SetUID 权限的系统命令赋予 SetUID 权限，会出现什么情况呢？\n比如说，我们尝试给 Vim 赋予 SetUID 权限：\n[root@localhost ~]# chmod u+s /usr/bin/vim [root@localhost ~]# ll /usr/bin/vim -rwsr-xr-x. 1 root root 1847752 Apr 5 2012 /usr/bin/vim 此时你会发现，即便是普通用户使用 vim 命令，都会暂时获得 root 的身份和权限，例如，很多原本普通用户不能查看和修改的文件，竟然可以查看了，以 /etc/passwd 和 /etc/shadow 文件为例，普通用户也可以将自己的 UID 手动修改为 0，这意味着，此用户升级成为了超级用户。除此之外，普通用户还可以修改例如 /etc/inittab 和 /etc/fstab 这样重要的系统文件，可以轻易地使系统瘫痪。\n其实，任何只有管理员可以执行的命令，如果被赋予了 SetUID 权限，那么后果都是灾难性的。普通用户可以随时重启服务器、随时关闭看得不顺眼的服务、随时添加其他普通用户的服务器，可以想象是什么样子。所以，SetUID 权限不能随便设置。\n有读者可能会问，如何防止他人（例如黑客）对 SetUID 权限的恶意篡改呢？这里，给大家提供以下几点建议： 关键目录要严格控制写权限，比如 \u0026ldquo;/\u0026quot;、\u0026quot;/usr\u0026rdquo; 等。 用户的密码设置要严格遵守密码规范。 对系统中默认应该有 SetUID 权限的文件制作一张列表，定时检査有没有列表之外的文件被设置了 SetUID 权限。\n前面 2 点不再做过多解释，这里就最后一点，给大家提供一个脚本，仅供参考。\n首先，在服务器第一次安装完成后，马上查找系统中所有拥有 SetUID 和 SetGID 权限的文件，把它们记录下来，作为扫描的参考模板。如果某次扫描的结果和本次保存下来的模板不一致，就说明有文件被修改了 SetUID 和 SetGID 权限。命令如下：\n[root@localhost ~]# find / -perm -4000 -o -perm -2000 \u0026gt; /root/suid.list #-perm安装权限査找。-4000对应的是SetUID权限，-2000对应的是SetGID权限 #-o是逻辑或\u0026#34;or\u0026#34;的意思。并把命令搜索的结果放在/root/suid.list文件中 接下来，只要定时扫描系统，然后和模板文件比对就可以了。脚本如下：\n[root@localhost ~]#vi suidcheck.sh #!/bin/bash find / -perm -4000 -o -perm -2000 \u0026gt; /tmp/setuid.check #搜索系统中所有拥有SetUID和SetGID权限的文件，并保存到临时目录中 for i in $(cat /tmp/setuid.check) #循环，每次循环都取出临时文件中的文件名 do grep $i /root/suid.list \u0026gt; /dev/null #比对这个文件名是否在模板文件中 if [\u0026#34;$?\u0026#34;!=\u0026#34;o\u0026#34;] #检测测上一条命令的返回值，如果不为0，则证明上一条命令报错 then echo \u0026#34;$iisn\u0026#39;t in listfile! \u0026#34; \u0026gt;\u0026gt;/root/suid_log_$(date +%F) #如果文件名不在模板文件中，则输出错误信息，并把报错写入日志中 fi done rm -rf/tmp/setuid.check #删除临时文件 [root@localhost ~]# chmod u+s /bin/vi #手工给vi加入SetUID权限 [root@localhost ~]# ./suidcheck.sh #执行检测脚本 [root@localhost ~]# cat suid_log_2013-01-20 /bin/vi isn\u0026#39;t in listfile! #报错了，vi不在模板文件中。代表vi被修改了SetUID权限 这个脚本成功的关键在于模板文件是否正常。所以一定要安装完系统就马上建立模板文件，并保证模板文件的安全。\n注意，除非特殊情况，否则不要手工修改 SetUID 和 SetGID 权限，这样做非常不安全。而且就算我们做实验修改了 SetUID 和 SetGID 权限，也要马上修改回来，以免造成安全隐患。 SetGID 特殊权限的相关内容，下节会做详细介绍。\n12. Linux SetGID（SGID）文件特殊权限用法详解 前面学习了 SetUID，那么，什么是 SetGID 呢？很简单，当 s 权限位于所属组的 x 权限位时，就被称为 SetGID，简称 SGID 特殊权限。例如：\n[root@localhost ~]# ll /usr/bin/locate -rwx--s--x. 1 root slocate 35612 8月24 2010 /usr/bin/locate 与 SUID 不同的是，SGID 既可以对文件进行配置，也可以对目录进行配置。 SetGID（SGID）对文件的作用 同 SUID 类似，对于文件来说，SGID 具有如下几个特点： SGID 只针对可执行文件有效，换句话说，只有可执行文件才可以被赋予 SGID 权限，普通文件赋予 SGID 没有意义。 用户需要对此可执行文件有 x 权限； 用户在执行具有 SGID 权限的可执行文件时，用户的群组身份会变为文件所属群组； SGID 权限赋予用户改变组身份的效果，只在可执行文件运行过程中有效； 其实，SGID 和 SUID 的不同之处就在于，SUID 赋予用户的是文件所有者的权限，而 SGID 赋予用户的是文件所属组的权限，就这么简单。\n就以本节开头的 locate 命令为例，可以看到，/usr/bin/locate 文件被赋予了 SGID 的特殊权限，这就意味着，当普通用户使用 locate 命令时，该用户的所属组会直接变为 locate 命令的所属组，也就是 slocate。\n我们知道，locate 命令是用于在系统中按照文件名查找符合条件的文件的，当执行搜索操作时，它会通过搜索 /var/lib/mlocate/mlocate.db 这个数据库中的数据找到答案，我们来看看此数据库的权限：\n[root@localhost ~]# ll /var/lib/mlocate/mlocate.db -rw-r-----. 1 root slocate 1838850 1月20 04:29 /var/lib/mlocate/mlocate.db 可以看到，mlocate.db 文件的所属组为 slocate，虽然对文件只拥有 r 权限，但对于普通用户执行 locate 命令来说，已经足够了。一方面，普通用户对 locate命令拥有执行权限，其次，locate 命令拥有 SGID 权限，这使得普通用户在执行 locate 命令时，所属组身份会变为 slocate，而 slocate 对 mlocate.db 数据库文件拥有 r 权限，所以即便是普通用户，也可以成功执行 locate 命令。 再次强调，无论是 SUID，还是 SGID，它们对用户身份的转换，只有在命令执行的过程中有效，一旦命令执行完毕，身份转换也随之失效。\nSetGID（SGID）对目录的作用 事实上，SGID 也能作用于目录，且这种用法很常见。\n当一个目录被赋予 SGID 权限后，进入此目录的普通用户，其有效群组会变为该目录的所属组，会就使得用户在创建文件（或目录）时，该文件（或目录）的所属组将不再是用户的所属组，而使用的是目录的所属组。\n也就是说，只有当普通用户对具有 SGID 权限的目录有 rwx 权限时，SGID 的功能才能完全发挥。比如说，如果用户对该目录仅有 rx 权限，则用户进入此目录后，虽然其有效群组变为此目录的所属组，但由于没有 x 权限，用户无法在目录中创建文件或目录，SGID 权限也就无法发挥它的作用。\n举个例子：\n[root@localhost ~]# cd /tmp #进入临时目录做此实验。因为只有临时目录才允许普通用户修改 [root@localhost tmp]# mkdir dtest #建立测试目录 [root@localhost tmp]# chmod g+s dtest #给测试目录赋予SetGID权限 [root@localhost tmp]# ll -d dtest drwxr-sr-x 2 root root 4096 Apr 19 06:04 dtest #SetGID权限已经生效 [root@localhost tmp]# chmod 777 dtest #给测试目录赋予777权限，让普通用户可以写 [root@localhost tmp]# su - lamp [lamp@localhost ~]# grep lamp /etc/passwd /etc/group /etc/passwd:lamp:x:501:501::/home/lamp:/bin/bash /etc/group:lamp:x:501: #切换成普通用户lamp，此用户的所属群组为 lamp [lamp@localhost ~]$ cd /tmp/dtest/ #普通用户进入测试目录 [lamp@localhost dtest]$ touch abc [lamp@localhost dtest]$ mkdir zimulu #在此目录中创建新的文件 abc 和子目录 zimulu [lamp@localhost dtest]$ ll total 0 -rw-rw-r--. 1 lamp root 0 Apr 19 06:07 abc drwxrwsr-x. 2 lamp root 40 Apr 19 06:07 zimulu 可以看到，虽然是 lamp 用户创建的 abc 文件和 zimulu 目录，但它们的所属组都不是 lamp（lamp 用户的所属组），而是 root（dtest 目录的所属组）。\n13. Linux Stick BIT（SBIT）文件特殊权限用法详解 Sticky BIT，简称 SBIT 特殊权限，可意为粘着位、粘滞位、防删除位等。\nSBIT 权限仅对目录有效，一旦目录设定了 SBIT 权限，则用户在此目录下创建的文件或目录，就只有自己和 root 才有权利修改或删除该文件。\n也就是说，当甲用户以目录所属组或其他人的身份进入 A 目录时，如果甲对该目录有 w 权限，则表示对于 A 目录中任何用户创建的文件或子目录，甲都可以进行修改甚至删除等操作。但是，如果 A 目录设定有 SBIT 权限，那就大不一样啦，甲用户只能操作自己创建的文件或目录，而无法修改甚至删除其他用户创建的文件或目录。\n举个例子，Linux 系统中，存储临时文件的 /tmp 目录就设定有 SBIT 权限：\n[root@localhost ~]# ll -d /tmp drwxrwxrwt. 4 root root 4096 Apr 19 06:17 /tmp 可以看到，在其他人身份的权限设定中，原来的 x 权限位被 t 权限占用了，这就表示此目录拥有 SBIT 权限。通过下面一系列的命令操作，我们来具体看看 SBIT 权限对 /tmp 目录的作用。 [root@localhost ~]# useradd lamp [root@localhost ~]# useradd lamp1 #建立测试用户lamp和lamp1，省略设置密码过程 [root@localhost ~]# su -lamp #切换为lamp用户 [lamp@localhost ~]$ cd /tmp [lamp@localhost tmp]$ touch ftest #建立测试文件 [lamp@localhost tmp]$ll ftest -rw-rw-r-- 1 lamp lamp Apr 19 06:36 ftest [lamp@localhost tmp]$ su - lamp1 #省略输入lamp1用户密码的过程，切换成lamp1用户 [lamp1 @localhost ~]$ cd /tmp/ [lamp1 @localhost tmp]$ rm -rf ftest rm:cannot remove \u0026#39;ftest\u0026#39;:Operation not permitted 可以看到，虽然 /tmp 目录的权限设定是 777，但由于其具有 SBIT 权限，因此 lamp 用户在此目录创建的文件 ftest，lamp1 用户删除失败。\n14. Linux文件特殊权限（SUID、SGID和SBIT）设置详解 前面已经学习 SUID、SGID、SBIT 特殊权限，以及各自的含义和功能，那么，如何给文件或目录手动设定这些特殊权限呢？\n还是要依赖 chmod 命令。我们知道，使用 chmod 命令给文件或目录设定权限，有 2 种方式，分别是使用数字形式和字母形式。例如：\n#数字形式 [root@localhost ~]# chmod 755 ftest #字母形式 [root@localhost ~]# chmod u=rwx,go=rx ftest 给文件或目录设定 SUID、SGID 和 SBIT 特殊权限，也可以使用这 2 种形式。\n我们知道，给 chmod 命令传递 3 个数字，即可实现给文件或目录设定普通权限。比如说，\u0026ldquo;755\u0026rdquo; 表示所有者拥有 rwx 权限，所属组拥有 rx 权限，其他人拥有 tx 权限。\n给文件或目录设定特殊权限，只需在这 3 个数字之前增加一个数字位，用来放置给文件或目录设定的特殊权限，就这么简单。\n因此，我们有必要知道 SUID、SGID、SBIT 分别对应的数字，如下所示：\n 4 \u0026ndash;\u0026gt; SUID 2 \u0026ndash;\u0026gt; SGID 1 \u0026ndash;\u0026gt; SBIT  举个例子，如果要将一个文件权限设置为 -rwsr-xr-x，怎么办呢？此文件的普通权限为 755，另外，此文件还有 SUID 权限，因此只需在 755 的前面，加上 SUID 对应的数字 4 即可。也就是说，只需执行chmod 4755 文件名命令，就完成了-rwsr-xr-x 权限的设定。 关于 -rwsr-xr-x 的普通权限是 755，你可以这样理解，标记有 s 和 t 的权限位，隐藏有 x 权限，对此，本节后续会给出更详细的解释。\n同样的道理，如果某文件拥有 SUID 和 SGID 权限，则只需要给 chmod 命令传递 6\u0026mdash;（- 表示数字）即可；如果某目录拥有 SGID 和 SBIT，只需要给 chmod 命令传递 3\u0026mdash; 即可。\n注意，不同的特殊权限，作用的对象是不同的，SUID 只对可执行文件有效；SGID 对可执行文件和目录都有效；SBIT 只对目录有效。当然，你也可以给文件设置 7\u0026mdash;，也就是将 SUID、SGID、SBIT赋予一个文件或目录，例如：\n[root@localhost ~]# chmod 7777 ftest #一次赋予SetUID、SetGID和SBIT权限 [root@localhost ~]# ll ftest -rwsrwsrwt. 1 root root Apr 19 23:54 ftest 执行过程虽然没有报错，但这样做，没有任何实际意义。\n除了赋予 chmod 命令 4 个数字设定特殊权限，还可以使用字母的形式。例如，可以通过 \u0026ldquo;u+s\u0026rdquo; 给文件赋予 SUID 权限；通过 \u0026ldquo;g+s\u0026rdquo; 给文件或目录赋予 SGID 权限；通过 \u0026ldquo;o+t\u0026rdquo; 给目录赋予 SBIT 权限。\n举一个例子：\n[root@localhost ~]#chmod u+s, g+s, o+t ftest #设置特殊权限 [root@localhost ~]# ll ftest -rwsr-sr-t. 1 root root Apr 19 23:54 ftest [root@localhost ~]# chmod u-s, g-s, o-t ftest #取消特殊权限 [root@localhost ~]# ll ftest -rwxr-xr-x. 1 root root Apr 19 23:54 ftest 例子中，通过字母的形式成功给 ftest 文件赋予了 3 种特殊权限，此做法仅为验证字母形式的可行性，对 ftest 文件来说，并无实际意义。\n细心的读者可能发现这样一个问题，使用 chmod 命令给文件或目录赋予特殊权限时，原文件或目录中存在的 x 权限会被替换成 s 或 t，而当我们使用 chmod 命令消除文件或目录的特殊权限时，原本消失的 x 权限又会显现出来。\n这是因为，无论是 SUID、SGID 还是 SBIT，它们只针对具有 x 权限的文件或目录有效。没有 x 权限的文件或目录，即便赋予特殊权限，也无法发挥它们的功能，没有任何意义。\n例如，我们就是要给不具有 x 权限的文件或目录赋予特殊权限，看看有什么效果：\n[root@localhost ~]# chmod 7666 ftest [root@localhost ~]# ll ftest -rwSrwSrwT. 1 root root Apr 23:54 ftest 可以看到，相应的权限位会被标记为 S（大写）和 T（大写），指的就是设置的 SUID、SGID 和 SBIT 权限没有意义。\n15. Linux chattr命令详解：修改文件系统的权限属性 管理 Linux 系统中的文件和目录，除了可以设定普通权限和特殊权限外，还可以利用文件和目录具有的一些隐藏属性。\nchattr 命令，专门用来修改文件或目录的隐藏属性，只有 root 用户可以使用。该命令的基本格式为：\n[root@localhost ~]# chattr [+-=] [属性] 文件或目录名  表示给文件或目录添加属性，- 表示移除文件或目录拥有的某些属性，= 表示给文件或目录设定一些属性。  表 1 列出了常用的一些属性及功能。 表 1 chattr 命令常用的属性选项及功能\n   属性选项 功能     i 如果对文件设置 i 属性，那么不允许对文件进行删除、改名，也不能添加和修改数据；如果对目录设置 i 属性，那么只能修改目录下文件中的数据，但不允许建立和删除文件；   a 如果对文件设置 a 属性，那么只能在文件中増加数据，但是不能删除和修改数据； 如果对目录设置 a 属性，那么只允许在目录中建立和修改文件，但是不允许删除文件；   u 设置此属性的文件或目录，在删除时，其内容会被保存，以保证后期能够恢复，常用来防止意外删除文件或目录。   s 和 u 相反，删除文件或目录时，会被彻底删除（直接从硬盘上删除，然后用 0 填充所占用的区域），不可恢复。    【例 1】 给文件赋予 i 属性。\n[root@localhost ~]# touch ftest #建立测试文件 [root@localhost ~]# chattr +i ftest [root@localhost ~]# rm -rf ftest rm:cannot remove \u0026#39;ftest\u0026#39;:Operation not permitted #无法删除\u0026#34;ftesr\u0026#34;，操作不允许 #被赋予i属性后，root不能删除 [root@localhost ~]# echo 111\u0026gt;\u0026gt;ftest bash:ftest:Permission denied #权限不够，不能修改文件中的数据 可以看到，设置有 i 属性的文件，即便是 root 用户，也无法删除和修改数据。\n【例 2】为目录赋予 i 属性。\n[root@localhost ~]# mkdir dtest #建立测试目录 [root@localhost dtest]# touch dtest/abc #再建立一个测试文件abc [root@localhost ~]# chattr +i dtest #给目录赋予i属性 [root@localhost ~]# cd dtest [root@localhost dtest]# touch bed touch: cannot touch \u0026#39;bed\u0026#39;:Permission denied #无法创建\u0026#34;bcd\u0026#34;，权限不够，dtest目录不能新建文件 [root@localhost dtest]# echo 11\u0026gt;\u0026gt;abc [root@localhost dtest]# cat abc 11 #可以修改文件内容 [root@localhost dtest]# rm -rf abc rm: cannot remove \u0026#39;abc\u0026#39;: Permission denied #无法删除\u0026#34;abc\u0026#34;，权限不够 一旦给目录设置 i 属性，即使是 root 用户，也无法在目录内部新建或删除文件，但可以修改文件内容。 给设置有 i 属性的文件删除此属性也很简单，只需将 chattr 命令中 + 改为 - 即可。\n【例 3】演示 a 属性的作用。 假设有这样一种应用，我们每天自动实现把服务器的日志备份到指定目录，备份目录可设置 a 属性，变为只可创建文件而不可删除。命令如下：\n[root@localhost ~]# mkdir -p /back/log #建立备份目录 [root@localhost ~]# chattr +a /back/log #赋予a属性 [root@localhost ~]# cp /var/log/messages /back/log #可以复制文件和新建文件到指定目录中 [root@localhost ~]# rm -rf /back/log/messages rm: cannot remove \u0026#39;/back/log/messages\u0026#39;: Permission denied #无法删除 /back/log/messages，操作不允许 注意，通常情况下，不要使用 chattr 命令修改 /、/dev/、/tmp/、/var/ 等目录的隐藏属性，很容易导致系统无法启动。另外，chatrr 命令常与 lsattr 命令合用，前者修改文件或目录的隐藏属性，后者用于查看是否修改成功。有关 lsattr 命令，放到下节讲解。\n16. Linux lsattr命令：查看文件系统属性 使用 chattr 命令配置文件或目录的隐藏属性后，可以使用 lsattr 命令查看。\nlsattr 命令，用于显示文件或目录的隐藏属性，其基本格式如下：\n[root@localhost ~]# lsattr [选项] 文件或目录名 常用选项有以下 3 种：\n -a：后面不带文件或目录名，表示显示所有文件和目录（包括隐藏文件和目录） -d：如果目标是目录，只会列出目录本身的隐藏属性，而不会列出所含文件或子目录的隐藏属性信息； -R：和 -d 恰好相反，作用于目录时，会连同子目录的隐藏信息数据也一并显示出来。  【例 1】\n[root@localhost ~]# touch attrtest -----------e- attrtest [root@localhost ~]# chattr +aij attrtest [root@localhost ~]# lsattr attrtest ----ia---j-e- attrtest 注意，不使用任何选项，仅用于显示文件的隐藏信息，不适用于目录。\n【例 2】\n[root@localhost ~]#lsattr -a -----------e- ./. ------------- ./.. -----------e- ./.gconfd -----------e- ./.bashrc 【例 3】\n[root@localhost ~]#lsattr -d /back/log -----a------e- /back/log #查看/back/log目录，其拥有a和e属性 17. Linux sudo命令用法详解：系统权限管理 我们知道，使用 su 命令可以让普通用户切换到 root 身份去执行某些特权命令，但存在一些问题，比如说： 仅仅为了一个特权操作就直接赋予普通用户控制系统的完整权限； 当多人使用同一台主机时，如果大家都要使用 su 命令切换到 root 身份，那势必就需要 root 的密码，这就导致很多人都知道 root 的密码；\n考虑到使用 su 命令可能对系统安装造成的隐患，最常见的解决方法是使用 sudo 命令，此命令也可以让你切换至其他用户的身份去执行命令。\n相对于使用 su 命令还需要新切换用户的密码，sudo 命令的运行只需要知道自己的密码即可，甚至于，我们可以通过手动修改 sudo 的配置文件，使其无需任何密码即可运行。\nsudo 命令默认只有 root 用户可以运行，该命令的基本格式为：\n[root@localhost ~]# sudo [-b] [-u 新使用者账号] 要执行的命令 常用的选项与参数：\n -b ：将后续的命令放到背景中让系统自行运行，不对当前的 shell 环境产生影响。 -u ：后面可以接欲切换的用户名，若无此项则代表切换身份为 root 。 -l：此选项的用法为 sudo -l，用于显示当前用户可以用 sudo 执行那些命令。  【例 1】\n[root@localhost ~]# grep sshd /etc/passwd sshd:x:74:74:privilege-separated SSH:/var/empty/sshd:/sbin.nologin [root@localhost ~]# sudo -u sshd touch /tmp/mysshd [root@localhost ~]# ll /tmp/mysshd -rw-r--r-- 1 sshd sshd 0 Feb 28 17:42 /tmp/mysshd 本例中，无法使用 su - sshd 的方式成功切换到 sshd 账户中，因为此用户的默认 Shell 是 /sbin/nologin。这时就显现出 sudo 的优势，我们可以使用 sudo 以 sshd 的身份在 /tmp 目录下创建 mysshd 文件，可以看到，新创建的 mysshd 文件的所有者确实是 sshd。\n【例 2】\n[root@localhost ~]# sudo -u vbird1 sh -c \u0026#34;mkdir ~vbird1/www; cd ~vbird1/www; \\ \u0026gt; echo \u0026#39;This is index.html file\u0026#39; \u0026gt; index.html\u0026#34; [root@localhost ~]# ll -a ~vbird1/www drwxr-xr-x 2 vbird1 vbird1 4096 Feb 28 17:51 . drwx------ 5 vbird1 vbird1 4096 Feb 28 17:51 .. -rw-r--r-- 1 vbird1 vbird1 24 Feb 28 17:51 index.html 这个例子中，使用 sudo 命令切换至 vbird1 身份，并运行 sh -c 的方式来运行一连串的命令。\n前面说过，默认情况下 sudo 命令，只有 root 身份可以使用，那么，如何让普通用户也能使用它呢？\n解决这个问题之前，先给大家分析一下 sudo 命令的执行过程。sudo命令的运行，需经历如下几步： 当用户运行 sudo 命令时，系统会先通过 /etc/sudoers 文件，验证该用户是否有运行 sudo 的权限； 确定用户具有使用 sudo 命令的权限后，还要让用户输入自己的密码进行确认。出于对系统安全性的考虑，如果用户在默认时间内（默认是 5 分钟）不使用 sudo 命令，此后使用时需要再次输入密码； 密码输入成功后，才会执行 sudo 命令后接的命令。\n显然，能否使用 sudo 命令，取决于对 /etc/sudoers 文件的配置（默认情况下，此文件中只配置有 root 用户）。所以接下来，我们学习对 /etc/sudoers 文件进行合理的修改。 sudo命令的配置文件/etc/sudoers 修改 /etc/sudoers，不建议直接使用 vim，而是使用 visudo。因为修改 /etc/sudoers 文件需遵循一定的语法规则，使用 visudo 的好处就在于，当修改完毕 /etc/sudoers 文件，离开修改页面时，系统会自行检验 /etc/sudoers 文件的语法。\n因此，修改 /etc/sudoers 文件的命令如下：\n[root@localhost ~]# visudo …省略部分输出… root ALL=(ALL) ALL \u0026lt;--大约 76 行的位置 # %wheel ALL=(ALL) ALL \u0026lt;--大约84行的位置 #这两行是系统为我们提供的模板，我们参照它写自己的就可以了 …省略部分输出… 通过 visudo 命令，我们就打开了 /etc/sudoers 文件，可以看到如上显示的 2 行信息，这是系统给我们提供的 2 个模板，分别用于添加用户和群组，使其能够使用 sudo 命令。\n这两行模板的含义分为是：\nroot ALL=(ALL) ALL #用户名 被管理主机的地址=(可使用的身份) 授权命令(绝对路径) #%wheel ALL=(ALL) ALL #%组名 被管理主机的地址=(可使用的身份) 授权命令(绝对路径) 表 1 对以上 2 个模板的各部分进行详细的说明。 表 1 /etc/sudoers 用户和群组模板的含义\n   模块 含义     用户名或群组名 表示系统中的那个用户或群组，可以使用 sudo 这个命令。   被管理主机的地址 用户可以管理指定 IP 地址的服务器。这里如果写 ALL，则代表用户可以管理任何主机；如果写固定 IP，则代表用户可以管理指定的服务器。如果我们在这里写本机的 IP 地址，不代表只允许本机的用户使用指定命令，而是代表指定的用户可以从任何 IP 地址来管理当前服务器。   可使用的身份 就是把来源用户切换成什么身份使用，（ALL）代表可以切换成任意身份。这个字段可以省略。   授权命令 表示 root 把什么命令命令授权给用户，换句话说，可以用切换的身份执行什么命令。需要注意的是，此命令必须使用绝对路径写。默认值是 ALL，表示可以执行任何命令。    【例 3】 授权用户 lamp 可以重启服务器，由 root 用户添加，可以在 /etc/sudoers 模板下添加如下语句：\n[root@localhost ~]# visudo lamp ALL=/sbin/shutdown -r now 注意，这里也可以写多个授权命令，之间用逗号分隔。用户 lamp 可以使用 sudo -l 查看授权的命令列表：\n[root@localhost ~]# su - lamp #切换成lamp用户 [lamp@localhost ~]$ sudo -l [sudo] password for lamp: #需要输入lamp用户的密码 User lamp may run the following commands on this host: (root) /sbin/shutdown -r now 可以看到，lamp 用户拥有了 shutdown -r now 的权限。这时，lamp 用户就可以使用 sudo 执行如下命令重启服务器：\n[lamp@localhost ~]$ sudo /sbin/shutdown -r now 再次强调，授权命令要使用绝对路径（或者把 /sbin 路径导入普通用户 PATH 路径中，不推荐使用此方式），否则无法执行。\n【例 4】 假设现在有 pro1，pro2，pro3 这 3 个用户，还有一个 group 群组，我们可以通过在 /etc/sudoers 文件配置 wheel 群组信息，令这 3 个用户同时拥有管理系统的权限。\n首先，向 /etc/sudoers 文件中添加群组配置信息：\n[root@localhost ~]# visudo ....(前面省略).... %group ALL=(ALL) ALL #在 84 行#wheel这一行后面写入 此配置信息表示，group 这个群组中的所有用户都能够使用 sudo 切换任何身份，执行任何命令。接下来，我们使用 usermod 命令将 pro1 加入 group 群组，看看有什么效果：\n[root@localhost ~]# usermod -a -G group pro1 [pro1@localhost ~]# sudo tail -n 1 /etc/shadow \u0026lt;==注意身份是 pro1 ....(前面省略).... Password: \u0026lt;==输入 pro1 的口令喔！ pro3:$1$GfinyJgZ$9J8IdrBXXMwZIauANg7tW0:14302:0:99999:7::: [pro2@localhost ~]# sudo tail -n 1 /etc/shadow \u0026lt;==注意身份是 pro2 Password: pro2 is not in the sudoers file. This incident will be reported. #此错误信息表示 pro2 不在 /etc/sudoers 的配置中。 可以看到，由于 pro1 加入到了 group 群组，因此 pro1 就可以使用 sudo 命令，而 pro2 不行。同样的道理，如果我们想让 pro3 也可以使用 sudo 命令，不用再修改 /etc/sudoers 文件，只需要将 pro3 加入 group 群组即可。\n","permalink":"http://yangchnet.github.io/Dessert/posts/linux/linux%E4%B8%8B%E7%9A%84%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86/","summary":"Linux下的权限管理 Linux 系统中为什么需要设定不同的权限，所有用户都直接使用管理员（root）身份不好吗？\n 由于绝大多数用户使用的是个人计算机，使用者一般都是被信任的人（如家人、朋友等）。在这种情况下，大家都可以使用管理员身份直接登录。但在服务器上就不是这种情况了，往往运行的数据越重要（如游戏数据），价值越高（如电子商城数据、银行数据），则服务器中对权限的设定就要越详细，用户的分级也要越明确。\n和 Windows 系统不同，Linux 系统为每个文件都添加了很多的属性，最大的作用就是维护数据的安全。举个简单的例子，在你的 Linux 系统中，和系统服务相关的文件通常只有 root 用户才能读或写，就拿 /etc/shadow 这个文件来说，此文件记录了系统中所有用户的密码数据，非常重要，因此绝不能让任何人读取（否则密码数据会被窃取），只有 root 才可以有读取权限。 此外，如果你有一个软件开发团队，你希望团队中的每个人都可以使用某一些目录下的文件，而非团队的其他人则不予以开放。通过前面章节的学习我们知道，只需要将团队中的所有人加入新的群组，并赋予此群组读写目录的权限，即可实现要求。反之，如果你的目录权限没有做好，就很难防止其他人在你的系统中乱搞。 比如说，本来 root 用户才能做的开关机、ADSL 拨接程序，新增或删除用户等命令，一旦允许任何人拥有这些权限，系统很可能会经常莫名其妙的挂掉。而且，万一 root 用户的密码被其他人获取，他们就可以登录你的系统，从事一些只有 root 用户才能执行的操作，这是绝对不允许发生的。 因此，在服务器上，绝对不是所有的用户都使用 root 身份登录，而要根据不同的工作需要和职位需要，合理分配用户等级和权限等级。\n Linux 系统中，文件或目录的权限信息，可以使用 ls 命令查看，例如：\n[root@localhost ~]# ls -al total 156 drwxr-x---. 4 root root 4096 Sep 8 14:06 . drwxr-xr-x. 23 root root 4096 Sep 8 14:21 .. -rw-------. 1 root root 1474 Sep 4 18:27 anaconda-ks.cfg -rw-------. 1 root root 199 Sep 8 17:14 .","title":"Linux下的权限管理"},{"content":"Linux后台运行程序 使用screen\nscreen介绍 Screen是一个控制台应用程序，允许您在一个窗口中使用多个终端会话。该程序在shell会话中运行，并充当其他终端会话的容器和管理器，类似于窗口管理器管理窗口的方式。\n在许多情况下，创建多个终端窗口是不可能或不理想的。您可能需要在没有运行X服务器的情况下管理多个控制台会话，您可能需要轻松访问许多远程云服务器，或者您可能需要在处理其他任务时监视正在运行的程序的输出。所有需求都可以通过屏幕的强大功能轻松解决。\n安装srceen ubuntu下\nsudo apt-get install screen manjaro下\nsudo pacman -S screen 基本使用方法 使用screen命令打开一个新的窗口，在其中运行你想运行的脚本。\n开始运行后， 按ctrl+ad退出窗口\n使用screen -r重新进入窗口\n附：重定向    命令 说明     command \u0026gt; file 将输出重定向到 file。   command \u0026lt; file 将输入重定向到 file。   command \u0026raquo; file 将输出以追加的方式重定向到 file。   n \u0026gt; file 将文件描述符为 n 的文件重定向到 file。   n \u0026raquo; file 将文件描述符为 n 的文件以追加的方式重定向到 file。   n \u0026gt;\u0026amp; m 将输出文件 m 和 n 合并。   n \u0026lt;\u0026amp; m 将输入文件 m 和 n 合并。   \u0026laquo; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。    Edited by Li Chang\n","permalink":"http://yangchnet.github.io/Dessert/posts/linux/linux%E5%90%8E%E5%8F%B0%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F/","summary":"Linux后台运行程序 使用screen\nscreen介绍 Screen是一个控制台应用程序，允许您在一个窗口中使用多个终端会话。该程序在shell会话中运行，并充当其他终端会话的容器和管理器，类似于窗口管理器管理窗口的方式。\n在许多情况下，创建多个终端窗口是不可能或不理想的。您可能需要在没有运行X服务器的情况下管理多个控制台会话，您可能需要轻松访问许多远程云服务器，或者您可能需要在处理其他任务时监视正在运行的程序的输出。所有需求都可以通过屏幕的强大功能轻松解决。\n安装srceen ubuntu下\nsudo apt-get install screen manjaro下\nsudo pacman -S screen 基本使用方法 使用screen命令打开一个新的窗口，在其中运行你想运行的脚本。\n开始运行后， 按ctrl+ad退出窗口\n使用screen -r重新进入窗口\n附：重定向    命令 说明     command \u0026gt; file 将输出重定向到 file。   command \u0026lt; file 将输入重定向到 file。   command \u0026raquo; file 将输出以追加的方式重定向到 file。   n \u0026gt; file 将文件描述符为 n 的文件重定向到 file。   n \u0026raquo; file 将文件描述符为 n 的文件以追加的方式重定向到 file。   n \u0026gt;\u0026amp; m 将输出文件 m 和 n 合并。   n \u0026lt;\u0026amp; m 将输入文件 m 和 n 合并。   \u0026laquo; tag 将开始标记 tag 和结束标记 tag 之间的内容作为输入。    Edited by Li Chang","title":"Linux后台运行程序"},{"content":"manjaro换源 有关manjaro换源的文件：\n/etc/pacman.d/mirrorlist\n网上教程：\nsudo pacman-mirrors -gb testing -c China //选择中国源并更新 sudo pacman -Syyu //更新系统 manjaro更新\npacman -Sc //清空并且下载新数据 pacman-mirrors -gb testing -c China //更新源 or pacman-mirrors -c China -g //更新源 pacman -Syu //更新 pacman -Syy //更新源数据库 pacman -Syyu //安装更新 ","permalink":"http://yangchnet.github.io/Dessert/posts/linux/manjaro%E6%8D%A2%E6%BA%90/","summary":"manjaro换源 有关manjaro换源的文件：\n/etc/pacman.d/mirrorlist\n网上教程：\nsudo pacman-mirrors -gb testing -c China //选择中国源并更新 sudo pacman -Syyu //更新系统 manjaro更新\npacman -Sc //清空并且下载新数据 pacman-mirrors -gb testing -c China //更新源 or pacman-mirrors -c China -g //更新源 pacman -Syu //更新 pacman -Syy //更新源数据库 pacman -Syyu //安装更新 ","title":"manjaro换源"},{"content":"mysql 中无法插入中文解决办法 alert database tuanplus character set utf8； 使用此方法可更改整个数据库，但是数据可能会丢失\nalter table address convert to character set utf8； 使用此方法可更改某个表的编码\n","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E4%B8%AD%E6%96%87/","summary":"mysql 中无法插入中文解决办法 alert database tuanplus character set utf8； 使用此方法可更改整个数据库，但是数据可能会丢失\nalter table address convert to character set utf8； 使用此方法可更改某个表的编码","title":"mysql中无法插入中文解决办法"},{"content":"1. 安装mysql sudo apt update sudo apt install mysql-server 2. 配置mysql 运行 security script\nsudo mysql_secure_installation 根据提示进行一些必要的配置\n进入mysql\nsudo mysql 接下来，通过以下命令检查每个 MySQL 用户帐户使用的认证方法：\nSELECT user,authentication_string,plugin,host FROM mysql.user; 在输出中\n+------------------+-------------------------------------------+-----------------------+-----------+ | user | authentication_string | plugin | host | +------------------+-------------------------------------------+-----------------------+-----------+ | root | | auth_socket | localhost | | mysql.session | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | localhost | | mysql.sys | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | localhost | | debian-sys-maint | *E6CD266C880D217453293A0247D0142C9CF52730 | mysql_native_password | localhost | +------------------+-------------------------------------------+-----------------------+-----------+ 可以看出，root用户使用插件进行身份验证（进入时不需要输入密码）。如果想要root用户使用密码登陆，可使用如下命令进行配置：\nALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;password\u0026#39;;  将上面的password更改为你想要设置的密码\n 这条命令完成后，使用如下命令重新刷新配置：\nFLUSH PRIVILEGES; 再次检查用户认证方法\nSELECT user,authentication_string,plugin,host FROM mysql.user; 输出为：\n+------------------+-------------------------------------------+-----------------------+-----------+ | user | authentication_string | plugin | host | +------------------+-------------------------------------------+-----------------------+-----------+ | root | *35235E6B287036E68CD22314AFE8D80A0BB26D79 | mysql_native_password | localhost | | mysql.session | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | localhost | | mysql.sys | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | localhost | | debian-sys-maint | *E6CD266C880D217453293A0247D0142C9CF52730 | mysql_native_password | localhost | +------------------+-------------------------------------------+-----------------------+-----------+ 3. 新建一个用户 新建一个用户\nCREATE USER \u0026#39;sammy\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;password\u0026#39;;  localhost表示只允许本地访问，如果想要允许远程访问，可使用\u0026rsquo;user'@'%'， %表示所有网络。\n 更改用户权限\nGRANT ALL PRIVILEGES ON *.* TO \u0026#39;sammy\u0026#39;@\u0026#39;localhost\u0026#39; WITH GRANT OPTION;  这里需要注意的一点是，我们不需要再使用FLUSH PRIVILEGES;来刷新配置，因为只有在grant表上进行过INSERT, UPDATE, 或者DELETE之后才需要用到FLUSH PRIVILEGES;。Because you created a new user, instead of modifying an existing one, FLUSH PRIVILEGES is unnecessary here.\n 退出\nexit 4. Test Mysql 检查mysql服务状态\nsystemctl status mysql.service 输出为：\n● mysql.service - MySQL Community Server Loaded: loaded (/lib/systemd/system/mysql.service; enabled; vendor preset: enabled) Active: active (running) since Sat 2021-02-20 16:09:11 CST; 27min ago Process: 31328 ExecStart=/usr/sbin/mysqld --daemonize --pid-file=/run/mysqld/mysqld.pid (code=exited, status=0/SUCCESS) Process: 31319 ExecStartPre=/usr/share/mysql/mysql-systemd-start pre (code=exited, status=0/SUCCESS) Main PID: 31330 (mysqld) Tasks: 28 (limit: 2341) CGroup: /system.slice/mysql.service └─31330 /usr/sbin/mysqld --daemonize --pid-file=/run/mysqld/mysqld.pid ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E5%AE%89%E8%A3%85linux/","summary":"1. 安装mysql sudo apt update sudo apt install mysql-server 2. 配置mysql 运行 security script\nsudo mysql_secure_installation 根据提示进行一些必要的配置\n进入mysql\nsudo mysql 接下来，通过以下命令检查每个 MySQL 用户帐户使用的认证方法：\nSELECT user,authentication_string,plugin,host FROM mysql.user; 在输出中\n+------------------+-------------------------------------------+-----------------------+-----------+ | user | authentication_string | plugin | host | +------------------+-------------------------------------------+-----------------------+-----------+ | root | | auth_socket | localhost | | mysql.session | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | localhost | | mysql.sys | *THISISNOTAVALIDPASSWORDTHATCANBEUSEDHERE | mysql_native_password | localhost | | debian-sys-maint | *E6CD266C880D217453293A0247D0142C9CF52730 | mysql_native_password | localhost | +------------------+-------------------------------------------+-----------------------+-----------+ 可以看出，root用户使用插件进行身份验证（进入时不需要输入密码）。如果想要root用户使用密码登陆，可使用如下命令进行配置：","title":"MySql安装和配置"},{"content":"Mysql无法远程访问 在使用navicat远程连接阿里云的时候，出现“2003 can t connect to mysql server on 10061”错误\n经过艰难的谷歌百度stackflow后，发现是3306端口没有监听外部连接，只接收内部ip访问。\n解决方案  首先保证阿里云服务器3306端口开放 使用netstat -ntpl |grep 3306命令查看3306端口状态 tcp 0 0 127.0.0.1:22 0.0.0.0:* LISTEN -\n可看出只接收内部访问 打开/etc/mysql/mysql.conf.d/mysqld.cnf(网上大部分说是:/etc/mysql/my.cnf) 将bind-address = 127.0.0.1改成bind-address = 0.0.0.0 再次使用netstat -ntpl |grep 3306命令查看 tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN -\n此时3306端口开始监听所有网络访问 **如果是ipv6主机，则改为 bind-address = :: ,表示监听所有网络**  主机\u0026rsquo;xxx.xx.xxx.xxx\u0026rsquo;不允许连接到此MySQL服务器 在进行连接ipv6主机的时候出现了如下问题：django.db.utils.InternalError: (1130, \u0026ldquo;Host \u0026lsquo;2409:8930:1450:316:6179:c54:5901:2f2b\u0026rsquo; is not allowed to connect to this MySQL server\u0026rdquo;) 解决方法如下：\nmysql\u0026gt; CREATE USER \u0026#39;monty\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;some_pass\u0026#39;; mysql\u0026gt; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;monty\u0026#39;@\u0026#39;localhost\u0026#39; -\u0026gt; WITH GRANT OPTION; mysql\u0026gt; CREATE USER \u0026#39;monty\u0026#39;@\u0026#39;%\u0026#39; IDENTIFIED BY \u0026#39;some_pass\u0026#39;; mysql\u0026gt; GRANT ALL PRIVILEGES ON *.* TO \u0026#39;monty\u0026#39;@\u0026#39;%\u0026#39; -\u0026gt; WITH GRANT OPTION; \u0026lsquo;user\u0026rsquo;@'%\u0026lsquo;后面的百分号代表所有网络\n有时候用root用户还不行，要重新建一个用户 ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql%E6%97%A0%E6%B3%95%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/","summary":"Mysql无法远程访问 在使用navicat远程连接阿里云的时候，出现“2003 can t connect to mysql server on 10061”错误\n经过艰难的谷歌百度stackflow后，发现是3306端口没有监听外部连接，只接收内部ip访问。\n解决方案  首先保证阿里云服务器3306端口开放 使用netstat -ntpl |grep 3306命令查看3306端口状态 tcp 0 0 127.0.0.1:22 0.0.0.0:* LISTEN -\n可看出只接收内部访问 打开/etc/mysql/mysql.conf.d/mysqld.cnf(网上大部分说是:/etc/mysql/my.cnf) 将bind-address = 127.0.0.1改成bind-address = 0.0.0.0 再次使用netstat -ntpl |grep 3306命令查看 tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN -\n此时3306端口开始监听所有网络访问 **如果是ipv6主机，则改为 bind-address = :: ,表示监听所有网络**  主机\u0026rsquo;xxx.xx.xxx.xxx\u0026rsquo;不允许连接到此MySQL服务器 在进行连接ipv6主机的时候出现了如下问题：django.db.utils.InternalError: (1130, \u0026ldquo;Host \u0026lsquo;2409:8930:1450:316:6179:c54:5901:2f2b\u0026rsquo; is not allowed to connect to this MySQL server\u0026rdquo;) 解决方法如下：\nmysql\u0026gt; CREATE USER \u0026#39;monty\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;some_pass\u0026#39;; mysql\u0026gt; GRANT ALL PRIVILEGES ON *.","title":"Mysql无法远程访问"},{"content":"Nginx负载均衡配置\u0026ndash;简介  在使用tomcat部署静态网站的时候，由于服务器比较垃圾，所以如果多人同时访问的话，可能会造成卡顿，影响用户体验。所以想到了使用负载均衡。\n 1. 什么是负载均衡 负载平衡是高可用性基础架构的关键组件，通常用于通过在多个服务器之间分配工作负载来提高网站，应用程序，数据库和其他服务的性能和可靠性。\n没有负载平衡的Web基础结构可能如下所示：\n在此示例中，用户直接连接到web服务器yourdomain.com。如果此单个Web服务器出现故障，用户将无法再访问该网站。此外，如果许多用户尝试同时访问服务器并且无法处理负载，则可能会遇到加载时间缓慢或根本无法连接的情况。\n通过在后端引入负载均衡器和至少一个额外的Web服务器，可以减轻此单点故障。通常，所有后端服务器都将提供相同的内容，以便用户无论哪个服务器响应都会收到一致的内容。 在上面说明的示例中，用户访问负载均衡器，负载均衡器将用户的请求转发到后端服务器，后端服务器然后直接响应用户的请求。在这种情况下，单点故障现在是负载平衡器本身。这可以通过引入第二个负载均衡器来缓解.\n2. 负载均衡器可以处理什么样的流量   HTTP - 标准HTTP平衡基于标准HTTP机制定向请求。负载均衡器设置X-Forwarded-For，X-Forwarded-Proto以及X-Forwarded-Port头，提供有关原始请求的后端信息。\n  HTTPS - HTTPS平衡功能与HTTP平衡功能相同，但增加了加密功能。加密以两种方式之一处理：使用SSL直通，一直保持加密到后端，或者使用SSL终止，将解密负担放在负载均衡器上，但将未加密的流量发送到后端。\n  TCP - 对于不使用HTTP或HTTPS的应用程序，也可以平衡TCP流量。例如，数据库集群的流量可以分布在所有服务器上。\n  UDP\u0026ndash;最近，一些负载均衡器增加了对使用UDP的核心互联网协议（如DNS和syslogd）的负载平衡的支持。\n  这些转发规则将定义负载均衡器本身的协议和端口，并将它们映射到负载均衡器将用于将流量路由到后端的协议和端口。\n3. 负载均衡器如何选择后端服务器 负载均衡器根据两个因素的组合选择将请求转发到哪个服务器。他们将首先确保他们可以选择的任何服务器实际上对请求做出适当的响应，然后使用预先配置的规则从该健康池中进行选择。\n3.1 健康检查 负载均衡器应仅将流量转发到“健康”的后端服务器。要监视后端服务器的运行状况，运行状况检查会定期尝试使用转发规则定义的协议和端口连接到后端服务器，以确保服务器正在侦听。如果服务器未通过运行状况检查，因此无法提供请求，则会自动将其从池中删除，并且在再次响应运行状况检查之前，流量将不会转发给它。\n3.2 负载平衡算法 使用的负载平衡算法确定将选择后端中的哪些正常服务器。一些常用的算法是：\n  Round Robin - Round Robin意味着将按顺序选择服务器。负载均衡器将在其列表中为第一个请求选择第一个服务器，然后按顺序向下移动列表，当它到达结尾时从顶部开始。\n  least_conn - least_conn意味着负载均衡器将选择连接最少的服务器，并且当流量导致更长的会话时建议使用。\n  ip_hash：此平衡算法根据客户端的IP地址将请求分发到不同的服务器。前三个八位字节用作决定服务器处理请求的密钥。结果是客户端每次都倾向于由同一服务器提供服务，这有助于会话一致性。\n  hash：此平衡算法主要用于memcached代理。基于任意提供的散列密钥的值来划分服务器。这可以是文本，变量或组合。这是唯一需要用户提供数据的平衡方法，这是应该用于哈希的密钥。\n  管理员可用的算法取决于所使用的特定负载平衡技术。\n3.3 负载平衡器如何处理状态 某些应用程序要求用户继续连接到同一后端服务器。Source算法根据客户端IP信息创建关联。在Web应用程序级别实现此目的的另一种方法是通过粘性会话，其中负载平衡器设置cookie，并且来自该会话的所有请求都定向到同一物理服务器。\n4. 冗余负载均衡器 要将负载均衡器作为单点故障移除，可以将第二个负载均衡器连接到第一个负载均衡器以形成一个集群，其中每个负载均衡器监控其他负载平衡器的运行状况。每个人都具有同样的故障检测和恢复能力。如果主负载均衡器发生故障，DNS必须将用户带到第二个负载均衡器。由于DNS更改可能需要花费大量时间在Internet上传播并自动进行此故障转移，因此许多管理员将使用允许灵活IP地址重新映射的系统，例如浮动IP。按需IP地址重新映射通过提供可在需要时轻松重新映射的静态IP地址，消除了DNS更改中固有的传播和缓存问题。域名可以保持与相同的IP地址关联，而IP地址本身在服务器之间移动。\n这就是使用浮动IP的高可用性基础架构的外观： 使用 1. 一般代理信息 如果您过去仅使用Web服务器进行简单的单服务器配置，您可能想知道为什么需要代理请求。\n从Nginx代理其他服务器的一个原因是能够扩展您的基础架构。构建Nginx是为了同时处理许多并发连接。这使其成为客户联系点的理想选择。服务器可以将请求传递给任意数量的后端服务器，以处理大部分工作，从而在整个基础架构中分散负载。此设计还为您提供了轻松添加后端服务器或根据维护需要将其下载的灵活性。\nhttp代理可能有用的另一个实例是使用可能无法构建的应用程序服务器来直接处理来自生产环境中的客户端的请求。许多框架都包含Web服务器，但大多数框架都不如Nginx等高性能服务器那么强大。将Nginx放在这些服务器之前可以为用户带来更好的体验并提高安全性。\n在Nginx中代理是通过操纵针对Nginx服务器的请求并将其传递给其他服务器以进行实际处理来完成的。请求的结果将传递回Nginx，然后Nginx将信息中继到客户端。此实例中的其他服务器可以是远程计算机，本地服务器，甚至是Nginx中定义的其他虚拟服务器。Nginx代理请求的服务器称为上游服务器。\nNginx可以将请求代理到使用http（s），FastCGI，SCGI和uwsgi或memcached协议通过每种代理类型的单独指令集进行通信的服务器。在本指南中，我们将重点关注http协议。Nginx实例负责传递请求并将任何消息组件按摩成上游服务器可以理解的格式。\n2. 解构基本HTTP代理通行证 最直接的代理类型涉及将请求切换到可以使用http进行通信的单个服务器。这种类型的代理称为通用“代理传递”，由适当命名的proxy_pass指令处理。\n该proxy_pass指令主要在位置上下文中找到。它if在位置上下文和limit_except上下文中的块中也是有效的。当请求与具有proxy_pass指令的位置匹配时，请求将转发到指令给出的URL。\n我们来看一个例子：\n# server context location /match/here { proxy_pass http://example.com; } . . . 在上面的配置代码段中，proxy_pass定义中服务器末尾没有给出URI 。对于符合此模式的定义，客户端请求的URI将按原样传递到上游服务器。\n例如，当/match/here/please此块处理请求时，请求URI将作为发送到example.com服务器http://example.com/match/here/please。\n我们来看看替代方案：\n# server context location /match/here { proxy_pass http://example.com/new/prefix; } . . . 在上面的示例中，代理服务器在end（/new/prefix）上定义了一个URI段。当在proxy_pass定义中给出URI时，在传递期间，请求的与位置定义匹配的部分将被此URI替换。\n例如，/match/here/pleaseNginx服务器上的请求将作为传递给上游服务器http://example.com/new/prefix/please 该/match/here所取代/new/prefix。这是一个要记住的重点。\n有时，这种替换是不可能的。在这些情况下，将proxy_pass忽略定义末尾的URI，并且客户端的原始URI或其他指令修改的URI将传递给上游服务器。\n例如，当使用正则表达式匹配位置时，Nginx无法确定URI的哪个部分与表达式匹配，因此它发送原始客户端请求URI。另一个例子是在同一位置使用重写指令时，导致客户端URI被重写，但仍然在同一个块中处理。在这种情况下，将传递重写的URI。\n3. 了解Nginx如何处理Headers 有一点可能不会立即明确的是，如果您希望上游服务器正确处理请求，则传递的不仅仅是URI。代表客户端来自Nginx的请求与直接来自客户端的请求看起来不同。其中很大一部分是与请求一起出现的标头。\n当Nginx代理请求时，它会自动对从客户端收到的请求标头进行一些调整：\nNginx摆脱任何空头。没有必要将空值传递给另一台服务器; 它只会使请求膨胀。 默认情况下，Nginx会将包含下划线的任何标头视为无效。它将从代理请求中删除它们。如果你希望Nginx将这些解释为有效，你可以将underscores_in_headers指令设置为“on”，否则你的标题永远不会进入后端服务器。 “Host”头被重写为$proxy_host 变量定义的值。这将是上游的IP地址或名称和端口号，直接由proxy_pass指令定义。 “连接”标题更改为“关闭”。该标头用于表示关于双方之间建立的特定连接的信息。在这种情况下，Nginx将其设置为“关闭”以向上游服务器指示一旦原始请求被响应，该连接将被关闭。上游不应期望这种连接是持久的。 我们可以从上面推断的第一点是，您不希望传递的任何头应该设置为空字符串。具有空值的标头将从传递的请求中完全删除。\n从上述信息中收集的下一个要点是，如果您的后端应用程序将处理非标准标头，则必须确保它们没有下划线。如果需要使用下划线的标头，可以underscores_in_headers在配置中将指令设置为“on”（在http上下文或IP地址/端口组合的默认服务器声明的上下文中有效）。如果不这样做，Nginx会将这些标头标记为无效，并在传递给您的上游之前静默删除它们。\n“主机”标头在大多数代理方案中特别重要。如上所述，默认情况下，这将设置为$proxy_host 一个变量的值，该变量将包含直接从proxy_pass定义中获取的域名或IP地址和端口。这是默认情况下选择的，因为它是Nginx可以确定上游服务器响应的唯一地址（因为它是直接从连接信息中提取的）。\n“Host”标头的最常见值如下：\n  $proxy_host：这将“主机”标头设置为从proxy_pass定义中获取的域名或IP地址和端口组合。从Nginx的角度来看，这是默认的“安全”，但通常不是代理服务器正确处理请求所需要的。\n  $http_host： 将“Host”标头设置为客户端请求的“Host”标头。客户端发送的标头始终在Nginx中作为变量提供。变量将以$http_前缀开头，后跟小写的标题名称，任何短划线都用下划线替换。尽管$http_host变量在大多数情况下都有效，但是当客户端请求没有有效的“主机”标头时，这可能会导致传递失败。\n  $host：此变量按优先顺序设置：请求行本身的主机名，客户端请求的“主机”标头或与请求匹配的服务器名称。\n  在大多数情况下，您需要将“Host”标头设置为$host变量。它是最灵活的，通常会为代理服务器提供尽可能准确填写的“主机”标头\n4. 设置或重置标题 要调整或设置代理连接的标头，我们可以使用该proxy_set_header指令。例如，要像我们讨论的那样更改“Host”标头，并添加一些与代理请求相同的其他标头，我们可以使用以下内容：\n# server context location /match/here { proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_pass http://example.com/new/prefix; } . . . 上述请求将“Host”标头设置为$host变量，该变量应包含有关所请求的原始主机的信息的X-Forwarded-Proto报头给出了关于原始客户机请求的架构中的代理的服务器信息（它是否是一个HTTP或HTTPS请求）。\n将X-Real-IP其设置为客户端的IP地址，以便代理可以根据此信息正确地做出决策或记录。该X-Forwarded-For标题是包含每一个客户端已通过代理到这一点的服务器的IP地址的列表。在上面的例子中，我们将其设置为$proxy_add_x_forwarded_for变量。此变量X-Forwarded-For获取从客户端检索的原始标头的值，并将Nginx服务器的IP地址添加到结尾。\n当然，我们可以将proxy_set_header指令移到服务器或http上下文中，允许它在多个位置引用：\n# server context proxy_set_header HOST $host; proxy_set_header X-Forwarded-Proto $scheme; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location /match/here { proxy_pass http://example.com/new/prefix; } location /different/match { proxy_pass http://example.com; } 5. 为负载平衡代理连接定义上游上下文 在前面的示例中，我们演示了如何对单个后端服务器执行简单的http代理。Nginx允许我们通过指定可以传递请求的整个后端服务器池来轻松扩展此配置。\n我们可以通过使用该upstream指令来定义服务器池来实现此目的。此配置假定所列出的任何一个服务器都能够处理客户端的请求。这使我们可以毫不费力地扩展我们的基础设施。upstream必须在Nginx配置的http上下文中设置该指令。\n我们来看一个简单的例子：\n# http context upstream backend_hosts { server host1.example.com; server host2.example.com; server host3.example.com; } server { listen 80; server_name example.com; location /proxy-me { proxy_pass http://backend_hosts; } } 在上面的例子中，我们设置了一个名为的上游上下文backend_hosts。一旦定义，此名称将可用于代理传递，就像它是常规域名一样。如您所见，在我们的服务器块中，我们将任何请求传递example.com/proxy-me/…给我们上面定义的池。在该池中，通过应用可配置算法来选择主机。默认情况下，这只是一个简单的循环选择过程（每个请求将依次路由到不同的主机）。\n5.1 改变上游平衡算法 您可以通过在上游上下文中包含指令或标志来修改上游池使用的平衡算法：\n（循环法）：如果不存在其他平衡指令，则使用默认的负载平衡算法。在上游上下文中定义的每个服务器依次顺序传递请求。 least_conn：指定应始终为具有最少活动连接数的后端提供新连接。在与后端的连接可能持续一段时间的情况下，这尤其有用。 ip_hash：此平衡算法根据客户端的IP地址将请求分发到不同的服务器。前三个八位字节用作决定服务器处理请求的密钥。结果是客户端每次都倾向于由同一服务器提供服务，这有助于会话一致性。 hash：此平衡算法主要用于memcached代理。基于任意提供的散列密钥的值来划分服务器。这可以是文本，变量或组合。这是唯一需要用户提供数据的平衡方法，这是应该用于哈希的密钥。 更改平衡算法时，块可能如下所示：\n# http context upstream backend_hosts { least_conn; server host1.example.com; server host2.example.com; server host3.example.com; } . . . 在上面的示例中，将根据哪个连接最少来选择服务器。该ip_hash指令可以以相同的方式设置以获得一定量的会话“粘性”。\n至于hash方法，您必须提供哈希的密钥。这可以是你想要的任何东西：\n# http context upstream backend_hosts { hash $remote_addr$remote_port consistent; server host1.example.com; server host2.example.com; server host3.example.com; } . . . 上面的示例将根据客户端IP地址和端口的值分发请求。我们还添加了可选参数consistent，该参数实现了ketama一致性哈希算法。基本上，这意味着如果您的上游服务器发生更改，则对缓存的影响最小。\n5.2 设置服务器权重以进行平衡 在后端服务器的声明中，默认情况下，每个服务器都是“加权”的。这假设每个服务器可以并且应该处理相同的负载量（考虑到平衡算法的影响）。但是，您还可以在声明期间为服务器设置替代权重：\n# http context upstream backend_hosts { server host1.example.com weight=3; server host2.example.com; server host3.example.com; } . . . 在上面的例子中，host1.example.com将接收三倍于其他两个服务器的流量。默认情况下，为每个服务器分配权重1。\n6. 使用缓冲区释放后端服务器 涉及许多用户的代理问题是向流程添加其他服务器对性能的影响。在大多数情况下，利用Nginx的缓冲和缓存功能可以大大减轻这种影响。\n代理到另一台服务器时，两个不同连接的速度将影响客户端的体验：\n从客户端到Nginx代理的连接。 从Nginx代理到后端服务器的连接。 Nginx能够根据您希望优化的这些连接中的任何一个来调整其行为。\n没有缓冲区，数据从代理服务器发送并立即开始传输到客户端。如果假设客户端速度很快，则可以关闭缓冲，以便尽快将数据传送到客户端。使用缓冲区，Nginx代理将临时存储后端的响应，然后将此数据提供给客户端。如果客户端很慢，这允许Nginx服务器更快地关闭到后端的连接。然后，它可以处理以任何可能的速度将数据分发给客户端。\nNginx默认采用缓冲设计，因为客户端的连接速度往往差异很大。我们可以使用以下指令调整缓冲行为。这些可以在http，服务器或位置上下文中设置。重要的是要记住，每个请求都配置了大小调整指令，因此当有许多客户端请求时，增加它们超出您的需要会影响您的性能：\nproxy_buffering：此指令控制是否启用此上下文和子上下文的缓冲。默认情况下，这是“打开”。 proxy_buffers：此指令控制代理响应的缓冲区的数量（第一个参数）和大小（第二个参数）。默认设置是配置8个大小等于一个内存页面的缓冲区（4k或者8k）。增加缓冲区数量可以让您缓冲更多信息。 proxy_buffer_size：来自后端服务器的响应的初始部分（包含标头）与响应的其余部分分开缓冲。该指令设置响应的这一部分的缓冲区大小。默认情况下，这与大小相同proxy_buffers，但由于这用于标题信息，因此通常可以将其设置为较低的值。 proxy_busy_buffers_size：此指令设置可以标记为“客户端就绪”并因此忙碌的缓冲区的最大大小。虽然客户端一次只能从一个缓冲区读取数据，但缓冲区放在队列中以便以串联形式发送到客户端。该指令控制允许处于此状态的缓冲区空间的大小。 proxy_max_temp_file_size：这是磁盘上临时文件的每个请求的最大大小。这些是在上游响应太大而无法放入缓冲区时创建的。 proxy_temp_file_write_size：这是当代理服务器的响应对于配置的缓冲区而言太大时，Nginx将一次写入临时文件的数据量。 proxy_temp_path：这是磁盘上区域的路径，当上游服务器的响应无法容纳到配置的缓冲区时，Nginx应该存储任何临时文件。 如您所见，Nginx提供了许多不同的指令来调整缓冲行为。大多数情况下，您不必担心大多数这些，但调整其中一些值可能很有用。调整最有用的可能是proxy_buffers和proxy_buffer_size指令。\n增加每个上游请求的可用代理缓冲区数量的示例，同时减少可能存储标头的缓冲区将如下所示：\n# server context proxy_buffering on; proxy_buffer_size 1k; proxy_buffers 24 4k; proxy_busy_buffers_size 8k; proxy_max_temp_file_size 2048m; proxy_temp_file_write_size 32k; location / { proxy_pass http://example.com; } 相反，如果您想要立即向其提供数据的快速客户端，则可以完全关闭缓冲。如果上游比客户端更快，Nginx实际上仍将使用缓冲区，但它会立即尝试将数据刷新到客户端，而不是等待缓冲区池。如果客户端速度很慢，这可能导致上游连接保持打开状态，直到客户端赶上。当缓冲“关闭”时，仅proxy_buffer_size使用指令定义的缓冲区：\n# server context proxy_buffering off; proxy_buffer_size 4k; location / { proxy_pass http://example.com; } 6.1 高可用性（可选） 通过添加一组冗余的负载均衡器，可以使Nginx代理更加健壮，从而创建高可用性基础架构。\n甲高可用性（HA）的设置是无故障的单个点处的基础设施，和你的负载平衡器是该构造的一部分。通过使用多个负载均衡器，可以防止在负载均衡器不可用或需要将其关闭进行维护时可能导致的停机。\n以下是基本高可用性设置的图表： 在此示例中，您有一个静态IP地址后面的多个负载平衡器（一个活动和一个或多个被动），可以从一个服务器重新映射到另一个服务器。客户端请求从静态IP路由到活动负载平衡器，然后路由到后端服务器。要了解更多信息，请阅读如何使用浮动IP的这一节。\n7. 配置代理缓存以减少响应时间 虽然缓冲可以帮助释放后端服务器以处理更多请求，但Nginx还提供了一种从后端服务器缓存内容的方法，从而无需为许多请求连接到上游。\n7.1 配置代理缓存 要设置用于代理内容的缓存，我们可以使用该proxy_cache_path指令。这将创建一个区域，可以保留从代理服务器返回的数据。该proxy_cache_path指令必须在http上下文中设置。\n在下面的示例中，我们将配置此命令和一些相关指令来设置我们的缓存系统。\n# http context proxy_cache_path /var/lib/nginx/cache levels=1:2 keys_zone=backcache:8m max_size=50m; proxy_cache_key \u0026quot;$scheme$request_method$host$request_uri$is_args$args\u0026quot;; proxy_cache_valid 200 302 10m; proxy_cache_valid 404 1m; 使用该proxy_cache_path指令，我们已经在文件系统上定义了一个目录，我们希望存储缓存。在这个例子中，我们选择了/var/lib/nginx/cache目录。如果此目录不存在，您可以通过键入以下内容以正确的权限和所有权创建它：\nsudo mkdir -p /var/lib/nginx/cache sudo chown www-data /var/lib/nginx/cache sudo chmod 700 /var/lib/nginx/cache 该levels=参数指定缓存的组织方式。Nginx将通过散列键的值（下面配置）来创建缓存键。我们在上面选择的级别规定将创建一个单个字符目录（这将是散列值的最后一个字符），其中包含一个两个字符的子目录（取自散列值末尾的下两个字符）。您通常不必关心此细节，但它有助于Nginx快速找到相关值。\n该keys_zone=参数定义了我们调用的此缓存区的名称backcache。这也是我们定义要存储多少元数据的地方。在这种情况下，我们存储8 MB的密钥。对于每兆字节，Nginx可以存储大约8000个条目。该max_size参数设置实际缓存数据的最大大小。\n我们上面使用的另一个指令是proxy_cache_key。这用于设置将用于存储缓存值的键。该相同密钥用于检查是否可以从缓存提供请求。我们将此设置为方案（http或https），HTTP请求方法以及请求的主机和URI的组合。\n该proxy_cache_valid指令可以多次指定。它允许我们根据状态代码配置存储值的时间长度。在我们的示例中，我们存储成功和重定向10分钟，并且每分钟使缓存过期404响应。\n现在，我们已经配置了缓存区域，但我们仍然需要告诉Nginx何时使用缓存。\n在我们代理后端的位置，我们可以配置此缓存的使用：\n# server context location /proxy-me { proxy_cache backcache; proxy_cache_bypass $http_cache_control; add_header X-Proxy-Cache $upstream_cache_status; proxy_pass http://backend; } . . . 使用该proxy_cache指令，我们可以指定backcache缓存区域应该用于此上下文。在传递到后端之前，Nginx将在此处检查有效条目。\n该proxy_cache_bypass指令设置为$http_cache_control 变量。这将包含一个指示器，指示客户端是否明确请求资源的新的非缓存版本。设置此指令允许Nginx正确处理这些类型的客户端请求。无需进一步配置。\n我们还添加了一个名为的额外标题X-Proxy-Cache。我们将此标头设置为$upstream_cache_status变量的值。基本上，这会设置一个标头，允许我们查看请求是否导致缓存命中，缓存未命中，或者是否明确绕过了缓存。这对于调试尤其有用，但对于客户端也是有用的信息。\n7.2 有关缓存结果的说明 缓存可以极大地提高代理的性能。但是，配置缓存时必须牢记一些注意事项。\n首先，任何用户相关的数据应该不会被缓存。这可能导致一个用户的数据被呈现给另一个用户。如果您的网站完全是静态的，这可能不是问题。\n如果您的站点有一些动态元素，则必须在后端服务器中对此进行说明。如何处理这取决于处理后端处理的应用程序或服务器。对于私有内容，您应将Cache-Control标头设置为no-cache，no-store或private，具体取决于数据的性质： no-cache：表示如果没有先检查后端的数据是否未更改，则不应再次提供响应。如果数据是动态且重要的，则可以使用此方法。在每个请求上检查ETag散列元数据头，并且如果后端返回相同的散列值，则可以提供先前的值\nno-store ：表示在任何时候都不应该缓存接收到的数据。这是私有数据最安全的选项，因为这意味着每次都必须从服务器检索数据。\nprivate：这表示没有共享缓存空间应该缓存此数据。这可用于指示用户的浏览器可以缓存数据，但代理服务器不应认为此数据对后续请求有效。\npublic：这表示响应是可以在连接中的任何位置缓存的公共数据。\n可以控制此行为的相关标头是max-age标头，它指示应缓存任何资源的秒数。\n正确设置这些标题（取决于内容的敏感性）将有助于您利用缓存，同时保护您的私人数据安全并使您的动态数据保持新鲜。\n如果你的后端也使用Nginx，你可以使用expires指令设置一些，这将设置max-age为Cache-Control：\nlocation / { expires 60m; } location /check-me { expires -1; } 在上面的示例中，第一个块允许将内容缓存一小时。第二个块将Cache-Control标头设置为“no-cache”。要设置其他值，可以使用该add_header指令，如下所示：\nlocation /private { expires -1; add_header Cache-Control \u0026quot;no-store\u0026quot;; } 8. 结论 Nginx首先是一个反向代理，它也恰好具有作为Web服务器工作的能力。由于此设计决策，向其他服务器代理请求非常简单。Nginx非常灵活，如果需要，可以对代理配置进行更复杂的控制\n原文地址\n参考\n","permalink":"http://yangchnet.github.io/Dessert/posts/linux/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E5%85%A5%E9%97%A8/","summary":"Nginx负载均衡配置\u0026ndash;简介  在使用tomcat部署静态网站的时候，由于服务器比较垃圾，所以如果多人同时访问的话，可能会造成卡顿，影响用户体验。所以想到了使用负载均衡。\n 1. 什么是负载均衡 负载平衡是高可用性基础架构的关键组件，通常用于通过在多个服务器之间分配工作负载来提高网站，应用程序，数据库和其他服务的性能和可靠性。\n没有负载平衡的Web基础结构可能如下所示：\n在此示例中，用户直接连接到web服务器yourdomain.com。如果此单个Web服务器出现故障，用户将无法再访问该网站。此外，如果许多用户尝试同时访问服务器并且无法处理负载，则可能会遇到加载时间缓慢或根本无法连接的情况。\n通过在后端引入负载均衡器和至少一个额外的Web服务器，可以减轻此单点故障。通常，所有后端服务器都将提供相同的内容，以便用户无论哪个服务器响应都会收到一致的内容。 在上面说明的示例中，用户访问负载均衡器，负载均衡器将用户的请求转发到后端服务器，后端服务器然后直接响应用户的请求。在这种情况下，单点故障现在是负载平衡器本身。这可以通过引入第二个负载均衡器来缓解.\n2. 负载均衡器可以处理什么样的流量   HTTP - 标准HTTP平衡基于标准HTTP机制定向请求。负载均衡器设置X-Forwarded-For，X-Forwarded-Proto以及X-Forwarded-Port头，提供有关原始请求的后端信息。\n  HTTPS - HTTPS平衡功能与HTTP平衡功能相同，但增加了加密功能。加密以两种方式之一处理：使用SSL直通，一直保持加密到后端，或者使用SSL终止，将解密负担放在负载均衡器上，但将未加密的流量发送到后端。\n  TCP - 对于不使用HTTP或HTTPS的应用程序，也可以平衡TCP流量。例如，数据库集群的流量可以分布在所有服务器上。\n  UDP\u0026ndash;最近，一些负载均衡器增加了对使用UDP的核心互联网协议（如DNS和syslogd）的负载平衡的支持。\n  这些转发规则将定义负载均衡器本身的协议和端口，并将它们映射到负载均衡器将用于将流量路由到后端的协议和端口。\n3. 负载均衡器如何选择后端服务器 负载均衡器根据两个因素的组合选择将请求转发到哪个服务器。他们将首先确保他们可以选择的任何服务器实际上对请求做出适当的响应，然后使用预先配置的规则从该健康池中进行选择。\n3.1 健康检查 负载均衡器应仅将流量转发到“健康”的后端服务器。要监视后端服务器的运行状况，运行状况检查会定期尝试使用转发规则定义的协议和端口连接到后端服务器，以确保服务器正在侦听。如果服务器未通过运行状况检查，因此无法提供请求，则会自动将其从池中删除，并且在再次响应运行状况检查之前，流量将不会转发给它。\n3.2 负载平衡算法 使用的负载平衡算法确定将选择后端中的哪些正常服务器。一些常用的算法是：\n  Round Robin - Round Robin意味着将按顺序选择服务器。负载均衡器将在其列表中为第一个请求选择第一个服务器，然后按顺序向下移动列表，当它到达结尾时从顶部开始。\n  least_conn - least_conn意味着负载均衡器将选择连接最少的服务器，并且当流量导致更长的会话时建议使用。\n  ip_hash：此平衡算法根据客户端的IP地址将请求分发到不同的服务器。前三个八位字节用作决定服务器处理请求的密钥。结果是客户端每次都倾向于由同一服务器提供服务，这有助于会话一致性。\n  hash：此平衡算法主要用于memcached代理。基于任意提供的散列密钥的值来划分服务器。这可以是文本，变量或组合。这是唯一需要用户提供数据的平衡方法，这是应该用于哈希的密钥。\n  管理员可用的算法取决于所使用的特定负载平衡技术。\n3.3 负载平衡器如何处理状态 某些应用程序要求用户继续连接到同一后端服务器。Source算法根据客户端IP信息创建关联。在Web应用程序级别实现此目的的另一种方法是通过粘性会话，其中负载平衡器设置cookie，并且来自该会话的所有请求都定向到同一物理服务器。\n4. 冗余负载均衡器 要将负载均衡器作为单点故障移除，可以将第二个负载均衡器连接到第一个负载均衡器以形成一个集群，其中每个负载均衡器监控其他负载平衡器的运行状况。每个人都具有同样的故障检测和恢复能力。如果主负载均衡器发生故障，DNS必须将用户带到第二个负载均衡器。由于DNS更改可能需要花费大量时间在Internet上传播并自动进行此故障转移，因此许多管理员将使用允许灵活IP地址重新映射的系统，例如浮动IP。按需IP地址重新映射通过提供可在需要时轻松重新映射的静态IP地址，消除了DNS更改中固有的传播和缓存问题。域名可以保持与相同的IP地址关联，而IP地址本身在服务器之间移动。","title":"Nginx负载均衡配置--简介"},{"content":"pm2的使用 PM2 Runtime是具有内置Load Balancer的Node.js应用程序的生产过程管理器。它允许您永久保持应用程序的活动，无需停机即可重新加载它们，并促进常见的Devops任务。\n对于ipv4主机  用户名： lc 密码： Lichang1-  登录后使用以下命令查看当前后台进程状态\npm2 ls 若status为online，则表明脚本运行正常，若为其他状态，则说明出现错误或异常，可用以下命令停止脚本运行\npm2 stop 0 然后使用以下命令查看日志\ncat server.log 从日志中可获取错误信息或其他提示。\n若脚本一切正常，可直接进入数据库查看数据。\n注意：注销登录前请使用pm2 start server.sh命令重新启动脚本！！！\n对于ipv6主机  用户名： ubuntu 密码： ahnu2019  登录后使用以下命令查看当前后台进程状态\npm2 ls 若status为online，则表明脚本运行正常，若为其他状态，则说明出现错误或异常，可用以下命令停止脚本运行\npm2 stop 1 然后使用以下命令查看日志\ncat server.log 从日志中可获取错误信息或其他提示。\n若脚本一切正常，可直接进入数据库查看数据。\n注意：注销登录前请使用pm2 start server.sh命令重新启动脚本！！！\n","permalink":"http://yangchnet.github.io/Dessert/posts/linux/pm2/","summary":"pm2的使用 PM2 Runtime是具有内置Load Balancer的Node.js应用程序的生产过程管理器。它允许您永久保持应用程序的活动，无需停机即可重新加载它们，并促进常见的Devops任务。\n对于ipv4主机  用户名： lc 密码： Lichang1-  登录后使用以下命令查看当前后台进程状态\npm2 ls 若status为online，则表明脚本运行正常，若为其他状态，则说明出现错误或异常，可用以下命令停止脚本运行\npm2 stop 0 然后使用以下命令查看日志\ncat server.log 从日志中可获取错误信息或其他提示。\n若脚本一切正常，可直接进入数据库查看数据。\n注意：注销登录前请使用pm2 start server.sh命令重新启动脚本！！！\n对于ipv6主机  用户名： ubuntu 密码： ahnu2019  登录后使用以下命令查看当前后台进程状态\npm2 ls 若status为online，则表明脚本运行正常，若为其他状态，则说明出现错误或异常，可用以下命令停止脚本运行\npm2 stop 1 然后使用以下命令查看日志\ncat server.log 从日志中可获取错误信息或其他提示。\n若脚本一切正常，可直接进入数据库查看数据。\n注意：注销登录前请使用pm2 start server.sh命令重新启动脚本！！！","title":"pm2的使用"},{"content":"python与其他语言的对比（hello world）  C语言\n include\u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello world\u0026#34;); return 0; }  Java语言\n public class HelloWorld{ public static void main(String[] args) { System.out.println(\u0026#34;Hello World!\u0026#34;); } }  Python\n print(\u0026#39;hello world\u0026#39;) python中的常用数据类型  Number String List Tuple Dictionary  # Number a = 1 b = True c = 3.15 d = 1.1+2.2j # 字符串 str1 = \u0026#39;hello\u0026#39; str1_1 = \u0026#34;hello\u0026#34; str2 = \u0026#34;world\u0026#34; print(str1==str1_1) # 字符串连接 str3 = str1 + str2 print(str3) # 转义字符 str4 = \u0026#39;hello \\nworld\u0026#39; print(str4) str5 = \u0026#39;hello \\\\n world\u0026#39; print(str5) # 格式化输出 print(\u0026#39;str1:%s.\u0026#39;%str1) # 切片 print(str1[1:4]) True helloworld hello world hello \\n world str1:hello. ell  # 列表 list1 = [\u0026#39;google\u0026#39;, \u0026#39;alibaba\u0026#39;, 2001, 3.14] # 通过下标访问 print(list1[0]) # 更新列表 list1[2] = \u0026#39;baidu\u0026#39; print(list1) # 删除元素 del list1[3] print(list1) # 拼接列表 list2 = [\u0026#39;microsoft\u0026#39;, \u0026#39;amazon\u0026#39;] list3 = list1 + list2 print(list3) # 增添列表项 list1.append(\u0026#39;jingdong\u0026#39;) print(list1) google ['google', 'alibaba', 'baidu', 3.14] ['google', 'alibaba', 'baidu'] ['google', 'alibaba', 'baidu', 'microsoft', 'amazon'] ['google', 'alibaba', 'baidu', 'jingdong']  # 元组：类似列表,是一系列元素的有序集合,但元组中的元素无法修改 tuple1 = (\u0026#39;google\u0026#39;, \u0026#39;alibaba\u0026#39;, \u0026#39;baidu\u0026#39;) tuple1[0] = \u0026#39;amazon\u0026#39; # 不能被改变 --------------------------------------------------------------------------- TypeError Traceback (most recent call last) \u0026lt;ipython-input-23-4ed3e334c834\u0026gt; in \u0026lt;module\u0026gt; 1 # 元组：类似列表,是一系列元素的有序集合,但元组中的元素无法修改 2 tuple1 = ('google', 'alibaba', 'baidu') ----\u0026gt; 3 tuple1[0] = 'amazon' TypeError: 'tuple' object does not support item assignment  # 字典 dict1 = { \u0026#39;color\u0026#39;: \u0026#39;green\u0026#39;, \u0026#39;points\u0026#39;: 5 } # 访问列表中的值 print(dict1[\u0026#39;color\u0026#39;]) # 增加字典中键值对 dict1[\u0026#39;x_pos\u0026#39;] = 0 dict1[\u0026#39;y_pos\u0026#39;] =4 print(dict1) green {'color': 'green', 'points': 5, 'x_pos': 0, 'y_pos': 4}  python中的结构语句 if条件语句 car = \u0026#39;bmw\u0026#39; if car == \u0026#39;bmw\u0026#39;: print(car.upper()) # 输出car的大写版本 else: print(car.title()) # 输出car的标题版本 Bmw  现实世界中,很多情况下需要考虑的情形都超过两个。例如,来看一个根据年龄段收费的 游乐场:\n 4岁以下免费; 4~18岁收费5美元; 18岁(含)以上收费10美元。   如果只使用一条 if 语句,如何确定门票价格呢?下面的代码确定一个人所属的年龄段,并打印一条包含门票价格的消息:\n age = 12 if age \u0026lt; 4: print(\u0026#34;Your admission cost is $0.\u0026#34;) elif age \u0026lt; 18: print(\u0026#34;Your admission cost is $5.\u0026#34;) else: print(\u0026#34;Your admission cost is $10.\u0026#34;) Your admission cost is $5.  for循环语句 fruits = [\u0026#39;banana\u0026#39;, \u0026#39;apple\u0026#39;, \u0026#39;mango\u0026#39;] for fruit in fruits: print(\u0026#39;当前水果：%s\u0026#39;%fruit) 当前水果：banana 当前水果：apple 当前水果：mango  # range 步长为1 for i in range(0, 6): print(i) 1 2 3 4 5  # range 步长为2 for i in range(0, 6, 2): print(i) 0 2 4  # break 和 continue for i in range(0, 6): if i == 3: break print(i) for i in range(0, 6): if i == 3: continue print(i, end=\u0026#39;\u0026#39;) 0 1 2 01245  # while循环 current_number = 1 while current_number \u0026lt;= 5: print(current_number) current_number += 1 1 2 3 4 5  函数 def greet_user(username): \u0026#34;\u0026#34;\u0026#34; 显示简单的问候语 \u0026#34;\u0026#34;\u0026#34; print(\u0026#34;Hello, \u0026#34; + username.title() + \u0026#34;!\u0026#34;) greet_user(\u0026#39;jesse\u0026#39;) greet_user(\u0026#39;jack\u0026#39;) Hello, Jesse! Hello, Jack!  # 有返回值的函数 def add(a, b): return a+b print(\u0026#39;第一个函数：%d\u0026#39;%add(2, 3)) # 列表作为参数的函数 def add_l(mylist): result = 0 for l in mylist: result += l return result print(\u0026#39;第二个函数：%d\u0026#39;%add_l([1, 2, 3, 4])) # 有多个返回值的函数 def muti_re(mylist): a = max(mylist) b = min(mylist) return a, b a, b = muti_re([1, 2, 3, 4]) print(\u0026#39;第三个函数, 最大值：%d, 最小值：%d\u0026#39;%(a,b)) 第一个函数：5 第二个函数：10 第三个函数, 最大值：4, 最小值：1  ","permalink":"http://yangchnet.github.io/Dessert/posts/django/python%E5%9F%BA%E7%A1%80/","summary":"python与其他语言的对比（hello world）  C语言\n include\u0026lt;stdio.h\u0026gt; int main() { printf(\u0026#34;hello world\u0026#34;); return 0; }  Java语言\n public class HelloWorld{ public static void main(String[] args) { System.out.println(\u0026#34;Hello World!\u0026#34;); } }  Python\n print(\u0026#39;hello world\u0026#39;) python中的常用数据类型  Number String List Tuple Dictionary  # Number a = 1 b = True c = 3.15 d = 1.1+2.2j # 字符串 str1 = \u0026#39;hello\u0026#39; str1_1 = \u0026#34;hello\u0026#34; str2 = \u0026#34;world\u0026#34; print(str1==str1_1) # 字符串连接 str3 = str1 + str2 print(str3) # 转义字符 str4 = \u0026#39;hello \\nworld\u0026#39; print(str4) str5 = \u0026#39;hello \\\\n world\u0026#39; print(str5) # 格式化输出 print(\u0026#39;str1:%s.","title":"python与其他语言的对比（helloworld）"},{"content":"Python中的拷贝   直接赋值：其实就是对象的引用（别名）.两个对象是引用的同一块内存区域\n  浅拷贝(copy)：拷贝父对象，不会拷贝对象的内部的子对象。\n  深拷贝(deepcopy)： copy 模块的 deepcopy 方法，完全拷贝了父对象及其子对象。\n  引用示例\na = [1,2,3,4] b = a a.append(5) print(a, b) [1, 2, 3, 4, 5] [1, 2, 3, 4, 5]  浅拷贝示例\nimport copy a = [1, 2, 3, 4, [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]] b = copy.copy(a) a.append(5) a[4].append(\u0026#39;c\u0026#39;) print(a) print(b) [1, 2, 3, 4, ['a', 'b', 'c'], 5] [1, 2, 3, 4, ['a', 'b', 'c']]  可以看到,父对象被拷贝了,当直接对父对象做修改时,拷贝值也相应的得到了变化,但是对子对象修改时,拷贝值不变\n深拷贝示例\nimport copy c = [1, 2, 3, 4, [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]] d = copy.deepcopy(a) c.append(5) c[4].append(\u0026#39;c\u0026#39;) print(c) print(d) [1, 2, 3, 4, ['a', 'b', 'c'], 5] [1, 2, 3, 4, ['a', 'b', 'c'], 5]  ","permalink":"http://yangchnet.github.io/Dessert/posts/python/%E6%B7%B1%E6%B5%85%E6%8B%B7%E8%B4%9D/","summary":"Python中的拷贝   直接赋值：其实就是对象的引用（别名）.两个对象是引用的同一块内存区域\n  浅拷贝(copy)：拷贝父对象，不会拷贝对象的内部的子对象。\n  深拷贝(deepcopy)： copy 模块的 deepcopy 方法，完全拷贝了父对象及其子对象。\n  引用示例\na = [1,2,3,4] b = a a.append(5) print(a, b) [1, 2, 3, 4, 5] [1, 2, 3, 4, 5]  浅拷贝示例\nimport copy a = [1, 2, 3, 4, [\u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;]] b = copy.copy(a) a.append(5) a[4].append(\u0026#39;c\u0026#39;) print(a) print(b) [1, 2, 3, 4, ['a', 'b', 'c'], 5] [1, 2, 3, 4, ['a', 'b', 'c']]  可以看到,父对象被拷贝了,当直接对父对象做修改时,拷贝值也相应的得到了变化,但是对子对象修改时,拷贝值不变","title":"Python中的拷贝"},{"content":"Python换源 1. 临时换源 可以在使用pip的时候在后面加上-i参数，指定pip源\npip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple 2. 永久换源 永久修改： linux: 修改 ~/.pip/pip.conf (没有就创建一个)， 内容如下：\n[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple ","permalink":"http://yangchnet.github.io/Dessert/posts/python/python%E6%8D%A2%E6%BA%90/","summary":"Python换源 1. 临时换源 可以在使用pip的时候在后面加上-i参数，指定pip源\npip install scrapy -i https://pypi.tuna.tsinghua.edu.cn/simple 2. 永久换源 永久修改： linux: 修改 ~/.pip/pip.conf (没有就创建一个)， 内容如下：\n[global] index-url = https://pypi.tuna.tsinghua.edu.cn/simple ","title":"Python换源"},{"content":"python 网络编程 使用socket模块，即套接字 使用socket来创建套接字的语法如下： socket.socket(family[, type[, proto]])\n 参数解释：\n  family: 套接字家族可以使AF_UNIX或者AF_INET type: 套接字类型可以根据是面向连接的还是非连接分为SOCK_STREAM或SOCK_DGRAM protocol：一般不填默认为0  socket对象的方法  s.bind() 绑定地址（host,port）到套接字， 在AF_INET下,以元组（host,port）的形式表示地址。 s.listen() 开始TCP监听。backlog指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为1，大部分应用程序设为5就可以了。 s.accept() 被动接受TCP客户端连接,(阻塞式)等待连接的到来 客户端套接字 s.connect() 主动初始化TCP服务器连接，。一般address的格式为元组（hostname,port），如果连接出错，返回socket.error错误。 s.connect_ex() connect()函数的扩展版本,出错时返回出错码,而不是抛出异常 公共用途的套接字函数 s.recv() 接收TCP数据，数据以字符串形式返回，bufsize指定要接收的最大数据量。flag提供有关消息的其他信息，通常可以忽略。 s.send() 发送TCP数据，将string中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于string的字节大小。 s.sendall() 完整发送TCP数据，完整发送TCP数据。将string中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回None，失败则抛出异常。 s.recvfrom() 接收UDP数据，与recv()类似，但返回值是（data,address）。其中data是包含接收数据的字符串，address是发送数据的套接字地址。 s.sendto() 发送UDP数据，将数据发送到套接字，address是形式为（ipaddr，port）的元组，指定远程地址。返回值是发送的字节数。 s.close() 关闭套接字 s.getpeername() 返回连接套接字的远程地址。返回值通常是元组（ipaddr,port）。 s.getsockname() 返回套接字自己的地址。通常是一个元组(ipaddr,port) s.setsockopt(level,optname,value) 设置给定套接字选项的值。 s.getsockopt(level,optname[.buflen]) 返回套接字选项的值。 s.settimeout(timeout) 设置套接字操作的超时期，timeout是一个浮点数，单位是秒。值为None表示没有超时期。一般，超时期应该在刚创建套接字时设置，因为它们可能用于连接的操作（如connect()） s.gettimeout() 返回当前超时期的值，单位是秒，如果没有设置超时期，则返回None。 s.fileno() 返回套接字的文件描述符。 s.setblocking(flag) 如果flag为0，则将套接字设为非阻塞模式，否则将套接字设为阻塞模式（默认值）。非阻塞模式下，如果调用recv()没有发现任何数据，或send()调用无法立即发送数据，那么将引起socket.error异常。 s.makefile() 创建一个与该套接字相关连的文件  网络编程的基本设置步骤 服务端配置  导入socket模块 使用bind方法创建套接字 使用listen方法等待连接， 使用accept方法被动接收tcp连接 使用send或recv方法进行收发  客户端配置  导入socket模块 使用bind方法创建套接字 使用connect方法进行主动tcp连接 使用send或recv方法进行收发  ","permalink":"http://yangchnet.github.io/Dessert/posts/python/python%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/","summary":"python 网络编程 使用socket模块，即套接字 使用socket来创建套接字的语法如下： socket.socket(family[, type[, proto]])\n 参数解释：\n  family: 套接字家族可以使AF_UNIX或者AF_INET type: 套接字类型可以根据是面向连接的还是非连接分为SOCK_STREAM或SOCK_DGRAM protocol：一般不填默认为0  socket对象的方法  s.bind() 绑定地址（host,port）到套接字， 在AF_INET下,以元组（host,port）的形式表示地址。 s.listen() 开始TCP监听。backlog指定在拒绝连接之前，操作系统可以挂起的最大连接数量。该值至少为1，大部分应用程序设为5就可以了。 s.accept() 被动接受TCP客户端连接,(阻塞式)等待连接的到来 客户端套接字 s.connect() 主动初始化TCP服务器连接，。一般address的格式为元组（hostname,port），如果连接出错，返回socket.error错误。 s.connect_ex() connect()函数的扩展版本,出错时返回出错码,而不是抛出异常 公共用途的套接字函数 s.recv() 接收TCP数据，数据以字符串形式返回，bufsize指定要接收的最大数据量。flag提供有关消息的其他信息，通常可以忽略。 s.send() 发送TCP数据，将string中的数据发送到连接的套接字。返回值是要发送的字节数量，该数量可能小于string的字节大小。 s.sendall() 完整发送TCP数据，完整发送TCP数据。将string中的数据发送到连接的套接字，但在返回之前会尝试发送所有数据。成功返回None，失败则抛出异常。 s.recvfrom() 接收UDP数据，与recv()类似，但返回值是（data,address）。其中data是包含接收数据的字符串，address是发送数据的套接字地址。 s.sendto() 发送UDP数据，将数据发送到套接字，address是形式为（ipaddr，port）的元组，指定远程地址。返回值是发送的字节数。 s.close() 关闭套接字 s.getpeername() 返回连接套接字的远程地址。返回值通常是元组（ipaddr,port）。 s.getsockname() 返回套接字自己的地址。通常是一个元组(ipaddr,port) s.setsockopt(level,optname,value) 设置给定套接字选项的值。 s.getsockopt(level,optname[.buflen]) 返回套接字选项的值。 s.settimeout(timeout) 设置套接字操作的超时期，timeout是一个浮点数，单位是秒。值为None表示没有超时期。一般，超时期应该在刚创建套接字时设置，因为它们可能用于连接的操作（如connect()） s.gettimeout() 返回当前超时期的值，单位是秒，如果没有设置超时期，则返回None。 s.fileno() 返回套接字的文件描述符。 s.setblocking(flag) 如果flag为0，则将套接字设为非阻塞模式，否则将套接字设为阻塞模式（默认值）。非阻塞模式下，如果调用recv()没有发现任何数据，或send()调用无法立即发送数据，那么将引起socket.error异常。 s.makefile() 创建一个与该套接字相关连的文件  网络编程的基本设置步骤 服务端配置  导入socket模块 使用bind方法创建套接字 使用listen方法等待连接， 使用accept方法被动接收tcp连接 使用send或recv方法进行收发  客户端配置  导入socket模块 使用bind方法创建套接字 使用connect方法进行主动tcp连接 使用send或recv方法进行收发  ","title":"python网络编程"},{"content":"RESTful API 入门 1. 简介 表现层状态转换（英语：Representational State Transfer，缩写：REST）是Roy Thomas Fielding博士于2000年在他的博士论文中提出来的一种万维网软件架构风格，目的是便于不同软件/程序在网络（例如互联网）中互相传递信息。表现层状态转换是根基于超文本传输协议（HTTP）之上而确定的一组约束和属性，是一种设计提供万维网络服务的软件构建风格。符合或兼容于这种架构风格（简称为 REST 或 RESTful）的网络服务，允许客户端发出以统一资源标识符访问和操作网络资源的请求，而与预先定义好的无状态操作集一致化。因此表现层状态转换提供了在互联网络的计算系统之间，彼此资源可交互使用的协作性质（interoperability）。相对于其它种类的网络服务，例如SOAP服务，则是以本身所定义的操作集，来访问网络上的资源。\n2. REST 架构约束   客户端－服务器 从本质上讲，这意味着客户端应用程序和服务器应用程序必须能够独立发展而彼此之间没有任何依赖关系。客户端应该只知道资源URI，仅此而已。今天，这是Web开发中的常规做法，因此您不需要任何花哨。把事情简单化。\n 服务器和客户端也可以独立替换和开发，只要它们之间的接口没有更改即可。\n   无状态\nRoy fielding的灵感来自HTTP，因此它反映了这一约束。使所有客户端-服务器交互都变为无状态。服务器将不存储有关客户端发出的最新HTTP请求的任何内容。它将每个请求视为新请求。没有会议，没有历史。\n如果客户端应用程序需要是最终用户的有状态应用程序，则用户必须登录一次并在此之后执行其他授权操作，则来自客户端的每个请求都应包含服务于该请求的所有必要信息，包括身份验证和授权细节。\n 请求之间不得在服务器上存储任何客户端上下文。客户端负责管理应用程序的状态。\n   统一的接口 在约束名称本身适用的情况下，您必须为系统内部暴露给API使用者并认真遵循的资源确定API接口。系统中的资源应仅具有一个逻辑URI，并且应提供一种获取相关或附加数据的方式。最好将资源与网页同义。\n任何单个资源都不应太大，并在其表示中包含所有内容。只要相关，资源应包含指向相对URI的链接（HATEOAS），以获取相关信息。\n此外，整个系统上的资源表示应遵循特定的准则，例如命名约定，链接格式或数据格式（XML或/和JSON）。\n所有资源都应通过通用方法（例如HTTP GET）进行访问，并使用一致的方法进行类似的修改。\n 一旦开发人员熟悉您的一个API，他就应该能够对其他API遵循类似的方法。\n   分层系统\nREST允许您使用分层的系统架构，在该架构中，您可以在服务器A上部署API，并在服务器B上存储数据并在服务器C中对请求进行身份验证。客户端通常无法确定它是直接连接到最终服务器还是中​​间连接。\n  可缓存的\n在当今世界中，缓存数据和响应在任何适用/可能的地方都至关重要。我们阅读的网页也是HTML页面的缓存版本。缓存可以提高客户端的性能，并为服务器提供更好的可伸缩性。\n在REST中，缓存应在适用时应用于资源，然后这些资源必须声明自己可缓存。可以在服务器或客户端上实现缓存。\n 管理良好的缓存部分或完全消除了某些客户端-服务器交互，从而进一步提高了可伸缩性和性能。\n   按需代码（可选）\n好吧，这个约束是可选的。大多数时候，您将以XML或JSON的形式发送资源的静态表示。但是，如果需要，您可以自由地return executable code支持应用程序的一部分，例如，客户端可以调用您的API来获取UI小部件呈现代码。这是允许的。\n 以上所有约束条件都可以帮助您构建真正的RESTful API，并且应该遵循它们。不过，有时您可能会发现自己违反了一两个约束。别担心; 您仍在制作RESTful API，但不是“真正的RESTful”。\n   3. REST资源命名指南 在REST中，主要数据表示称为Resource。从长远来看，拥有一个强大且一致的REST资源命名策略–无疑将证明是最佳的设计决策之一。\n REST中信息的关键抽象是一种资源。可以命名的任何信息都可以是资源：文档或图像，临时服务（例如“洛杉矶今天的天气”），其他资源的集合，非虚拟对象（例如人）等上。换句话说，任何可能成为作者超文本引用目标的概念都必须符合资源的定义。资源是到一组实体的概念映射，而不是在任何特定时间点对应于该映射的实体。\n 一个资源可以是单个的或一个集合。例如，在一个银行应用中，customers代表一个资源集合，customer代表单个资源。我们可以使用URL\u0026quot;/customers\u0026ldquo;来标记customers，可以使用URL\u0026rdquo;/customers/{customerId}\u0026ldquo;来标记customer\n一个资源可能包括多个子资源。例如，一个customer的子资源account可以使用URL\u0026rdquo;/customers/{customerId}/accounts\u0026ldquo;来标记；类似的，accounts的子资源account可以标记如下：URL\u0026rdquo;```/customers/{customerId}/accounts/{accountId}\n4. REST资源命名实践 4.1 使用名词来表示资源 RESTful URI应该引用作为事物（名词）的资源，而不是引用动作（动词），因为名词具有动词所没有的属性–类似于资源具有属性。资源的一些示例是：\n Users of the system User Accounts Network Devices etc.  他们的资源URL应该如下：\n* http://api.example.com/device-management/managed-devices * http://api.example.com/device-management/managed-devices/{device-id} * http://api.example.com/user-management/users/ * http://api.example.com/user-management/users/{id} 为了更加清晰，让我们将资源原型分为四类**（document, collection, store and controller）**，然后您始终应该以将资源放入一个原型为目标，然后一致地使用其命名约定。为了统一起见，请抵制设计资源的诱惑，这些资源是多个原型的混合体。\n  Document\n文档资源是单个概念，类似于对象实例或数据库记录。在REST中，您可以将其视为资源集合中的单个资源。文档的状态表示形式通常包括带有值的字段以及指向其他相关资源的链接。\n使用“单数”名称表示文档资源原型。\nhttp://api.example.com/device-management/managed-devices/{device-id} http://api.example.com/user-management/users/{id} http://api.example.com/user-management/users/admin   Collection\nCollection资源是服务器管理的资源目录。客户可以建议将新资源添加到Collection中。但是，由Collection决定是否创建新资源。Collection资源选择要包含的内容，并确定每个包含的资源的URI。\n使用复数名称表示Collection资源原型。\nhttp://api.example.com/device-management/managed-devices http://api.example.com/user-management/users http://api.example.com/user-management/users/{id}/admin   Store\nStore是客户端管理的资源存储库。Store资源可让API客户端放入资源，将其撤回并决定何时删除它们。Store永远不会生成新的URI。取而代之的是，每个存储的资源都有一个URI，该URI是客户端在最初将其放入Store时选择的。\n使用复数名称表示Store资源原型。\nhttp://api.example.com/cart-management/users/{id}/carts http://api.example.com/song-management/users/{id}/accounts   Controller\nController 资源为过程概念建模。Controller 资源就像可执行函数一样，带有参数和返回值。输入和输出。\n使用动词表示控制器原型。\nhttp://api.example.com/cart-management/users/{id}/cart/checkout http://api.example.com/song-management/users/{id}/playlist/play   4.2. 一致性是关键 使用一致的资源命名约定和URI格式，以最大程度地减少歧义并最大程度地提高可读性和可维护性。您可以实现以下设计提示以实现一致性：\n  使用正斜杠（/）表示层次关系\nURI的路径部分使用正斜杠（/）字符表示资源之间的层次关系。例如\nhttp://api.example.com/device-management http://api.example.com/device-management/managed-devices http://api.example.com/device-management/managed-devices/{id} http://api.example.com/device-management/managed-devices/{id}/scripts http://api.example.com/device-management/managed-devices/{id}/scripts/{id}   不要在URI中使用结尾的正斜杠(/)\n作为URI路径中的最后一个字符，正斜杠（/）不添加语义值，并且可能引起混淆。最好将它们完全删除。\nhttp://api.example.com/device-management/managed-devices/ http://api.example.com/device-management/managed-devices # 这是更好的版本 ```   使用连字符（-）来提高URI的可读性\n为了使你的URI易于人们扫描和解释，请使用连字符（-）来提高长路径段中名称的可读性。\nhttp://api.example.com/inventory-management/managed-entities/{id}/install-script-location # 可读性强 http://api.example.com/inventory-management/managedEntities/{id}/installScriptLocation # 可读性较低   请勿使用下划线（_）\n可以使用下划线代替连字符作为分隔符–但是，根据应用程序的字体，下划线（_）字符可能会在某些浏览器或屏幕中被部分遮盖或完全隐藏。\n为避免这种混淆，请使用连字符（-）代替下划线（_）。\nhttp://api.example.com/inventory-management/managed-entities/{id}/install-script-location # More readable http://api.example.com/inventory_management/managed_entities/{id}/install_script_location # More error prone   在URI中使用小写字母\n方便时，在URI路径中应始终首选小写字母。\nRFC 3986将URI定义为区分大小写，但方案和主机组件除外。例如\nhttp://api.example.org/my-folder/my-doc // 1 HTTP://API.EXAMPLE.ORG/my-folder/my-doc // 2 http://api.example.org/My-Folder/my-doc // 3 在上面的示例中，1和2相同，但3不是，因为它以大写字母使用My-Folder。\n  不要使用文件扩展名\n文件扩展名看起来很糟糕，并且没有任何优势。删除它们也会减少URI的长度。没有理由保留它们。\n除上述原因外，如果要使用文件扩展名突出显示API的媒体类型，则应依靠通过Content-Type标头传达的媒体类型来确定如何处理正文内容。\nhttp://api.example.com/device-management/managed-devices.xml # 请勿使用 http://api.example.com/device-management/managed-devices # 这是正确的URI   5. 不要在URL中使用CRUD函数名称 URI不应用于指示执行CRUD功能。URI应该用于唯一标识资源，而不是对资源进行任何操作。应该使用HTTP请求方法来指示执行了哪个CRUD功能。\nHTTP GET http://api.example.com/device-management/managed-devices //获取所有设备 HTTP POST http://api.example.com/device-management/managed-devices //创建新设备 HTTP GET http://api.example.com/device-management/managed-devices/{id} //获取给定ID的设备 HTTP PUT http://api.example.com/device-management/managed-devices/{id} //更新给定ID的设备 HTTP DELETE http://api.example.com/device-management/managed-devices/{id} //删除给定ID的设备 6. 使用查询组件过滤URL集合 很多时候，您会遇到需求，在这些需求中，您将需要根据某些资源属性对资源进行排序，过滤或限制的集合。为此，请勿创建新的API，而应在资源收集API中启用排序，过滤和分页功能，并将输入参数作为查询参数传递。例如\nhttp://api.example.com/device-management/managed-devices http://api.example.com/device-management/managed-devices?region=USA http://api.example.com/device-management/managed-devices?region=USA\u0026amp;brand=XYZ http://api.example.com/device-management/managed-devices?region=USA\u0026amp;brand=XYZ\u0026amp;sort=installation-date 7. 使用正确的HTTP Status Code表示访问状态 8. 错误返回使用明确易懂的文本 ","permalink":"http://yangchnet.github.io/Dessert/posts/golang/restful-api/","summary":"RESTful API 入门 1. 简介 表现层状态转换（英语：Representational State Transfer，缩写：REST）是Roy Thomas Fielding博士于2000年在他的博士论文中提出来的一种万维网软件架构风格，目的是便于不同软件/程序在网络（例如互联网）中互相传递信息。表现层状态转换是根基于超文本传输协议（HTTP）之上而确定的一组约束和属性，是一种设计提供万维网络服务的软件构建风格。符合或兼容于这种架构风格（简称为 REST 或 RESTful）的网络服务，允许客户端发出以统一资源标识符访问和操作网络资源的请求，而与预先定义好的无状态操作集一致化。因此表现层状态转换提供了在互联网络的计算系统之间，彼此资源可交互使用的协作性质（interoperability）。相对于其它种类的网络服务，例如SOAP服务，则是以本身所定义的操作集，来访问网络上的资源。\n2. REST 架构约束   客户端－服务器 从本质上讲，这意味着客户端应用程序和服务器应用程序必须能够独立发展而彼此之间没有任何依赖关系。客户端应该只知道资源URI，仅此而已。今天，这是Web开发中的常规做法，因此您不需要任何花哨。把事情简单化。\n 服务器和客户端也可以独立替换和开发，只要它们之间的接口没有更改即可。\n   无状态\nRoy fielding的灵感来自HTTP，因此它反映了这一约束。使所有客户端-服务器交互都变为无状态。服务器将不存储有关客户端发出的最新HTTP请求的任何内容。它将每个请求视为新请求。没有会议，没有历史。\n如果客户端应用程序需要是最终用户的有状态应用程序，则用户必须登录一次并在此之后执行其他授权操作，则来自客户端的每个请求都应包含服务于该请求的所有必要信息，包括身份验证和授权细节。\n 请求之间不得在服务器上存储任何客户端上下文。客户端负责管理应用程序的状态。\n   统一的接口 在约束名称本身适用的情况下，您必须为系统内部暴露给API使用者并认真遵循的资源确定API接口。系统中的资源应仅具有一个逻辑URI，并且应提供一种获取相关或附加数据的方式。最好将资源与网页同义。\n任何单个资源都不应太大，并在其表示中包含所有内容。只要相关，资源应包含指向相对URI的链接（HATEOAS），以获取相关信息。\n此外，整个系统上的资源表示应遵循特定的准则，例如命名约定，链接格式或数据格式（XML或/和JSON）。\n所有资源都应通过通用方法（例如HTTP GET）进行访问，并使用一致的方法进行类似的修改。\n 一旦开发人员熟悉您的一个API，他就应该能够对其他API遵循类似的方法。\n   分层系统\nREST允许您使用分层的系统架构，在该架构中，您可以在服务器A上部署API，并在服务器B上存储数据并在服务器C中对请求进行身份验证。客户端通常无法确定它是直接连接到最终服务器还是中​​间连接。\n  可缓存的\n在当今世界中，缓存数据和响应在任何适用/可能的地方都至关重要。我们阅读的网页也是HTML页面的缓存版本。缓存可以提高客户端的性能，并为服务器提供更好的可伸缩性。\n在REST中，缓存应在适用时应用于资源，然后这些资源必须声明自己可缓存。可以在服务器或客户端上实现缓存。\n 管理良好的缓存部分或完全消除了某些客户端-服务器交互，从而进一步提高了可伸缩性和性能。\n   按需代码（可选）\n好吧，这个约束是可选的。大多数时候，您将以XML或JSON的形式发送资源的静态表示。但是，如果需要，您可以自由地return executable code支持应用程序的一部分，例如，客户端可以调用您的API来获取UI小部件呈现代码。这是允许的。\n 以上所有约束条件都可以帮助您构建真正的RESTful API，并且应该遵循它们。不过，有时您可能会发现自己违反了一两个约束。别担心; 您仍在制作RESTful API，但不是“真正的RESTful”。\n   3. REST资源命名指南 在REST中，主要数据表示称为Resource。从长远来看，拥有一个强大且一致的REST资源命名策略–无疑将证明是最佳的设计决策之一。","title":"RESTfulAPI入门"},{"content":"Simple Support Vector Machine First we will import numpy to easily manage linear algebra and calculus operations in python. To plot the learning progress later on, we will use matplotlib.\nimport numpy as np from matplotlib import pyplot as plt %matplotlib inline Stochastic Gradient Descent The svm will learn using the stochastic gradient descent algorithm (SGD). Gradient Descent minimizes a function by following the gradients of the cost function.\nCalculating the Error To calculate the error of a prediction we first need to define the objective function of the svm.\nHinge Loss Function To do this, we need to define the loss function, to calculate the prediction error. We will use hinge loss for our perceptron:\n$$c(x, y, f(x)) = (1 - y * f(x))_+$$\n$c$ is the loss function, $x$ the sample, $y$ is the true label, $f(x)$ the predicted label.\nThis means the following: $$ c(x, y, f(x))= \\begin{cases} 0,\u0026amp; \\text{if } yf(x)\\geq 1\\\n1-yf(x), \u0026amp; \\text{else} \\end{cases} $$\nSo consider, if y and f(x) are signed values $(+1,-1)$:\nObjective Function As we defined the loss function, we can now define the objective function for the svm:\n$$\\underset{w}{min}\\ \\lambda\\parallel w\\parallel^2 + \\ \\sum_{i=1}^n\\big(1-y_i \\langle x_i,w \\rangle\\big)_+$$\nAs you can see, our objective of a svm consists of two terms. The first term is a regularizer, the second term the loss. The regularizer balances between margin maximization and loss. To get more informations I advice you the tutorial introduction of the above adviced Schölkopf \u0026amp; Smola book.\nDerive the Objective Function To minimize this function, we need the gradients of this function.\nAs we have two terms, we will derive them seperately using the sum rule in differentiation.\n$$ \\frac{\\delta}{\\delta w_k} \\lambda\\parallel w\\parallel^2 \\ = 2 \\lambda w_k $$\n$$ \\frac{\\delta}{\\delta w_k} \\big(1-y_i \\langle x_i,w \\rangle\\big)+ \\ = \\begin{cases} 0,\u0026amp; \\text{if } y_i \\langle x_i,w \\rangle\\geq 1\\\n-y_ix{ik}, \u0026amp; \\text{else} \\end{cases} $$\nThis means, if we have a misclassified sample $x_i$, respectively $y_i \\langle x_i,w \\rangle \\ \u0026lt; \\ 1$, we update the weight vector w using the gradients of both terms, if $y_i \\langle x_i,w \\rangle \\geq 1$ we just update w by the gradient of the regularizer. To sum it up, our stochastic gradient descent for the svm looks like this:\nif $y_i⟨x_i,w⟩ \u0026lt; 1$: $$ w = w + \\eta (y_ix_i - 2\\lambda w) $$ else: $$ w = w + \\eta (-2\\lambda w) $$\nOur Data Set First we need to define a labeled data set. If you read the perceptron tutorial you will already know it.\nX = np.array([ [-2, 4], [4, 1], [1, 6], [2, 4], [6, 2] ]) y = np.array([-1,-1,1,1,1]) For simplicity\u0026rsquo;s sake we again fold the bias term into the data set:\nX = np.array([ [-2,4,-1], [4,1,-1], [1, 6, -1], [2, 4, -1], [6, 2, -1], ]) y = np.array([-1,-1,1,1,1]) This small toy data set contains two samples labeled with $-1$ and three samples labeled with $+1$. This means we have a binary classification problem, as the data set contains two sample classes. Lets plot the dataset to see, that is is linearly seperable:\nfor d, sample in enumerate(X): # Plot the negative samples if d \u0026lt; 2: plt.scatter(sample[0], sample[1], s=120, marker=\u0026#39;_\u0026#39;, linewidths=2) # Plot the positive samples else: plt.scatter(sample[0], sample[1], s=120, marker=\u0026#39;+\u0026#39;, linewidths=2) # Print a possible hyperplane, that is seperating the two classes. plt.plot([-2,6],[6,0.5]) [\u0026lt;matplotlib.lines.Line2D at 0x7f4b846e42e8\u0026gt;]  Lets Start implementing Stochastic Gradient Descent Finally we can code our SGD algorithm using our update rules. In opposite to the perceptrons objective function, we use a regularizer in our algorithm. As we have a small data set, which is easily lineary seperable, this is actually not needed and our stochastic gradient descent algorithm would probably converge faster without it. To give you a more powerfull code at hand, I will keep it in the following algorithm.\nTo keep it simple, we will linearly loop over the sample set. For larger data sets it makes sence, to randomly pick a sample during each iteration in the for-loop.\ndef svm_sgd(X, Y): w = np.zeros(len(X[0])) eta = 1 epochs = 100000 for epoch in range(1,n): for i, x in enumerate(X): if (Y[i]*np.dot(X[i], w)) \u0026lt; 1: w = w + eta * ( (X[i] * Y[i]) + (-2 *(1/epoch)* w) ) else: w = w + eta * (-2 *(1/epoch)* w) return w We will run the sgd $100000$ times. Our learning parameter eta is set to $1$. As a regulizing parameter we choose $1/t$, so this parameter will decrease, as the number of epochs increases.\nCode Description Line by Line line 2: Initialize the weight vector for the perceptron with zerosline 3: Set the learning rate to 1line 4: Set the number of epochsline 6: Iterate n times over the whole data set. The Iterator is begins with $1$ to avoid division by zero during regularization parameter calculationline 7: Iterate over each sample in the data set. line 8: Misclassification condition $y_i \\langle x_i,w \\rangle \u0026lt; 1$line 9: Update rule for the weights $w = w + \\eta (y_ix_i - 2\\lambda w)$ including the learning rate $\\eta$ and the regularizer $\\lambda$line 11: If classified correctly just update the weight vector by the derived regularizer term $w = w + \\eta (-2\\lambda w)$.Let the SVM learn! Next we can execute our code, to calculate the proper weight vector, which fits out training data. If there are misclassified samples we will print the number of misclassified and correctly classified samples.\ndef svm_sgd_plot(X, Y): w = np.zeros(len(X[0])) eta = 1 epochs = 100000 errors = [] for epoch in range(1,epochs): error = 0 for i, x in enumerate(X): if (Y[i]*np.dot(X[i], w)) \u0026lt; 1: w = w + eta * ( (X[i] * Y[i]) + (-2 *(1/epoch)* w) ) error = 1 else: w = w + eta * (-2 *(1/epoch)* w) errors.append(error) print(w) plt.plot(errors, \u0026#39;|\u0026#39;) plt.ylim(0.5,1.5) plt.axes().set_yticklabels([]) plt.xlabel(\u0026#39;Epoch\u0026#39;) plt.ylabel(\u0026#39;Misclassified\u0026#39;) plt.show() svm_sgd_plot(X,y) [ 1.58876117 3.17458055 11.11863105] /usr/lib/python3.7/site-packages/matplotlib/figure.py:98: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance. In a future version, a new instance will always be created and returned. Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance. \u0026quot;Adding an axes using the same arguments as a previous axes \u0026quot;  Homework Complete your own Support Vector Machine!\n","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/svm-primal/","summary":"Simple Support Vector Machine First we will import numpy to easily manage linear algebra and calculus operations in python. To plot the learning progress later on, we will use matplotlib.\nimport numpy as np from matplotlib import pyplot as plt %matplotlib inline Stochastic Gradient Descent The svm will learn using the stochastic gradient descent algorithm (SGD). Gradient Descent minimizes a function by following the gradients of the cost function.\nCalculating the Error To calculate the error of a prediction we first need to define the objective function of the svm.","title":"SimpleSupportVectorMachine"},{"content":"import tensorflow as tf import numpy as np from IPython.display import Image tf.ones_like() 创建一个所有元素设置为1的tensor\ntf.subtract() 两个矩阵相减\n decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)\n  这一句计算出1-d\n tf.stack 矩阵拼接，例如\na = tf.constant([1,2,3]) b = tf.constant([4,5,6]) c = tf.stack([a, b], axis = 0) d = tf.stack([a, b], axis = 1) sess = tf.Session() print(sess.run(c)) print(sess.run(d)) [[1 2 3] [4 5 6]] [[1 4] [2 5] [3 6]]  tf.expand_dims 在axis位置增加一个维度\ntf.tile 在同一维度上进行复制\nwith tf.Graph().as_default(): a = tf.constant([1,2],name=\u0026#39;a\u0026#39;) b = tf.tile(a,[3]) sess = tf.Session() print(sess.run(b)) [1 2 1 2 1 2]  axis 0 代表行 1 代表列\ntf.reduce_mean 计算张量的各个维度上的元素的平均值。\nx = tf.constant([[1., 1.], [2., 2.]]) tf.reduce_mean(x) # 1.5 tf.reduce_mean(x, 0) # [1.5, 1.5] tf.reduce_mean(x, 1) # [1., 2.] \u0026lt;tf.Tensor 'Mean_2:0' shape=(2,) dtype=float32\u0026gt;  tf.nn.dropout dropout的作用是为了防止或减轻过拟合，它一般用在全连接层 通过在不同的训练过程中随机扔掉一部分神经元，也就是让某个神经元的激活值以一定的概率p, 让其停止工作，这次训练过程中不更新权值，也不参加神经网络的计算，但是他的权重得保存下来，待下次样本输入时可能会重新工作。 其函数原型： tf.nn.dropout(x, keep_prob, noise_shape=None, seed=None,name=None) 第一个参数为输入，第二个参数设置神经元被选中的概率，\ntf.gather 根据索引，从输入张量中依次取元素，构成一个新的张量\n","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/tensorflowapi/","summary":"import tensorflow as tf import numpy as np from IPython.display import Image tf.ones_like() 创建一个所有元素设置为1的tensor\ntf.subtract() 两个矩阵相减\n decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p)\n  这一句计算出1-d\n tf.stack 矩阵拼接，例如\na = tf.constant([1,2,3]) b = tf.constant([4,5,6]) c = tf.stack([a, b], axis = 0) d = tf.stack([a, b], axis = 1) sess = tf.Session() print(sess.run(c)) print(sess.run(d)) [[1 2 3] [4 5 6]] [[1 4] [2 5] [3 6]]  tf.expand_dims 在axis位置增加一个维度\ntf.tile 在同一维度上进行复制\nwith tf.","title":"tf.ones_like()"},{"content":"ubuntu中增加用户 sudo useradd -m [username] -s /bin/bash #创建账户，使用/bin/bash作为shell sudo passwd [username] #设置密码 sudo adduser [username] sudo #添加管理员权限 su [username]#切换用户 ","permalink":"http://yangchnet.github.io/Dessert/posts/linux/ubuntu%E5%88%9B%E5%BB%BA%E7%94%A8%E6%88%B7/","summary":"ubuntu中增加用户 sudo useradd -m [username] -s /bin/bash #创建账户，使用/bin/bash作为shell sudo passwd [username] #设置密码 sudo adduser [username] sudo #添加管理员权限 su [username]#切换用户 ","title":"ubuntu中增加用户"},{"content":"Ubuntu完全删除nginx 1. 卸载nginx及相关软件  卸载nginx  sudo apt-get --purge remove nginx  移除全部无用包  sudo apt-get autoremove  列出与nginx相关的软件  dpkg --get-selections | grep nginx  删除之  sudo apt-get --purge remove nginx-common sudo apt-get --purge remove nginx-core 2. 停止所有与nginx有关的进程  查看相关进程  ps -ef | grep nginx  停止这些进程  sudo kill -9 {process_id}  00:00:00 grep \u0026ndash;color=auto nginx 这个不是\n 3. 查找主机中与nginx相关的文件 使用命令：\nsudo find / -name nginx* 删除之\nsudo rm -rf {dir} 4. 现在可以重新安装nginx sudo apt-get update sudo apt-get install nginx ","permalink":"http://yangchnet.github.io/Dessert/posts/linux/%E5%AE%8C%E5%85%A8%E5%88%A0%E9%99%A4nginx/","summary":"Ubuntu完全删除nginx 1. 卸载nginx及相关软件  卸载nginx  sudo apt-get --purge remove nginx  移除全部无用包  sudo apt-get autoremove  列出与nginx相关的软件  dpkg --get-selections | grep nginx  删除之  sudo apt-get --purge remove nginx-common sudo apt-get --purge remove nginx-core 2. 停止所有与nginx有关的进程  查看相关进程  ps -ef | grep nginx  停止这些进程  sudo kill -9 {process_id}  00:00:00 grep \u0026ndash;color=auto nginx 这个不是\n 3. 查找主机中与nginx相关的文件 使用命令：\nsudo find / -name nginx* 删除之","title":"Ubuntu完全删除nginx"},{"content":"Vue中的指令介绍 指令  解释：指令 (Directives) 是带有 v- 前缀的特殊属性 作用：当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM  v-text 解释：更新元素的 textContent\n\u0026lt;h1 v-text=\u0026#34;msg\u0026#34;\u0026gt;\u0026lt;/h1\u0026gt; v-html 解释：更新元素的 innerHTML\n\u0026lt;h1 v-html=\u0026#34;msg\u0026#34;\u0026gt;\u0026lt;/h1\u0026gt; v-bind 作用：当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM.响应式地更新 HTML attribute： 语法：v-bind:title=\u0026quot;msg\u0026quot; 简写：:title=\u0026quot;msg\u0026quot;\n\u0026lt;!-- 完整语法 --\u0026gt; \u0026lt;a v-bind:href=\u0026#34;url\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;!-- 缩写 --\u0026gt; \u0026lt;a :href=\u0026#34;url\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;script\u0026gt; // 2 创建 Vue 的实例对象  var vm = new Vue({ // el 用来指定vue挂载到页面中的元素，值是：选择器  // 理解：用来指定vue管理的HTML区域  el: \u0026#39;#app\u0026#39;, // 数据对象，用来给视图中提供数据的  data: { url: \u0026#39;http://www.baidu.com\u0026#39; } }) \u0026lt;/script\u0026gt; v-on 作用：绑定事件 语法：v-on:click=\u0026quot;say\u0026quot; or v-on:click=\u0026quot;say('参数', $event)\u0026quot; 简写：@click=\u0026quot;say\u0026quot; 说明：绑定的事件从methods中获取\n\u0026lt;!-- 完整语法 --\u0026gt; \u0026lt;a v-on:click=\u0026#34;doSomething\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;!-- 缩写 --\u0026gt; \u0026lt;a @click=\u0026#34;doSomething\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;!-- 方法传参 --\u0026gt; \u0026lt;a @click=\u0026#34;doSomething（“123”）\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;script\u0026gt; // 2 创建 Vue 的实例对象  var vm = new Vue({ el: \u0026#39;#app\u0026#39;, // methods属性用来给vue实例提供方法（事件）  methods: { doSomething: function(str) { //接受参数，并输出  console.log(str); } } }) \u0026lt;/script\u0026gt; 事件修饰符  .stop 阻止冒泡，调用 event.stopPropagation() .prevent 阻止默认事件，调用 event.preventDefault() .capture 添加事件侦听器时使用事件捕获模式 .self 只当事件在该元素本身（比如不是子元素）触发时触发回调 .once 事件只触发一次  v-model 作用：在表单元素上创建双向数据绑定 说明：监听用户的输入事件以更新数据\n\u0026lt;input v-model=\u0026#34;message\u0026#34; placeholder=\u0026#34;edit me\u0026#34;\u0026gt; \u0026lt;p\u0026gt;Message is: {{ message }}\u0026lt;/p\u0026gt; v-for 作用：基于源数据多次渲染元素或模板块\n\u0026lt;!-- 1 基础用法 --\u0026gt; \u0026lt;div v-for=\u0026#34;item in items\u0026#34;\u0026gt; {{ item.text }} \u0026lt;/div\u0026gt; \u0026lt;!-- item 为当前项，index 为索引 --\u0026gt; \u0026lt;p v-for=\u0026#34;(item, index) in list\u0026#34;\u0026gt;{{item}} -- {{index}}\u0026lt;/p\u0026gt; \u0026lt;!-- item 为值，key 为键，index 为索引 --\u0026gt; \u0026lt;p v-for=\u0026#34;(item, key, index) in obj\u0026#34;\u0026gt;{{item}} -- {{key}}\u0026lt;/p\u0026gt; \u0026lt;p v-for=\u0026#34;item in 10\u0026#34;\u0026gt;{{item}}\u0026lt;/p\u0026gt; key属性 推荐：使用 v-for 的时候提供 key 属性，以获得性能提升。 说明：使用 key，VUE会基于 key 的变化重新排列元素顺序，并且会移除 key 不存在的元素。\n\u0026lt;div v-for=\u0026#34;item in items\u0026#34; :key=\u0026#34;item.id\u0026#34;\u0026gt; \u0026lt;!-- 内容 --\u0026gt; \u0026lt;/div\u0026gt; 样式处理 class和style 说明：这两个都是HTML元素的属性，使用v-bind，只需要通过表达式计算出字符串结果即可 表达式的类型：字符串、数组、对象 语法：\n\u0026lt;!-- 1 --\u0026gt; \u0026lt;div v-bind:class=\u0026#34;{ active: true }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; ===\u0026gt; \u0026lt;div class=\u0026#34;active\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- 2 --\u0026gt; \u0026lt;div :class=\u0026#34;[\u0026#39;active\u0026#39;, \u0026#39;text-danger\u0026#39;]\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; ===\u0026gt; \u0026lt;div class=\u0026#34;active text-danger\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- 3 --\u0026gt; \u0026lt;div v-bind:class=\u0026#34;[{ active: true }, errorClass]\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; ===\u0026gt; \u0026lt;div class=\u0026#34;active text-danger\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; --- style --- \u0026lt;!-- 1 --\u0026gt; \u0026lt;div v-bind:style=\u0026#34;{ color: activeColor, fontSize: fontSize + \u0026#39;px\u0026#39; }\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;!-- 2 将多个 样式对象 应用到一个元素上--\u0026gt; \u0026lt;div v-bind:style=\u0026#34;[baseStyles, overridingStyles]\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; v-if 和 v-show*  条件渲染 v-if：根据表达式的值的真假条件，销毁或重建元素 v-show：根据表达式之真假值，切换元素的 display CSS 属性  提升用户体验：v-cloak 这个指令保持在元素上直到关联实例结束编译。和 CSS 规则如 [v-cloak] { display: none } 一起用时，这个指令可以隐藏未编译的 Mustache 标签直到实例准备完毕。 防止刷新页面，网速慢的情况下出现{{ message }}等数据格式\n\u0026lt;div v-cloak\u0026gt; {{ message }} \u0026lt;/div\u0026gt; 提升性能：v-pre 说明：跳过这个元素和它的子元素的编译过程。可以用来显示原始 Mustache 标签。跳过大量没有指令的节点会加快编译。\n\u0026lt;span vpre\u0026gt;{{ this will not be compiled }}\u0026lt;/span\u0026gt; 提升性能：v-once 说明：只渲染元素和组件一次。随后的重新渲染，元素/组件及其所有的子节点将被视为静态内容并跳过。这可以用于优化更新性能。\n\u0026lt;span v-once\u0026gt;This will never change: {{msg}}\u0026lt;/span\u0026gt; ","permalink":"http://yangchnet.github.io/Dessert/posts/%E5%89%8D%E7%AB%AF/vue%E6%8C%87%E4%BB%A4/","summary":"Vue中的指令介绍 指令  解释：指令 (Directives) 是带有 v- 前缀的特殊属性 作用：当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM  v-text 解释：更新元素的 textContent\n\u0026lt;h1 v-text=\u0026#34;msg\u0026#34;\u0026gt;\u0026lt;/h1\u0026gt; v-html 解释：更新元素的 innerHTML\n\u0026lt;h1 v-html=\u0026#34;msg\u0026#34;\u0026gt;\u0026lt;/h1\u0026gt; v-bind 作用：当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM.响应式地更新 HTML attribute： 语法：v-bind:title=\u0026quot;msg\u0026quot; 简写：:title=\u0026quot;msg\u0026quot;\n\u0026lt;!-- 完整语法 --\u0026gt; \u0026lt;a v-bind:href=\u0026#34;url\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;!-- 缩写 --\u0026gt; \u0026lt;a :href=\u0026#34;url\u0026#34;\u0026gt;\u0026lt;/a\u0026gt; \u0026lt;script\u0026gt; // 2 创建 Vue 的实例对象  var vm = new Vue({ // el 用来指定vue挂载到页面中的元素，值是：选择器  // 理解：用来指定vue管理的HTML区域  el: \u0026#39;#app\u0026#39;, // 数据对象，用来给视图中提供数据的  data: { url: \u0026#39;http://www.baidu.com\u0026#39; } }) \u0026lt;/script\u0026gt; v-on 作用：绑定事件 语法：v-on:click=\u0026quot;say\u0026quot; or v-on:click=\u0026quot;say('参数', $event)\u0026quot; 简写：@click=\u0026quot;say\u0026quot; 说明：绑定的事件从methods中获取","title":"Vue中的指令介绍"},{"content":"Windows装系统遇到的问题 1. 问题描述 windows无法安装到这个磁盘，选中的磁盘具有MBR分区表。在EFI系统上，Windows只能安装到GPT磁盘\n2. 问题来源 这个问题的根源网上众说纷纭，暂且不管他\n3. 解决办法   首先选择U盘安装，进入安装界面\n  按shift+F10打开命令行\n  输入diskpart并回车\n  输入list disk查看磁盘，一般会出现两个磁盘，一个是机器本身的磁盘，编号为0，另一个为U盘，编号为1\n  输入select disk x（x为要选择的磁盘编号） cmd会提示当前选择的磁盘为x\n  执行clean命令清除该磁盘上所有分区信息，并且会清空所有硬盘数据\n  执行convert gpt，将该硬盘转化为GPT格式\n  完成，继续安装系统\n  ","permalink":"http://yangchnet.github.io/Dessert/posts/windows/mbr-gpt/","summary":"Windows装系统遇到的问题 1. 问题描述 windows无法安装到这个磁盘，选中的磁盘具有MBR分区表。在EFI系统上，Windows只能安装到GPT磁盘\n2. 问题来源 这个问题的根源网上众说纷纭，暂且不管他\n3. 解决办法   首先选择U盘安装，进入安装界面\n  按shift+F10打开命令行\n  输入diskpart并回车\n  输入list disk查看磁盘，一般会出现两个磁盘，一个是机器本身的磁盘，编号为0，另一个为U盘，编号为1\n  输入select disk x（x为要选择的磁盘编号） cmd会提示当前选择的磁盘为x\n  执行clean命令清除该磁盘上所有分区信息，并且会清空所有硬盘数据\n  执行convert gpt，将该硬盘转化为GPT格式\n  完成，继续安装系统\n  ","title":"Windows装系统遇到的问题"},{"content":"WordPress安装踩坑 1. 第一个坑，忘了安装PHP。。。 2. 第二个坑，访问页面not found 发现是因为同时开了apache2和nginx,导致冲突了，把nginx关掉就好了\n3. 第三个坑，打开页面全是源代码  打开/etc/apache2/apache2.conf，将以下内容添加到文件的底部：  \u0026lt;FilesMatch \\ .php $\u0026gt; SetHandler application / x-httpd-php \u0026lt;/ FilesMatch\u0026gt; 为了使PHP正常运行，您必须禁用mpm_event模块并启用mpm_prefork和php7模块。为此，请返回您的终端窗口并发出命令：  sudo a2dismod mpm_event \u0026amp;\u0026amp; sudo a2enmod mpm_prefork \u0026amp;\u0026amp; sudo a2enmod php7.0 4. 在执行上面的命令时，遇到了第四个坑 ERROR: Module php7.0 does not exist! 解决办法\nsudo apt-get install libapache2-mod-php7.0 5. 您的PHP似乎没有安装运行WordPress所必需的MySQL扩展。 sudo apt-get install php-mysql 爬出来了。。\n","permalink":"http://yangchnet.github.io/Dessert/posts/linux/wordpress%E5%AE%89%E8%A3%85%E8%B8%A9%E5%9D%91/","summary":"WordPress安装踩坑 1. 第一个坑，忘了安装PHP。。。 2. 第二个坑，访问页面not found 发现是因为同时开了apache2和nginx,导致冲突了，把nginx关掉就好了\n3. 第三个坑，打开页面全是源代码  打开/etc/apache2/apache2.conf，将以下内容添加到文件的底部：  \u0026lt;FilesMatch \\ .php $\u0026gt; SetHandler application / x-httpd-php \u0026lt;/ FilesMatch\u0026gt; 为了使PHP正常运行，您必须禁用mpm_event模块并启用mpm_prefork和php7模块。为此，请返回您的终端窗口并发出命令：  sudo a2dismod mpm_event \u0026amp;\u0026amp; sudo a2enmod mpm_prefork \u0026amp;\u0026amp; sudo a2enmod php7.0 4. 在执行上面的命令时，遇到了第四个坑 ERROR: Module php7.0 does not exist! 解决办法\nsudo apt-get install libapache2-mod-php7.0 5. 您的PHP似乎没有安装运行WordPress所必需的MySQL扩展。 sudo apt-get install php-mysql 爬出来了。。","title":"WordPress安装踩坑"},{"content":"使用sklearn的贝叶斯分类器进行文本分类 1、sklearn简介 sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。\n2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利 朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。\n2.1、多项式模型 2.2、伯努利模型 2.3、两个模型的区别 3、实战演练 使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。\n  读取全部数据，并随机打乱\n import os import random def get_dataset(): data = [] for root, dirs, files in os.walk(\u0026#39;../dataset/aclImdb/neg\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r\u0026#39;../dataset/aclImdb/pos\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [(\u0026quot;Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see. What I got was something completely satisfying, and quite a bit more than I expected. Being an artist myself (I work in clay), finding inspiration within our surroundings to make good art is imperative, and it is something Andy Goldsworthy has mastered. Following him over the course of a year, the director captures the spontaneous energy, skill, and devotion to the artists connection with nature with dratic inspiring flair. The music set to the film is embracing and intoxicating. If you are an artist in need of inspiration, or anyone else in need of an uplifting experience, then SEE THIS MOVIE. I for one am glad to know that Andy is somewhere out there. Creating, dancing, wrestling with the forces of nature to make our world more beautiful.\u0026quot;, 1), (\u0026quot;A film I expected very little from, and only watched to pass a quiet hour - but what an hour it turned out to be. Roll is an excellent if none-too-serious little story of 'country-boy-lost-in-the-big-city-makes-good', it is funny throughout, the characters are endearing and the pace is just right.\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;Toby Malone is the true star of the film with his endearing portrayal of Matt, said country boy and local Aussie Rules football hero come to the big city to try out for one of the big teams. He is supported superbly by John Batchelor as local gangster Tiny. Watch out for these two.\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;Highly recommended.\u0026quot;, 1)]    按照7:3的比例划分训练集和测试集\n def train_and_test_data(data_): filesize = int(0.7 * len(data_)) # 训练集和测试集的比例为7:3 train_data_ = [each[0] for each in data_[:filesize]] train_target_ = [each[1] for each in data_[:filesize]] test_data_ = [each[0] for each in data_[filesize:]] test_target_ = [each[1] for each in data_[filesize:]] return train_data_, train_target_, test_data_, test_target_ train_data, train_target, test_data, test_target = train_and_test_data(data)   使用多项式贝叶斯分类器\n from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer from sklearn import metrics from sklearn.naive_bayes import BernoulliNB nbc = Pipeline([ (\u0026#39;vect\u0026#39;, TfidfVectorizer()), (\u0026#39;clf\u0026#39;, MultinomialNB(alpha=1.0)), ]) nbc.fit(train_data, train_target) #训练我们的多项式模型贝叶斯分类器 predict = nbc.predict(test_data) #在测试集上预测结果 y_score = nbc.fit(train_data, train_target).predict_proba(test_data) print(y_score) count = 0 #统计预测正确的结果个数 for left , right in zip(predict, test_target): if left == right: count += 1 print(count/len(test_target)) [[0.21379806 0.78620194] [0.61108605 0.38891395] [0.25629837 0.74370163] ... [0.33889503 0.66110497] [0.73665026 0.26334974] [0.1870178 0.8129822 ]] 0.8596    使用伯努利模型分类器\n nbc_1= Pipeline([ (\u0026#39;vect\u0026#39;, TfidfVectorizer()), (\u0026#39;clf\u0026#39;, BernoulliNB(alpha=0.1)), ]) nbc_1.fit(train_data, train_target) predict = nbc_1.predict(test_data) #在测试集上预测结果 count = 0 #统计预测正确的结果个数 for left , right in zip(predict, test_target): if left == right: count += 1 print(count/len(test_target)) 0.8818635607321131   从分类结果可以看出，和多项式模型相比，使用伯努利模型的贝叶斯分类器，在文本分类方面的精度相比，差别不大，我们可以针对我们面对的具体问题，进行实验，选择最为合适的分类器。\n作业 sklearn中一共提供了四种贝叶斯分类器：\n 高斯朴素贝叶斯 多项式朴素贝叶斯 补充朴素贝叶斯 伯努利朴素贝叶斯  从四种贝叶斯分类器模型中找出具有最佳分类效果的分类器，并用直方图直观表示其分类准确率。\n参考资料 sklearn官方网站\nhttps://scikit-learn.org/stable/index.html\nsklearn:朴素贝叶斯 https://scikit-learn.org/stable/modules/naive_bayes.html#naive-bayes\n","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/sklearn_%E8%B4%9D%E5%8F%B6%E6%96%AF/","summary":"使用sklearn的贝叶斯分类器进行文本分类 1、sklearn简介 sklearn是一个Python第三方提供的非常强力的机器学习库，它包含了从数据预处理到训练模型的各个方面。在实战使用scikit-learn中可以极大的节省我们编写代码的时间以及减少我们的代码量，使我们有更多的精力去分析数据分布，调整模型和修改超参。\n2、朴素贝叶斯在文本分类中的常用模型：多项式、伯努利 朴素贝叶斯分类器是一种有监督学习，常见有两种模型，多项式模型(multinomial model)即为词频型和伯努利模(Bernoulli model)即文档型。二者的计算粒度不一样，多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。这里暂不虑特征抽取、为避免消除测试文档时类条件概率中有为0现象而做的取对数等问题。\n2.1、多项式模型 2.2、伯努利模型 2.3、两个模型的区别 3、实战演练 使用在康奈尔大学下载的2M影评作为训练数据和测试数据，里面共同、共有1400条，好评和差评各自700条，我选择总数的70%作为训练数据，30%作为测试数据，来检测sklearn自带的贝叶斯分类器的分类效果。\n  读取全部数据，并随机打乱\n import os import random def get_dataset(): data = [] for root, dirs, files in os.walk(\u0026#39;../dataset/aclImdb/neg\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r\u0026#39;../dataset/aclImdb/pos\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [(\u0026quot;Being a fan of Andy Goldsworthy's art for a while now, and owning some of his books, I had some expectations of what I would see.","title":"使用sklearn的贝叶斯分类器进行文本分类"},{"content":"分类指标作业（第二题） 题目 给定完整数据集，分别计算在使用完整数据集的10%,30%,50%,80%,100%数据时的查准率、查全率，f1度量和ROC，使用折线图表现出这些指标的变化情况，并画出在不同数据量下的ROC曲线\n加载数据集 import os import random def get_dataset(): data = [] for root, dirs, files in os.walk(\u0026#39;../dataset/aclImdb/neg\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r\u0026#39;../dataset/aclImdb/pos\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [('Unless you are between the ages of 10 and 14 (except for the R rating), there are very few things to like here. One or two lines from Kenan Thompson, David Koechner (we really should see him more) and Sam Jackson are humorous and Julianna Margulies is as good as she can be considering her surroundings, but sadly, that\\'s it. Poor plot. Poor acting. Worse writing and delivery. The special effects are dismal. As much as the entire situation is an odd and awful joke, the significant individual embedded situations are all equally terrible. If we consider the action portions, well there are unbelievable action sequences in some films that make you giddy and there are some that make you groan. This movie only contains the latter kind. This leaves little left. I\\'m so glad I did not pay for this.\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;Despite any hype, I can read and think, so as I sat down to watch, I did not expect anything good. I had no expectations, but was somewhat worried going in. Yet, like a train wreck, one cannot merely look away. And even with no expectations, I was let down. Bad. Not even \\'so bad, it\\'s good\\' material. I\\'m _very_ tolerant of bad movies, but this makes \u0026quot;Six String Samurai\u0026quot; (which I liked) Oscar worthy.\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;No, this piece of over CGI\\'d rubbish is in the same company as Battlefield Earth, Little Man and Gigli. How this is currently rated a 7.2 completely mystifies me. Brainwashing or somehow stacking the voting system is all that I can think of as answers.\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;I could go on and on but suffice to say that tonight, I witnessed a train wreck. I need to go wash my eyes. 1 of 10', 0), (\u0026quot;BEFORE THE DEVIL KNOWS YOU'RE DEAD starts off promisingly, setting up a simple heist that goes awry, told from varying perspectives (in RASHOMON style). At around the hour mark, Sidney Lumet transforms this film into something that is so much more than the sum of its parts; it eventually morphs into a multi-faceted family drama, exploring the full realm of human emotions/relations, as the story comes to its chilling climax.\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;As is the case with Lumet, he manages to coax exceptional performances out of his star-studded cast, without any notion of over-acting or hyperbole. Philip Seymour Hoffman, in one of his best roles, is a complex, mysterious, and interesting character, and oftentimes dwarfs Ethan Hawke, who plays his brother, Hank. That's not to say that Hawke is not bad; in fact he is quite above adequate, in a troubled role that suits his style. Marisa Tomei is excellent for her relatively short appearance (the fact that she bares her flesh adds to this). Albert Finney's character (Andy and Hank's father) is the most intriguing, and in my opinion, he deserved a bit more screen-time. Amy Ryan also performs her job adequately.\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;BEFORE THE DEVIL KNOWS YOU'RE DEAD is not an exceptional movie, but it proves that Lumet is still near the top of his game at the (apparent) twilight of an illustrious career. Many of his characteristics and trademarks appear here, not least of which involves the use of his characters. Infused with a killer script (no pun intended), smart dialogue and pacing, and a decent score, BEFORE THE DEVIL KNOWS YOU'RE DEAD is a must-see. A truly underrated gem. 8/10. 3 stars (out of 4). Should just enter my Top 250 at 248. Highly recommended.\u0026quot;, 1)]  按7：3划分数据集 def train_and_test_data(data_): filesize = int(0.7 * len(data_)) # 训练集和测试集的比例为7:3 train_data_ = [each[0] for each in data_[:filesize]] train_target_ = [each[1] for each in data_[:filesize]] test_data_ = [each[0] for each in data_[filesize:]] test_target_ = [each[1] for each in data_[filesize:]] return train_data_, train_target_, test_data_, test_target_ train_data, train_target, test_data, test_target = train_and_test_data(data) 定义分类器 from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer from sklearn import metrics from sklearn.naive_bayes import BernoulliNB nbc = Pipeline([ (\u0026#39;vect\u0026#39;, TfidfVectorizer()), (\u0026#39;clf\u0026#39;, MultinomialNB(alpha=1.0)), ]) nbc.fit(train_data, train_target) #训练我们的多项式模型贝叶斯分类器 predict = nbc.predict(test_data) #在测试集上预测结果 y_score = nbc.fit(train_data, train_target).predict_proba(test_data) print(y_score) count = 0 #统计预测正确的结果个数 for left , right in zip(predict, test_target): if left == right: count += 1 print(count/len(test_target)) [[0.51083071 0.48916929] [0.73102053 0.26897947] [0.30725664 0.69274336] ... [0.7051641 0.2948359 ] [0.95670055 0.04329945] [0.96212725 0.03787275]] 0.8618666666666667  from sklearn.naive_bayes import MultinomialNB from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer from sklearn import metrics from sklearn.naive_bayes import BernoulliNB from sklearn.metrics import roc_curve, auc import matplotlib.pyplot as plt from itertools import cycle nbc = Pipeline([ (\u0026#39;vect\u0026#39;, TfidfVectorizer()), (\u0026#39;clf\u0026#39;, MultinomialNB(alpha=1.0)), ]) fpr = [] tpr = [] roc_auc = [] for k, v in enumerate([0.1, 0.3, 0.5, 0.8, 1]): train_data_ = train_data[0: int(len(train_data)*v)] train_target_ = train_target[0: int(len(train_data)*v)] test_data_ = test_data[0: int(len(train_data)*v)] test_target_ = test_target[0: int(len(train_data)*v)] nbc.fit(train_data_, train_target_) predict = nbc.predict(test_data_) y_score = nbc.fit(train_data_, train_target_).predict_proba(test_data_) print(y_score) f, t , _ = roc_curve(test_target_, y_score[:, 1]) fpr.append(f) tpr.append(t) roc_auc.append(auc(fpr[k], tpr[k])) plt.figure(figsize=(8,6), dpi=200) colors = cycle([\u0026#39;aqua\u0026#39;, \u0026#39;darkorange\u0026#39;, \u0026#39;cornflowerblue\u0026#39;, \u0026#39;navy\u0026#39;, \u0026#39;green\u0026#39;]) for i, color in zip(range(5), colors): plt.plot(fpr[i], tpr[i], color=color, lw=lw, label=\u0026#39;ROC curve of {0} (area = {1:0.2f})\u0026#39; \u0026#39;\u0026#39;.format([0.1, 0.3, 0.5, 0.8, 1][i], roc_auc[i])) plt.plot([0, 1], [0, 1], color=\u0026#39;black\u0026#39;, lw=lw, linestyle=\u0026#39;--\u0026#39;) plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) plt.title(\u0026#39;Receiver operating characteristic example\u0026#39;) plt.legend(loc=\u0026#34;lower right\u0026#34;) plt.show() [[0.52592994 0.47407006] [0.50514363 0.49485637] [0.38757784 0.61242216] ... [0.56621401 0.43378599] [0.35758914 0.64241086] [0.31767289 0.68232711]] [[0.49465951 0.50534049] [0.70456524 0.29543476] [0.42657598 0.57342402] ... [0.49094946 0.50905054] [0.92783796 0.07216204] [0.8024358 0.1975642 ]] [[0.49445208 0.50554792] [0.72624226 0.27375774] [0.35817261 0.64182739] ... [0.72512198 0.27487802] [0.95407643 0.04592357] [0.95014618 0.04985382]] [[0.47846521 0.52153479] [0.74802248 0.25197752] [0.30833458 0.69166542] ... [0.7419486 0.2580514 ] [0.95732057 0.04267943] [0.95765587 0.04234413]] [[0.51083071 0.48916929] [0.73102053 0.26897947] [0.30725664 0.69274336] ... [0.7051641 0.2948359 ] [0.95670055 0.04329945] [0.96212725 0.03787275]]  ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/%E5%88%86%E7%B1%BB%E6%8C%87%E6%A0%87%E4%BD%9C%E4%B8%9A%E7%AC%AC%E4%BA%8C%E9%A2%98/","summary":"分类指标作业（第二题） 题目 给定完整数据集，分别计算在使用完整数据集的10%,30%,50%,80%,100%数据时的查准率、查全率，f1度量和ROC，使用折线图表现出这些指标的变化情况，并画出在不同数据量下的ROC曲线\n加载数据集 import os import random def get_dataset(): data = [] for root, dirs, files in os.walk(\u0026#39;../dataset/aclImdb/neg\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 0)) for root, dirs, files in os.walk(r\u0026#39;../dataset/aclImdb/pos\u0026#39;): for file in files: realpath = os.path.join(root, file) with open(realpath, errors=\u0026#39;ignore\u0026#39;) as f: data.append((f.read(), 1)) random.shuffle(data) return data data = get_dataset() data[:2] [('Unless you are between the ages of 10 and 14 (except for the R rating), there are very few things to like here.","title":"分类指标作业（第二题）"},{"content":"删除WordPress  删除网络文件：  rm -Rf /var/www/html/* 删除数据库。首先获取mysql的root密码（通过ssh登录时显示在MOTD中）。  mysql -uroot -p 输入密码后使用语句：\nDROP DATABASE wordpress; 删除WordPress数据库\nexit; ","permalink":"http://yangchnet.github.io/Dessert/posts/linux/%E5%88%A0%E9%99%A4wordpress/","summary":"删除WordPress  删除网络文件：  rm -Rf /var/www/html/* 删除数据库。首先获取mysql的root密码（通过ssh登录时显示在MOTD中）。  mysql -uroot -p 输入密码后使用语句：\nDROP DATABASE wordpress; 删除WordPress数据库\nexit; ","title":"删除WordPress"},{"content":"四种常见的POST类型 1. application/x-www-form-urlencoded 这应该是最常见的 POST 提交数据的方式了。浏览器的原生 表单，如果不设置 enctype 属性，那么最终就会以 application/x-www-form-urlencoded 方式提交数据。请求类似于下面这样（无关的请求头在本文中都省略掉了）：\nPOST http://www.example.com HTTP/1.1 Content-Type: application/x-www-form-urlencoded;charset=utf-8 title=test\u0026amp;sub%5B%5D=1\u0026amp;sub%5B%5D=2\u0026amp;sub%5B%5D=3 首先，Content-Type 被指定为 application/x-www-form-urlencoded；其次，提交的数据按照 key1=val1\u0026amp;key2=val2 的方式进行编码，key 和 val 都进行了 URL 转码。大部分服务端语言都对这种方式有很好的支持。例如 PHP 中，$_POST[\u0026lsquo;title\u0026rsquo;] 可以获取到 title 的值，$_POST[\u0026lsquo;sub\u0026rsquo;] 可以得到 sub 数组。\n很多时候，我们用 Ajax 提交数据时，也是使用这种方式。例如 JQuery 和 QWrap 的 Ajax，Content-Type 默认值都是「application/x-www-form-urlencoded;charset=utf-8」。\n2. multipart/form-data 这又是一个常见的 POST 数据提交的方式。我们使用表单上传文件时，必须让 \u0026lt;form\u0026gt; 表单的 enctype 等于 multipart/form-data。直接来看一个请求示例：\nPOST http://www.example.com HTTP/1.1 Content-Type:multipart/form-data; boundary=----WebKitFormBoundaryrGKCBY7qhFd3TrwA ------WebKitFormBoundaryrGKCBY7qhFd3TrwA Content-Disposition: form-data; name=\u0026#34;text\u0026#34; title ------WebKitFormBoundaryrGKCBY7qhFd3TrwA Content-Disposition: form-data; name=\u0026#34;file\u0026#34;; filename=\u0026#34;chrome.png\u0026#34; Content-Type: image/png PNG ... content of chrome.png ... ------WebKitFormBoundaryrGKCBY7qhFd3TrwA-- 这个例子稍微复杂点。首先生成了一个 boundary 用于分割不同的字段，为了避免与正文内容重复，boundary 很长很复杂。然后 Content-Type 里指明了数据是以 multipart/form-data 来编码，本次请求的 boundary 是什么内容。消息主体里按照字段个数又分为多个结构类似的部分，每部分都是以 \u0026ndash;boundary 开始，紧接着是内容描述信息，然后是回车，最后是字段具体内容（文本或二进制）。如果传输的是文件，还要包含文件名和文件类型信息。消息主体最后以 \u0026ndash;boundary\u0026ndash; 标示结束。关于 multipart/form-data 的详细定义，请前往 rfc1867 查看。\n这种方式一般用来上传文件，各大服务端语言对它也有着良好的支持。\n上面提到的这两种 POST 数据的方式，都是浏览器原生支持的，而且现阶段标准中原生 \u0026lt;form\u0026gt; 表单也只支持这两种方式（通过 \u0026lt;form\u0026gt; 元素的 enctype 属性指定，默认为 application/x-www-form-urlencoded。其实 enctype 还支持 text/plain，不过用得非常少）。\n随着越来越多的 Web 站点，尤其是 WebApp，全部使用 Ajax 进行数据交互之后，我们完全可以定义新的数据提交方式，给开发带来更多便利。\n3. application/json application/json 这个 Content-Type 作为响应头大家肯定不陌生。实际上，现在越来越多的人把它作为请求头，用来告诉服务端消息主体是序列化后的 JSON 字符串。由于 JSON 规范的流行，除了低版本 IE 之外的各大浏览器都原生支持 JSON.stringify，服务端语言也都有处理 JSON 的函数，使用 JSON 不会遇上什么麻烦。\nJSON 格式支持比键值对复杂得多的结构化数据，这一点也很有用。记得我几年前做一个项目时，需要提交的数据层次非常深，我就是把数据 JSON 序列化之后来提交的。不过当时我是把 JSON 字符串作为 val，仍然放在键值对里，以 x-www-form-urlencoded 方式提交。\nGoogle 的 AngularJS 中的 Ajax 功能，默认就是提交 JSON 字符串。例如下面这段代码：\nvar data = {\u0026#39;title\u0026#39;:\u0026#39;test\u0026#39;, \u0026#39;sub\u0026#39; : [1,2,3]}; $http.post(url, data).success(function(result) { ... }); 最终发送的请求是：\nPOST http://www.example.com HTTP/1.1 Content-Type: application/json;charset=utf-8 {\u0026#34;title\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;sub\u0026#34;:[1,2,3]}\\ 这种方案，可以方便的提交复杂的结构化数据，特别适合 RESTful 的接口。各大抓包工具如 Chrome 自带的开发者工具、Firebug、Fiddler，都会以树形结构展示 JSON 数据，非常友好。但也有些服务端语言还没有支持这种方式，例如 php 就无法通过 $_POST 对象从上面的请求中获得内容。这时候，需要自己动手处理下：在请求头中 Content-Type 为 application/json 时，从 php://input 里获得原始输入流，再 json_decode 成对象。一些 php 框架已经开始这么做了。\n4. text/xml XML-RPC（XML Remote Procedure Call）是一种使用 HTTP 作为传输协议，XML 作为编码方式的远程调用规范。典型的 XML-RPC 请求是这样的：\nPOST http://www.example.com HTTP/1.1 Content-Type: text/xml \u0026lt;?xml version=\u0026#34;1.0\u0026#34;?\u0026gt; \u0026lt;methodCall\u0026gt; \u0026lt;methodName\u0026gt;examples.getStateName\u0026lt;/methodName\u0026gt; \u0026lt;params\u0026gt; \u0026lt;param\u0026gt; \u0026lt;value\u0026gt;\u0026lt;i4\u0026gt;41\u0026lt;/i4\u0026gt;\u0026lt;/value\u0026gt; \u0026lt;/param\u0026gt; \u0026lt;/params\u0026gt; \u0026lt;/methodCall\u0026gt; XML-RPC 协议简单、功能够用，各种语言的实现都有。它的使用也很广泛，如 WordPress 的 XML-RPC Api，搜索引擎的 ping 服务等等。JavaScript 中，也有现成的库支持以这种方式进行数据交互，能很好的支持已有的 XML-RPC 服务。\n","permalink":"http://yangchnet.github.io/Dessert/posts/net/%E5%9B%9B%E7%A7%8D%E5%B8%B8%E8%A7%81%E7%9A%84post%E7%B1%BB%E5%9E%8B/","summary":"四种常见的POST类型 1. application/x-www-form-urlencoded 这应该是最常见的 POST 提交数据的方式了。浏览器的原生 表单，如果不设置 enctype 属性，那么最终就会以 application/x-www-form-urlencoded 方式提交数据。请求类似于下面这样（无关的请求头在本文中都省略掉了）：\nPOST http://www.example.com HTTP/1.1 Content-Type: application/x-www-form-urlencoded;charset=utf-8 title=test\u0026amp;sub%5B%5D=1\u0026amp;sub%5B%5D=2\u0026amp;sub%5B%5D=3 首先，Content-Type 被指定为 application/x-www-form-urlencoded；其次，提交的数据按照 key1=val1\u0026amp;key2=val2 的方式进行编码，key 和 val 都进行了 URL 转码。大部分服务端语言都对这种方式有很好的支持。例如 PHP 中，$_POST[\u0026lsquo;title\u0026rsquo;] 可以获取到 title 的值，$_POST[\u0026lsquo;sub\u0026rsquo;] 可以得到 sub 数组。\n很多时候，我们用 Ajax 提交数据时，也是使用这种方式。例如 JQuery 和 QWrap 的 Ajax，Content-Type 默认值都是「application/x-www-form-urlencoded;charset=utf-8」。\n2. multipart/form-data 这又是一个常见的 POST 数据提交的方式。我们使用表单上传文件时，必须让 \u0026lt;form\u0026gt; 表单的 enctype 等于 multipart/form-data。直接来看一个请求示例：\nPOST http://www.example.com HTTP/1.1 Content-Type:multipart/form-data; boundary=----WebKitFormBoundaryrGKCBY7qhFd3TrwA ------WebKitFormBoundaryrGKCBY7qhFd3TrwA Content-Disposition: form-data; name=\u0026#34;text\u0026#34; title ------WebKitFormBoundaryrGKCBY7qhFd3TrwA Content-Disposition: form-data; name=\u0026#34;file\u0026#34;; filename=\u0026#34;chrome.png\u0026#34; Content-Type: image/png PNG .","title":"四种常见的POST类型"},{"content":"在docker中构建django项目 （需安装docker-compose, 安装教程）\n1. 定义项目组件 对于此项目，您需要创建Dockerfile，Python依赖项文件和docker-compose.yml文件。（您可以使用此文件的扩展名.yml或.yaml扩展名。）\n1.1. 创建一个空目录 该目录应仅包含构建该映像的资源。\n1.2 创建Dockerfile 内容如下：\nFROM python:3 ENV PYTHONUNBUFFERED 1 RUN mkdir /code WORKDIR /code COPY requirements.txt /code/ RUN pip install -r requirements.txt COPY . /code/ 对于DockerFile的解释\n1.3 创建requirements.txt 内容如下：\ndjango django-ckeditor pillow numpy 1.4 创建docker-compose.yml 该docker-compose.yml文件描述了构成应用程序的服务。在此示例中，这些服务是Web服务器和数据库。撰写文件还描述了这些服务使用哪些Docker映像，它们如何链接在一起，以及它们可能需要安装在容器内的任何卷。最后，该docker-compose.yml文件描述了这些服务公开的端口。有关此文件如何工作的更多信息，请参阅docker-compose.yml参考。 内容如下：\nversion: \u0026#39;3\u0026#39; services: db: image: postgres web: build: . command: python manage.py runserver 0.0.0.0:8000 volumes: - .:/code ports: - \u0026#34;8000:8000\u0026#34; depends_on: - db 2 创建django项目  切换到项目跟目录】 通过运行docker-compose run 命令创建django项目  sudo docker-compose run web django-admin startproject mysite . 查看项目内容\nls -l 更改文件所有权  sudo chown -R $USER:$USER . 3 连接数据库  打开mysite/setting.py\n改为：  DATABASES = { \u0026#39;default\u0026#39;: { \u0026#39;ENGINE\u0026#39;: \u0026#39;django.db.backends.postgresql\u0026#39;, \u0026#39;NAME\u0026#39;: \u0026#39;postgres\u0026#39;, \u0026#39;USER\u0026#39;: \u0026#39;postgres\u0026#39;, \u0026#39;HOST\u0026#39;: \u0026#39;db\u0026#39;, \u0026#39;PORT\u0026#39;: 5432, } } 从项目的顶级目录运行 docker-compose up命令  ","permalink":"http://yangchnet.github.io/Dessert/posts/%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%AE%B9%E5%99%A8/%E5%9C%A8docker%E4%B8%AD%E6%9E%84%E5%BB%BAdjango%E9%A1%B9%E7%9B%AE/","summary":"在docker中构建django项目 （需安装docker-compose, 安装教程）\n1. 定义项目组件 对于此项目，您需要创建Dockerfile，Python依赖项文件和docker-compose.yml文件。（您可以使用此文件的扩展名.yml或.yaml扩展名。）\n1.1. 创建一个空目录 该目录应仅包含构建该映像的资源。\n1.2 创建Dockerfile 内容如下：\nFROM python:3 ENV PYTHONUNBUFFERED 1 RUN mkdir /code WORKDIR /code COPY requirements.txt /code/ RUN pip install -r requirements.txt COPY . /code/ 对于DockerFile的解释\n1.3 创建requirements.txt 内容如下：\ndjango django-ckeditor pillow numpy 1.4 创建docker-compose.yml 该docker-compose.yml文件描述了构成应用程序的服务。在此示例中，这些服务是Web服务器和数据库。撰写文件还描述了这些服务使用哪些Docker映像，它们如何链接在一起，以及它们可能需要安装在容器内的任何卷。最后，该docker-compose.yml文件描述了这些服务公开的端口。有关此文件如何工作的更多信息，请参阅docker-compose.yml参考。 内容如下：\nversion: \u0026#39;3\u0026#39; services: db: image: postgres web: build: . command: python manage.py runserver 0.0.0.0:8000 volumes: - .:/code ports: - \u0026#34;8000:8000\u0026#34; depends_on: - db 2 创建django项目  切换到项目跟目录】 通过运行docker-compose run 命令创建django项目  sudo docker-compose run web django-admin startproject mysite .","title":"在docker中构建django项目"},{"content":"在通过日期获取数据库条目时，出现 django It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\u0026quot;]错误 由于日期是从前端获取的，因此将前端日期引用标签改为：{{ comment.time|date:\u0026quot;Y-m-d H:i:s.u\u0026quot;}}\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/yyyy-mm-dd%E9%94%99%E8%AF%AF/","summary":"在通过日期获取数据库条目时，出现 django It must be in YYYY-MM-DD HH:MM[:ss[.uuuuuu]][TZ] format.\u0026quot;]错误 由于日期是从前端获取的，因此将前端日期引用标签改为：{{ comment.time|date:\u0026quot;Y-m-d H:i:s.u\u0026quot;}}","title":"在通过日期获取数据库条目时，出现djangoItmustbeinYYYY-MM-DDHH:MM[:ss[.uuuuuu]][TZ]format.\"]错误"},{"content":"基于卷积神经网络和决策树的体域网数据融合方法 现阶段想法:在softmax层后接随机森林，通过种树增加分类准确率\nimport tensorflow as tf import numpy as np import tensorflow.examples.tutorials.mnist.input_data as input_data import scipy as sp %matplotlib inline sess = tf.Session() DEPTH = 3 # Depth of a tree N_LEAF = 2 ** (DEPTH + 1) # Number of leaf node N_LABEL = 10 # Number of classes N_TREE = 5 # Number of trees (ensemble) N_BATCH = 128 # Number of data points per mini-batch 分批训练，每一批128个  初始化矩阵 def init_weights(shape): return tf.Variable(tf.random_normal(shape, stddev=0.01)) def init_prob_weights(shape, minval=-5, maxval=5): return tf.Variable(tf.random_uniform(shape, minval, maxval))  定义模型  a表示alive,激活之意，eg:l1a,表示layer_1_alive，第一个激活层 w表示weight,权重  def model(X, w, w2, w3, w4_e, w_d_e, w_l_e, p_keep_conv, p_keep_hidden): # 激活层1 \u0026amp; 池化层1 \u0026amp; dropout l1a = tf.nn.relu(tf.nn.conv2d(X, w, [1, 1, 1, 1], \u0026#39;SAME\u0026#39;)) l1 = tf.nn.max_pool(l1a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\u0026#39;SAME\u0026#39;) l1 = tf.nn.dropout(l1, p_keep_conv) # 激活层2 \u0026amp; 池化层 \u0026amp; dropout l2a = tf.nn.relu(tf.nn.conv2d(l1, w2, [1, 1, 1, 1], \u0026#39;SAME\u0026#39;)) l2 = tf.nn.max_pool(l2a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\u0026#39;SAME\u0026#39;) l2 = tf.nn.dropout(l2, p_keep_conv) # 激活层3 \u0026amp; 池化层 \u0026amp; full connected layer \u0026amp; dropout l3a = tf.nn.relu(tf.nn.conv2d(l2, w3, [1, 1, 1, 1], \u0026#39;SAME\u0026#39;)) l3 = tf.nn.max_pool(l3a, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\u0026#39;SAME\u0026#39;) l3 = tf.reshape(l3, [-1, w4_e[0].get_shape().as_list()[0]]) l3 = tf.nn.dropout(l3, p_keep_conv) # decision node \u0026amp; prediction node (leaf node) decision_p_e = [] leaf_p_e = [] for w4, w_d, w_l in zip(w4_e, w_d_e, w_l_e): l4 = tf.nn.relu(tf.matmul(l3, w4)) l4 = tf.nn.dropout(l4, p_keep_conv) decision_p = tf.nn.sigmoid(tf.matmul(l4, w_d)) # 从这一句看，好像叶子节点不与决策节点相关 leaf_p = tf.nn.softmax(w_l) decision_p_e.append(decision_p) leaf_p_e.append(leaf_p) return decision_p_e, leaf_p_e 创建占位符作为输入 X = tf.placeholder(\u0026#34;float\u0026#34;, [N_BATCH, 28, 28, 1]) Y = tf.placeholder(\u0026#34;float\u0026#34;, [N_BATCH, N_LABEL]) 初始化参数 w = init_weights([3, 3, 1, 32]) w2 = init_weights([3, 3, 32, 64]) w3 = init_weights([3, 3, 64, 128]) w4_ensemble = [] w_d_ensemble = [] w_l_ensemble = [] for i in range(N_TREE): w4_ensemble.append(init_weights([128*4*4, 625])) w_d_ensemble.append(init_prob_weights([625, N_LEAF], -1, 1)) w_l_ensemble.append(init_prob_weights([N_LEAF, N_LABEL], -2, 2)) p_keep_conv = tf.placeholder(\u0026#34;float\u0026#34;) p_keep_hidden = tf.placeholder(\u0026#34;float\u0026#34;) 定义一个完全可微deep-ndf decision_p_e, leaf_p_e = model(X, w, w2, w3, w4_ensemble, w_d_ensemble, w_l_ensemble, p_keep_conv, p_keep_hidden) flat_decision_p_e = [] for decision_p in decision_p_e: # decision_p是d, decision_p_comp是1-d decision_p_comp = tf.subtract(tf.ones_like(decision_p), decision_p) decision_p_pack = tf.stack([decision_p, decision_p_comp]) flat_decision_p = tf.reshape(decision_p_pack, [-1]) flat_decision_p_e.append(flat_decision_p) batch_0_indices = \\ tf.tile(tf.expand_dims(tf.range(0, N_BATCH * N_LEAF, N_LEAF), 1), [1, N_LEAF])  sess = tf.Session() sess.run(batch_0_indices) array([[ 0, 0, 0, ..., 0, 0, 0], [ 16, 16, 16, ..., 16, 16, 16], [ 32, 32, 32, ..., 32, 32, 32], ..., [2000, 2000, 2000, ..., 2000, 2000, 2000], [2016, 2016, 2016, ..., 2016, 2016, 2016], [2032, 2032, 2032, ..., 2032, 2032, 2032]], dtype=int32)  batch_0_indices.shape = 128 * 16\nin_repeat = N_LEAF / 2 out_repeat = N_BATCH batch_complement_indices = \\ np.array([[0] * int(in_repeat), [N_BATCH * N_LEAF] \\ * int(in_repeat)] * out_repeat).reshape(N_BATCH, N_LEAF) print(batch_complement_indices) [[ 0 0 0 ... 2048 2048 2048] [ 0 0 0 ... 2048 2048 2048] [ 0 0 0 ... 2048 2048 2048] ... [ 0 0 0 ... 2048 2048 2048] [ 0 0 0 ... 2048 2048 2048] [ 0 0 0 ... 2048 2048 2048]]  sess.run(tf.add(batch_0_indices, batch_complement_indices)) array([[ 0, 0, 0, ..., 2048, 2048, 2048], [ 16, 16, 16, ..., 2064, 2064, 2064], [ 32, 32, 32, ..., 2080, 2080, 2080], ..., [2000, 2000, 2000, ..., 4048, 4048, 4048], [2016, 2016, 2016, ..., 4064, 4064, 4064], [2032, 2032, 2032, ..., 4080, 4080, 4080]], dtype=int32)  ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/dnf/","summary":"基于卷积神经网络和决策树的体域网数据融合方法 现阶段想法:在softmax层后接随机森林，通过种树增加分类准确率\nimport tensorflow as tf import numpy as np import tensorflow.examples.tutorials.mnist.input_data as input_data import scipy as sp %matplotlib inline sess = tf.Session() DEPTH = 3 # Depth of a tree N_LEAF = 2 ** (DEPTH + 1) # Number of leaf node N_LABEL = 10 # Number of classes N_TREE = 5 # Number of trees (ensemble) N_BATCH = 128 # Number of data points per mini-batch 分批训练，每一批128个  初始化矩阵 def init_weights(shape): return tf.","title":"基于卷积神经网络和决策树的体域网数据融合方法"},{"content":"基本计算指令  这里的汇编指令均基于x86-64架构\n 0. 先验知识 0.1 寄存器设置 一个x86-64的中央处理单元包含一组16个64位通用目的寄存器。这些寄存器用来存储整数数据和指针。指令可以对这16个寄存器的低位字节中存放的不同大小的数据进行操作。字节级操作可以访问最低的字节，16位操作可以访问最低的2个字节，32位操作可以访问最低的4个字节，而64位操作可以访问整个寄存器。\n3. 寻址方式 1. 数据传送指令 最简单形式的数据传送指令\u0026ndash;mov类。这些指令把数据从源位置复制到目的位置，不做任何变化。mov类指令由四条指令组成：movb, movw, movl,movq.这些指令都执行相同的操作，区别在于它们操作的数据大小不同：分别是1，2，4，8字节。\n 由于历史原因，Intel处理器将16位作为一个字（w），8位为一个字节(b)，32位为双字(l),64位为4字（q）\n    指令 效果 描述     MOV S D D \u0026lt;- S 传送   movb  传送字节   movw  传送字   movl  传送双字   movq  传送四字   movabsq I, R  传送绝对的四字    传送指令的两个操作数不能都指向内存位置。将一个值从一个内存位置复制到另一个内存位置需要两个步骤，第一个指令将源值加载到寄存器，第二条指令将该寄存器写入目的位置。\nexample\n C code\n long exchange(lone *xp, long y){ long x = *xp; *xp = y; return x; }  汇编代码\n exchange: movq (%rdi), %rax get x at xp, Set as return value movq %rsi, (%rdi) Store y at xp. ret 2. 压栈和出栈 在x86-64中，程序栈存放在内存中某个区域，栈向下增长，这样，栈顶元素的地址是所有栈中元素地址最低的。栈指针%rsp保存着栈顶元素的地址。\npushq指令的功能是把数据压入到栈上，而popq指令是弹出数据。这些指令都只有一个操作数\u0026ndash;压入的数据源和弹出的数据目的。\n将一个四字值压入栈中，首先要将栈指针减8，然后再将值写入到新的栈顶地址。因此，pushq %rbp的行为等价于下面两条命令：\nsubq $8, %rsp Decrement stack pointer movq %rbp, (%rsp) Store %rbp on stack 弹出一个四字的操作包括从栈顶位置读出数据，然后将栈指针加8，因此，指令popq %rax等价于下面两条指令：\nmovq (%rsp) , %rax Read %rax from stack addq $8, %rsp Increment stack pointer example 3. 算术和逻辑操作  每个指令类都有b, w, l, q这四种不同大小的指令\n 算术和逻辑操作指令\n3.1 加载有效地址 加载有效地址（load effective address）指令leaq实际上是movq指令的变形。它的指令形式是从内存读数据到寄存器，但实际上它根本就没有引用内存。它的第一个操作数看上去是一个内存引用，但该指令并不是从指定的位置读入数据，而是将有效地址写入到目的操作数。\nlea还可以简洁的描述普通的算术操作。例如，如果寄存器%rdx的值为x， 那么指令leaq 7(%rdx, %rdx, 4),%rax将设置寄存器%rax的值为5x+7\nexample\n c code\n long scale(long x, long y, long z){ long t = x + 4 * y + 12 * z; return t; }  汇编指令\n lone scale(long x, long y, long z) x in %rdi, y in %rsi, z in %rdx scale: leaq (%rdi, %rsi, 4), %rax x + 4 * y leaq (%rdx, %rdx, 2), %rax z + 2 * z = 3 * z leaq (%rax, %rdx, 4), %rax (x+4×y) + 4*(3*z) = x + 4*y + 12*z ret 3.2 一元和二元操作 上表中的第二组中的操作是一元操作，只有一个操作数，既是源又是目的。这个操作数可以是寄存器，也可以是内存位置。比如说，指令incq (%rsp)会使栈顶的8字节元素+1.\n第三组是二元操作，其中第二个操作数既是源又是目的。不过，要注意，源操作数是第一个，目的操作数是第二个，对于不可交换来说，这看上去很奇特。例如，指令subq %rax, %rdx使寄存器%rdx的值减去%rax中的值。\n3.3 移位操作 最后一组是移位操作，先给出移位量，然后第二项给出的是要移位的数。可以进行算术和逻辑右移。移位量可以是一个立即数，或者放在单字节寄存器%cl中。\n左移指令有两个名字：sal和shl。二者的效果是一样的，都是将右边填上0.右移指令不同，sar执行算术移位（填上符号位），而shr执行逻辑移位（填上0）.\n 当寄存器%cl的十六进制值为0xFF时，指令salb会移7位，salw会移15为，sall会移31位，salq会移63位`\n 3.4 特殊的算术操作 两个64位有符号或无符号整数相乘得到的乘积需要128位来表示。intel把16字节的数成为八字（oct word）.\n 特殊的算术操作\n example: 如何从两个无符号64位数字x和y生成128位的乘积\n c code\n #include\u0026lt;inttypes.h\u0026gt; typedef unsigned __int128 uint128_t void store_uprod(uint128_t *dest, uint64_t x, uint64_t y){ *dest = x * (uint128_t) y; }  汇编代码\n dest in %rdi, x in %rsi, y in %rdx store_uprod: movq %rsi, %rax copy x to multiplicand mulq %rdx multiply by y movq %rax, (%rdi) store lower 8 bytes at dest movq %rdx, 8(%rdi) store upper 8 bytes at dest+8 ret example： 如何实现除法\n c code\n void remdiv(long x, long y, long *qp, long *rp){ long q = x/y; long r = x%y; *qp = q; *rp = r; }  汇编代码\n x in %rdi, y in %rsi, qp in %rdx, rp in %rcx remdiv: movq %rdx, %r8 copy qp movq %rdi, %rax mov x to lower 8 bytes of divident cqto idivq %rsi divide by y movq %rax, (%r8) store quotient at qp movq %rdx, (%rcx) store remainder at rp  cqto指令不需要操作数，它隐含读出%rax的符号位，并将它复制到%rdx的所有位\n ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%B1%87%E7%BC%96/%E5%9F%BA%E6%9C%AC%E8%AE%A1%E7%AE%97%E6%8C%87%E4%BB%A4/","summary":"基本计算指令  这里的汇编指令均基于x86-64架构\n 0. 先验知识 0.1 寄存器设置 一个x86-64的中央处理单元包含一组16个64位通用目的寄存器。这些寄存器用来存储整数数据和指针。指令可以对这16个寄存器的低位字节中存放的不同大小的数据进行操作。字节级操作可以访问最低的字节，16位操作可以访问最低的2个字节，32位操作可以访问最低的4个字节，而64位操作可以访问整个寄存器。\n3. 寻址方式 1. 数据传送指令 最简单形式的数据传送指令\u0026ndash;mov类。这些指令把数据从源位置复制到目的位置，不做任何变化。mov类指令由四条指令组成：movb, movw, movl,movq.这些指令都执行相同的操作，区别在于它们操作的数据大小不同：分别是1，2，4，8字节。\n 由于历史原因，Intel处理器将16位作为一个字（w），8位为一个字节(b)，32位为双字(l),64位为4字（q）\n    指令 效果 描述     MOV S D D \u0026lt;- S 传送   movb  传送字节   movw  传送字   movl  传送双字   movq  传送四字   movabsq I, R  传送绝对的四字    传送指令的两个操作数不能都指向内存位置。将一个值从一个内存位置复制到另一个内存位置需要两个步骤，第一个指令将源值加载到寄存器，第二条指令将该寄存器写入目的位置。\nexample\n C code","title":"基本计算指令"},{"content":"处理文本数据 1. 单词和字符的one-hot编码 one-hot编码是将标记转换为向量的最常用，最基本的方法。它将每个单词与一个唯一的整数索引相关联，然后将这个整数索引i转换为长度为N的二进制向量（N是词表大小），这个向量只有第i个元素是1，其余元素都是0.\n当然，也可以进行字符级的one-hot编码。\n1.1. 单词级的one-hot编码 import numpy as np samples = [\u0026#39;The cat sat on the mat.\u0026#39;, \u0026#39;The dog ate my homework.\u0026#39;] token_index = {} for sample in samples: for word in sample.split(): if word not in token_index: token_index[word] = len(token_index) + 1 # 为每个唯一单词指定一个唯一索引，没有为0索引指定单词 max_length = 10 results = np.zeros(shape=(len(samples), max_length, max(token_index.values())+1)) for i, sample in enumerate(samples): for j, word in list(enumerate(sample.split()))[:max_length]: index = token_index.get(word) results[i, j, index] = 1 results array([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]])  1.2. 字符级的one-hot编码 import string samples = [\u0026#39;The cat sat on the mat.\u0026#39;, \u0026#39;The dog ate my homework.\u0026#39;] characters = string.printable # 可打印的所有字符，共101个 token_index = dict(zip(range(1, len(characters) + 1), characters)) max_length = 50 results = np.zeros((len(samples), max_length, max(token_index.keys()) + 1)) for i, sample in enumerate(samples): for j, character in enumerate(sample): index = token_index.get(character) results[i, j, index] = 1 results.shape (2, 50, 101)  1.3. 使用keras的内置函数实现one-hot编码 Keras的内置函数可以对原始文本数据进行单词级或字符级的one-hot编码。我们应该使用这些函数，它们实现了许多重要的特性，比如从字符串中去除特殊字符、只考虑数据集中前N个常见的单词等。\nfrom keras.preprocessing.text import Tokenizer samples = [\u0026#39;The cat sat on the mat.\u0026#39;, \u0026#39;The dog ate my homework.\u0026#39;] tokenizer = Tokenizer(num_words=1000) # 创建一个分词器，只考虑前1000个单词 tokenizer.fit_on_texts(samples) sequences = tokenizer.texts_to_sequences(samples) # 将字符串转化为整数索引构建的列表 one_hot_results = tokenizer.texts_to_matrix(samples, mode=\u0026#39;binary\u0026#39;) word_index = tokenizer.word_index # 找回单词索引 print(\u0026#39;Found %sunique tokens.\u0026#39; % len(word_index)) one_hot_results.shape Found 9 unique tokens. (2, 1000)  1.4. one-hot散列技巧 所谓的one-hot散列技巧是one-hot编码的一种变体，如果词表中唯一标记的数量太大而无法直接处理，就可以使用这种技巧。这种方法没有为每个单词显式分配一个索引并将这些索引保存在一个字典中，而是将单词散列编码为固定长度的向量，通常用一个非常简单的散列函数来实现。这种方法的主要优点在于，它避免了维护一个显式的单词索引，从而节省内存并允许数据的在线编码（在读取完所有数据之前，你就可以立刻生成标记向量）。\n这种方法有个缺点，就是可能会出现散列冲突，即两个不同的单词可能具有相同的散列值，随后任何机器学习模型观察这些散列值，都无法区分它们对应的单词。如果散列空间的维度远大于需要散列的唯一标记的个数，散列冲突的可能性会减小。\n# 使用散列技巧的单词级的one-hot编码 samples = [\u0026#39;The cat sat on the mat.\u0026#39;, \u0026#39;The dog ate my homework.\u0026#39;] dimensionality = 1000 max_length = 10 results = np.zeros((len(samples), max_length, dimensionality)) for i, sample in enumerate(samples): for j, word in list(enumerate(sample.split()))[:max_length]: index = abs(hash(word)) % dimensionality # 将单词散列为0-1000范围内的一个随机整数索引。 results[i, j, index] = 1 results.shape (2, 10, 1000)  2. 使用词嵌入 密集的词向量，也叫词嵌入。one-hot编码得到的向量是二进制的、稀疏的（绝大部分元素都是0）维度很高的（维度大小等于词表中的单词个数），而词嵌入是低维的浮点数向量（即密集向量、与稀疏向量相对）。与one-hot编码得到的词向量不同，词嵌入是从数据中学习得到的。常见的词向量维度是256， 512或1024（处理非常大的词表时）。于此相对，one-hot编码的词向量维度通常为20000或更高（对应包含20000个标记的词表），因此词向量可以将更多的信息塞入更低的维度中\n获取词嵌入有两种方法:\n 在完成主任务（比如文档分类或情感预测）的同时学习词嵌入。在这种情况下，一开始是随机的词向量，然后对这些词向量进行学习，其学习方式与学习神经网络的权重相同。 在不同于待解决问题的机器学习任务上预计算好词嵌入，然后将其加载到模型中。这些词嵌入叫做预训练词嵌入  2.1. 利用Embedding层学习词嵌入 要将一个词与一个密集向量相关联，最简单的方法就是随机选择向量。这种方法的问题在于，得到的嵌入空间没有任何结构。说的更抽象一点，词向量之间的几何关系应该表示这些词之间的语义关系。词嵌入的作用应该是将人类的语言映射到几何空间中。例如，在一个合理的嵌入空间中，同义词应该被嵌入到相似的词向量中，一般来说，任意两个词向量之间的几何距离（比如L2距离）应该和这两个词的语义距离有关。.\n一个好的词嵌入空间在很大程度上取决于你的任务，某些语义关系的重要性因任务而异。因此，合理的做法是对每个新任务都学习一个新的嵌入空间。\n# 将一个Embedding 层实例化 from keras.layers import Embedding embedding_layer = Embedding(1000, 64) #(标记的个数， 嵌入的维度) 可以将Embedding层理解为一个字典，将整数索引（表示特定单词）映射为密集向量。它接收整数作为输入，并在内部字典中查找这些整数，然后返回相关联的向量。Embedding实际上是一种字典查找。\n# 加载IMDB数据，准备用于Embedding层 from keras.datasets import imdb from keras import preprocessing max_features = 10000 #作为特征的单词个数 maxlen = 20 # 这么多单词后截断文本 # 将数据加载为整数列表 (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features) x_train[0:2] array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]), list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])], dtype=object)  #将整数列表转换成形状为（samples, maxlen）的二维整数张量 x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen) x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen) x_train[0:2] array([[ 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32], [ 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]], dtype=int32)  y_train.shape (25000,)  # 在IMDB数据集上使用Embedding层和分类器 from keras.models import Sequential from keras.layers import Flatten, Dense, Embedding model = Sequential() model.add(Embedding(10000, 8, input_length=maxlen)) model.add(Flatten()) model.add(Dense(1, activation=\u0026#39;sigmoid\u0026#39;)) model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;acc\u0026#39;]) model.summary() history = model.fit(x_train, y_train, epochs=10, batch_size=32, validation_split=0.2) Model: \u0026quot;sequential_2\u0026quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_3 (Embedding) (None, 20, 8) 80000 _________________________________________________________________ flatten_2 (Flatten) (None, 160) 0 _________________________________________________________________ dense_1 (Dense) (None, 1) 161 ================================================================= Total params: 80,161 Trainable params: 80,161 Non-trainable params: 0 _________________________________________________________________ /usr/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. \u0026quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. \u0026quot; Train on 20000 samples, validate on 5000 samples Epoch 1/10 20000/20000 [==============================] - 3s 146us/step - loss: 0.6799 - acc: 0.5913 - val_loss: 0.6468 - val_acc: 0.6846 Epoch 2/10 20000/20000 [==============================] - 2s 103us/step - loss: 0.5643 - acc: 0.7456 - val_loss: 0.5399 - val_acc: 0.7220 Epoch 3/10 20000/20000 [==============================] - 2s 97us/step - loss: 0.4697 - acc: 0.7858 - val_loss: 0.5068 - val_acc: 0.7436 Epoch 4/10 20000/20000 [==============================] - 2s 100us/step - loss: 0.4239 - acc: 0.8084 - val_loss: 0.4975 - val_acc: 0.7500 Epoch 5/10 20000/20000 [==============================] - 2s 98us/step - loss: 0.3931 - acc: 0.8238 - val_loss: 0.4984 - val_acc: 0.7560 Epoch 6/10 20000/20000 [==============================] - 2s 97us/step - loss: 0.3684 - acc: 0.8400 - val_loss: 0.4990 - val_acc: 0.7558 Epoch 7/10 20000/20000 [==============================] - 2s 115us/step - loss: 0.3462 - acc: 0.8519 - val_loss: 0.5049 - val_acc: 0.7554 Epoch 8/10 20000/20000 [==============================] - 2s 97us/step - loss: 0.3268 - acc: 0.8640 - val_loss: 0.5121 - val_acc: 0.7556 Epoch 9/10 20000/20000 [==============================] - 2s 98us/step - loss: 0.3082 - acc: 0.8734 - val_loss: 0.5203 - val_acc: 0.7528 Epoch 10/10 20000/20000 [==============================] - 2s 102us/step - loss: 0.2905 - acc: 0.8841 - val_loss: 0.5298 - val_acc: 0.7506  2.2. 使用预训练的词嵌入 ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/%E5%A4%84%E7%90%86%E6%96%87%E6%9C%AC%E6%95%B0%E6%8D%AE/","summary":"处理文本数据 1. 单词和字符的one-hot编码 one-hot编码是将标记转换为向量的最常用，最基本的方法。它将每个单词与一个唯一的整数索引相关联，然后将这个整数索引i转换为长度为N的二进制向量（N是词表大小），这个向量只有第i个元素是1，其余元素都是0.\n当然，也可以进行字符级的one-hot编码。\n1.1. 单词级的one-hot编码 import numpy as np samples = [\u0026#39;The cat sat on the mat.\u0026#39;, \u0026#39;The dog ate my homework.\u0026#39;] token_index = {} for sample in samples: for word in sample.split(): if word not in token_index: token_index[word] = len(token_index) + 1 # 为每个唯一单词指定一个唯一索引，没有为0索引指定单词 max_length = 10 results = np.zeros(shape=(len(samples), max_length, max(token_index.values())+1)) for i, sample in enumerate(samples): for j, word in list(enumerate(sample.split()))[:max_length]: index = token_index.get(word) results[i, j, index] = 1 results array([[[0.","title":"处理文本数据"},{"content":"多输入模型 函数式API可以用于构建具有多个输入的模型，通常情况下，这种模型会在某一时刻用一个可以组合多个张量的层将不同的输入分支合并，张量组合方式可能是相加，连接等。这通常利用Keras的合并运算来实现，比如keras.layers.add, keras.layers.concatenate等。\n下面来看一个非常简单的多输入模型示例：一个问答模型\n典型的问答模型有两个输入，一个自然语言描述的问题和一个文本片段（比如新闻文章），后者提供用于回答问题的信息。然后模型要生成一个回答，在最简单的情况下，这个回答只包含一个词，可以通过对某个预定义的词表做softmax得到。\n# 具有两个输入的模型 from keras.models import Model from keras import layers from keras import Input text_vocabulary_size = 10000 question_vocabulary_size = 10000 answer_vocabulary_size = 500 text_input = Input(shape=(None, ), dtype=\u0026#39;int32\u0026#39;, name=\u0026#39;text\u0026#39;) embedded_text = layers.Embedding( text_vocabulary_size, 64) (text_input) # 将输入嵌入到长度为64的向量 encoded_text = layers.LSTM(32)(embedded_text) # 对问题进行相同的处理，使用不同的层实例 question_input = Input(shape=(None, ), dtype=\u0026#39;int32\u0026#39;, name=\u0026#39;question\u0026#39;) embedded_question = layers.Embedding( question_vocabulary_size, 32)(question_input) encoded_question = layers.LSTM(16)(embedded_question) # 将编码后的问题和文本连接起来 concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1) # 在上面添加一个softmax分类器 answer = layers.Dense(answer_vocabulary_size, activation=\u0026#39;softmax\u0026#39;)(concatenated) model = Model([text_input, question_input], answer) model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;categorical_crossentropy\u0026#39;, metrics=[\u0026#39;acc\u0026#39;]) Using TensorFlow backend. /usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint8 = np.dtype([(\u0026quot;qint8\u0026quot;, np.int8, 1)]) /usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_quint8 = np.dtype([(\u0026quot;quint8\u0026quot;, np.uint8, 1)]) /usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint16 = np.dtype([(\u0026quot;qint16\u0026quot;, np.int16, 1)]) /usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_quint16 = np.dtype([(\u0026quot;quint16\u0026quot;, np.uint16, 1)]) /usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. _np_qint32 = np.dtype([(\u0026quot;qint32\u0026quot;, np.int32, 1)]) /usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'. np_resource = np.dtype([(\u0026quot;resource\u0026quot;, np.ubyte, 1)])  ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/%E5%A4%9A%E8%BE%93%E5%85%A5%E6%A8%A1%E5%9E%8B/","summary":"多输入模型 函数式API可以用于构建具有多个输入的模型，通常情况下，这种模型会在某一时刻用一个可以组合多个张量的层将不同的输入分支合并，张量组合方式可能是相加，连接等。这通常利用Keras的合并运算来实现，比如keras.layers.add, keras.layers.concatenate等。\n下面来看一个非常简单的多输入模型示例：一个问答模型\n典型的问答模型有两个输入，一个自然语言描述的问题和一个文本片段（比如新闻文章），后者提供用于回答问题的信息。然后模型要生成一个回答，在最简单的情况下，这个回答只包含一个词，可以通过对某个预定义的词表做softmax得到。\n# 具有两个输入的模型 from keras.models import Model from keras import layers from keras import Input text_vocabulary_size = 10000 question_vocabulary_size = 10000 answer_vocabulary_size = 500 text_input = Input(shape=(None, ), dtype=\u0026#39;int32\u0026#39;, name=\u0026#39;text\u0026#39;) embedded_text = layers.Embedding( text_vocabulary_size, 64) (text_input) # 将输入嵌入到长度为64的向量 encoded_text = layers.LSTM(32)(embedded_text) # 对问题进行相同的处理，使用不同的层实例 question_input = Input(shape=(None, ), dtype=\u0026#39;int32\u0026#39;, name=\u0026#39;question\u0026#39;) embedded_question = layers.Embedding( question_vocabulary_size, 32)(question_input) encoded_question = layers.LSTM(16)(embedded_question) # 将编码后的问题和文本连接起来 concatenated = layers.concatenate([encoded_text, encoded_question], axis=-1) # 在上面添加一个softmax分类器 answer = layers.","title":"多输入模型"},{"content":"如何在manjaro中安装MySQL # 安装MySQL pacman -S mysql # 初始化MySQL，记住输出的root密码 mysqld --initialize --user=mysql --basedir=/usr --datadir=/var/lib/mysql # 设置开机启动MySQL服务 systemctl enable mysqld.service systemctl daemon-reload systemctl start mysqld.service # 使用MySQL前必须修改root密码，MySQL 8.0.15不能使用set password修改密码 mysql -u root -p mysql\u0026gt; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;新密码\u0026#39;; ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/manjaro%E5%AE%89%E8%A3%85mysql/","summary":"如何在manjaro中安装MySQL # 安装MySQL pacman -S mysql # 初始化MySQL，记住输出的root密码 mysqld --initialize --user=mysql --basedir=/usr --datadir=/var/lib/mysql # 设置开机启动MySQL服务 systemctl enable mysqld.service systemctl daemon-reload systemctl start mysqld.service # 使用MySQL前必须修改root密码，MySQL 8.0.15不能使用set password修改密码 mysql -u root -p mysql\u0026gt; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;新密码\u0026#39;; ","title":"如何在manjaro中安装MySQL"},{"content":"安装docker-compose  下载最新版本的docker-compose  sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 对二进制文件应用可执行权限  sudo chmod +x /usr/local/bin/docker-compose 测试安装完成  docker-compose --version ","permalink":"http://yangchnet.github.io/Dessert/posts/%E4%BA%91%E8%AE%A1%E7%AE%97%E4%B8%8E%E5%AE%B9%E5%99%A8/%E5%AE%89%E8%A3%85docker-compose/","summary":"安装docker-compose  下载最新版本的docker-compose  sudo curl -L \u0026#34;https://github.com/docker/compose/releases/download/1.23.2/docker-compose-$(uname -s)-$(uname -m)\u0026#34; -o /usr/local/bin/docker-compose 对二进制文件应用可执行权限  sudo chmod +x /usr/local/bin/docker-compose 测试安装完成  docker-compose --version ","title":"安装docker-compose"},{"content":"安装完virtualbox后，提示内核问题 解决方法 安装内核匹配版本 sudo pacman -S linux419-virtualbox-host-modules\n重新加载内核模块 sudo /sbin/rcvboxdrv 然后重启即可\n","permalink":"http://yangchnet.github.io/Dessert/posts/linux/virtualbox%E7%9A%84%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98/","summary":"安装完virtualbox后，提示内核问题 解决方法 安装内核匹配版本 sudo pacman -S linux419-virtualbox-host-modules\n重新加载内核模块 sudo /sbin/rcvboxdrv 然后重启即可","title":"安装完virtualbox后，提示内核问题"},{"content":"快速入门Matplotlib教程 介绍 Matplotlib 可能是 Python 2D-绘图领域使用最广泛的套件。它能让使用者很轻松地将数据图形化，并且提供多样化的输出格式。\npylab pylab 是 matplotlib 面向对象绘图库的一个接口。它的语法和 Matlab 十分相近。也就是说，它主要的绘图命令和 Matlab 对应的命令有相似的参数。\n初级绘制 这一节中，我们将从简到繁：先尝试用默认配置在同一张图上绘制正弦和余弦函数图像，然后逐步美化它。\n第一步，是取得正弦函数和余弦函数的值：\nimport numpy as np X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) X 是一个 numpy 数组，包含了从 −π−π 到 +π+π 等间隔的 256 个值。C和 S 则分别是这 256 个值对应的余弦和正弦函数值组成的 numpy 数组。\nnp.linspace\n使用默认配置 Matplotlib 的默认配置都允许用户自定义。你可以调整大多数的默认配置：图片大小和分辨率（dpi）、线宽、颜色、风格、坐标轴、坐标轴以及网格的属性、文字与字体属性等。不过，matplotlib 的默认配置在大多数情况下已经做得足够好，你可能只在很少的情况下才会想更改这些默认配置。\nplot函数详解\nfrom pylab import * plot(X,C) plot(X,S) show() \u0026lt;Figure size 640x480 with 1 Axes\u0026gt;  默认配置的具体内容 下面的代码中，我们展现了 matplotlib 的默认配置并辅以注释说明，这部分配置包含了有关绘图样式的所有配置。代码中的配置与默认配置完全相同，你可以在交互模式中修改其中的值来观察效果。\n# 导入 matplotlib 的所有内容（nympy 可以用 np 这个名字来使用） from pylab import * # 创建一个 8 * 6 点（point）的图，并设置分辨率为 80 figure(figsize=(8,6), dpi=80) # 创建一个新的 1 * 1 的子图，接下来的图样绘制在其中的第 1 块（也是唯一的一块） subplot(1,1,1) X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) # 绘制余弦曲线，使用蓝色的、连续的、宽度为 1 （像素）的线条 plot(X, C, color=\u0026#34;blue\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) # 绘制正弦曲线，使用绿色的、连续的、宽度为 1 （像素）的线条 plot(X, S, color=\u0026#34;green\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) # 设置横轴的上下限 xlim(-4.0,4.0) # 设置横轴记号 xticks(np.linspace(-4,4,9,endpoint=True)) # 设置纵轴的上下限 ylim(-1.0,1.0) # 设置纵轴记号 yticks(np.linspace(-1,1,5,endpoint=True)) # 以分辨率 72 来保存图片 # savefig(\u0026#34;exercice_2.png\u0026#34;,dpi=72) # 在屏幕上显示 show() \u0026lt;Figure size 640x480 with 1 Axes\u0026gt;  改变线条的颜色和粗细 figure(figsize=(10,6), dpi=80) plot(X, C, color=\u0026#34;blue\u0026#34;, linewidth=10, linestyle=\u0026#34;-\u0026#34;) plot(X, S, color=\u0026#34;red\u0026#34;, linewidth=2.5, linestyle=\u0026#34;-\u0026#34;) [\u0026lt;matplotlib.lines.Line2D at 0x7f6c66774470\u0026gt;]  设置图片边界 当前的图片边界设置得不好，所以有些地方看得不是很清楚。\nfrom pylab import * figure(figsize=(8,6), dpi=80) subplot(1,1,1) X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plot(X, C, color=\u0026#34;blue\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) plot(X, S, color=\u0026#34;green\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) xticks(np.linspace(-4,4,9,endpoint=True)) xlim(X.min()*1.1, X.max()*1.1) # 此处发生改变 ylim(C.min()*1.1, C.max()*1.1) # 此处发生改变 yticks(np.linspace(-1,1,5,endpoint=True)) show() 设置记号 我们讨论正弦和余弦函数的时候，通常希望知道函数在 $±π±π$ 和 $±π/2±π/2$ 的值。这样看来，当前的设置就不那么理想了。\nfrom pylab import * figure(figsize=(8,6), dpi=80) subplot(1,1,1) X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plot(X, C, color=\u0026#34;blue\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) plot(X, S, color=\u0026#34;green\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) xlim(X.min()*1.1, X.max()*1.1) ylim(C.min()*1.1, C.max()*1.1) xticks( [-np.pi, -np.pi/2, 0, np.pi/2, np.pi]) # 此处发生改变 yticks([-1, 0, +1]) # 此处发生改变 show() 设置记号的标签 记号现在没问题了，不过标签却不大符合期望。我们可以把 3.142 当做是 $π$，但毕竟不够精确。当我们设置记号的时候，我们可以同时设置记号的标签。注意这里使用了 LaTeX。(以后会讲LaTeX)\nfrom pylab import * figure(figsize=(8,6), dpi=80) subplot(1,1,1) X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plot(X, C, color=\u0026#34;blue\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) plot(X, S, color=\u0026#34;green\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) xlim(X.min()*1.1, X.max()*1.1) ylim(C.min()*1.1, C.max()*1.1) plt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi],[r\u0026#39;$-\\pi$\u0026#39;, r\u0026#39;$-\\pi/2$\u0026#39;, r\u0026#39;$0$\u0026#39;, r\u0026#39;$+\\pi/2$\u0026#39;, r\u0026#39;$+\\pi$\u0026#39;]) # 此处发生改变 plt.yticks([-1, 0, +1],[r\u0026#39;$-1$\u0026#39;, r\u0026#39;$0$\u0026#39;, r\u0026#39;$+1$\u0026#39;]) # 此处发生改变 show() 移动脊柱 坐标轴线和上面的记号连在一起就形成了脊柱（Spines，一条线段上有一系列的凸起，是不是很像脊柱骨啊~），它记录了数据区域的范围。它们可以放在任意位置，不过至今为止，我们都把它放在图的四边。\n实际上每幅图有四条脊柱（上下左右），为了将脊柱放在图的中间，我们必须将其中的两条（上和右）设置为无色，然后调整剩下的两条到合适的位置——数据空间的 0 点。\nfrom pylab import * figure(figsize=(8,6), dpi=80) subplot(1,1,1) X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plot(X, C, color=\u0026#34;blue\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) plot(X, S, color=\u0026#34;green\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) xlim(X.min()*1.1, X.max()*1.1) plt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi],[r\u0026#39;$-\\pi$\u0026#39;, r\u0026#39;$-\\pi/2$\u0026#39;, r\u0026#39;$0$\u0026#39;, r\u0026#39;$+\\pi/2$\u0026#39;, r\u0026#39;$+\\pi$\u0026#39;]) ylim(C.min()*1.1, C.max()*1.1) plt.yticks([-1, 0, +1],[r\u0026#39;$-1$\u0026#39;, r\u0026#39;$0$\u0026#39;, r\u0026#39;$+1$\u0026#39;]) # 移动脊柱 ax = plt.gca() ax.spines[\u0026#39;right\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.spines[\u0026#39;top\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.xaxis.set_ticks_position(\u0026#39;bottom\u0026#39;) ax.spines[\u0026#39;bottom\u0026#39;].set_position((\u0026#39;data\u0026#39;,0)) ax.yaxis.set_ticks_position(\u0026#39;left\u0026#39;) ax.spines[\u0026#39;left\u0026#39;].set_position((\u0026#39;data\u0026#39;,0)) show() 添加图例 我们在图的左上角添加一个图例。为此，我们只需要在 plot 函数里以「键 - 值」的形式增加一个参数。\nfrom pylab import * figure(figsize=(8,6), dpi=80) subplot(1,1,1) X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) plot(X, C, color=\u0026#34;blue\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) plot(X, S, color=\u0026#34;green\u0026#34;, linewidth=1.0, linestyle=\u0026#34;-\u0026#34;) xlim(X.min()*1.1, X.max()*1.1) plt.xticks([-np.pi, -np.pi/2, 0, np.pi/2, np.pi],[r\u0026#39;$-\\pi$\u0026#39;, r\u0026#39;$-\\pi/2$\u0026#39;, r\u0026#39;$0$\u0026#39;, r\u0026#39;$+\\pi/2$\u0026#39;, r\u0026#39;$+\\pi$\u0026#39;]) ylim(C.min()*1.1, C.max()*1.1) plt.yticks([-1, 0, +1],[r\u0026#39;$-1$\u0026#39;, r\u0026#39;$0$\u0026#39;, r\u0026#39;$+1$\u0026#39;]) # 移动脊柱 ax = plt.gca() ax.spines[\u0026#39;right\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.spines[\u0026#39;top\u0026#39;].set_color(\u0026#39;none\u0026#39;) ax.xaxis.set_ticks_position(\u0026#39;bottom\u0026#39;) ax.spines[\u0026#39;bottom\u0026#39;].set_position((\u0026#39;data\u0026#39;,0)) ax.yaxis.set_ticks_position(\u0026#39;left\u0026#39;) ax.spines[\u0026#39;left\u0026#39;].set_position((\u0026#39;data\u0026#39;,0)) # 增加图例 plt.plot(X, C, color=\u0026#34;blue\u0026#34;, linewidth=2.5, linestyle=\u0026#34;-\u0026#34;, label=\u0026#34;cosine\u0026#34;) plt.plot(X, S, color=\u0026#34;red\u0026#34;, linewidth=2.5, linestyle=\u0026#34;-\u0026#34;, label=\u0026#34;sine\u0026#34;) plt.legend(loc=\u0026#39;upper left\u0026#39;, frameon=False) show() 其他类型的图 普通图 import numpy as np import matplotlib.pyplot as plt n = 256 X = np.linspace(-np.pi,np.pi,n,endpoint=True) Y = np.sin(2*X) plt.axes([0.025,0.025,0.95,0.95]) plt.plot (X, Y+1, color=\u0026#39;blue\u0026#39;, alpha=1.00) plt.fill_between(X, 1, Y+1, color=\u0026#39;blue\u0026#39;, alpha=.25) plt.plot (X, Y-1, color=\u0026#39;blue\u0026#39;, alpha=1.00) plt.fill_between(X, -1, Y-1, (Y-1) \u0026gt; -1, color=\u0026#39;blue\u0026#39;, alpha=.25) plt.fill_between(X, -1, Y-1, (Y-1) \u0026lt; -1, color=\u0026#39;red\u0026#39;, alpha=.25) plt.xlim(-np.pi,np.pi), plt.xticks([]) plt.ylim(-2.5,2.5), plt.yticks([]) # savefig(\u0026#39;../figures/plot_ex.png\u0026#39;,dpi=48) plt.show() 散点图 import numpy as np import matplotlib.pyplot as plt n = 1024 X = np.random.normal(0,1,n) Y = np.random.normal(0,1,n) T = np.arctan2(Y,X) plt.axes([0.025,0.025,0.95,0.95]) plt.scatter(X,Y, s=75, c=T, alpha=.5) plt.xlim(-1.5,1.5), plt.xticks([]) plt.ylim(-1.5,1.5), plt.yticks([]) # savefig(\u0026#39;../figures/scatter_ex.png\u0026#39;,dpi=48) plt.show() 条形图 import numpy as np import matplotlib.pyplot as plt n = 12 X = np.arange(n) Y1 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) Y2 = (1-X/float(n)) * np.random.uniform(0.5,1.0,n) plt.axes([0.025,0.025,0.95,0.95]) plt.bar(X, +Y1, facecolor=\u0026#39;#9999ff\u0026#39;, edgecolor=\u0026#39;white\u0026#39;) plt.bar(X, -Y2, facecolor=\u0026#39;#ff9999\u0026#39;, edgecolor=\u0026#39;white\u0026#39;) for x,y in zip(X,Y1): plt.text(x+0.4, y+0.05, \u0026#39;%.2f\u0026#39; % y, ha=\u0026#39;center\u0026#39;, va= \u0026#39;bottom\u0026#39;) for x,y in zip(X,Y2): plt.text(x+0.4, -y-0.05, \u0026#39;%.2f\u0026#39; % y, ha=\u0026#39;center\u0026#39;, va= \u0026#39;top\u0026#39;) plt.xlim(-.5,n), plt.xticks([]) plt.ylim(-1.25,+1.25), plt.yticks([]) # savefig(\u0026#39;../figures/bar_ex.png\u0026#39;, dpi=48) plt.show() 等高线图 import numpy as np import matplotlib.pyplot as plt def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 256 x = np.linspace(-3,3,n) y = np.linspace(-3,3,n) X,Y = np.meshgrid(x,y) plt.axes([0.025,0.025,0.95,0.95]) plt.contourf(X, Y, f(X,Y), 8, alpha=.75, cmap=plt.cm.hot) C = plt.contour(X, Y, f(X,Y), 8, colors=\u0026#39;black\u0026#39;, linewidth=.5) plt.clabel(C, inline=1, fontsize=10) plt.xticks([]), plt.yticks([]) # savefig(\u0026#39;../figures/contour_ex.png\u0026#39;,dpi=48) plt.show() /usr/lib/python3.7/site-packages/matplotlib/contour.py:1000: UserWarning: The following kwargs were not used by contour: 'linewidth' s)  灰度图 import numpy as np import matplotlib.pyplot as plt def f(x,y): return (1-x/2+x**5+y**3)*np.exp(-x**2-y**2) n = 10 x = np.linspace(-3,3,3.5*n) y = np.linspace(-3,3,3.0*n) X,Y = np.meshgrid(x,y) Z = f(X,Y) plt.axes([0.025,0.025,0.95,0.95]) plt.imshow(Z,interpolation=\u0026#39;bicubic\u0026#39;, cmap=\u0026#39;bone\u0026#39;, origin=\u0026#39;lower\u0026#39;) plt.colorbar(shrink=.92) plt.xticks([]), plt.yticks([]) # savefig(\u0026#39;../figures/imshow_ex.png\u0026#39;, dpi=48) plt.show() /usr/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: object of type \u0026lt;class 'float'\u0026gt; cannot be safely interpreted as an integer. /usr/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: object of type \u0026lt;class 'float'\u0026gt; cannot be safely interpreted as an integer. if __name__ == '__main__':  饼状图 import numpy as np import matplotlib.pyplot as plt n = 20 Z = np.ones(n) Z[-1] *= 2 plt.axes([0.025, 0.025, 0.95, 0.95]) plt.pie(Z, explode=Z*.05, colors=[\u0026#39;%f\u0026#39; % (i/float(n)) for i in range(n)], wedgeprops={\u0026#34;linewidth\u0026#34;: 1, \u0026#34;edgecolor\u0026#34;: \u0026#34;black\u0026#34;}) plt.gca().set_aspect(\u0026#39;equal\u0026#39;) plt.xticks([]), plt.yticks([]) # savefig(\u0026#39;../figures/pie_ex.png\u0026#39;,dpi=48) plt.show() 极轴图 import numpy as np import matplotlib.pyplot as plt ax = plt.axes([0.025,0.025,0.95,0.95], polar=True) N = 20 theta = np.arange(0.0, 2*np.pi, 2*np.pi/N) radii = 10*np.random.rand(N) width = np.pi/4*np.random.rand(N) bars = plt.bar(theta, radii, width=width, bottom=0.0) for r,bar in zip(radii, bars): bar.set_facecolor( plt.cm.jet(r/10.)) bar.set_alpha(0.5) ax.set_xticklabels([]) ax.set_yticklabels([]) # savefig(\u0026#39;../figures/polar_ex.png\u0026#39;,dpi=48) plt.show() 3D图 import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D fig = plt.figure() ax = Axes3D(fig) X = np.arange(-4, 4, 0.25) Y = np.arange(-4, 4, 0.25) X, Y = np.meshgrid(X, Y) R = np.sqrt(X**2 + Y**2) Z = np.sin(R) ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=plt.cm.hot) ax.contourf(X, Y, Z, zdir=\u0026#39;z\u0026#39;, offset=-2, cmap=plt.cm.hot) ax.set_zlim(-2,2) # savefig(\u0026#39;../figures/plot3d_ex.png\u0026#39;,dpi=48) plt.show() 作业 熟悉以上画图方法，从其官方文档中了解“子图”的概念，将[散点图， 条形图， 等高线图， 灰度图， 饼状图， 极轴图， 3D图]放在一张$3*2$的子图中\n附：参考资料  matplotlib官方文档 matplotlib中文文档 matplotlib官方教程 详解图像各个部分 matplotlib  np.linspace numpy.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)\n在指定的间隔内返回均匀间隔的数字。\n返回num均匀分布的样本，在[start, stop]。\n这个区间的端点可以任意的被排除在外。\n 参数：   start ： array_like\n序列的起始值。\n  stop ： array_like 序列的结束值，除非端点设置为False。在这种情况下，序列由除 均匀间隔的样本之外的所有样本组成，因此不包括停止。请注意，当端点为False 时，步长会发生变化。num + 1\n  num ： int，可选 要生成的样本数。默认值为50.必须为非负数。\n  endpoint ： bool，可选 如果为True，则stop是最后一个样本。否则，它不包括在内。默认为True。\n  retstep ： bool，可选 如果为True，则返回（samples，step），其中step是样本之间的间距。\n  dtype ： dtype，可选 输出数组的类型。如果dtype未给出，则从其他输入参数推断数据类型。\n   返回   samples : ndarray 有NUM同样在闭区间隔开的样品 或半开间隔 （取决于是否端点是真或假）。[start, stop][start, stop)\n  step : float, optional 仅在retstep为True 时才返回样本之间的间距大小。\n    返回初级配置\n","permalink":"http://yangchnet.github.io/Dessert/posts/python/matplotlib%E5%88%9D%E7%BA%A7%E6%95%99%E7%A8%8B/","summary":"快速入门Matplotlib教程 介绍 Matplotlib 可能是 Python 2D-绘图领域使用最广泛的套件。它能让使用者很轻松地将数据图形化，并且提供多样化的输出格式。\npylab pylab 是 matplotlib 面向对象绘图库的一个接口。它的语法和 Matlab 十分相近。也就是说，它主要的绘图命令和 Matlab 对应的命令有相似的参数。\n初级绘制 这一节中，我们将从简到繁：先尝试用默认配置在同一张图上绘制正弦和余弦函数图像，然后逐步美化它。\n第一步，是取得正弦函数和余弦函数的值：\nimport numpy as np X = np.linspace(-np.pi, np.pi, 256,endpoint=True) C,S = np.cos(X), np.sin(X) X 是一个 numpy 数组，包含了从 −π−π 到 +π+π 等间隔的 256 个值。C和 S 则分别是这 256 个值对应的余弦和正弦函数值组成的 numpy 数组。\nnp.linspace\n使用默认配置 Matplotlib 的默认配置都允许用户自定义。你可以调整大多数的默认配置：图片大小和分辨率（dpi）、线宽、颜色、风格、坐标轴、坐标轴以及网格的属性、文字与字体属性等。不过，matplotlib 的默认配置在大多数情况下已经做得足够好，你可能只在很少的情况下才会想更改这些默认配置。\nplot函数详解\nfrom pylab import * plot(X,C) plot(X,S) show() \u0026lt;Figure size 640x480 with 1 Axes\u0026gt;  默认配置的具体内容 下面的代码中，我们展现了 matplotlib 的默认配置并辅以注释说明，这部分配置包含了有关绘图样式的所有配置。代码中的配置与默认配置完全相同，你可以在交互模式中修改其中的值来观察效果。","title":"快速入门Matplotlib教程"},{"content":"怎样从本地现有代码新建一个库  在本地代码目录初始化git  git init 然后将代码添加到仓库中  git add . #这里是添加了当前目录所有的文件 提交代码到本地库中  git commit -m \u0026#34;这里是提交的注释\u0026#34;  接下来我们需要在github上新建一个库，比如说新库的名字为hello\n  将本地的仓库关联到github上\n  git remote add origin https://github.com/yourname/hello 上传之前，先要拉取远程的相关信息  git pull origin master 最后上传  git push -u origin master 遇到的问题  来自 https://github.com/yangchnet/Mygolang * branch master -\u0026gt; FETCH_HEAD fatal: 拒绝合并无关的历史\n 解决方案 首先将远程仓库和本地仓库关联起来：\ngit branch --set-upstream-to=origin/master master 然后使用git pull整合远程仓库和本地仓库，\ngit pull --allow-unrelated-histories (忽略版本不同造成的影响) ","permalink":"http://yangchnet.github.io/Dessert/posts/git/%E6%96%B0%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%BA%93/","summary":"怎样从本地现有代码新建一个库  在本地代码目录初始化git  git init 然后将代码添加到仓库中  git add . #这里是添加了当前目录所有的文件 提交代码到本地库中  git commit -m \u0026#34;这里是提交的注释\u0026#34;  接下来我们需要在github上新建一个库，比如说新库的名字为hello\n  将本地的仓库关联到github上\n  git remote add origin https://github.com/yourname/hello 上传之前，先要拉取远程的相关信息  git pull origin master 最后上传  git push -u origin master 遇到的问题  来自 https://github.com/yangchnet/Mygolang * branch master -\u0026gt; FETCH_HEAD fatal: 拒绝合并无关的历史\n 解决方案 首先将远程仓库和本地仓库关联起来：\ngit branch --set-upstream-to=origin/master master 然后使用git pull整合远程仓库和本地仓库，\ngit pull --allow-unrelated-histories (忽略版本不同造成的影响) ","title":"怎样从本地现有代码新建一个库"},{"content":"数据库中的视图 1. 什么是数据库视图 数据库视图的创建是基于SQL SELECT query和JOIN的。视图和表很相似，它也包含行和列，所以可以直接对它进行查询操作。另外大多数的数据库同样允许进行UPADTE操作，但必须满足一定的条件。视图的数据结构如图：\n数据库并没有存储视图这个关系,存储的只是一个查询定义\n2. 数据库视图可以干什么   视图可以简化复杂查询\n视图的定义是基于一个查询声明，这个查询声明可能关联了很多底层表。可以使用视图向数据库的使用者或者外部程序隐藏复杂的底层表关系。\n  视图可以限制特定用户的数据访问权\n有时希望对一些特定用户隐藏某些表的某些数据，这时视图可以很好的实现这个功能。\n  视图可以使用可计算的列\n表的列一般都不支持动态计算，但是视图的列是支持的。假设在有一张order_details表，其中包含product_nums和price_each两列，当需要查询order总价时就需要查询出结果后在代码中进行计算，如果使用视图的话可以在视图中添加一列total_price(product_nums*price_each)。这样就可以直接查询出order的总价。\n  视图可以帮助兼容旧的系统\n假设一个数据中心，这个数据中心被很多的程序在使用。如果有一天决定重新设计这个数据中心以适应一些新的业务需求，可能需要删除一些旧的表，并且创建一些新的表，但又不希望这些变动影响到那些老的程序。那么这时可以创建一些视图用来适配那些老的程序。\n  3. 如何定义数据库视图 ","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/%E8%A7%86%E5%9B%BE/","summary":"数据库中的视图 1. 什么是数据库视图 数据库视图的创建是基于SQL SELECT query和JOIN的。视图和表很相似，它也包含行和列，所以可以直接对它进行查询操作。另外大多数的数据库同样允许进行UPADTE操作，但必须满足一定的条件。视图的数据结构如图：\n数据库并没有存储视图这个关系,存储的只是一个查询定义\n2. 数据库视图可以干什么   视图可以简化复杂查询\n视图的定义是基于一个查询声明，这个查询声明可能关联了很多底层表。可以使用视图向数据库的使用者或者外部程序隐藏复杂的底层表关系。\n  视图可以限制特定用户的数据访问权\n有时希望对一些特定用户隐藏某些表的某些数据，这时视图可以很好的实现这个功能。\n  视图可以使用可计算的列\n表的列一般都不支持动态计算，但是视图的列是支持的。假设在有一张order_details表，其中包含product_nums和price_each两列，当需要查询order总价时就需要查询出结果后在代码中进行计算，如果使用视图的话可以在视图中添加一列total_price(product_nums*price_each)。这样就可以直接查询出order的总价。\n  视图可以帮助兼容旧的系统\n假设一个数据中心，这个数据中心被很多的程序在使用。如果有一天决定重新设计这个数据中心以适应一些新的业务需求，可能需要删除一些旧的表，并且创建一些新的表，但又不希望这些变动影响到那些老的程序。那么这时可以创建一些视图用来适配那些老的程序。\n  3. 如何定义数据库视图 ","title":"数据库中的视图"},{"content":"数据库表结构说明 \u0026amp;\u0026amp; 远程访问说明  code by lichang\n 数据库表结构说明 数据库名为django_mysql\n1.用户  所有和用户有关的数据\n 1.1 mhuse_mhuser表  用户总表，包含基本用户信息\n  id(key) password（密文密码） last_login is_superuser username first_name last_name email is_staff is_active date_joined usertype(normal, doctor) deviceid （设备id） mypassword(明文密码)  1.2 mhuser_normal表  普通用户表,包含普通用户的个人信息\n  user (foreign key, mhuser_mhuser.id) age [IntegerField, blank=True] gender [CharField,default=\u0026lsquo;man\u0026rsquo;,choice=(\u0026lsquo;man\u0026rsquo;,\u0026lsquo;woman\u0026rsquo;), max_length=10, blank=True] (性别) weight [FloatField, blank=True] （体重） marry [BooleanField, blank=True]（婚否） career [CharField, blank=True]（职业） signature [CharField, blank=True]（个性签名） medicalhistory [TextField, max_length=1000, blank=True] （用药史） avatar [ImageField, blank=True] (头像)  1.3 mhuser_doctoruser表  医生用户表, 包含医生用户的基本信息\n  user (foreign key, mhuser_mhuser.id) age *[IntegerField, blank=True] gender [CharField,default=\u0026lsquo;man\u0026rsquo;,choice=(\u0026lsquo;man\u0026rsquo;,\u0026lsquo;woman\u0026rsquo;), max_length=10, blank=True] (性别) signature [CharField, blank=True]（个性签名） expert [CharField, blank=True] (擅长) avatar [ImageField, blank=True] (头像)  1.4 mhuser_match表  普通用户\u0026amp;医生匹配,包含负责项\n  normaluser [foreign key, mhusr_normaluser.user] doctor [foreign key, mhuser_doctoruser.user] charged [CharField, choice=((\u0026lsquo;pressure\u0026rsquo;, \u0026lsquo;血压数据\u0026rsquo;),(\u0026lsquo;oxygen\u0026rsquo;,\u0026lsquo;血氧数据\u0026rsquo;),(\u0026lsquo;heartbeat\u0026rsquo;, \u0026lsquo;心跳数据\u0026rsquo;),(\u0026lsquo;tem\u0026rsquo;, \u0026lsquo;体温数据\u0026rsquo;)] (负责的部分)  1.5 mhuser_temdata表  普通用户个人体温信息表\n  own [foreign key, mhuser_normaluser.user] deviceid [CharField, default='', max_length=50] time [DateTimeField] tem_value [IntegerField] ××.×× 整数两位，小数两位  1.6 mhuser_heartdata表  普通用户个人心率信息表\n  own [foreign key, mhuser_normaluser.user] time [DateTimeField] deviceid [CharField, default='', max_length=50] b_value [IntegerField] 心率 3位整数 q_value [IntegerField] 心率间隔 3位整数 s_value [IntegerField] 信号强度 3位整数  1.7 mhuser_oxygendata表  普通用户个人血氧信息表\n  own [foreign key, mhuser_normaluser.user] time [DateTimeField] deviceid [CharField, default='', max_length=50] hr_value [IntegerField] 心率 3位整数 spo2_value [IntegerField] 血氧 3位整数  1.8 mhuser_pressuredata表  普通用户个人血压信息表\n  own [foreign key, mhuser_normaluser.user] time [DateTimeField] deviceid [CharField, default='', max_length=50] bpss_value [IntegerField] 舒张压 3位整数 bpsz_value [IntegerField] 收缩压 3位整数  2. 留言 2.1 explain_explain表  对普通用户健康数据的评论,称留言\n  match [foreign key, mhuser_match] author [foreign key, mhuser_mhuser] touserid [foreign key, mhuser_normaluser] time [DateTimeField] context [RichTextField, max_length=10000] read [CharField]   author对应fromuserid, touserid为接受意见的用户，是普通用户。\n 3. 设备 3.1 device_device表  有关设备,包含5张封面图,5张详情图\n  name [CharField, max_length=30] cover1 [ImageField] cover2 [ImageField, blank=True] cover3 [ImageField, blank=True] cover4 [ImageField, blank=True] cover5 [ImageField, blank=True] label [TextField, max_length=50] (标签) sales [IntegerField, default=0] (销量) price [FloatField, default=0.0] (价格) detailimage1 [ImageField, blank=True] (详情图片) detailimage2 [ImageField, blank=True] (详情图片) detailimage3 [ImageField, blank=True] (详情图片) detailimage4 [ImageField, blank=True] (详情图片) detailimage5 [ImageField, blank=True] (详情图片)  4. 评论  对博客的评论系统\n 4.1 comment_blogcomment表  一级评论， 对博客进行评论\n  author [foreign key, mhuser_mhuser] time [DateTimeField] comment [RichTextField] (评论内容) followed_blog [foreign key, blog_blog] (评论对象)  4.2 comment_bottomcomment表  二级评论，对一级评论进行回复或自回复）\n  author [foreign key, mhuser_mhuser] time [DateTimeField] comment [RichTextField] (评论内容) followed_comment [foreign key, blog_blog] (评论的评论对象) followed_self [foreign key, self] (评论的二级评论对象)  5. 博客 5.1 blog_blog表  博客的基本数据\n  author [foreign key, mhuser_mhuser] date [DateTimeField] essay [RichTexTextFieldtField] (博客正文) label [CharField, max_length=20] (标签) views [IntegerField, default=0] (观看次数)  远程访问说明（通过navicat）  也可使用代码段从服务器的ip地址访问MySql默认的3306端口，或者通过服务器的ssh代理访问。具体每种语言不尽相同，不再详说。\n 1、直接访问服务器的3306端口  navicat配置如下：\n 其中，用户名和密码为MySQL数据库的用户名和密码，分别是：\n用户名：root\n密码：Lichang1-\n  2、通过ssh代理访问  navicat配置：\n 常规选项卡中主机地址配置为：0.0.0.0，其他不变，另外还要开启ssh代理，选中ssh选项卡，勾选使用ssh通道，ssh具体配置如下：\n主机：59.110.140.133\n端口：22\n用户名：ahnu\n密码：ahnu2019\n  配置截图如下：\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AF%B4%E6%98%8E/","summary":"数据库表结构说明 \u0026amp;\u0026amp; 远程访问说明  code by lichang\n 数据库表结构说明 数据库名为django_mysql\n1.用户  所有和用户有关的数据\n 1.1 mhuse_mhuser表  用户总表，包含基本用户信息\n  id(key) password（密文密码） last_login is_superuser username first_name last_name email is_staff is_active date_joined usertype(normal, doctor) deviceid （设备id） mypassword(明文密码)  1.2 mhuser_normal表  普通用户表,包含普通用户的个人信息\n  user (foreign key, mhuser_mhuser.id) age [IntegerField, blank=True] gender [CharField,default=\u0026lsquo;man\u0026rsquo;,choice=(\u0026lsquo;man\u0026rsquo;,\u0026lsquo;woman\u0026rsquo;), max_length=10, blank=True] (性别) weight [FloatField, blank=True] （体重） marry [BooleanField, blank=True]（婚否） career [CharField, blank=True]（职业） signature [CharField, blank=True]（个性签名） medicalhistory [TextField, max_length=1000, blank=True] （用药史） avatar [ImageField, blank=True] (头像)  1.","title":"数据库表结构说明\u0026\u0026远程访问说明"},{"content":"数据集的清洗 一、一般数据集的处理 1、读取 首先创建文件对象，然后进行读取，两种写法\n# 第一种 f = open(\u0026#39;./Chinese.txt\u0026#39;, \u0026#39;r\u0026#39;) # 节选自：《父亲》（朱自清） article = [] # 创建一个列表 for l in f.readlines(): article.append(l) article ['我说道，“爸爸，你走吧。”他望车外看了看，说，“我买几个橘子去。你就在此地，不要走动。”我看那边月台的栅栏外有几个卖东西的等着顾客。走到那边月台，须穿过铁道，须跳下去又爬上去。父亲是一个胖子，走过去自然要费事些。我本来要去的，他不肯，只好让他去。我看见他戴着黑布小帽，穿着黑布大马褂，深青布棉袍，蹒跚地走到铁道边，慢慢探身下去，尚不大难。可是他穿过铁道，要爬上那边月台，就不容易了。他用两手攀着上面，两脚再向上缩；他肥胖的身子向左微倾，显出努力的样子。这时我看见他的背影，我的泪很快地流下来了。我赶紧拭干了泪，怕他看见，也怕别人看见。我再向外看时，他已抱了朱红的橘子望回走了。过铁道时，他先将橘子散放在地上，自己慢慢爬下，再抱起橘子走。到这边时，我赶紧去搀他。他和我走到车上，将橘子一股脑儿放在我的皮大衣上。于是扑扑衣上的泥土，心里很轻松似的，过一会说，“我走了；到那边来信！”我望着他走出去。他走了几步，回过头看见我，说，“进去吧，里边没人。”等他的背影混入来来往往的人里，再找不着了，我便进来坐下，我的眼泪又来了。']  # 第二种 article = [] # 创建一个列表 with open(\u0026#39;./Chinese.txt\u0026#39;, \u0026#39;r\u0026#39;) as file_project: for l in file_project.readlines(): article.append(l) article ['我说道，“爸爸，你走吧。”他望车外看了看，说，“我买几个橘子去。你就在此地，不要走动。”我看那边月台的栅栏外有几个卖东西的等着顾客。走到那边月台，须穿过铁道，须跳下去又爬上去。父亲是一个胖子，走过去自然要费事些。我本来要去的，他不肯，只好让他去。我看见他戴着黑布小帽，穿着黑布大马褂，深青布棉袍，蹒跚地走到铁道边，慢慢探身下去，尚不大难。可是他穿过铁道，要爬上那边月台，就不容易了。他用两手攀着上面，两脚再向上缩；他肥胖的身子向左微倾，显出努力的样子。这时我看见他的背影，我的泪很快地流下来了。我赶紧拭干了泪，怕他看见，也怕别人看见。我再向外看时，他已抱了朱红的橘子望回走了。过铁道时，他先将橘子散放在地上，自己慢慢爬下，再抱起橘子走。到这边时，我赶紧去搀他。他和我走到车上，将橘子一股脑儿放在我的皮大衣上。于是扑扑衣上的泥土，心里很轻松似的，过一会说，“我走了；到那边来信！”我望着他走出去。他走了几步，回过头看见我，说，“进去吧，里边没人。”等他的背影混入来来往往的人里，再找不着了，我便进来坐下，我的眼泪又来了。']  2、把每一句单独放在一行，并去除标点 # 首先读取到字符串 article = \u0026#39;\u0026#39; # 创建一个字符串 with open(\u0026#39;./Chinese.txt\u0026#39;, \u0026#39;r\u0026#39;) as file_project: for l in file_project.readlines(): article += l article '我说道，“爸爸，你走吧。”他望车外看了看，说，“我买几个橘子去。你就在此地，不要走动。”我看那边月台的栅栏外有几个卖东西的等着顾客。走到那边月台，须穿过铁道，须跳下去又爬上去。父亲是一个胖子，走过去自然要费事些。我本来要去的，他不肯，只好让他去。我看见他戴着黑布小帽，穿着黑布大马褂，深青布棉袍，蹒跚地走到铁道边，慢慢探身下去，尚不大难。可是他穿过铁道，要爬上那边月台，就不容易了。他用两手攀着上面，两脚再向上缩；他肥胖的身子向左微倾，显出努力的样子。这时我看见他的背影，我的泪很快地流下来了。我赶紧拭干了泪，怕他看见，也怕别人看见。我再向外看时，他已抱了朱红的橘子望回走了。过铁道时，他先将橘子散放在地上，自己慢慢爬下，再抱起橘子走。到这边时，我赶紧去搀他。他和我走到车上，将橘子一股脑儿放在我的皮大衣上。于是扑扑衣上的泥土，心里很轻松似的，过一会说，“我走了；到那边来信！”我望着他走出去。他走了几步，回过头看见我，说，“进去吧，里边没人。”等他的背影混入来来往往的人里，再找不着了，我便进来坐下，我的眼泪又来了。'  # 使用replace函数，将标点替换为换行符 result_1 = article.replace(\u0026#39;，\u0026#39;,\u0026#39;\\n\u0026#39;).\\ replace(\u0026#39;“\u0026#39;, \u0026#39;\u0026#39;).\\ replace(\u0026#39;”\u0026#39;, \u0026#39;\u0026#39;).\\ replace(\u0026#39;！\u0026#39;, \u0026#39;\\n\u0026#39;).\\ replace(\u0026#39;。\u0026#39;, \u0026#39;\\n\u0026#39;).\\ replace(\u0026#39;；\u0026#39;, \u0026#39;\u0026#39;) with open(\u0026#39;./result.txt\u0026#39;, \u0026#39;w\u0026#39;) as file_project: file_project.write(result_1) file_project.close() result_1 '我说道\\n爸爸\\n你走吧\\n他望车外看了看\\n说\\n我买几个橘子去\\n你就在此地\\n不要走动\\n我看那边月台的栅栏外有几个卖东西的等着顾客\\n走到那边月台\\n须穿过铁道\\n须跳下去又爬上去\\n父亲是一个胖子\\n走过去自然要费事些\\n我本来要去的\\n他不肯\\n只好让他去\\n我看见他戴着黑布小帽\\n穿着黑布大马褂\\n深青布棉袍\\n蹒跚地走到铁道边\\n慢慢探身下去\\n尚不大难\\n可是他穿过铁道\\n要爬上那边月台\\n就不容易了\\n他用两手攀着上面\\n两脚再向上缩他肥胖的身子向左微倾\\n显出努力的样子\\n这时我看见他的背影\\n我的泪很快地流下来了\\n我赶紧拭干了泪\\n怕他看见\\n也怕别人看见\\n我再向外看时\\n他已抱了朱红的橘子望回走了\\n过铁道时\\n他先将橘子散放在地上\\n自己慢慢爬下\\n再抱起橘子走\\n到这边时\\n我赶紧去搀他\\n他和我走到车上\\n将橘子一股脑儿放在我的皮大衣上\\n于是扑扑衣上的泥土\\n心里很轻松似的\\n过一会说\\n我走了到那边来信\\n我望着他走出去\\n他走了几步\\n回过头看见我\\n说\\n进去吧\\n里边没人\\n等他的背影混入来来往往的人里\\n再找不着了\\n我便进来坐下\\n我的眼泪又来了\\n'  3、去除常见词 \u0026amp;\u0026amp; 分词 （此处把出现次数最多的5个字作为停用词去除）\n# 首先做字符出现次数统计 word_count = {} # 初始化一个字典，用于储存字符出现次数 # 首先去除标点符号 result_2 = article.replace(\u0026#39;，\u0026#39;,\u0026#39;\u0026#39;).\\ replace(\u0026#39;“\u0026#39;, \u0026#39;\u0026#39;).\\ replace(\u0026#39;”\u0026#39;, \u0026#39;\u0026#39;).\\ replace(\u0026#39;！\u0026#39;, \u0026#39;\u0026#39;).\\ replace(\u0026#39;。\u0026#39;, \u0026#39;\u0026#39;).\\ replace(\u0026#39;；\u0026#39;, \u0026#39;\u0026#39;) for w in result_2: word_count.setdefault(w, 0) word_count[w] += 1 sorted(word_count.items(), key=lambda k:k[1], reverse=True) #排序后原字典不变 # word_count [('我', 17), ('他', 16), ('的', 14), ('走', 11), ('了', 10), ('去', 10), ('看', 9), ('子', 8), ('上', 8), ('边', 7), ('来', 7), ('着', 6), ('过', 6), ('道', 5), ('橘', 5), ('不', 5), ('到', 5), ('下', 5), ('见', 5), ('说', 4), ('地', 4), ('要', 4), ('那', 4), ('铁', 4), ('慢', 4), ('再', 4), ('时', 4), ('望', 3), ('外', 3), ('几', 3), ('个', 3), ('在', 3), ('月', 3), ('台', 3), ('穿', 3), ('爬', 3), ('是', 3), ('一', 3), ('布', 3), ('大', 3), ('向', 3), ('泪', 3), ('人', 3), ('里', 3), ('爸', 2), ('你', 2), ('吧', 2), ('车', 2), ('就', 2), ('等', 2), ('须', 2), ('又', 2), ('胖', 2), ('自', 2), ('黑', 2), ('身', 2), ('两', 2), ('；', 2), ('出', 2), ('这', 2), ('背', 2), ('影', 2), ('很', 2), ('赶', 2), ('紧', 2), ('怕', 2), ('抱', 2), ('回', 2), ('将', 2), ('放', 2), ('衣', 2), ('扑', 2), ('进', 2), ('往', 2), ('买', 1), ('此', 1), ('动', 1), ('栅', 1), ('栏', 1), ('有', 1), ('卖', 1), ('东', 1), ('西', 1), ('顾', 1), ('客', 1), ('跳', 1), ('父', 1), ('亲', 1), ('然', 1), ('费', 1), ('事', 1), ('些', 1), ('本', 1), ('肯', 1), ('只', 1), ('好', 1), ('让', 1), ('戴', 1), ('小', 1), ('帽', 1), ('马', 1), ('褂', 1), ('深', 1), ('青', 1), ('棉', 1), ('袍', 1), ('蹒', 1), ('跚', 1), ('探', 1), ('尚', 1), ('难', 1), ('可', 1), ('容', 1), ('易', 1), ('用', 1), ('手', 1), ('攀', 1), ('面', 1), ('脚', 1), ('缩', 1), ('肥', 1), ('左', 1), ('微', 1), ('倾', 1), ('显', 1), ('努', 1), ('力', 1), ('样', 1), ('快', 1), ('流', 1), ('拭', 1), ('干', 1), ('也', 1), ('别', 1), ('已', 1), ('朱', 1), ('红', 1), ('先', 1), ('散', 1), ('己', 1), ('起', 1), ('搀', 1), ('和', 1), ('股', 1), ('脑', 1), ('儿', 1), ('皮', 1), ('于', 1), ('泥', 1), ('土', 1), ('心', 1), ('轻', 1), ('松', 1), ('似', 1), ('会', 1), ('信', 1), ('步', 1), ('头', 1), ('没', 1), ('混', 1), ('入', 1), ('找', 1), ('便', 1), ('坐', 1), ('眼', 1)]  # 提取出出现次数最多的字符作为停用词 stop_words = [] count = 5 # print(word_count) sorted_dict = sorted(word_count.items(), key=lambda k:k[1], reverse=True) stop_words = [] for i in range(5): stop_words.append(sorted_dict[i][0]) # 分词 import jieba r_f = open(\u0026#39;./result.txt\u0026#39;, \u0026#39;r\u0026#39;) w_f = open(\u0026#39;./result_1.txt\u0026#39;, \u0026#39;w\u0026#39;) for row in r_f.readlines(): line = \u0026#39;\u0026#39; for r in row: if r in stop_words: continue else: line += r words = jieba.cut(line) w_f.write(\u0026#39; \u0026#39;.join(words)) 作业： 处理以下课文片段  要求：\n  从文件中读取 选取出现次数最多的5个字作为停用词 利用jieba分词进行分词处理  真的猛士，敢于直面惨淡的人生，敢于正视淋漓的鲜血。这是怎样的哀痛者和幸福者？然而造化又常常为庸人设计，以时间的流驶，来洗涤旧迹，仅使留下淡红的血色和微漠的悲哀。在这淡红的血色和微漠的悲哀中，又给人暂得偷生，维持着这似人非人的世界。我不知道这样的世界何时是一个尽头！ 我们还在这样的世上活着；我也早觉得有写一点东西的必要了。离三月十八日也已有两星期，忘却的救主快要降临了罢，我正有写一点东西的必要了。 （节选自《纪念刘和珍君》（鲁迅））\n","permalink":"http://yangchnet.github.io/Dessert/posts/python/%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/","summary":"数据集的清洗 一、一般数据集的处理 1、读取 首先创建文件对象，然后进行读取，两种写法\n# 第一种 f = open(\u0026#39;./Chinese.txt\u0026#39;, \u0026#39;r\u0026#39;) # 节选自：《父亲》（朱自清） article = [] # 创建一个列表 for l in f.readlines(): article.append(l) article ['我说道，“爸爸，你走吧。”他望车外看了看，说，“我买几个橘子去。你就在此地，不要走动。”我看那边月台的栅栏外有几个卖东西的等着顾客。走到那边月台，须穿过铁道，须跳下去又爬上去。父亲是一个胖子，走过去自然要费事些。我本来要去的，他不肯，只好让他去。我看见他戴着黑布小帽，穿着黑布大马褂，深青布棉袍，蹒跚地走到铁道边，慢慢探身下去，尚不大难。可是他穿过铁道，要爬上那边月台，就不容易了。他用两手攀着上面，两脚再向上缩；他肥胖的身子向左微倾，显出努力的样子。这时我看见他的背影，我的泪很快地流下来了。我赶紧拭干了泪，怕他看见，也怕别人看见。我再向外看时，他已抱了朱红的橘子望回走了。过铁道时，他先将橘子散放在地上，自己慢慢爬下，再抱起橘子走。到这边时，我赶紧去搀他。他和我走到车上，将橘子一股脑儿放在我的皮大衣上。于是扑扑衣上的泥土，心里很轻松似的，过一会说，“我走了；到那边来信！”我望着他走出去。他走了几步，回过头看见我，说，“进去吧，里边没人。”等他的背影混入来来往往的人里，再找不着了，我便进来坐下，我的眼泪又来了。']  # 第二种 article = [] # 创建一个列表 with open(\u0026#39;./Chinese.txt\u0026#39;, \u0026#39;r\u0026#39;) as file_project: for l in file_project.readlines(): article.append(l) article ['我说道，“爸爸，你走吧。”他望车外看了看，说，“我买几个橘子去。你就在此地，不要走动。”我看那边月台的栅栏外有几个卖东西的等着顾客。走到那边月台，须穿过铁道，须跳下去又爬上去。父亲是一个胖子，走过去自然要费事些。我本来要去的，他不肯，只好让他去。我看见他戴着黑布小帽，穿着黑布大马褂，深青布棉袍，蹒跚地走到铁道边，慢慢探身下去，尚不大难。可是他穿过铁道，要爬上那边月台，就不容易了。他用两手攀着上面，两脚再向上缩；他肥胖的身子向左微倾，显出努力的样子。这时我看见他的背影，我的泪很快地流下来了。我赶紧拭干了泪，怕他看见，也怕别人看见。我再向外看时，他已抱了朱红的橘子望回走了。过铁道时，他先将橘子散放在地上，自己慢慢爬下，再抱起橘子走。到这边时，我赶紧去搀他。他和我走到车上，将橘子一股脑儿放在我的皮大衣上。于是扑扑衣上的泥土，心里很轻松似的，过一会说，“我走了；到那边来信！”我望着他走出去。他走了几步，回过头看见我，说，“进去吧，里边没人。”等他的背影混入来来往往的人里，再找不着了，我便进来坐下，我的眼泪又来了。']  2、把每一句单独放在一行，并去除标点 # 首先读取到字符串 article = \u0026#39;\u0026#39; # 创建一个字符串 with open(\u0026#39;./Chinese.txt\u0026#39;, \u0026#39;r\u0026#39;) as file_project: for l in file_project.readlines(): article += l article '我说道，“爸爸，你走吧。”他望车外看了看，说，“我买几个橘子去。你就在此地，不要走动。”我看那边月台的栅栏外有几个卖东西的等着顾客。走到那边月台，须穿过铁道，须跳下去又爬上去。父亲是一个胖子，走过去自然要费事些。我本来要去的，他不肯，只好让他去。我看见他戴着黑布小帽，穿着黑布大马褂，深青布棉袍，蹒跚地走到铁道边，慢慢探身下去，尚不大难。可是他穿过铁道，要爬上那边月台，就不容易了。他用两手攀着上面，两脚再向上缩；他肥胖的身子向左微倾，显出努力的样子。这时我看见他的背影，我的泪很快地流下来了。我赶紧拭干了泪，怕他看见，也怕别人看见。我再向外看时，他已抱了朱红的橘子望回走了。过铁道时，他先将橘子散放在地上，自己慢慢爬下，再抱起橘子走。到这边时，我赶紧去搀他。他和我走到车上，将橘子一股脑儿放在我的皮大衣上。于是扑扑衣上的泥土，心里很轻松似的，过一会说，“我走了；到那边来信！”我望着他走出去。他走了几步，回过头看见我，说，“进去吧，里边没人。”等他的背影混入来来往往的人里，再找不着了，我便进来坐下，我的眼泪又来了。'  # 使用replace函数，将标点替换为换行符 result_1 = article.","title":"数据集的清洗"},{"content":"数组越界判定问题  今天写了一个数组的代码，里面有个函数为数组越界判定，测试的时候没通过，看了答案才发现另有玄机\n 数组定义 type Array struct{ data []int length uint } 越界判定1 // 判断索引是否越界 func (this *Array)isIndexOutRange1(index uint) bool{ if index \u0026gt; this.length-1{ //这种写法错误  return true } return false } 越界判定2 // 判断索引是否越界 func (this *Array)isIndexOutRange2(index uint) bool{ if index \u0026gt;= uint(cap(this.data)){ return true } return false } 第一种写法根据数组当前长度与要访问的下标进行比较，来判定是否下标越界\n第二种写法根绝数组占用内存大小与下标比较来判定\n二者的区别在哪?\na := Array{ data: []int{1,2,3}, length: 3, } a.length 3  cap(a.data) 3  a.isIndexOutRange1(2) false  a.isIndexOutRange2(2) false  这样看起来两者似乎没有什么差别，其实差别出在对数组类型的初试化\nfunc NewArray(capacity uint) *Array{ if capacity == 0 { return nil } return \u0026amp;Array{ /** @Des: make中第一个参数是类型，第二个参数是分配的空间， 第三个参数是预留空间，需要重新切片使用 */ data: make([]int, capacity, capacity), length: 0, } } 在NewArray函数中，我们定义了一个长度为capacity，容量为capacity的Array，也就是说，假如capacity为10，那么这个切片的长度就为10，当其length为3时，代表里面只有3个元素被赋值了，但是其实他有10个元素的位置，访问第四个元素，是可以访问到的。\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/%E6%95%B0%E7%BB%84%E8%B6%8A%E7%95%8C%E5%88%A4%E5%AE%9A%E9%97%AE%E9%A2%98/","summary":"数组越界判定问题  今天写了一个数组的代码，里面有个函数为数组越界判定，测试的时候没通过，看了答案才发现另有玄机\n 数组定义 type Array struct{ data []int length uint } 越界判定1 // 判断索引是否越界 func (this *Array)isIndexOutRange1(index uint) bool{ if index \u0026gt; this.length-1{ //这种写法错误  return true } return false } 越界判定2 // 判断索引是否越界 func (this *Array)isIndexOutRange2(index uint) bool{ if index \u0026gt;= uint(cap(this.data)){ return true } return false } 第一种写法根据数组当前长度与要访问的下标进行比较，来判定是否下标越界\n第二种写法根绝数组占用内存大小与下标比较来判定\n二者的区别在哪?\na := Array{ data: []int{1,2,3}, length: 3, } a.length 3  cap(a.data) 3  a.isIndexOutRange1(2) false  a.","title":"数组越界判定问题"},{"content":"朴素贝叶斯 1、理论部分 1.1、贝叶斯公式 $$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\qquad\\dots(1)$$\n其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$\n类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。\n对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。\n基于属性条件独立性假设，贝叶斯公式可重写为： $$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\qquad=\\frac{P(c)}{P(x)}\\prod_{i=1}^d{P(x_i|c)}\\dots(2)$$ 其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值\n由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\\in y}P(c)\\prod_{i=1}^d{P(x_i|c)}\\dots(3)$$\n显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$\n令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\\frac{|D_c|}{|D|}\\dots(4)$$\n对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\\qquad\\dots(5)$$ 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\\hat{P}(c)=\\frac{D_c+1}{|D|+N}\\qquad\\dots(6)$$ $$\\hat{P}(x_i|c)=\\frac{D_{c,x_i}+1}{|D|+N}\\qquad\\dots(7)$$\n2、实战演练 2.1、加载数据集 import numpy as np def loadDataSet(): \u0026#34;\u0026#34;\u0026#34; 导入数据， 1代表脏话 @ return postingList: 数据集 @ return classVec: 分类向量 \u0026#34;\u0026#34;\u0026#34; postingList = [[\u0026#39;my\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;has\u0026#39;, \u0026#39;flea\u0026#39;, \u0026#39;problems\u0026#39;, \u0026#39;help\u0026#39;, \u0026#39;please\u0026#39;], [\u0026#39;maybe\u0026#39;, \u0026#39;not\u0026#39;, \u0026#39;take\u0026#39;, \u0026#39;him\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;park\u0026#39;, \u0026#39;stupid\u0026#39;], [\u0026#39;my\u0026#39;, \u0026#39;dalmation\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;so\u0026#39;, \u0026#39;cute\u0026#39;, \u0026#39;I\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;him\u0026#39;], [\u0026#39;stop\u0026#39;, \u0026#39;posting\u0026#39;, \u0026#39;stupid\u0026#39;, \u0026#39;worthless\u0026#39;, \u0026#39;garbage\u0026#39;], [\u0026#39;mr\u0026#39;, \u0026#39;licks\u0026#39;, \u0026#39;ate\u0026#39;, \u0026#39;my\u0026#39;, \u0026#39;steak\u0026#39;, \u0026#39;how\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;stop\u0026#39;, \u0026#39;him\u0026#39;], [\u0026#39;quit\u0026#39;, \u0026#39;buying\u0026#39;, \u0026#39;worthless\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;food\u0026#39;, \u0026#39;stupid\u0026#39;]] classVec = [0, 1, 0, 1, 0, 1] return postingList, classVec 导入训练集及其分类，1代表是脏话，0代表不是\nloadDataSet() ([['my', 'dog', 'has', 'flea', 'problems', 'help', 'please'], ['maybe', 'not', 'take', 'him', 'to', 'dog', 'park', 'stupid'], ['my', 'dalmation', 'is', 'so', 'cute', 'I', 'love', 'him'], ['stop', 'posting', 'stupid', 'worthless', 'garbage'], ['mr', 'licks', 'ate', 'my', 'steak', 'how', 'to', 'stop', 'him'], ['quit', 'buying', 'worthless', 'dog', 'food', 'stupid']], [0, 1, 0, 1, 0, 1])  2.2、创建单词表 将训练数据中的每一个词都存储到词库中。\ndef createVocabList(dataSet): \u0026#34;\u0026#34;\u0026#34; 创建词库 @ param dataSet: 数据集 @ return vocabSet: 词库 \u0026#34;\u0026#34;\u0026#34; vocabSet = set([]) for document in dataSet: # 求并集 vocabSet = vocabSet | set(document) return list(vocabSet) listOPosts, listClasses = loadDataSet() myVocabList = createVocabList(listOPosts) myVocabList ['quit', 'how', 'problems', 'mr', 'dalmation', 'garbage', 'love', 'stop', 'maybe', 'him', 'take', 'to', 'stupid', 'food', 'not', 'cute', 'buying', 'flea', 'park', 'help', 'ate', 'dog', 'licks', 'please', 'so', 'has', 'my', 'is', 'posting', 'I', 'steak', 'worthless']  2.3、生成词向量 def setOfWords2Vec(vocabList, inputSet): \u0026#34;\u0026#34;\u0026#34; 文本词向量.词库中每个词当作一个特征，文本中有该词，该词特征就是1，没有就是0 @ param vocabList: 词表 @ param inputSet: 输入的数据集 @ return returnVec: 返回的向量 \u0026#34;\u0026#34;\u0026#34; returnVec = [0] * len(vocabList) for word in inputSet: if word in vocabList: returnVec[vocabList.index(word)] = 1 else: print(\u0026#34;单词: %s不在词库中!\u0026#34; % word) return returnVec testEntry = [\u0026#39;love\u0026#39;, \u0026#39;my\u0026#39;, \u0026#39;dalmation\u0026#39;] thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry)) thisDoc array([0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])  2.4、训练分类器 def trainNB0(trainMatrix, trainCategory): \u0026#34;\u0026#34;\u0026#34; 训练 @ param trainMatrix: 训练集 @ param trainCategory: 分类 \u0026#34;\u0026#34;\u0026#34; numTrainDocs = len(trainMatrix) # 训练数据的长度 numWords = len(trainMatrix[0]) # 训练数据的词汇量 pAbusive = sum(trainCategory) / float(numTrainDocs) # 防止某个类别计算出的概率为0，导致最后相乘都为0，所以初始词都赋值1，分母赋值为2. 拉普拉斯修正 p0Num = np.ones(numWords) # 分子 p1Num = np.ones(numWords) p0Denom = 2 # 分母 p1Denom = 2 for i in range(numTrainDocs): if trainCategory[i] == 1: p1Num += trainMatrix[i] p1Denom += sum(trainMatrix[i]) else: p0Num += trainMatrix[i] p0Denom += sum(trainMatrix[i]) # 这里使用log函数，方便计算，因为最后是比较大小，所有对结果没有影响。 p1Vect = np.log(p1Num / p1Denom) # P^(x_1|c) p0Vect = np.log(p0Num / p0Denom) # P^(x_2|c) return p0Vect, p1Vect, pAbusive 2.5、 进行分类 def classifyNB(vec2Classify, p0Vec, p1Vec, pClass1): \u0026#34;\u0026#34;\u0026#34; 判断大小 \u0026#34;\u0026#34;\u0026#34; p1 = sum(vec2Classify * p1Vec) # P(c)*P(x_1|c) p0 = sum(vec2Classify * p0Vec) # P(c)*P(x_2|c) if p1 \u0026gt; p0: return 1 else: return 0 2.6、测试 def testingNB(): listOPosts, listClasses = loadDataSet() myVocabList = createVocabList(listOPosts) trainMat = [] for postinDoc in listOPosts: trainMat.append(setOfWords2Vec(myVocabList, postinDoc)) print(trainMat) # 查看训练集矩阵 p0V, p1V, pAb = trainNB0(np.array(trainMat), np.array(listClasses)) testEntry = [\u0026#39;love\u0026#39;, \u0026#39;my\u0026#39;, \u0026#39;dalmation\u0026#39;] thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry)) print(testEntry, \u0026#39;classified as: \u0026#39;, classifyNB(thisDoc, p0V, p1V, pAb)) testEntry = [\u0026#39;stupid\u0026#39;, \u0026#39;garbage\u0026#39;] thisDoc = np.array(setOfWords2Vec(myVocabList, testEntry)) print(testEntry, \u0026#39;classified as: \u0026#39;, classifyNB(thisDoc, p0V, p1V, pAb)) testingNB() [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0], [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1], [0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0], [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]] ['love', 'my', 'dalmation'] classified as: 0 ['stupid', 'garbage'] classified as: 1  ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/","summary":"朴素贝叶斯 1、理论部分 1.1、贝叶斯公式 $$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\qquad\\dots(1)$$\n其中，$P(c)$是类“先验概率”；$P(x|c)$是样本$x$相对于类标记$c$的类条件概率，或称为“似然”；$P(x)$是用于归一化的“证据因子”。对给定样本$x$，证据因子$P(x)$与类标记无关，因此估计$P(c|x)$的问题就转化为如何基于训练数据$D$来估计先验$P(c)$和似然$P(x|c)$\n类先验概率$P(c)$表达了样本空间中各类样本所占的比例，根据大数定律，当训练集包含充足的独立同分布样本时，$P(c)$可通过各类样本出现的频率来进行估计。\n对类条件概率$(P(x|c))$来说，由于它涉及关于$x$所有属性的联合概率，直接根据样本出现的频率来估计将会遇到严重的困难。为避开这个障碍，朴素贝叶斯分类器采用了“属性条件独立性假设”；对已知类别，假设所有属性相互独立。换言之，假设每个属性独立的对分类结果产生影响。\n基于属性条件独立性假设，贝叶斯公式可重写为： $$P(c|x)=\\frac{P(c)P(x|c)}{P(x)}\\qquad=\\frac{P(c)}{P(x)}\\prod_{i=1}^d{P(x_i|c)}\\dots(2)$$ 其中$d$为属性数目，$x_i$为$x$在第i个属性上的取值\n由于对于所有类别来说$P(x)$相同，因此贝叶斯判定准则：$$h_{nb}(x)=arg max_{c\\in y}P(c)\\prod_{i=1}^d{P(x_i|c)}\\dots(3)$$\n显然，朴素贝叶斯分类器的训练过程就是基于训练集$D$来估计类先验概率$P(c)$，并为每个属性估计条件概率$P(x_i|c)$\n令$D_c$表示训练集$D$中第$c$类样本组成的集合，若有充足的独立同分布样本，则可容易的估计出先验概率：$$P(c)=\\frac{|D_c|}{|D|}\\dots(4)$$\n对离散属性而言，令$D_{c,x_i}$表示$D_c$中在第$i$个属性上取值为$x_i$的样本组成的集合，则条件概率$P(x_i|c)$可估计为$$P(x_i|c)=\\frac{|D_{c,x_i}|}{|D_c|}\\qquad\\dots(5)$$ 为了避免其他属性携带的信息被训练集中未出现的属性值抹去，在估计概率值时通常要进行“平滑”，常用“拉普拉斯修正”。具体来说，令$N$表示训练集$D$中可能的类别数，$N_i$表示第$i$个属性可能的取值数，则(4)(5)两式分别修正为：$$\\hat{P}(c)=\\frac{D_c+1}{|D|+N}\\qquad\\dots(6)$$ $$\\hat{P}(x_i|c)=\\frac{D_{c,x_i}+1}{|D|+N}\\qquad\\dots(7)$$\n2、实战演练 2.1、加载数据集 import numpy as np def loadDataSet(): \u0026#34;\u0026#34;\u0026#34; 导入数据， 1代表脏话 @ return postingList: 数据集 @ return classVec: 分类向量 \u0026#34;\u0026#34;\u0026#34; postingList = [[\u0026#39;my\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;has\u0026#39;, \u0026#39;flea\u0026#39;, \u0026#39;problems\u0026#39;, \u0026#39;help\u0026#39;, \u0026#39;please\u0026#39;], [\u0026#39;maybe\u0026#39;, \u0026#39;not\u0026#39;, \u0026#39;take\u0026#39;, \u0026#39;him\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;park\u0026#39;, \u0026#39;stupid\u0026#39;], [\u0026#39;my\u0026#39;, \u0026#39;dalmation\u0026#39;, \u0026#39;is\u0026#39;, \u0026#39;so\u0026#39;, \u0026#39;cute\u0026#39;, \u0026#39;I\u0026#39;, \u0026#39;love\u0026#39;, \u0026#39;him\u0026#39;], [\u0026#39;stop\u0026#39;, \u0026#39;posting\u0026#39;, \u0026#39;stupid\u0026#39;, \u0026#39;worthless\u0026#39;, \u0026#39;garbage\u0026#39;], [\u0026#39;mr\u0026#39;, \u0026#39;licks\u0026#39;, \u0026#39;ate\u0026#39;, \u0026#39;my\u0026#39;, \u0026#39;steak\u0026#39;, \u0026#39;how\u0026#39;, \u0026#39;to\u0026#39;, \u0026#39;stop\u0026#39;, \u0026#39;him\u0026#39;], [\u0026#39;quit\u0026#39;, \u0026#39;buying\u0026#39;, \u0026#39;worthless\u0026#39;, \u0026#39;dog\u0026#39;, \u0026#39;food\u0026#39;, \u0026#39;stupid\u0026#39;]] classVec = [0, 1, 0, 1, 0, 1] return postingList, classVec 导入训练集及其分类，1代表是脏话，0代表不是","title":"朴素贝叶斯"},{"content":"检查Apache配置文件语法错误 在/etc/apache2目录下输入apache2ctl configtest即可检查错误\n","permalink":"http://yangchnet.github.io/Dessert/posts/linux/%E6%A3%80%E6%9F%A5apache%E7%9A%84%E6%96%87%E4%BB%B6%E9%85%8D%E7%BD%AE%E8%AF%AD%E6%B3%95%E9%94%99%E8%AF%AF/","summary":"检查Apache配置文件语法错误 在/etc/apache2目录下输入apache2ctl configtest即可检查错误","title":"检查Apache配置文件语法错误"},{"content":"检查nginx的语法错误 使用nginx -t\n","permalink":"http://yangchnet.github.io/Dessert/posts/linux/%E6%A3%80%E6%9F%A5nginx%E7%9A%84%E8%AF%AD%E6%B3%95%E9%94%99%E8%AF%AF/","summary":"检查nginx的语法错误 使用nginx -t","title":"检查nginx的语法错误"},{"content":"模型评估 此节内容只针对分类模型，使用sklearn库\n1、准确率 accuracy_score函数计算精度，在多标签分类中，该函数返回子集精度。如果样本的整个预测标签集与真实的标签集严格匹配，则子集精度为1.0; 否则它是0.0。如果$\\hat{y}i$是第$i$类样本预测值，$y_i$是相应的真值，那么正确预测的分数$n\\text{samples}$被定义为$$\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1(\\hat{y}_i = y_i)$$\nimport numpy as np from sklearn.metrics import accuracy_score y_pred = [0, 2, 1, 3] y_true = [0, 1, 2, 3] accuracy_score(y_true, y_pred) 0.5  accuracy_score(y_true, y_pred, normalize=False) # 若normalize为False,则返回正确分类的样本数 2  2、混淆矩阵 该confusion_matrix函数通过计算混淆矩阵来评估分类准确性，行对应于真正的类，列表示预测值。\nfrom sklearn.metrics import confusion_matrix y_true = [2, 0, 2, 2, 0, 1] y_pred = [0, 0, 2, 2, 0, 2] confusion_matrix(y_true, y_pred) array([[2, 0, 0], [0, 0, 1], [1, 0, 2]])  3、汉明损失 如果$\\hat{y}j$是预测为第$j$类的样本，$y_j$是真值，$n\\text{labels}$是类别的数目，则两个样本之间的汉明损失定义为：$$L_{Hamming}(y, \\hat{y}) = \\frac{1}{n_\\text{labels}} \\sum_{j=0}^{n_\\text{labels} - 1} 1(\\hat{y}_j \\not= y_j)$$ $1(x)$是指标函数\nfrom sklearn.metrics import hamming_loss y_pred = [1, 2, 3, 4] y_true = [2, 2, 3, 4] hamming_loss(y_true, y_pred) 0.25  4、查准率、查全率和f1度量 在二元分类任务中，术语“正”和“负”指的是分类器的预测，术语“真”和“假”指的是该预测是否与外部判断相对应。\n   。 实际类别 。     预测类别 tp(真 正) fp(假 正)   - fn(假 负) tn(真 负)    在这种情况下，我们可以定义查准率，查全率和f1度量的概念： $$\\text{precision} = \\frac{tp}{tp + fp},$$ $$\\text{recall} = \\frac{tp}{tp + fn},$$ $$F_\\beta = (1 + \\beta^2) \\frac{\\text{precision} \\times \\text{recall}}{\\beta^2 \\text{precision} + \\text{recall}}.$$\n查准率与查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。例如：若希望将正样本尽可能多的选出来，则可通过增加选择样本的数量来实现，如果将所有的样本都选中，那么所有的正样本也必然都被选上了，但这样查准率就会较低；若希望选出的样本中正样本比例尽可能高，则可只挑选最有把握的样本，但这样难免就会漏掉不少正样本，使得查全率较低。通常只有在一些简单任务中，才可能使查全率和查准率都很高。f1度量的一般形式\u0026mdash;$F_\\beta$，能让我们表达出对查准率/查全率的不同偏好。\n 详情可参考周志华《机器学习》P30-P32\n from sklearn import metrics y_pred = [0, 1, 0, 0] y_true = [0, 1, 0, 1] metrics.precision_score(y_true, y_pred) 1.0   metrics.recall_score(y_true, y_pred) 0.5   metrics.f1_score(y_true, y_pred) 0.6666666666666666   metrics.fbeta_score(y_true, y_pred, beta=0.5) 0.8333333333333334   metrics.fbeta_score(y_true, y_pred, beta=1) 0.6666666666666666   metrics.fbeta_score(y_true, y_pred, beta=2) 0.5555555555555556   metrics.precision_recall_fscore_support(y_true, y_pred, beta=0.5) (array([0.66666667, 1. ]), array([1. , 0.5]), array([0.71428571, 0.83333333]), array([2, 2]))  precision_recall_fscore_support计算每个类的查准率，查全率、f1度量和support，返回值：presion, recall, fbeta_score, support(每个标签出现的次数)\n 5、分类报告 该classification_report函数构建一个显示主要分类指标的文本报告\nfrom sklearn.metrics import classification_report y_true = [0, 1, 2, 2, 0] y_pred = [0, 0, 2, 1, 0] target_names = [\u0026#39;class 0\u0026#39;, \u0026#39;class 1\u0026#39;, \u0026#39;class 2\u0026#39;] print(classification_report(y_true, y_pred, target_names=target_names))  precision recall f1-score support class 0 0.67 1.00 0.80 2 class 1 0.00 0.00 0.00 1 class 2 1.00 0.50 0.67 2 micro avg 0.60 0.60 0.60 5 macro avg 0.56 0.50 0.49 5 weighted avg 0.67 0.60 0.59 5  6、 ROC曲线 ROC全称是“受试者工作特征”，根据学习器的预测结果对样例进行排序，按此顺序把样本作为正例进行预测，每次计算出两个重要的值，分别以它们为横纵坐标作图，就得到了ROC曲线。ROC曲线的纵轴是“真正例率（TPR）”，横轴是“假正例率（FPR）”，二者定义为：$$\\text{TPR} = \\frac{tp}{tp + fn}$$, $$\\text{FPR} = \\frac{fp}{tn + fp}$$\nROC曲线通常在Y轴上具有真正例率，在X轴上具有假正例率，这意味着图的左上角是“理想”点-假阳性率为零，真阳性率为1。因此，曲线下面积越大越好，The “steepness” of ROC curves is also important, since it is ideal to maximize the true positive rate while minimizing the false positive rate.\nimport numpy as np # from pylab import * from sklearn.metrics import roc_curve, roc_auc_score y = np.array([1, 1, 2, 2]) scores = np.array([0.1, 0.4, 0.35, 0.8]) fpr, tpr, thresholds = roc_curve(y, scores, pos_label=2) roc_auc = roc_auc_score(y, scores) plt.figure() lw = 2 plt.plot(fpr, tpr, color=\u0026#39;darkorange\u0026#39;, lw=lw, label=\u0026#39;ROC curve (area = %0.2f)\u0026#39; % roc_auc) plt.plot([0, 1], [0, 1], color=\u0026#39;navy\u0026#39;, lw=lw, linestyle=\u0026#39;--\u0026#39;) plt.xlim([0.0, 1.0]) plt.ylim([0.0, 1.05]) plt.xlabel(\u0026#39;False Positive Rate\u0026#39;) plt.ylabel(\u0026#39;True Positive Rate\u0026#39;) plt.title(\u0026#39;Receiver operating characteristic example\u0026#39;) plt.legend(loc=\u0026#34;lower right\u0026#34;) plt.show()  由于数据过于简单，因此画出的图形也比较简单：(\n 作业  在上节课实验的基础上，计算出朴素贝叶斯针对所给数据集的准确率，汉明损失，混淆矩阵，查准率、查全率，f1度量和ROC，并画出ROC曲线 给定完整数据集，分别计算在使用完整数据集的10%,30%,50%,80%,100%数据时的查准率、查全率，f1度量和ROC，使用折线图表现出这些指标的变化情况，并画出在不同数据量下的ROC曲线  ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/%E5%88%86%E7%B1%BB%E6%8C%87%E6%A0%87/","summary":"模型评估 此节内容只针对分类模型，使用sklearn库\n1、准确率 accuracy_score函数计算精度，在多标签分类中，该函数返回子集精度。如果样本的整个预测标签集与真实的标签集严格匹配，则子集精度为1.0; 否则它是0.0。如果$\\hat{y}i$是第$i$类样本预测值，$y_i$是相应的真值，那么正确预测的分数$n\\text{samples}$被定义为$$\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1(\\hat{y}_i = y_i)$$\nimport numpy as np from sklearn.metrics import accuracy_score y_pred = [0, 2, 1, 3] y_true = [0, 1, 2, 3] accuracy_score(y_true, y_pred) 0.5  accuracy_score(y_true, y_pred, normalize=False) # 若normalize为False,则返回正确分类的样本数 2  2、混淆矩阵 该confusion_matrix函数通过计算混淆矩阵来评估分类准确性，行对应于真正的类，列表示预测值。\nfrom sklearn.metrics import confusion_matrix y_true = [2, 0, 2, 2, 0, 1] y_pred = [0, 0, 2, 2, 0, 2] confusion_matrix(y_true, y_pred) array([[2, 0, 0], [0, 0, 1], [1, 0, 2]])  3、汉明损失 如果$\\hat{y}j$是预测为第$j$类的样本，$y_j$是真值，$n\\text{labels}$是类别的数目，则两个样本之间的汉明损失定义为：$$L_{Hamming}(y, \\hat{y}) = \\frac{1}{n_\\text{labels}} \\sum_{j=0}^{n_\\text{labels} - 1} 1(\\hat{y}_j \\not= y_j)$$ $1(x)$是指标函数","title":"模型评估"},{"content":"正则表达式 1、什么是正则表达式 正则表达式，又称规则表达式。（英语：Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。正则表达式通常被用来检索、替换那些符合某个模式(规则)的文本。（摘自百度百科）\n你可能熟悉文本查找,即按下 Ctrl-F,输入你要查找的词。“正则表达式”更进一步,它们让你指定要查找的“模式”。你也许不知道一家公司的准确电话号码,但如果你住在美国或加拿大,你就知道有3 位数字,然后是一个短横线,然后是 4 位数字(有时候以 3 位区号开始)。因此作为一个人,你看到一个电话号码就知道:415-555-1234 是电话号码,但 4,155,551,234 不是。 正则表达式很有用,但如果不是程序员,很少会有人了解,它,尽管大多数现代文本编辑器和文字处理器(诸如微软的 Word 或 OpenOffice)都有查找和查找替换功能,可以根据正则表达式查找。正则表达式可以节约大量时间,不仅适用于软件用户,也适用于程序员。实际上,技术作家 Cory Doctorow 声称,甚至应该在教授编程之前,先教授正则表达式: “知道[正则表达式]可能意味着用 3 步解决一个问题,而不是用 3000 步。如果你是一个技术怪侠,别忘了你用几次击键就能解决的问题,其他人需要数天的烦琐工作才能解决,而且他们容易犯错。” 1 (摘自《Python编程快速上手—让繁琐工作自动化》)\n2、不用正则表达式来查找文本模式 假设你希望在字符串中查找电话号码。你知道模式:3 个数字,一个短横线,3 个数字,一个短横线,再是 4 个数字。例如:415-555-4242。 假定我们用一个名为 isPhoneNumber()的函数,来检查字符串是否匹配模式,它 返回 True 或 False。\ndef isPhoneNumber(text): if len(text) != 12: return False for i in range(0, 3): if not text[i].isdecimal(): return False if text[3] != \u0026#39;-\u0026#39;: return False for i in range(4, 7): if not text[i].isdecimal(): return False if text[7] != \u0026#39;-\u0026#39;: return False for i in range(8, 12): if not text[i].isdecimal(): return False return True print(\u0026#39;415-555-4242 is a phone number:\u0026#39;) print(isPhoneNumber(\u0026#39;415-555-4242\u0026#39;)) print(\u0026#39;Moshi moshi is a phone number:\u0026#39;) print(isPhoneNumber(\u0026#39;Moshi moshi\u0026#39;)) 415-555-4242 is a phone number: True Moshi moshi is a phone number: False  添加更多代码,才能在更长的字符串中寻找这种文本模式\nmessage = \u0026#39;Call me at 415-555-1011 tomorrow. 415-555-9999 is my office.\u0026#39; for i in range(len(message)): chunk = message[i:i+12] if isPhoneNumber(chunk): print(\u0026#39;Phone number found: \u0026#39; + chunk) print(\u0026#39;Done\u0026#39;) Phone number found: 415-555-1011 Phone number found: 415-555-9999 Done  3、使用正则表达式进行匹配 3.1、 创建正则表达式对象 # 导入re模块来使用正则 import re # 创建正则表达式 phoneNumRegex = re.compile(r\u0026#39;\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d\u0026#39;) 3.2、使用正则进行查询 phoneNumRegex = re.compile(r\u0026#39;\\d\\d\\d-\\d\\d\\d-\\d\\d\\d\\d\u0026#39;) mo = phoneNumRegex.search(\u0026#39;My number is 415-555-4242.\u0026#39;) print(\u0026#39;Phone number found: \u0026#39; + mo.group()) Phone number found: 415-555-4242  3.3、利用括号分组 假定想要将区号从电话号码中分离。添加括号将在正则表达式中创建“分组”(\\d\\d\\d)-(\\d\\d\\d-\\d\\d\\d\\d)。然后可以使用 group()匹配对象方法,从个分组中获取匹配的文本。正则表达式字符串中的第一对括号是第 1 组。第二对括号是第 2 组。向 group()匹配对象方法传入整数 1 或 2,就可以取得匹配文本的不同部分。向 group()方法传入 0 或不传入参数,将返回整个匹配的文本\nphoneNumRegex = re.compile(r\u0026#39;(\\d\\d\\d)-(\\d\\d\\d-\\d\\d\\d\\d)\u0026#39;) mo = phoneNumRegex.search(\u0026#39;My number is 415-555-4242.\u0026#39;) # 第一个分组 mo.group(1) # 第二个分组 # mo.group(2) # 全部 # mo.group(0) # mo.group() '415'  3.4、用管道匹配多个分组 字符|称为“管道”正则表达式 r\u0026rsquo;Batman|Tina Fey\u0026rsquo;将匹配\u0026rsquo;Batman\u0026rsquo;或\u0026rsquo;Tina Fey'。如果 Batman 和 Tina Fey 都出现在被查找的字符串中,第一次出现的匹配文本,将作为 Match 对象返回\nheroRegex = re.compile (r\u0026#39;Batman|Tina Fey\u0026#39;) mo1 = heroRegex.search(\u0026#39;Batman and Tina Fey.\u0026#39;) mo1.group() 'Tina Fey'  mo2 = heroRegex.search(\u0026#39;Tina Fey and Batman.\u0026#39;) mo2.group() 'Tina Fey'  3.5、 用问号实现可选匹配 有时候,想匹配的模式是可选的。就是说,不论这段文本在不在,正则表达式都会认为匹配。字符?表明它前面的分组在这个模式中是可选的。\nbatRegex = re.compile(r\u0026#39;Bat(wo)?man\u0026#39;) mo1 = batRegex.search(\u0026#39;The Adventures of Batman\u0026#39;) mo1.group() 'Batwoman'  mo2 = batRegex.search(\u0026#39;The Adventures of Batwoman\u0026#39;) mo2.group() 'Batwoman'  3.6、 用星号匹配零次或多次 *(称为星号)意味着“匹配零次或多次”,即星号之前的分组,可以在文本中出现任意次。它可以完全不存在,或一次又一次地重复。\nbatRegex = re.compile(r\u0026#39;Bat(wo)*man\u0026#39;) mo1 = batRegex.search(\u0026#39;The Adventures of Batman\u0026#39;) mo1.group() 'Batman'  mo2 = batRegex.search(\u0026#39;The Adventures of Batwoman\u0026#39;) mo2.group() 'Batwoman'  mo3 = batRegex.search(\u0026#39;The Adventures of Batwowowowoman\u0026#39;) mo3.group() 'Batwowowowoman'  3.7、 用加号匹配一次或多次 *意味着“匹配零次或多次”,+(加号)则意味着“匹配一次或多次”。星号不要求分组出现在匹配的字符串中,但加号不同,加号前面的分组必须“至少出现一次”。这不是可选的。\nbatRegex = re.compile(r\u0026#39;Bat(wo)+man\u0026#39;) mo1 = batRegex.search(\u0026#39;The Adventures of Batwoman\u0026#39;) mo1.group() 'Batwoman'  mo2 = batRegex.search(\u0026#39;The Adventures of Batwowowowoman\u0026#39;) mo2.group() 'Batwowowowoman'  mo3 = batRegex.search(\u0026#39;The Adventures of Batman\u0026#39;) mo3 == None True   未完待续\n ","permalink":"http://yangchnet.github.io/Dessert/posts/python/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/","summary":"正则表达式 1、什么是正则表达式 正则表达式，又称规则表达式。（英语：Regular Expression，在代码中常简写为regex、regexp或RE），计算机科学的一个概念。正则表达式通常被用来检索、替换那些符合某个模式(规则)的文本。（摘自百度百科）\n你可能熟悉文本查找,即按下 Ctrl-F,输入你要查找的词。“正则表达式”更进一步,它们让你指定要查找的“模式”。你也许不知道一家公司的准确电话号码,但如果你住在美国或加拿大,你就知道有3 位数字,然后是一个短横线,然后是 4 位数字(有时候以 3 位区号开始)。因此作为一个人,你看到一个电话号码就知道:415-555-1234 是电话号码,但 4,155,551,234 不是。 正则表达式很有用,但如果不是程序员,很少会有人了解,它,尽管大多数现代文本编辑器和文字处理器(诸如微软的 Word 或 OpenOffice)都有查找和查找替换功能,可以根据正则表达式查找。正则表达式可以节约大量时间,不仅适用于软件用户,也适用于程序员。实际上,技术作家 Cory Doctorow 声称,甚至应该在教授编程之前,先教授正则表达式: “知道[正则表达式]可能意味着用 3 步解决一个问题,而不是用 3000 步。如果你是一个技术怪侠,别忘了你用几次击键就能解决的问题,其他人需要数天的烦琐工作才能解决,而且他们容易犯错。” 1 (摘自《Python编程快速上手—让繁琐工作自动化》)\n2、不用正则表达式来查找文本模式 假设你希望在字符串中查找电话号码。你知道模式:3 个数字,一个短横线,3 个数字,一个短横线,再是 4 个数字。例如:415-555-4242。 假定我们用一个名为 isPhoneNumber()的函数,来检查字符串是否匹配模式,它 返回 True 或 False。\ndef isPhoneNumber(text): if len(text) != 12: return False for i in range(0, 3): if not text[i].isdecimal(): return False if text[3] != \u0026#39;-\u0026#39;: return False for i in range(4, 7): if not text[i].","title":"正则表达式"},{"content":"温度预测 1. 观察耶拿天气数据集的数据 import os fname = \u0026#39;./data/jena_climate_2009_2016.csv\u0026#39; f = open(fname) data = f.read() f.close() lines = data.split(\u0026#39;\\n\u0026#39;) header = lines[0].split(\u0026#39;,\u0026#39;) lines = lines[1:] print(header) print(len(lines)) ['\u0026quot;Date Time\u0026quot;', '\u0026quot;p (mbar)\u0026quot;', '\u0026quot;T (degC)\u0026quot;', '\u0026quot;Tpot (K)\u0026quot;', '\u0026quot;Tdew (degC)\u0026quot;', '\u0026quot;rh (%)\u0026quot;', '\u0026quot;VPmax (mbar)\u0026quot;', '\u0026quot;VPact (mbar)\u0026quot;', '\u0026quot;VPdef (mbar)\u0026quot;', '\u0026quot;sh (g/kg)\u0026quot;', '\u0026quot;H2OC (mmol/mol)\u0026quot;', '\u0026quot;rho (g/m**3)\u0026quot;', '\u0026quot;wv (m/s)\u0026quot;', '\u0026quot;max. wv (m/s)\u0026quot;', '\u0026quot;wd (deg)\u0026quot;'] 420551  # 解析数据 import numpy as np float_data = np.zeros((len(lines), len(header) - 1)) for i, line in enumerate(lines): values = [float(x) for x in line.split(\u0026#39;,\u0026#39;)[1:]] float_data[i, :] = values # 绘制温度时间序列 from matplotlib import pyplot as plt temp = float_data[:, 1] # 温度（摄氏度） plt.plot(range(len(temp)), temp) plt.show() plt.plot(range(1440), temp[:1440]) [\u0026lt;matplotlib.lines.Line2D at 0x7f596ff56978\u0026gt;]  2. 准备数据 问题描述：一个时间步是10分钟，没steps个时间步采样一次数据，给定过去lookback个时间步之内的数据，能否预测delay个时间步之后的温度？用到的参数如下:\nlookback = 720 # 给定过去5天内的观测数据\nsteps = 6 # 观测数据的采样频率是每小时一个数据点\ndelay = 144 # 目标是未来24小时之后的数据\n数据标准化\nmean = float_data[:200000].mean(axis=0) float_data -= mean std = float_data[:200000].std(axis=0) float_data /= std 下面这个生成器以当前的浮点数数组作为输入，并从最近的数据中生成数据批量，同时生成未来的目标温度。sample是输入数据的一个批量，targets是对应的目标温度数组\ndef generator(data, lookback, delay, min_index, max_index, shuffle=False, batch_size=128, step=6): \u0026#39;\u0026#39;\u0026#39; data:浮点数据组成的原始数组 lookback: 输入数据应该包括过去多少个时间步 delay：目标应该在未来多少个时间后 min_index 和 max_index: data数组中的索引，用于界定需要抽取那些时间步。 shuffle: 是打乱样本，还是按顺序抽取样本 batch_size:每个批量的样本数 step:数据采样的周期。 \u0026#39;\u0026#39;\u0026#39; if max_index is None: max_index = len(data) - delay - 1 i = min_index + lookback while 1: if shuffle: rows = np.random.randint( min_index + lookback, max_index, size=batch_size) else: if i + batch_size \u0026gt;= max_index: i = min_index + lookback rows = np.arange(i, min(i + batch_size, max_index)) i += len(rows) samples = np.zeros((len(rows), lookback // step, data.shape[-1])) targets = np.zeros((len(rows),)) for j, row in enumerate(rows): indices = range(rows[j] - lookback, rows[j], step) samples[j] = data[indices] targets[j] = data[rows[j] + delay][1] yield samples, targets 准备训练生成器、验证生成器和测试生成器\nlookback = 1440 step = 6 delay = 144 batch_size = 128 train_gen = generator(float_data, lookback=lookback, delay=delay, min_index=0, max_index=200000, shuffle=True, step=step, batch_size=batch_size) val_gen = generator(float_data, lookback=lookback, delay=delay, min_index=2000001, max_index=3000000, step=step, batch_size=batch_size) test_gen = generator(float_data, lookback=lookback, delay=delay, min_index=3000001, max_index=None, step=step, batch_size=batch_size) val_steps = (300000 - 200001 - lookback) // batch_size # 为了查看整个验证集，需要从val_gen中抽取多少次 test_steps = (len(float_data) - 300001 - lookback) // batch_size # 为了查看整个测试集，需要从test_gen中抽取多少次 3. 一种基本的机器学习方法 在尝试机器学习方法之前，建立一个基于常识的基准方法是很有用的；同样，在开始研究复杂且计算代价很高的模型（如RNN）之前，尝试使用简单且计算代价低的机器学习模型也是很有用的，比如小型的密集连接网络。这可以保证进一步增加问题的复杂度是合理的，并且会带来真正的好处\n# 训练并评估一个密集连接模型 from keras.models import Sequential from keras import layers from keras.optimizers import RMSprop model = Sequential() model.add(layers.Flatten(input_shape=(lookback // step, float_data.shape[-1]))) model.add(layers.Dense(32, activation=\u0026#39;relu\u0026#39;)) model.add(layers.Dense(1)) model.compile(optimizer=RMSprop(), loss=\u0026#39;mae\u0026#39;) history = model.fit_generator(train_gen, steps_per_epoch=500, epochs=20, validation_data=val_gen, validation_steps=val_steps) ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/%E6%B8%A9%E5%BA%A6%E9%A2%84%E6%B5%8B/","summary":"温度预测 1. 观察耶拿天气数据集的数据 import os fname = \u0026#39;./data/jena_climate_2009_2016.csv\u0026#39; f = open(fname) data = f.read() f.close() lines = data.split(\u0026#39;\\n\u0026#39;) header = lines[0].split(\u0026#39;,\u0026#39;) lines = lines[1:] print(header) print(len(lines)) ['\u0026quot;Date Time\u0026quot;', '\u0026quot;p (mbar)\u0026quot;', '\u0026quot;T (degC)\u0026quot;', '\u0026quot;Tpot (K)\u0026quot;', '\u0026quot;Tdew (degC)\u0026quot;', '\u0026quot;rh (%)\u0026quot;', '\u0026quot;VPmax (mbar)\u0026quot;', '\u0026quot;VPact (mbar)\u0026quot;', '\u0026quot;VPdef (mbar)\u0026quot;', '\u0026quot;sh (g/kg)\u0026quot;', '\u0026quot;H2OC (mmol/mol)\u0026quot;', '\u0026quot;rho (g/m**3)\u0026quot;', '\u0026quot;wv (m/s)\u0026quot;', '\u0026quot;max. wv (m/s)\u0026quot;', '\u0026quot;wd (deg)\u0026quot;'] 420551  # 解析数据 import numpy as np float_data = np.zeros((len(lines), len(header) - 1)) for i, line in enumerate(lines): values = [float(x) for x in line.","title":"温度预测"},{"content":"理解LSTM层与GRU层  SimpleRNN的问题在于，在时刻t，理论上来说，它应该能够记住许多时间部之前见过的各种信息，但实际上它是不可能学到这种长期依赖的。其原因在于“梯度消失”问题，这一效应类似于在层数较多的非循环网络中观察到的效应，随着层数的增加，网络最终变得无法训练。\n 1. LSTM层 LSTM层是SimpleRNN的一种变体，它增加了一种携带信息跨越多个时间步的方法。假设有一条传送带，其运行方向平行于你所处理的序列。序列中的信息可以在任意位置跳上传送带，然后被传送到更晚的时间步，并在需要时原封不动地跳回来。这实际上就是LSTM的原理：它保存信息以便后面使用，从而防止较早期的信号在处理过程中逐渐消失。\n1.1 Keras 中一个LSTM的例子 # 准备数据 from keras.datasets import imdb from keras.preprocessing import sequence max_features = 10000 maxlen = 500 batch_size = 32 print(\u0026#39;Loading data...\u0026#39;) (input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features) print(len(input_train), \u0026#39;train_sequences\u0026#39;) print(len(input_test), \u0026#39;test sequences\u0026#39;) print(\u0026#39;Pad sequences (samples x time)\u0026#39;) input_train = sequence.pad_sequences(input_train, maxlen=maxlen) input_test = sequence.pad_sequences(input_test, maxlen=maxlen) print(\u0026#39;input_train shape: \u0026#39;, input_train.shape) print(\u0026#39;input_test shape:\u0026#39;, input_test.shape) Loading data... 25000 train_sequences 25000 test sequences Pad sequences (samples x time) input_train shape: (25000, 500) input_test shape: (25000, 500)  # 使用Keras中的LSTM层 from keras.layers import LSTM, Dense from keras.models import Sequential from keras.layers import Embedding, SimpleRNN max_features = 10000 model = Sequential() model.add(Embedding(max_features, 32)) model.add(LSTM(32)) model.add(Dense(1, activation=\u0026#39;sigmoid\u0026#39;)) model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;acc\u0026#39;]) history = model.fit(input_train, y_train, epochs=10, batch_size=128, validation_split=0.2) /usr/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. \u0026quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. \u0026quot; Train on 20000 samples, validate on 5000 samples Epoch 1/10 20000/20000 [==============================] - 487s 24ms/step - loss: 0.5123 - acc: 0.7542 - val_loss: 0.4508 - val_acc: 0.7902 Epoch 2/10 20000/20000 [==============================] - 489s 24ms/step - loss: 0.2947 - acc: 0.8866 - val_loss: 0.2914 - val_acc: 0.8816 Epoch 3/10 20000/20000 [==============================] - 482s 24ms/step - loss: 0.2368 - acc: 0.9094 - val_loss: 0.3113 - val_acc: 0.8738 Epoch 4/10 20000/20000 [==============================] - 530s 26ms/step - loss: 0.2033 - acc: 0.9258 - val_loss: 0.3399 - val_acc: 0.8534 Epoch 5/10 20000/20000 [==============================] - 480s 24ms/step - loss: 0.1735 - acc: 0.9384 - val_loss: 0.5543 - val_acc: 0.8110 Epoch 6/10 20000/20000 [==============================] - 465s 23ms/step - loss: 0.1608 - acc: 0.9438 - val_loss: 0.2991 - val_acc: 0.8796 Epoch 7/10 20000/20000 [==============================] - 454s 23ms/step - loss: 0.1406 - acc: 0.9494 - val_loss: 0.3217 - val_acc: 0.8870 Epoch 8/10 20000/20000 [==============================] - 448s 22ms/step - loss: 0.1361 - acc: 0.9531 - val_loss: 0.6040 - val_acc: 0.8540 Epoch 9/10 20000/20000 [==============================] - 449s 22ms/step - loss: 0.1270 - acc: 0.9553 - val_loss: 0.4197 - val_acc: 0.8782 Epoch 10/10 20000/20000 [==============================] - 448s 22ms/step - loss: 0.1165 - acc: 0.9596 - val_loss: 0.3421 - val_acc: 0.8856  ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/lstm/","summary":"理解LSTM层与GRU层  SimpleRNN的问题在于，在时刻t，理论上来说，它应该能够记住许多时间部之前见过的各种信息，但实际上它是不可能学到这种长期依赖的。其原因在于“梯度消失”问题，这一效应类似于在层数较多的非循环网络中观察到的效应，随着层数的增加，网络最终变得无法训练。\n 1. LSTM层 LSTM层是SimpleRNN的一种变体，它增加了一种携带信息跨越多个时间步的方法。假设有一条传送带，其运行方向平行于你所处理的序列。序列中的信息可以在任意位置跳上传送带，然后被传送到更晚的时间步，并在需要时原封不动地跳回来。这实际上就是LSTM的原理：它保存信息以便后面使用，从而防止较早期的信号在处理过程中逐渐消失。\n1.1 Keras 中一个LSTM的例子 # 准备数据 from keras.datasets import imdb from keras.preprocessing import sequence max_features = 10000 maxlen = 500 batch_size = 32 print(\u0026#39;Loading data...\u0026#39;) (input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features) print(len(input_train), \u0026#39;train_sequences\u0026#39;) print(len(input_test), \u0026#39;test sequences\u0026#39;) print(\u0026#39;Pad sequences (samples x time)\u0026#39;) input_train = sequence.pad_sequences(input_train, maxlen=maxlen) input_test = sequence.pad_sequences(input_test, maxlen=maxlen) print(\u0026#39;input_train shape: \u0026#39;, input_train.shape) print(\u0026#39;input_test shape:\u0026#39;, input_test.shape) Loading data... 25000 train_sequences 25000 test sequences Pad sequences (samples x time) input_train shape: (25000, 500) input_test shape: (25000, 500)  # 使用Keras中的LSTM层 from keras.","title":"理解LSTM层与GRU层"},{"content":"理解循环神经网络 1. 简单的循环神经网络 RNN以渐进的方式处理信息，同时保存一个关于所处理内容的内部模型，这个模型是根据过去的信息构建的，并随着新信息的进入而不断更新。\nRNN处理序列的方式是：遍历所有序列元素，并保存一个状态（State），其中包含与已查看内容相关的信息。\nRNN的伪代码：\nstate_t = 0 for input_t in input_sequence: output_t = f(input_t, state_t) state_t = output_t 可以给出具体的函数f,从输入和状态到输出的变换，其参数包括两个矩阵（W和U）和一个偏置向量。它类似于前馈网络中密集连接层所做的变换。\nstate_t = 0 for input_t in input_sequence: output_t = activation(dot(W, input_t) + dot(U, state_t) + b) state_t = output_t # 简单RNN的numpy实现 import numpy as np timesteps = 100 # 输入序列的时间步数 input_features = 32 # 输入特征空间的维度 output_features = 64 # 输出特征空间的维度 inputs = np.random.random((timesteps, input_features)) # 输入数据：随机噪声，仅作为示例 state_t = np.zeros((output_features,)) # 初试状态：全零向量 # 创建随机的权重矩阵 W = np.random.random((output_features, input_features)) U = np.random.random((output_features, output_features)) b = np.random.random((output_features, )) successive_outputs = [] for input_t in inputs: # input_t是形状为（input_features, )的向量 output_t = np.tanh(np.dot(W, input_t) + np.dot(U, state_t) + b) # 由输入和当前状态计算得到当前输出 successive_outputs.append(output_t) # 将这个输出保存到一个列表中 state_t = output_t # 更新网络的状态，用于下一个时间步 # 最终输出是一个形状为（timesteps, output_features）的二维张量 final_output_sequence = np.stack(successive_outputs, axis=0) final_output_sequence array([[0.99999999, 0.99999995, 0.99999999, ..., 0.99999999, 0.9999997 , 0.99999992], [1. , 1. , 1. , ..., 1. , 1. , 1. ], [1. , 1. , 1. , ..., 1. , 1. , 1. ], ..., [1. , 1. , 1. , ..., 1. , 1. , 1. ], [1. , 1. , 1. , ..., 1. , 1. , 1. ], [1. , 1. , 1. , ..., 1. , 1. , 1. ]])  2. Keras 中的循环层 上面numpy的简单实现，对应一个实际的Keras层，即SimpleRNN层。\nfrom keras.layers import SimpleRNN 与Keras中所有的循环层一样，SimpleRNN可以在两种不同的模式下运行：一种是返回每个时间步连续输出的完整序列，即形状为（batch_size, timesteps, output_features）的三维张量；另一种是只返回每个输入系列的最终输出，即形状为(batch_size, output_featrues)的二维张量。这个两种模式由return_sequences这个构造函数参数来控制。\nfrom keras.models import Sequential from keras.layers import Embedding, SimpleRNN model = Sequential() model.add(Embedding(10000, 32)) model.add(SimpleRNN(32)) #` 只返回最后一个时间步的输出 model.summary() Model: \u0026quot;sequential_2\u0026quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_2 (Embedding) (None, None, 32) 320000 _________________________________________________________________ simple_rnn_2 (SimpleRNN) (None, 32) 2080 ================================================================= Total params: 322,080 Trainable params: 322,080 Non-trainable params: 0 _________________________________________________________________  from keras.models import Sequential from keras.layers import Embedding, SimpleRNN model = Sequential() model.add(Embedding(10000, 32)) model.add(SimpleRNN(32, return_sequences=True)) # 返回完整的状态序列 model.summary() Model: \u0026quot;sequential_3\u0026quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_3 (Embedding) (None, None, 32) 320000 _________________________________________________________________ simple_rnn_3 (SimpleRNN) (None, 32) 2080 ================================================================= Total params: 322,080 Trainable params: 322,080 Non-trainable params: 0 _________________________________________________________________  为了提高网络的表示能力，将多个循环层逐个堆叠有时也是很有用的。在这种情况下，你需要让所有中间层都返回完整的输出序列。\nmodel = Sequential() model.add(Embedding(10000, 32)) model.add(SimpleRNN(32, return_sequences=True)) model.add(SimpleRNN(32, return_sequences=True)) model.add(SimpleRNN(32, return_sequences=True)) model.add(SimpleRNN(32)) model.summary() Model: \u0026quot;sequential_4\u0026quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_4 (Embedding) (None, None, 32) 320000 _________________________________________________________________ simple_rnn_4 (SimpleRNN) (None, None, 32) 2080 _________________________________________________________________ simple_rnn_5 (SimpleRNN) (None, None, 32) 2080 _________________________________________________________________ simple_rnn_6 (SimpleRNN) (None, None, 32) 2080 _________________________________________________________________ simple_rnn_7 (SimpleRNN) (None, 32) 2080 ================================================================= Total params: 328,320 Trainable params: 328,320 Non-trainable params: 0 _________________________________________________________________  3. 将RNN应用于IMDB数据集 3.1 准备数据 from keras.datasets import imdb from keras.preprocessing import sequence max_features = 10000 maxlen = 500 batch_size = 32 print(\u0026#39;Loading data...\u0026#39;) (input_train, y_train), (input_test, y_test) = imdb.load_data(num_words=max_features) print(len(input_train), \u0026#39;train_sequences\u0026#39;) print(len(input_test), \u0026#39;test sequences\u0026#39;) print(\u0026#39;Pad sequences (samples x time)\u0026#39;) input_train = sequence.pad_sequences(input_train, maxlen=maxlen) input_test = sequence.pad_sequences(input_test, maxlen=maxlen) print(\u0026#39;input_train shape: \u0026#39;, input_train.shape) print(\u0026#39;input_test shape:\u0026#39;, input_test.shape) Loading data... 25000 train_sequences 25000 test sequences Pad sequences (samples x time) input_train shape: (25000, 500) input_test shape: (25000, 500)  # 用Embedding层和SimpleRNN层来训练模型 from keras.layers import Dense model = Sequential() model.add(Embedding(max_features, 32)) model.add(SimpleRNN(32)) model.add(Dense(1, activation=\u0026#39;sigmoid\u0026#39;)) model.compile(optimizer=\u0026#39;rmsprop\u0026#39;, loss=\u0026#39;binary_crossentropy\u0026#39;, metrics=[\u0026#39;acc\u0026#39;]) history = model.fit(input_train, y_train, epochs=10, batch_size=10, validation_split=0.2) /usr/lib/python3.7/site-packages/tensorflow/python/ops/gradients_util.py:93: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory. \u0026quot;Converting sparse IndexedSlices to a dense Tensor of unknown shape. \u0026quot; Train on 20000 samples, validate on 5000 samples Epoch 1/10 20000/20000 [==============================] - 4783s 239ms/step - loss: 0.5510 - acc: 0.7012 - val_loss: 0.4217 - val_acc: 0.8162 Epoch 2/10 1080/20000 [\u0026gt;.............................] - ETA: 1:14:34 - loss: 0.3898 - acc: 0.8250 --------------------------------------------------------------------------- KeyboardInterrupt Traceback (most recent call last) \u0026lt;ipython-input-10-a41d37bef560\u0026gt; in \u0026lt;module\u0026gt; 8 9 model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) ---\u0026gt; 10 history = model.fit(input_train, y_train, epochs=10, batch_size=10, validation_split=0.2) /usr/lib/python3.7/site-packages/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs) 1237 steps_per_epoch=steps_per_epoch, 1238 validation_steps=validation_steps, -\u0026gt; 1239 validation_freq=validation_freq) 1240 1241 def evaluate(self, /usr/lib/python3.7/site-packages/keras/engine/training_arrays.py in fit_loop(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq) 194 ins_batch[i] = ins_batch[i].toarray() 195 --\u0026gt; 196 outs = fit_function(ins_batch) 197 outs = to_list(outs) 198 for l, o in zip(out_labels, outs): /usr/lib/python3.7/site-packages/tensorflow/python/keras/backend.py in __call__(self, inputs) 3215 value = math_ops.cast(value, tensor.dtype) 3216 converted_inputs.append(value) -\u0026gt; 3217 outputs = self._graph_fn(*converted_inputs) 3218 return nest.pack_sequence_as(self._outputs_structure, 3219 [x.numpy() for x in outputs]) /usr/lib/python3.7/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs) 556 raise TypeError(\u0026quot;Keyword arguments {} unknown. Expected {}.\u0026quot;.format( 557 list(kwargs.keys()), list(self._arg_keywords))) --\u0026gt; 558 return self._call_flat(args) 559 560 def _filtered_call(self, args, kwargs): /usr/lib/python3.7/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args) 625 # Only need to override the gradient in graph mode and when we have outputs. 626 if context.executing_eagerly() or not self.outputs: --\u0026gt; 627 outputs = self._inference_function.call(ctx, args) 628 else: 629 self._register_gradient() /usr/lib/python3.7/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args) 413 attrs=(\u0026quot;executor_type\u0026quot;, executor_type, 414 \u0026quot;config_proto\u0026quot;, config), --\u0026gt; 415 ctx=ctx) 416 # Replace empty list with None 417 outputs = outputs or None /usr/lib/python3.7/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name) 58 tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name, 59 op_name, inputs, attrs, ---\u0026gt; 60 num_outputs) 61 except core._NotOkStatusException as e: 62 if name is not None: KeyboardInterrupt:  import matplotlib.pyplot as plt acc = history.history[\u0026#39;acc\u0026#39;] val_acc = history.history[\u0026#39;val_acc\u0026#39;] loss = history.history[\u0026#39;loss\u0026#39;] val_loss = history.history[\u0026#39;val_loss\u0026#39;] epochs = range(1, len(acc)+1) plt.plot(epochs, acc, \u0026#39;bo\u0026#39;, label=\u0026#39;Training acc\u0026#39;) plt.plot(epochs, val, \u0026#39;b\u0026#39;, label=\u0026#39;Validation acc\u0026#39;) plt.title(\u0026#34;Trainging and validation accuracy\u0026#34;) plt.legend() plt.figure() plt.plot(epochs, loss, \u0026#39;bo\u0026#39;, label=\u0026#39;Training loss\u0026#39;) plt.plot(epochs, val_loss, \u0026#39;b\u0026#39;, label=\u0026#39;Validation loss\u0026#39;) plt.title(\u0026#39;Training and validation loss\u0026#39;) plt.legend() plt.show() ","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/%E7%90%86%E8%A7%A3rnn/","summary":"理解循环神经网络 1. 简单的循环神经网络 RNN以渐进的方式处理信息，同时保存一个关于所处理内容的内部模型，这个模型是根据过去的信息构建的，并随着新信息的进入而不断更新。\nRNN处理序列的方式是：遍历所有序列元素，并保存一个状态（State），其中包含与已查看内容相关的信息。\nRNN的伪代码：\nstate_t = 0 for input_t in input_sequence: output_t = f(input_t, state_t) state_t = output_t 可以给出具体的函数f,从输入和状态到输出的变换，其参数包括两个矩阵（W和U）和一个偏置向量。它类似于前馈网络中密集连接层所做的变换。\nstate_t = 0 for input_t in input_sequence: output_t = activation(dot(W, input_t) + dot(U, state_t) + b) state_t = output_t # 简单RNN的numpy实现 import numpy as np timesteps = 100 # 输入序列的时间步数 input_features = 32 # 输入特征空间的维度 output_features = 64 # 输出特征空间的维度 inputs = np.random.random((timesteps, input_features)) # 输入数据：随机噪声，仅作为示例 state_t = np.zeros((output_features,)) # 初试状态：全零向量 # 创建随机的权重矩阵 W = np.","title":"理解循环神经网络"},{"content":"类型断言 类型断言是一个使用在接口上的操作，语法上看起来像是x.(T)，因此被称为断言类型，这里x是接口，T是类型。一个类型断言检查它操作对象的动态类型是否和断言的类型匹配。\n这里有两种可能：\n 如果断言的类型T是一个具体类型\n类型断言检查x的动态类型是否和T相同。如果检查成功了，类型断言的结果是x的动态值，即T。换句话说，具体类型的类型断言从它的操作对象中获得具体的值。如果检查失败，接下来这个操作会panic。  import ( \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; ) var w io.Writer w = os.Stdout f := w.(*os.File) // 类型检查成功了，所以f的值为os.Stdout f == os.Stdout // true fmt.Printf(\u0026#34;%p\u0026#34;, f)  输出\n 0xc0004560c0\n c := w.(*bytes.Buffer) // 类型检查失败  输出\n interface conversion: \u0026lt;io.Writer\u0026gt; is \u0026lt;*os.File\u0026gt;, not \u0026lt;*bytes.Buffer\u0026gt; 断言的类型T是一个接口类型  t, ok := i.(T) 如果i是类型T（实现了T接口），即检查成功了，那么t将是i的原值，ok为true；如果检查失败了，t将为T类型的零值，ok为false，并且不引发panic。\n对一个接口类型的类型断言改变了类型的表述方式，改变了可以获取的方法集合（通常更大）， 但是它保护了接口值内部的动态类型和值的部分。\nvar w io Wirter w = os.Stdout rw := w.(io.ReadWriter) w = new(ByterCounter) rw = w.(io.ReadWriter)  输出\n repl.go:1:10: expected \u0026lsquo;;\u0026rsquo;, found \u0026lsquo;IDENT\u0026rsquo; Wirter如果断言操作的对象是一个nil接口值，那么不论被断言的是什么类型，断言都会失败。\n对一个更少限制性的接口类型（更少的方法集合）做断言，因为它表现的就像赋值操作一样，除了对于nil接口值的情况。\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/go%E4%B8%AD%E7%9A%84%E7%B1%BB%E5%9E%8B%E6%96%AD%E8%A8%80-unc/","summary":"类型断言 类型断言是一个使用在接口上的操作，语法上看起来像是x.(T)，因此被称为断言类型，这里x是接口，T是类型。一个类型断言检查它操作对象的动态类型是否和断言的类型匹配。\n这里有两种可能：\n 如果断言的类型T是一个具体类型\n类型断言检查x的动态类型是否和T相同。如果检查成功了，类型断言的结果是x的动态值，即T。换句话说，具体类型的类型断言从它的操作对象中获得具体的值。如果检查失败，接下来这个操作会panic。  import ( \u0026#34;io\u0026#34; \u0026#34;os\u0026#34; \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; ) var w io.Writer w = os.Stdout f := w.(*os.File) // 类型检查成功了，所以f的值为os.Stdout f == os.Stdout // true fmt.Printf(\u0026#34;%p\u0026#34;, f)  输出\n 0xc0004560c0\n c := w.(*bytes.Buffer) // 类型检查失败  输出\n interface conversion: \u0026lt;io.Writer\u0026gt; is \u0026lt;*os.File\u0026gt;, not \u0026lt;*bytes.Buffer\u0026gt; 断言的类型T是一个接口类型  t, ok := i.(T) 如果i是类型T（实现了T接口），即检查成功了，那么t将是i的原值，ok为true；如果检查失败了，t将为T类型的零值，ok为false，并且不引发panic。\n对一个接口类型的类型断言改变了类型的表述方式，改变了可以获取的方法集合（通常更大）， 但是它保护了接口值内部的动态类型和值的部分。\nvar w io Wirter w = os.Stdout rw := w.","title":"类型断言"},{"content":"网页静态文件找不到 在19-2-18的开始，突然发现网页的静态文件找不到了 在将static目录移动到app目录内之后，发现网页可以正常显示。\n 原来static目录是和app目录一个层级\n 针对此问题的思考 STATIC_URL = \u0026lsquo;/static/\u0026rsquo; 注意此处是url，即对于静态文件的定位，这是必要的前提配置 STATIC_URL的定义制定了静态资源的url，具体指各个app下的static目录  STATIC_ROOT = os.path.join(BASE_DIR, \u0026ldquo;static\u0026rdquo;) STATIC_ROOT是总的static目录，主要用于在运行 collectstatic命令时存储所有的静态文件  STATICFILES_DIRS = [os.path.join(BASE_DIR, \u0026ldquo;static\u0026rdquo;), \u0026lsquo;mysite/static\u0026rsquo;,]  STATICFILES_DIRS是一个列表，存放各个app的static目录及公共的static目录  ​\n官网配置   确保django.contrib.staticfiles包含在您的 INSTALLED_APPS。\n  在您的设置文件中，定义STATIC_URL，例如：\n  STATIC_URL = \u0026#39;/static/\u0026#39; 在模板中，使用static模板标记使用已配置的相对路径构建URL STATICFILES_STORAGE。  {% load static %} \u0026lt;img src=\u0026#34;{% static \u0026#34;my_app/example.jpg\u0026#34; %}\u0026#34; alt=\u0026#34;My image\u0026#34;/\u0026gt; 将静态文件存储static在应用程序中调用的文件夹中。例如my_app/static/my_app/example.jpg。  对于模板中的{% load static%} 当在模板中使用过load static之后，再次使用static时，将会使用STATICFILES_FINDERS寻找静态文件，其默认值为：\n[ \u0026#39;django.contrib.staticfiles.finders.FileSystemFinder\u0026#39;, \u0026#39;django.contrib.staticfiles.finders.AppDirectoriesFinder\u0026#39;, ] 对此的解释是，将会从STATICFILES_DIRS的目录中以及每个app下的static目录中寻找静态文件。\n在url后加入+ static(settings.MEDIA_URL, document_root=settings.MEDIA_ROOT)\n（要在setting定义 MEDIA_URL MEDIA_ROOT）\n","permalink":"http://yangchnet.github.io/Dessert/posts/django/%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E6%89%BE%E4%B8%8D%E5%88%B0/","summary":"网页静态文件找不到 在19-2-18的开始，突然发现网页的静态文件找不到了 在将static目录移动到app目录内之后，发现网页可以正常显示。\n 原来static目录是和app目录一个层级\n 针对此问题的思考 STATIC_URL = \u0026lsquo;/static/\u0026rsquo; 注意此处是url，即对于静态文件的定位，这是必要的前提配置 STATIC_URL的定义制定了静态资源的url，具体指各个app下的static目录  STATIC_ROOT = os.path.join(BASE_DIR, \u0026ldquo;static\u0026rdquo;) STATIC_ROOT是总的static目录，主要用于在运行 collectstatic命令时存储所有的静态文件  STATICFILES_DIRS = [os.path.join(BASE_DIR, \u0026ldquo;static\u0026rdquo;), \u0026lsquo;mysite/static\u0026rsquo;,]  STATICFILES_DIRS是一个列表，存放各个app的static目录及公共的static目录  ​\n官网配置   确保django.contrib.staticfiles包含在您的 INSTALLED_APPS。\n  在您的设置文件中，定义STATIC_URL，例如：\n  STATIC_URL = \u0026#39;/static/\u0026#39; 在模板中，使用static模板标记使用已配置的相对路径构建URL STATICFILES_STORAGE。  {% load static %} \u0026lt;img src=\u0026#34;{% static \u0026#34;my_app/example.jpg\u0026#34; %}\u0026#34; alt=\u0026#34;My image\u0026#34;/\u0026gt; 将静态文件存储static在应用程序中调用的文件夹中。例如my_app/static/my_app/example.jpg。  对于模板中的{% load static%} 当在模板中使用过load static之后，再次使用static时，将会使用STATICFILES_FINDERS寻找静态文件，其默认值为：\n[ \u0026#39;django.contrib.staticfiles.finders.FileSystemFinder\u0026#39;, \u0026#39;django.contrib.staticfiles.finders.AppDirectoriesFinder\u0026#39;, ] 对此的解释是，将会从STATICFILES_DIRS的目录中以及每个app下的static目录中寻找静态文件。\n在url后加入+ static(settings.MEDIA_URL, document_root=settings.","title":"网页静态文件找不到"},{"content":"解决github每次push都要输入密码 进入你的本地仓库目录 输入：\ngit config --global credential.helper store 然后再运行一遍git pull或git push就可以了\n","permalink":"http://yangchnet.github.io/Dessert/posts/git/git%E6%AF%8F%E6%AC%A1%E9%83%BD%E8%A6%81%E8%BE%93%E5%85%A5%E5%AF%86%E7%A0%81/","summary":"解决github每次push都要输入密码 进入你的本地仓库目录 输入：\ngit config --global credential.helper store 然后再运行一遍git pull或git push就可以了","title":"解决github每次push都要输入密码"},{"content":"鸭子类型 1. 什么是鸭子类型 只要走起路来像鸭子，叫起来像鸭子，就可以认为是鸭子。这就是鸭子类型\n2. 鸭子类型有什么作用？ 对应于golang中的接口的概念，一个接口定义了一组操作，这组操作可以看做是鸭子的走路，叫。也就是说，只要任何类型满足了这组方法，那么就可以看做是鸭子\u0026ndash;即满足了这个接口，可以看做是这个接口类型。\n","permalink":"http://yangchnet.github.io/Dessert/posts/golang/%E9%B8%AD%E5%AD%90%E7%B1%BB%E5%9E%8B/","summary":"鸭子类型 1. 什么是鸭子类型 只要走起路来像鸭子，叫起来像鸭子，就可以认为是鸭子。这就是鸭子类型\n2. 鸭子类型有什么作用？ 对应于golang中的接口的概念，一个接口定义了一组操作，这组操作可以看做是鸭子的走路，叫。也就是说，只要任何类型满足了这组方法，那么就可以看做是鸭子\u0026ndash;即满足了这个接口，可以看做是这个接口类型。","title":"鸭子类型"},{"content":"","permalink":"http://yangchnet.github.io/Dessert/posts/dlml/%E6%9C%AA%E5%91%BD%E5%90%8D/","summary":"","title":""},{"content":"","permalink":"http://yangchnet.github.io/Dessert/posts/golang/prometheus%E7%9A%84%E4%BD%BF%E7%94%A8/","summary":"","title":""},{"content":"Tem 这里存储我个人网站的markdown文件，并通过hugo生成静态文件，我的个人网站在这里，欢迎访问😊😘。\n","permalink":"http://yangchnet.github.io/Dessert/posts/readme/","summary":"Tem 这里存储我个人网站的markdown文件，并通过hugo生成静态文件，我的个人网站在这里，欢迎访问😊😘。","title":""},{"content":"","permalink":"http://yangchnet.github.io/Dessert/posts/%E5%89%8D%E7%AB%AF/test/","summary":"","title":""},{"content":"","permalink":"http://yangchnet.github.io/Dessert/posts/%E6%95%B0%E6%8D%AE%E5%BA%93/prisma/","summary":"","title":""}]